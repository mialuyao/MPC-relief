{
    "sourceFile": "draft.py",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 309,
            "patches": [
                {
                    "date": 1718610785581,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                },
                {
                    "date": 1718610820737,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -44,5 +44,6 @@\n     return feature, int_labels\n \n \n data_train = DataSet.sonar\n-feature,label = load_dataset(data_train.dataset_name)\n\\ No newline at end of file\n+feature,label = load_dataset(data_train.dataset_name)\n+print(feature)\n\\ No newline at end of file\n"
                },
                {
                    "date": 1718610825956,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -45,5 +45,5 @@\n \n \n data_train = DataSet.sonar\n feature,label = load_dataset(data_train.dataset_name)\n-print(feature)\n\\ No newline at end of file\n+print(feature)\n"
                },
                {
                    "date": 1718610832543,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -46,4 +46,5 @@\n \n data_train = DataSet.sonar\n feature,label = load_dataset(data_train.dataset_name)\n print(feature)\n+print(label)\n"
                },
                {
                    "date": 1718613650159,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -47,4 +47,118 @@\n data_train = DataSet.sonar\n feature,label = load_dataset(data_train.dataset_name)\n print(feature)\n print(label)\n+\n+\n+\n+#!/usr/bin/env python3\n+\n+# Copyright (c) Facebook, Inc. and its affiliates.\n+#\n+# This source code is licensed under the MIT license found in the\n+# LICENSE file in the root directory of this source tree.\n+\n+import logging\n+import time\n+\n+import crypten\n+import torch\n+from examples.meters import AverageMeter\n+\n+\n+def train_linear_svm(features, labels, epochs=50, lr=0.5, print_time=False):\n+    # Initialize random weights\n+    w = features.new(torch.randn(1, features.size(0)))\n+    b = features.new(torch.randn(1))\n+\n+    if print_time:\n+        pt_time = AverageMeter()\n+        end = time.time()\n+\n+    for epoch in range(epochs):\n+        # Forward\n+        label_predictions = w.matmul(features).add(b).sign()\n+\n+        # Compute accuracy\n+        correct = label_predictions.mul(labels)\n+        accuracy = correct.add(1).div(2).mean()\n+        if crypten.is_encrypted_tensor(accuracy):\n+            accuracy = accuracy.get_plain_text()\n+\n+        # Print Accuracy once\n+        if crypten.communicator.get().get_rank() == 0:\n+            print(\n+                f\"Epoch {epoch} --- Training Accuracy %.2f%%\" % (accuracy.item() * 100)\n+            )\n+\n+        # Backward\n+        loss_grad = -labels * (1 - correct) * 0.5  # Hinge loss\n+        b_grad = loss_grad.mean()\n+        w_grad = loss_grad.matmul(features.t()).div(loss_grad.size(1))\n+\n+        # Update\n+        w -= w_grad * lr\n+        b -= b_grad * lr\n+\n+        if print_time:\n+            iter_time = time.time() - end\n+            pt_time.add(iter_time)\n+            logging.info(\"    Time %.6f (%.6f)\" % (iter_time, pt_time.value()))\n+            end = time.time()\n+\n+    return w, b\n+\n+\n+def evaluate_linear_svm(features, labels, w, b):\n+    \"\"\"Compute accuracy on a test set\"\"\"\n+    predictions = w.matmul(features).add(b).sign()\n+    correct = predictions.mul(labels)\n+    accuracy = correct.add(1).div(2).mean().get_plain_text()\n+    if crypten.communicator.get().get_rank() == 0:\n+        print(\"Test accuracy %.2f%%\" % (accuracy.item() * 100))\n+\n+\n+def run_mpc_linear_svm(\n+    epochs=50, examples=50, features=100, lr=0.5, skip_plaintext=True\n+):\n+    crypten.init()\n+\n+    # Set random seed for reproducibility\n+    torch.manual_seed(1)\n+\n+    # Initialize x, y, w, b\n+    x = torch.randn(features, examples)\n+    w_true = torch.randn(1, features)\n+    b_true = torch.randn(1)\n+    y = w_true.matmul(x) + b_true\n+    y = y.sign()\n+\n+    # if not skip_plaintext:\n+    #     logging.info(\"==================\")\n+    #     logging.info(\"PyTorch Training\")\n+    #     logging.info(\"==================\")\n+    #     w_torch, b_torch = train_linear_svm(x, y, lr=lr, print_time=True)\n+\n+# NOTE：crypten.cryptensor \n+    # Encrypt features / labels\n+    x = crypten.cryptensor(x)\n+    y = crypten.cryptensor(y)\n+\n+    logging.info(\"==================\")\n+    logging.info(\"CrypTen Training\")\n+    logging.info(\"==================\")\n+# NOTE：训练无差异\n+    w, b = train_linear_svm(x, y, lr=lr, print_time=True)\n+\n+    # if not skip_plaintext:\n+    #     logging.info(\"PyTorch Weights  :\")\n+    #     logging.info(w_torch)\n+    logging.info(\"CrypTen Weights:\")\n+# NOTE：get_plain_text()\n+    logging.info(w.get_plain_text())\n+\n+    # if not skip_plaintext:\n+    #     logging.info(\"PyTorch Bias  :\")\n+    #     logging.info(b_torch)\n+    logging.info(\"CrypTen Bias:\")\n+    logging.info(b.get_plain_text())\n"
                },
                {
                    "date": 1718613657993,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -49,24 +49,8 @@\n print(feature)\n print(label)\n \n \n-\n-#!/usr/bin/env python3\n-\n-# Copyright (c) Facebook, Inc. and its affiliates.\n-#\n-# This source code is licensed under the MIT license found in the\n-# LICENSE file in the root directory of this source tree.\n-\n-import logging\n-import time\n-\n-import crypten\n-import torch\n-from examples.meters import AverageMeter\n-\n-\n def train_linear_svm(features, labels, epochs=50, lr=0.5, print_time=False):\n     # Initialize random weights\n     w = features.new(torch.randn(1, features.size(0)))\n     b = features.new(torch.randn(1))\n"
                },
                {
                    "date": 1718613666826,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -49,8 +49,10 @@\n print(feature)\n print(label)\n \n \n+\n+\n def train_linear_svm(features, labels, epochs=50, lr=0.5, print_time=False):\n     # Initialize random weights\n     w = features.new(torch.randn(1, features.size(0)))\n     b = features.new(torch.randn(1))\n"
                },
                {
                    "date": 1718613680932,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,8 +1,15 @@\n import os\n import csv\n import numpy as np\n \n+import logging\n+import time\n+\n+import crypten\n+import torch\n+from examples.meters import AverageMeter\n+\n DATASET_DIR = os.path.join(os.path.dirname(__file__), 'dataset')\n \n class DataSetParam:\n     def __init__(self, dataset_name):\n@@ -43,16 +50,9 @@\n \n     return feature, int_labels\n \n \n-data_train = DataSet.sonar\n-feature,label = load_dataset(data_train.dataset_name)\n-print(feature)\n-print(label)\n \n-\n-\n-\n def train_linear_svm(features, labels, epochs=50, lr=0.5, print_time=False):\n     # Initialize random weights\n     w = features.new(torch.randn(1, features.size(0)))\n     b = features.new(torch.randn(1))\n"
                },
                {
                    "date": 1718613688957,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,150 +0,0 @@\n-import os\n-import csv\n-import numpy as np\n-\n-import logging\n-import time\n-\n-import crypten\n-import torch\n-from examples.meters import AverageMeter\n-\n-DATASET_DIR = os.path.join(os.path.dirname(__file__), 'dataset')\n-\n-class DataSetParam:\n-    def __init__(self, dataset_name):\n-        self.dataset_name = dataset_name\n-\n-\n-class DataSet:\n-    sonar = DataSetParam('sonar.csv')\n-\n-\n-def load_dataset(dataset):\n-    dataset_path = os.path.join(DATASET_DIR, dataset)\n-\n-    # 尝试打开并读取CSV文件\n-    try:\n-        with open(dataset_path, 'r', encoding='utf-8') as csvfile:\n-            spamreader = csv.reader(csvfile)\n-            data = np.array(list(spamreader))\n-    except FileNotFoundError:\n-        print(f\"Error: The file {dataset_path} was not found.\")\n-        return None, None\n-    except Exception as e:\n-        print(f\"Error: An error occurred while reading the file: {e}\")\n-        return None, None\n-\n-    # 检查数据是否为空\n-    if data.size == 0:\n-        print(\"Error: The dataset is empty.\")\n-        return None, None\n-\n-    feature = data[:, :-1].astype(np.float64)\n-    labels = data[:, -1]\n-\n-    # 创建标签映射\n-    unique_labels = np.unique(labels)\n-    label_to_int = {label: idx for idx, label in enumerate(unique_labels)}\n-    int_labels = np.array([label_to_int[label] for label in labels], dtype=np.uint8)\n-\n-    return feature, int_labels\n-\n-\n-\n-def train_linear_svm(features, labels, epochs=50, lr=0.5, print_time=False):\n-    # Initialize random weights\n-    w = features.new(torch.randn(1, features.size(0)))\n-    b = features.new(torch.randn(1))\n-\n-    if print_time:\n-        pt_time = AverageMeter()\n-        end = time.time()\n-\n-    for epoch in range(epochs):\n-        # Forward\n-        label_predictions = w.matmul(features).add(b).sign()\n-\n-        # Compute accuracy\n-        correct = label_predictions.mul(labels)\n-        accuracy = correct.add(1).div(2).mean()\n-        if crypten.is_encrypted_tensor(accuracy):\n-            accuracy = accuracy.get_plain_text()\n-\n-        # Print Accuracy once\n-        if crypten.communicator.get().get_rank() == 0:\n-            print(\n-                f\"Epoch {epoch} --- Training Accuracy %.2f%%\" % (accuracy.item() * 100)\n-            )\n-\n-        # Backward\n-        loss_grad = -labels * (1 - correct) * 0.5  # Hinge loss\n-        b_grad = loss_grad.mean()\n-        w_grad = loss_grad.matmul(features.t()).div(loss_grad.size(1))\n-\n-        # Update\n-        w -= w_grad * lr\n-        b -= b_grad * lr\n-\n-        if print_time:\n-            iter_time = time.time() - end\n-            pt_time.add(iter_time)\n-            logging.info(\"    Time %.6f (%.6f)\" % (iter_time, pt_time.value()))\n-            end = time.time()\n-\n-    return w, b\n-\n-\n-def evaluate_linear_svm(features, labels, w, b):\n-    \"\"\"Compute accuracy on a test set\"\"\"\n-    predictions = w.matmul(features).add(b).sign()\n-    correct = predictions.mul(labels)\n-    accuracy = correct.add(1).div(2).mean().get_plain_text()\n-    if crypten.communicator.get().get_rank() == 0:\n-        print(\"Test accuracy %.2f%%\" % (accuracy.item() * 100))\n-\n-\n-def run_mpc_linear_svm(\n-    epochs=50, examples=50, features=100, lr=0.5, skip_plaintext=True\n-):\n-    crypten.init()\n-\n-    # Set random seed for reproducibility\n-    torch.manual_seed(1)\n-\n-    # Initialize x, y, w, b\n-    x = torch.randn(features, examples)\n-    w_true = torch.randn(1, features)\n-    b_true = torch.randn(1)\n-    y = w_true.matmul(x) + b_true\n-    y = y.sign()\n-\n-    # if not skip_plaintext:\n-    #     logging.info(\"==================\")\n-    #     logging.info(\"PyTorch Training\")\n-    #     logging.info(\"==================\")\n-    #     w_torch, b_torch = train_linear_svm(x, y, lr=lr, print_time=True)\n-\n-# NOTE：crypten.cryptensor \n-    # Encrypt features / labels\n-    x = crypten.cryptensor(x)\n-    y = crypten.cryptensor(y)\n-\n-    logging.info(\"==================\")\n-    logging.info(\"CrypTen Training\")\n-    logging.info(\"==================\")\n-# NOTE：训练无差异\n-    w, b = train_linear_svm(x, y, lr=lr, print_time=True)\n-\n-    # if not skip_plaintext:\n-    #     logging.info(\"PyTorch Weights  :\")\n-    #     logging.info(w_torch)\n-    logging.info(\"CrypTen Weights:\")\n-# NOTE：get_plain_text()\n-    logging.info(w.get_plain_text())\n-\n-    # if not skip_plaintext:\n-    #     logging.info(\"PyTorch Bias  :\")\n-    #     logging.info(b_torch)\n-    logging.info(\"CrypTen Bias:\")\n-    logging.info(b.get_plain_text())\n\\ No newline at end of file\n"
                },
                {
                    "date": 1718613700838,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,1 +1,111 @@\n+#!/usr/bin/env python3\n \n+# Copyright (c) Facebook, Inc. and its affiliates.\n+#\n+# This source code is licensed under the MIT license found in the\n+# LICENSE file in the root directory of this source tree.\n+\n+import logging\n+import time\n+\n+import crypten\n+import torch\n+from examples.meters import AverageMeter\n+\n+\n+def train_linear_svm(features, labels, epochs=50, lr=0.5, print_time=False):\n+    # Initialize random weights\n+    w = features.new(torch.randn(1, features.size(0)))\n+    b = features.new(torch.randn(1))\n+\n+    if print_time:\n+        pt_time = AverageMeter()\n+        end = time.time()\n+\n+    for epoch in range(epochs):\n+        # Forward\n+        label_predictions = w.matmul(features).add(b).sign()\n+\n+        # Compute accuracy\n+        correct = label_predictions.mul(labels)\n+        accuracy = correct.add(1).div(2).mean()\n+        if crypten.is_encrypted_tensor(accuracy):\n+            accuracy = accuracy.get_plain_text()\n+\n+        # Print Accuracy once\n+        if crypten.communicator.get().get_rank() == 0:\n+            print(\n+                f\"Epoch {epoch} --- Training Accuracy %.2f%%\" % (accuracy.item() * 100)\n+            )\n+\n+        # Backward\n+        loss_grad = -labels * (1 - correct) * 0.5  # Hinge loss\n+        b_grad = loss_grad.mean()\n+        w_grad = loss_grad.matmul(features.t()).div(loss_grad.size(1))\n+\n+        # Update\n+        w -= w_grad * lr\n+        b -= b_grad * lr\n+\n+        if print_time:\n+            iter_time = time.time() - end\n+            pt_time.add(iter_time)\n+            logging.info(\"    Time %.6f (%.6f)\" % (iter_time, pt_time.value()))\n+            end = time.time()\n+\n+    return w, b\n+\n+\n+def evaluate_linear_svm(features, labels, w, b):\n+    \"\"\"Compute accuracy on a test set\"\"\"\n+    predictions = w.matmul(features).add(b).sign()\n+    correct = predictions.mul(labels)\n+    accuracy = correct.add(1).div(2).mean().get_plain_text()\n+    if crypten.communicator.get().get_rank() == 0:\n+        print(\"Test accuracy %.2f%%\" % (accuracy.item() * 100))\n+\n+\n+def run_mpc_linear_svm(\n+    epochs=50, examples=50, features=100, lr=0.5, skip_plaintext=True\n+):\n+    crypten.init()\n+\n+    # Set random seed for reproducibility\n+    torch.manual_seed(1)\n+\n+    # Initialize x, y, w, b\n+    x = torch.randn(features, examples)\n+    w_true = torch.randn(1, features)\n+    b_true = torch.randn(1)\n+    y = w_true.matmul(x) + b_true\n+    y = y.sign()\n+\n+    # if not skip_plaintext:\n+    #     logging.info(\"==================\")\n+    #     logging.info(\"PyTorch Training\")\n+    #     logging.info(\"==================\")\n+    #     w_torch, b_torch = train_linear_svm(x, y, lr=lr, print_time=True)\n+\n+# NOTE：crypten.cryptensor \n+    # Encrypt features / labels\n+    x = crypten.cryptensor(x)\n+    y = crypten.cryptensor(y)\n+\n+    logging.info(\"==================\")\n+    logging.info(\"CrypTen Training\")\n+    logging.info(\"==================\")\n+# NOTE：训练无差异\n+    w, b = train_linear_svm(x, y, lr=lr, print_time=True)\n+\n+    # if not skip_plaintext:\n+    #     logging.info(\"PyTorch Weights  :\")\n+    #     logging.info(w_torch)\n+    logging.info(\"CrypTen Weights:\")\n+# NOTE：get_plain_text()\n+    logging.info(w.get_plain_text())\n+\n+    # if not skip_plaintext:\n+    #     logging.info(\"PyTorch Bias  :\")\n+    #     logging.info(b_torch)\n+    logging.info(\"CrypTen Bias:\")\n+    logging.info(b.get_plain_text())\n"
                },
                {
                    "date": 1718613739147,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,11 +1,5 @@\n-#!/usr/bin/env python3\n \n-# Copyright (c) Facebook, Inc. and its affiliates.\n-#\n-# This source code is licensed under the MIT license found in the\n-# LICENSE file in the root directory of this source tree.\n-\n import logging\n import time\n \n import crypten\n@@ -64,8 +58,23 @@\n     if crypten.communicator.get().get_rank() == 0:\n         print(\"Test accuracy %.2f%%\" % (accuracy.item() * 100))\n \n \n+DATASET_DIR = os.path.join(os.path.dirname(__file__), '../dataset')\n+\n+class DataSetParam:\n+    def __init__(self, dataset_name):\n+        self.dataset_name = dataset_name\n+\n+\n+class DataSet:\n+    sonar = DataSetParam('sonar.csv')\n+\n+\n+\n+\n+\n+\n def run_mpc_linear_svm(\n     epochs=50, examples=50, features=100, lr=0.5, skip_plaintext=True\n ):\n     crypten.init()\n"
                },
                {
                    "date": 1718613752924,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,13 +1,27 @@\n \n import logging\n import time\n-\n+import csv\n+import os\n import crypten\n import torch\n from examples.meters import AverageMeter\n \n \n+DATASET_DIR = os.path.join(os.path.dirname(__file__), '../dataset')\n+\n+class DataSetParam:\n+    def __init__(self, dataset_name):\n+        self.dataset_name = dataset_name\n+\n+\n+class DataSet:\n+    sonar = DataSetParam('sonar.csv')\n+\n+\n+\n+\n def train_linear_svm(features, labels, epochs=50, lr=0.5, print_time=False):\n     # Initialize random weights\n     w = features.new(torch.randn(1, features.size(0)))\n     b = features.new(torch.randn(1))\n@@ -58,23 +72,13 @@\n     if crypten.communicator.get().get_rank() == 0:\n         print(\"Test accuracy %.2f%%\" % (accuracy.item() * 100))\n \n \n-DATASET_DIR = os.path.join(os.path.dirname(__file__), '../dataset')\n \n-class DataSetParam:\n-    def __init__(self, dataset_name):\n-        self.dataset_name = dataset_name\n \n \n-class DataSet:\n-    sonar = DataSetParam('sonar.csv')\n \n \n-\n-\n-\n-\n def run_mpc_linear_svm(\n     epochs=50, examples=50, features=100, lr=0.5, skip_plaintext=True\n ):\n     crypten.init()\n"
                },
                {
                    "date": 1718613776960,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -85,8 +85,11 @@\n \n     # Set random seed for reproducibility\n     torch.manual_seed(1)\n \n+\n+\n+        \n     # Initialize x, y, w, b\n     x = torch.randn(features, examples)\n     w_true = torch.randn(1, features)\n     b_true = torch.randn(1)\n"
                },
                {
                    "date": 1718613798491,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -72,24 +72,54 @@\n     if crypten.communicator.get().get_rank() == 0:\n         print(\"Test accuracy %.2f%%\" % (accuracy.item() * 100))\n \n \n+def load_dataset(dataset):\n+    dataset_path = os.path.join(DATASET_DIR, dataset)\n \n+    # 尝试打开并读取CSV文件\n+    try:\n+        with open(dataset_path, 'r', encoding='utf-8') as csvfile:\n+            spamreader = csv.reader(csvfile)\n+            data = np.array(list(spamreader))\n+    except FileNotFoundError:\n+        print(f\"Error: The file {dataset_path} was not found.\")\n+        return None, None\n+    except Exception as e:\n+        print(f\"Error: An error occurred while reading the file: {e}\")\n+        return None, None\n \n+    # 检查数据是否为空\n+    if data.size == 0:\n+        print(\"Error: The dataset is empty.\")\n+        return None, None\n \n+    feature = data[:, :-1].astype(np.float64)\n+    labels = data[:, -1]\n \n+    # 创建标签映射\n+    unique_labels = np.unique(labels)\n+    label_to_int = {label: idx for idx, label in enumerate(unique_labels)}\n+    int_labels = np.array([label_to_int[label] for label in labels], dtype=np.uint8)\n \n+    return feature, int_labels\n+\n+\n+\n+\n def run_mpc_linear_svm(\n     epochs=50, examples=50, features=100, lr=0.5, skip_plaintext=True\n ):\n     crypten.init()\n \n     # Set random seed for reproducibility\n     torch.manual_seed(1)\n \n+    data_train = DataSet.sonar\n+    \n+    feature,label = load_dataset(data_train.csv_file)\n \n \n-        \n     # Initialize x, y, w, b\n     x = torch.randn(features, examples)\n     w_true = torch.randn(1, features)\n     b_true = torch.randn(1)\n"
                },
                {
                    "date": 1718613806244,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -4,8 +4,9 @@\n import csv\n import os\n import crypten\n import torch\n+import num\n from examples.meters import AverageMeter\n \n \n DATASET_DIR = os.path.join(os.path.dirname(__file__), '../dataset')\n"
                },
                {
                    "date": 1718613827172,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -116,9 +116,9 @@\n     torch.manual_seed(1)\n \n     data_train = DataSet.sonar\n     \n-    feature,label = load_dataset(data_train.csv_file)\n+    x,label = load_dataset(data_train.csv_file)\n \n \n     # Initialize x, y, w, b\n     x = torch.randn(features, examples)\n"
                },
                {
                    "date": 1718613833505,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -4,9 +4,9 @@\n import csv\n import os\n import crypten\n import torch\n-import num\n+import numpy as np\n from examples.meters import AverageMeter\n \n \n DATASET_DIR = os.path.join(os.path.dirname(__file__), '../dataset')\n@@ -116,17 +116,17 @@\n     torch.manual_seed(1)\n \n     data_train = DataSet.sonar\n     \n-    x,label = load_dataset(data_train.csv_file)\n+    x, y = load_dataset(data_train.csv_file)\n \n \n     # Initialize x, y, w, b\n-    x = torch.randn(features, examples)\n-    w_true = torch.randn(1, features)\n-    b_true = torch.randn(1)\n-    y = w_true.matmul(x) + b_true\n-    y = y.sign()\n+    # x = torch.randn(features, examples)\n+    # w_true = torch.randn(1, features)\n+    # b_true = torch.randn(1)\n+    # y = w_true.matmul(x) + b_true\n+    # y = y.sign()\n \n     # if not skip_plaintext:\n     #     logging.info(\"==================\")\n     #     logging.info(\"PyTorch Training\")\n"
                },
                {
                    "date": 1718613881898,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -8,9 +8,9 @@\n import numpy as np\n from examples.meters import AverageMeter\n \n \n-DATASET_DIR = os.path.join(os.path.dirname(__file__), '../dataset')\n+DATASET_DIR = os.path.join(os.path.dirname(__file__), 'dataset')\n \n class DataSetParam:\n     def __init__(self, dataset_name):\n         self.dataset_name = dataset_name\n"
                },
                {
                    "date": 1718613905937,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -107,9 +107,9 @@\n \n \n \n def run_mpc_linear_svm(\n-    epochs=50, examples=50, features=100, lr=0.5, skip_plaintext=True\n+    epochs=50, examples=208, features=100, lr=0.5, skip_plaintext=True\n ):\n     crypten.init()\n \n     # Set random seed for reproducibility\n"
                },
                {
                    "date": 1718613913584,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -107,9 +107,9 @@\n \n \n \n def run_mpc_linear_svm(\n-    epochs=50, examples=208, features=100, lr=0.5, skip_plaintext=True\n+    epochs=50, lr=0.5, skip_plaintext=True\n ):\n     crypten.init()\n \n     # Set random seed for reproducibility\n"
                },
                {
                    "date": 1718801742147,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,158 +0,0 @@\n-\n-import logging\n-import time\n-import csv\n-import os\n-import crypten\n-import torch\n-import numpy as np\n-from examples.meters import AverageMeter\n-\n-\n-DATASET_DIR = os.path.join(os.path.dirname(__file__), 'dataset')\n-\n-class DataSetParam:\n-    def __init__(self, dataset_name):\n-        self.dataset_name = dataset_name\n-\n-\n-class DataSet:\n-    sonar = DataSetParam('sonar.csv')\n-\n-\n-\n-\n-def train_linear_svm(features, labels, epochs=50, lr=0.5, print_time=False):\n-    # Initialize random weights\n-    w = features.new(torch.randn(1, features.size(0)))\n-    b = features.new(torch.randn(1))\n-\n-    if print_time:\n-        pt_time = AverageMeter()\n-        end = time.time()\n-\n-    for epoch in range(epochs):\n-        # Forward\n-        label_predictions = w.matmul(features).add(b).sign()\n-\n-        # Compute accuracy\n-        correct = label_predictions.mul(labels)\n-        accuracy = correct.add(1).div(2).mean()\n-        if crypten.is_encrypted_tensor(accuracy):\n-            accuracy = accuracy.get_plain_text()\n-\n-        # Print Accuracy once\n-        if crypten.communicator.get().get_rank() == 0:\n-            print(\n-                f\"Epoch {epoch} --- Training Accuracy %.2f%%\" % (accuracy.item() * 100)\n-            )\n-\n-        # Backward\n-        loss_grad = -labels * (1 - correct) * 0.5  # Hinge loss\n-        b_grad = loss_grad.mean()\n-        w_grad = loss_grad.matmul(features.t()).div(loss_grad.size(1))\n-\n-        # Update\n-        w -= w_grad * lr\n-        b -= b_grad * lr\n-\n-        if print_time:\n-            iter_time = time.time() - end\n-            pt_time.add(iter_time)\n-            logging.info(\"    Time %.6f (%.6f)\" % (iter_time, pt_time.value()))\n-            end = time.time()\n-\n-    return w, b\n-\n-\n-def evaluate_linear_svm(features, labels, w, b):\n-    \"\"\"Compute accuracy on a test set\"\"\"\n-    predictions = w.matmul(features).add(b).sign()\n-    correct = predictions.mul(labels)\n-    accuracy = correct.add(1).div(2).mean().get_plain_text()\n-    if crypten.communicator.get().get_rank() == 0:\n-        print(\"Test accuracy %.2f%%\" % (accuracy.item() * 100))\n-\n-\n-def load_dataset(dataset):\n-    dataset_path = os.path.join(DATASET_DIR, dataset)\n-\n-    # 尝试打开并读取CSV文件\n-    try:\n-        with open(dataset_path, 'r', encoding='utf-8') as csvfile:\n-            spamreader = csv.reader(csvfile)\n-            data = np.array(list(spamreader))\n-    except FileNotFoundError:\n-        print(f\"Error: The file {dataset_path} was not found.\")\n-        return None, None\n-    except Exception as e:\n-        print(f\"Error: An error occurred while reading the file: {e}\")\n-        return None, None\n-\n-    # 检查数据是否为空\n-    if data.size == 0:\n-        print(\"Error: The dataset is empty.\")\n-        return None, None\n-\n-    feature = data[:, :-1].astype(np.float64)\n-    labels = data[:, -1]\n-\n-    # 创建标签映射\n-    unique_labels = np.unique(labels)\n-    label_to_int = {label: idx for idx, label in enumerate(unique_labels)}\n-    int_labels = np.array([label_to_int[label] for label in labels], dtype=np.uint8)\n-\n-    return feature, int_labels\n-\n-\n-\n-\n-def run_mpc_linear_svm(\n-    epochs=50, lr=0.5, skip_plaintext=True\n-):\n-    crypten.init()\n-\n-    # Set random seed for reproducibility\n-    torch.manual_seed(1)\n-\n-    data_train = DataSet.sonar\n-    \n-    x, y = load_dataset(data_train.csv_file)\n-\n-\n-    # Initialize x, y, w, b\n-    # x = torch.randn(features, examples)\n-    # w_true = torch.randn(1, features)\n-    # b_true = torch.randn(1)\n-    # y = w_true.matmul(x) + b_true\n-    # y = y.sign()\n-\n-    # if not skip_plaintext:\n-    #     logging.info(\"==================\")\n-    #     logging.info(\"PyTorch Training\")\n-    #     logging.info(\"==================\")\n-    #     w_torch, b_torch = train_linear_svm(x, y, lr=lr, print_time=True)\n-\n-# NOTE：crypten.cryptensor \n-    # Encrypt features / labels\n-    x = crypten.cryptensor(x)\n-    y = crypten.cryptensor(y)\n-\n-    logging.info(\"==================\")\n-    logging.info(\"CrypTen Training\")\n-    logging.info(\"==================\")\n-# NOTE：训练无差异\n-    w, b = train_linear_svm(x, y, lr=lr, print_time=True)\n-\n-    # if not skip_plaintext:\n-    #     logging.info(\"PyTorch Weights  :\")\n-    #     logging.info(w_torch)\n-    logging.info(\"CrypTen Weights:\")\n-# NOTE：get_plain_text()\n-    logging.info(w.get_plain_text())\n-\n-    # if not skip_plaintext:\n-    #     logging.info(\"PyTorch Bias  :\")\n-    #     logging.info(b_torch)\n-    logging.info(\"CrypTen Bias:\")\n-    logging.info(b.get_plain_text())\n\\ No newline at end of file\n"
                },
                {
                    "date": 1718801749846,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,1 +1,33 @@\n \n+def load_dataset(dataset):\n+    dataset_path = os.path.join(DATASET_DIR, dataset)\n+\n+    # 尝试打开并读取CSV文件\n+    try:\n+        with open(dataset_path, 'r', encoding='utf-8') as csvfile:\n+            spamreader = csv.reader(csvfile)\n+            data = np.array(list(spamreader))\n+    except FileNotFoundError:\n+        print(f\"Error: The file {dataset_path} was not found.\")\n+        return None, None\n+    except Exception as e:\n+        print(f\"Error: An error occurred while reading the file: {e}\")\n+        return None, None\n+\n+    # 检查数据是否为空\n+    if data.size == 0:\n+        print(\"Error: The dataset is empty.\")\n+        return None, None\n+\n+    feature = data[:, :-1].astype(np.float64)\n+    labels = data[:, -1]\n+\n+    # 创建标签映射\n+    unique_labels = np.unique(labels)\n+    label_to_int = {label: idx for idx, label in enumerate(unique_labels)}\n+    int_labels = np.array([label_to_int[label] for label in labels], dtype=np.uint8)\n+    labell = int_labels.reshape(-1,1)\n+\n+    # print(\"======feature_size=====\", feature.shape)\n+    # print(\"======label_size=====\", labell.shape)\n+    return feature, labell\n\\ No newline at end of file\n"
                },
                {
                    "date": 1718801759415,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,5 +1,26 @@\n \n+\n+import logging\n+import time\n+import csv\n+import os\n+import crypten\n+import torch\n+import numpy as np\n+from examples.meters import AverageMeter\n+\n+\n+DATASET_DIR = os.path.join(os.path.dirname(__file__), '../dataset')\n+\n+class DataSetParam:\n+    def __init__(self, dataset_name):\n+        self.dataset_name = dataset_name\n+\n+\n+class DataSet:\n+    sonar = DataSetParam('sonar.csv')\n+    sonar_selected = DataSetParam('sonar_selected.csv')\n def load_dataset(dataset):\n     dataset_path = os.path.join(DATASET_DIR, dataset)\n \n     # 尝试打开并读取CSV文件\n"
                },
                {
                    "date": 1718801766525,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,6 +1,5 @@\n \n-\n import logging\n import time\n import csv\n import os\n@@ -9,9 +8,9 @@\n import numpy as np\n from examples.meters import AverageMeter\n \n \n-DATASET_DIR = os.path.join(os.path.dirname(__file__), '../dataset')\n+DATASET_DIR = os.path.join(os.path.dirname(__file__), 'dataset')\n \n class DataSetParam:\n     def __init__(self, dataset_name):\n         self.dataset_name = dataset_name\n@@ -19,8 +18,11 @@\n \n class DataSet:\n     sonar = DataSetParam('sonar.csv')\n     sonar_selected = DataSetParam('sonar_selected.csv')\n+    \n+    \n+    \n def load_dataset(dataset):\n     dataset_path = os.path.join(DATASET_DIR, dataset)\n \n     # 尝试打开并读取CSV文件\n"
                },
                {
                    "date": 1718801773855,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -52,5 +52,8 @@\n     labell = int_labels.reshape(-1,1)\n \n     # print(\"======feature_size=====\", feature.shape)\n     # print(\"======label_size=====\", labell.shape)\n-    return feature, labell\n\\ No newline at end of file\n+    return feature, labell\n+\n+\n+load_dataset()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1718801782352,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -55,5 +55,5 @@\n     # print(\"======label_size=====\", labell.shape)\n     return feature, labell\n \n \n-load_dataset()\n\\ No newline at end of file\n+load_dataset(s)\n\\ No newline at end of file\n"
                },
                {
                    "date": 1718801798661,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -54,6 +54,6 @@\n     # print(\"======feature_size=====\", feature.shape)\n     # print(\"======label_size=====\", labell.shape)\n     return feature, labell\n \n-\n-load_dataset(s)\n\\ No newline at end of file\n+    data_train = DataSet.sonar\n+load_dataset(sonar)\n\\ No newline at end of file\n"
                },
                {
                    "date": 1718801806505,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -54,6 +54,7 @@\n     # print(\"======feature_size=====\", feature.shape)\n     # print(\"======label_size=====\", labell.shape)\n     return feature, labell\n \n-    data_train = DataSet.sonar\n-load_dataset(sonar)\n\\ No newline at end of file\n+data_train = DataSet.sonar\n+\n+load_dataset(data_train)\n\\ No newline at end of file\n"
                },
                {
                    "date": 1718801847777,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -56,5 +56,5 @@\n     return feature, labell\n \n data_train = DataSet.sonar\n \n-load_dataset(data_train)\n\\ No newline at end of file\n+load_dataset(data_train.dataset_name)\n\\ No newline at end of file\n"
                },
                {
                    "date": 1718801858991,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -50,10 +50,10 @@\n     label_to_int = {label: idx for idx, label in enumerate(unique_labels)}\n     int_labels = np.array([label_to_int[label] for label in labels], dtype=np.uint8)\n     labell = int_labels.reshape(-1,1)\n \n-    # print(\"======feature_size=====\", feature.shape)\n-    # print(\"======label_size=====\", labell.shape)\n+    print(\"======feature_size=====\", feature.shape)\n+    print(\"======label_size=====\", labell.shape)\n     return feature, labell\n \n data_train = DataSet.sonar\n \n"
                },
                {
                    "date": 1718801865472,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -50,9 +50,9 @@\n     label_to_int = {label: idx for idx, label in enumerate(unique_labels)}\n     int_labels = np.array([label_to_int[label] for label in labels], dtype=np.uint8)\n     labell = int_labels.reshape(-1,1)\n \n-    print(\"======feature_size=====\", feature.shape)\n+    # print(\"======feature_size=====\", feature.shape)\n     print(\"======label_size=====\", labell.shape)\n     return feature, labell\n \n data_train = DataSet.sonar\n"
                },
                {
                    "date": 1718801923644,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -50,10 +50,12 @@\n     label_to_int = {label: idx for idx, label in enumerate(unique_labels)}\n     int_labels = np.array([label_to_int[label] for label in labels], dtype=np.uint8)\n     labell = int_labels.reshape(-1,1)\n \n+\n+    \n     # print(\"======feature_size=====\", feature.shape)\n-    print(\"======label_size=====\", labell.shape)\n+    print(\"======label_size=====\", labell)\n     return feature, labell\n \n data_train = DataSet.sonar\n \n"
                },
                {
                    "date": 1718801935562,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -50,10 +50,11 @@\n     label_to_int = {label: idx for idx, label in enumerate(unique_labels)}\n     int_labels = np.array([label_to_int[label] for label in labels], dtype=np.uint8)\n     labell = int_labels.reshape(-1,1)\n \n+    # 将标签转换为独热矩阵\n+    \n \n-    \n     # print(\"======feature_size=====\", feature.shape)\n     print(\"======label_size=====\", labell)\n     return feature, labell\n \n"
                },
                {
                    "date": 1718801943591,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -51,10 +51,12 @@\n     int_labels = np.array([label_to_int[label] for label in labels], dtype=np.uint8)\n     labell = int_labels.reshape(-1,1)\n \n     # 将标签转换为独热矩阵\n-    \n+    one_hot_labels = np.zeros((int_labels.size, int_labels.max() + 1), dtype=np.uint8)\n+    one_hot_labels[np.arange(int_labels.size), int_labels] = 1\n \n+\n     # print(\"======feature_size=====\", feature.shape)\n     print(\"======label_size=====\", labell)\n     return feature, labell\n \n"
                },
                {
                    "date": 1718801957547,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -54,11 +54,10 @@\n     # 将标签转换为独热矩阵\n     one_hot_labels = np.zeros((int_labels.size, int_labels.max() + 1), dtype=np.uint8)\n     one_hot_labels[np.arange(int_labels.size), int_labels] = 1\n \n-\n     # print(\"======feature_size=====\", feature.shape)\n-    print(\"======label_size=====\", labell)\n+    print(\"======label_size=====\", one_hot_labels)\n     return feature, labell\n \n data_train = DataSet.sonar\n \n"
                },
                {
                    "date": 1718801963934,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -56,9 +56,9 @@\n     one_hot_labels[np.arange(int_labels.size), int_labels] = 1\n \n     # print(\"======feature_size=====\", feature.shape)\n     print(\"======label_size=====\", one_hot_labels)\n-    return feature, labell\n+    return feature, lone_hot_labels\n \n data_train = DataSet.sonar\n \n load_dataset(data_train.dataset_name)\n\\ No newline at end of file\n"
                },
                {
                    "date": 1720681463783,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -8,57 +8,59 @@\n import numpy as np\n from examples.meters import AverageMeter\n \n \n-DATASET_DIR = os.path.join(os.path.dirname(__file__), 'dataset')\n+# region \n+# DATASET_DIR = os.path.join(os.path.dirname(__file__), 'dataset')\n \n-class DataSetParam:\n-    def __init__(self, dataset_name):\n-        self.dataset_name = dataset_name\n+# class DataSetParam:\n+#     def __init__(self, dataset_name):\n+#         self.dataset_name = dataset_name\n \n \n-class DataSet:\n-    sonar = DataSetParam('sonar.csv')\n-    sonar_selected = DataSetParam('sonar_selected.csv')\n+# class DataSet:\n+#     sonar = DataSetParam('sonar.csv')\n+#     sonar_selected = DataSetParam('sonar_selected.csv')\n     \n     \n     \n-def load_dataset(dataset):\n-    dataset_path = os.path.join(DATASET_DIR, dataset)\n+# def load_dataset(dataset):\n+#     dataset_path = os.path.join(DATASET_DIR, dataset)\n \n-    # 尝试打开并读取CSV文件\n-    try:\n-        with open(dataset_path, 'r', encoding='utf-8') as csvfile:\n-            spamreader = csv.reader(csvfile)\n-            data = np.array(list(spamreader))\n-    except FileNotFoundError:\n-        print(f\"Error: The file {dataset_path} was not found.\")\n-        return None, None\n-    except Exception as e:\n-        print(f\"Error: An error occurred while reading the file: {e}\")\n-        return None, None\n+#     # 尝试打开并读取CSV文件\n+#     try:\n+#         with open(dataset_path, 'r', encoding='utf-8') as csvfile:\n+#             spamreader = csv.reader(csvfile)\n+#             data = np.array(list(spamreader))\n+#     except FileNotFoundError:\n+#         print(f\"Error: The file {dataset_path} was not found.\")\n+#         return None, None\n+#     except Exception as e:\n+#         print(f\"Error: An error occurred while reading the file: {e}\")\n+#         return None, None\n \n-    # 检查数据是否为空\n-    if data.size == 0:\n-        print(\"Error: The dataset is empty.\")\n-        return None, None\n\\ No newline at end of file\n+#     # 检查数据是否为空\n+#     if data.size == 0:\n+#         print(\"Error: The dataset is empty.\")\n+#         return None, None\n \n-    feature = data[:, :-1].astype(np.float64)\n-    labels = data[:, -1]\n+#     feature = data[:, :-1].astype(np.float64)\n+#     labels = data[:, -1]\n \n-    # 创建标签映射\n-    unique_labels = np.unique(labels)\n-    label_to_int = {label: idx for idx, label in enumerate(unique_labels)}\n-    int_labels = np.array([label_to_int[label] for label in labels], dtype=np.uint8)\n-    labell = int_labels.reshape(-1,1)\n+#     # 创建标签映射\n+#     unique_labels = np.unique(labels)\n+#     label_to_int = {label: idx for idx, label in enumerate(unique_labels)}\n+#     int_labels = np.array([label_to_int[label] for label in labels], dtype=np.uint8)\n+#     labell = int_labels.reshape(-1,1)\n \n-    # 将标签转换为独热矩阵\n-    one_hot_labels = np.zeros((int_labels.size, int_labels.max() + 1), dtype=np.uint8)\n-    one_hot_labels[np.arange(int_labels.size), int_labels] = 1\n+#     # 将标签转换为独热矩阵\n+#     one_hot_labels = np.zeros((int_labels.size, int_labels.max() + 1), dtype=np.uint8)\n+#     one_hot_labels[np.arange(int_labels.size), int_labels] = 1\n \n-    # print(\"======feature_size=====\", feature.shape)\n-    print(\"======label_size=====\", one_hot_labels)\n-    return feature, lone_hot_labels\n+#     # print(\"======feature_size=====\", feature.shape)\n+#     print(\"======label_size=====\", one_hot_labels)\n+#     return feature, one_hot_labels\n \n-data_train = DataSet.sonar\n+# data_train = DataSet.sonar\n \n-load_dataset(data_train.dataset_name)\n+# load_dataset(data_train.dataset_name)\n+# endregion\n\\ No newline at end of file\n"
                },
                {
                    "date": 1720681472458,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -62,5 +62,9 @@\n \n # data_train = DataSet.sonar\n \n # load_dataset(data_train.dataset_name)\n-# endregion\n\\ No newline at end of file\n+# endregion\n+\n+\n+\n+\n"
                },
                {
                    "date": 1720681524302,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,73 @@\n+\n+import crypten\n+import torch\n+import crypten.mpc as mpc\n+import crypten.mpc.primitives.beaver as beaver\n+import crypten.communicator as comm \n+import torch\n+from crypten.mpc import MPCTensor\n+from crypten.mpc.primitives import BinarySharedTensor\n+import time\n+\n+crypten.init()\n+\n+\n+# region \n+# DATASET_DIR = os.path.join(os.path.dirname(__file__), 'dataset')\n+\n+# class DataSetParam:\n+#     def __init__(self, dataset_name):\n+#         self.dataset_name = dataset_name\n+\n+\n+# class DataSet:\n+#     sonar = DataSetParam('sonar.csv')\n+#     sonar_selected = DataSetParam('sonar_selected.csv')\n+    \n+    \n+    \n+# def load_dataset(dataset):\n+#     dataset_path = os.path.join(DATASET_DIR, dataset)\n+\n+#     # 尝试打开并读取CSV文件\n+#     try:\n+#         with open(dataset_path, 'r', encoding='utf-8') as csvfile:\n+#             spamreader = csv.reader(csvfile)\n+#             data = np.array(list(spamreader))\n+#     except FileNotFoundError:\n+#         print(f\"Error: The file {dataset_path} was not found.\")\n+#         return None, None\n+#     except Exception as e:\n+#         print(f\"Error: An error occurred while reading the file: {e}\")\n+#         return None, None\n+\n+#     # 检查数据是否为空\n+#     if data.size == 0:\n+#         print(\"Error: The dataset is empty.\")\n+#         return None, None\n+\n+#     feature = data[:, :-1].astype(np.float64)\n+#     labels = data[:, -1]\n+\n+#     # 创建标签映射\n+#     unique_labels = np.unique(labels)\n+#     label_to_int = {label: idx for idx, label in enumerate(unique_labels)}\n+#     int_labels = np.array([label_to_int[label] for label in labels], dtype=np.uint8)\n+#     labell = int_labels.reshape(-1,1)\n+\n+#     # 将标签转换为独热矩阵\n+#     one_hot_labels = np.zeros((int_labels.size, int_labels.max() + 1), dtype=np.uint8)\n+#     one_hot_labels[np.arange(int_labels.size), int_labels] = 1\n+\n+#     # print(\"======feature_size=====\", feature.shape)\n+#     print(\"======label_size=====\", one_hot_labels)\n+#     return feature, one_hot_labels\n+\n+# data_train = DataSet.sonar\n+\n+# load_dataset(data_train.dataset_name)\n+# endregion\n+\n+\n+\n+\n"
                },
                {
                    "date": 1720681536121,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -68,76 +68,10 @@\n # load_dataset(data_train.dataset_name)\n # endregion\n \n \n+def generate_boolean_tensor(N):\n+    # 生成一个长度为N的随机布尔tensor\n+    random_tensor = torch.randint(0, 2, (N,))\n+    return random_tensor\n \n \n-\n-import logging\n-import time\n-import csv\n-import os\n-import crypten\n-import torch\n-import numpy as np\n-from examples.meters import AverageMeter\n-\n-\n-# region \n-# DATASET_DIR = os.path.join(os.path.dirname(__file__), 'dataset')\n-\n-# class DataSetParam:\n-#     def __init__(self, dataset_name):\n-#         self.dataset_name = dataset_name\n-\n-\n-# class DataSet:\n-#     sonar = DataSetParam('sonar.csv')\n-#     sonar_selected = DataSetParam('sonar_selected.csv')\n-    \n-    \n-    \n-# def load_dataset(dataset):\n-#     dataset_path = os.path.join(DATASET_DIR, dataset)\n-\n-#     # 尝试打开并读取CSV文件\n-#     try:\n-#         with open(dataset_path, 'r', encoding='utf-8') as csvfile:\n-#             spamreader = csv.reader(csvfile)\n-#             data = np.array(list(spamreader))\n-#     except FileNotFoundError:\n-#         print(f\"Error: The file {dataset_path} was not found.\")\n-#         return None, None\n-#     except Exception as e:\n-#         print(f\"Error: An error occurred while reading the file: {e}\")\n-#         return None, None\n-\n-#     # 检查数据是否为空\n-#     if data.size == 0:\n-#         print(\"Error: The dataset is empty.\")\n-#         return None, None\n-\n-#     feature = data[:, :-1].astype(np.float64)\n-#     labels = data[:, -1]\n-\n-#     # 创建标签映射\n-#     unique_labels = np.unique(labels)\n-#     label_to_int = {label: idx for idx, label in enumerate(unique_labels)}\n-#     int_labels = np.array([label_to_int[label] for label in labels], dtype=np.uint8)\n-#     labell = int_labels.reshape(-1,1)\n-\n-#     # 将标签转换为独热矩阵\n-#     one_hot_labels = np.zeros((int_labels.size, int_labels.max() + 1), dtype=np.uint8)\n-#     one_hot_labels[np.arange(int_labels.size), int_labels] = 1\n-\n-#     # print(\"======feature_size=====\", feature.shape)\n-#     print(\"======label_size=====\", one_hot_labels)\n-#     return feature, one_hot_labels\n-\n-# data_train = DataSet.sonar\n-\n-# load_dataset(data_train.dataset_name)\n-# endregion\n-\n-\n-\n-\n"
                },
                {
                    "date": 1720681556835,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -74,4 +74,9 @@\n     random_tensor = torch.randint(0, 2, (N,))\n     return random_tensor\n \n \n+N = 10\n+x = generate_boolean_tensor(N)\n+y = generate_boolean_tensor(N)\n+x_enc = crypten.cryptensor(x, ptype=crypten.mpc.binary)\n+y_enc = crypten.cryptensor(y, ptype=crypten.mpc.binary)\n\\ No newline at end of file\n"
                },
                {
                    "date": 1720681562581,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,82 @@\n+\n+import crypten\n+import torch\n+import crypten.mpc as mpc\n+import crypten.mpc.primitives.beaver as beaver\n+import crypten.communicator as comm \n+import torch\n+from crypten.mpc import MPCTensor\n+from crypten.mpc.primitives import BinarySharedTensor\n+import time\n+\n+crypten.init()\n+\n+\n+# region \n+# DATASET_DIR = os.path.join(os.path.dirname(__file__), 'dataset')\n+\n+# class DataSetParam:\n+#     def __init__(self, dataset_name):\n+#         self.dataset_name = dataset_name\n+\n+\n+# class DataSet:\n+#     sonar = DataSetParam('sonar.csv')\n+#     sonar_selected = DataSetParam('sonar_selected.csv')\n+    \n+    \n+    \n+# def load_dataset(dataset):\n+#     dataset_path = os.path.join(DATASET_DIR, dataset)\n+\n+#     # 尝试打开并读取CSV文件\n+#     try:\n+#         with open(dataset_path, 'r', encoding='utf-8') as csvfile:\n+#             spamreader = csv.reader(csvfile)\n+#             data = np.array(list(spamreader))\n+#     except FileNotFoundError:\n+#         print(f\"Error: The file {dataset_path} was not found.\")\n+#         return None, None\n+#     except Exception as e:\n+#         print(f\"Error: An error occurred while reading the file: {e}\")\n+#         return None, None\n+\n+#     # 检查数据是否为空\n+#     if data.size == 0:\n+#         print(\"Error: The dataset is empty.\")\n+#         return None, None\n+\n+#     feature = data[:, :-1].astype(np.float64)\n+#     labels = data[:, -1]\n+\n+#     # 创建标签映射\n+#     unique_labels = np.unique(labels)\n+#     label_to_int = {label: idx for idx, label in enumerate(unique_labels)}\n+#     int_labels = np.array([label_to_int[label] for label in labels], dtype=np.uint8)\n+#     labell = int_labels.reshape(-1,1)\n+\n+#     # 将标签转换为独热矩阵\n+#     one_hot_labels = np.zeros((int_labels.size, int_labels.max() + 1), dtype=np.uint8)\n+#     one_hot_labels[np.arange(int_labels.size), int_labels] = 1\n+\n+#     # print(\"======feature_size=====\", feature.shape)\n+#     print(\"======label_size=====\", one_hot_labels)\n+#     return feature, one_hot_labels\n+\n+# data_train = DataSet.sonar\n+\n+# load_dataset(data_train.dataset_name)\n+# endregion\n+\n+\n+def generate_boolean_tensor(N):\n+    # 生成一个长度为N的随机布尔tensor\n+    random_tensor = torch.randint(0, 10)\n+    return random_tensor\n+\n+\n+N = 10\n+x = generate_boolean_tensor(N)\n+y = generate_boolean_tensor(N)\n+x_enc = crypten.cryptensor(x, ptype=crypten.mpc.binary)\n+y_enc = crypten.cryptensor(y, ptype=crypten.mpc.binary)\n\\ No newline at end of file\n"
                },
                {
                    "date": 1720681569705,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -68,97 +68,12 @@\n # load_dataset(data_train.dataset_name)\n # endregion\n \n \n-def generate_boolean_tensor(N):\n+def generate_random(N):\n     # 生成一个长度为N的随机布尔tensor\n     random_tensor = torch.randint(0, 10)\n     return random_tensor\n-\n-\n-N = 10\n x = generate_boolean_tensor(N)\n y = generate_boolean_tensor(N)\n x_enc = crypten.cryptensor(x, ptype=crypten.mpc.binary)\n-y_enc = crypten.cryptensor(y, ptype=crypten.mpc.binary)\n-\n-import crypten\n-import torch\n-import crypten.mpc as mpc\n-import crypten.mpc.primitives.beaver as beaver\n-import crypten.communicator as comm \n-import torch\n-from crypten.mpc import MPCTensor\n-from crypten.mpc.primitives import BinarySharedTensor\n-import time\n-\n-crypten.init()\n-\n-\n-# region \n-# DATASET_DIR = os.path.join(os.path.dirname(__file__), 'dataset')\n-\n-# class DataSetParam:\n-#     def __init__(self, dataset_name):\n-#         self.dataset_name = dataset_name\n-\n-\n-# class DataSet:\n-#     sonar = DataSetParam('sonar.csv')\n-#     sonar_selected = DataSetParam('sonar_selected.csv')\n-    \n-    \n-    \n-# def load_dataset(dataset):\n-#     dataset_path = os.path.join(DATASET_DIR, dataset)\n-\n-#     # 尝试打开并读取CSV文件\n-#     try:\n-#         with open(dataset_path, 'r', encoding='utf-8') as csvfile:\n-#             spamreader = csv.reader(csvfile)\n-#             data = np.array(list(spamreader))\n-#     except FileNotFoundError:\n-#         print(f\"Error: The file {dataset_path} was not found.\")\n-#         return None, None\n-#     except Exception as e:\n-#         print(f\"Error: An error occurred while reading the file: {e}\")\n-#         return None, None\n-\n-#     # 检查数据是否为空\n-#     if data.size == 0:\n-#         print(\"Error: The dataset is empty.\")\n-#         return None, None\n-\n-#     feature = data[:, :-1].astype(np.float64)\n-#     labels = data[:, -1]\n-\n-#     # 创建标签映射\n-#     unique_labels = np.unique(labels)\n-#     label_to_int = {label: idx for idx, label in enumerate(unique_labels)}\n-#     int_labels = np.array([label_to_int[label] for label in labels], dtype=np.uint8)\n-#     labell = int_labels.reshape(-1,1)\n-\n-#     # 将标签转换为独热矩阵\n-#     one_hot_labels = np.zeros((int_labels.size, int_labels.max() + 1), dtype=np.uint8)\n-#     one_hot_labels[np.arange(int_labels.size), int_labels] = 1\n-\n-#     # print(\"======feature_size=====\", feature.shape)\n-#     print(\"======label_size=====\", one_hot_labels)\n-#     return feature, one_hot_labels\n-\n-# data_train = DataSet.sonar\n-\n-# load_dataset(data_train.dataset_name)\n-# endregion\n-\n-\n-def generate_boolean_tensor(N):\n-    # 生成一个长度为N的随机布尔tensor\n-    random_tensor = torch.randint(0, 2, (N,))\n-    return random_tensor\n-\n-\n-N = 10\n-x = generate_boolean_tensor(N)\n-y = generate_boolean_tensor(N)\n-x_enc = crypten.cryptensor(x, ptype=crypten.mpc.binary)\n y_enc = crypten.cryptensor(y, ptype=crypten.mpc.binary)\n\\ No newline at end of file\n"
                },
                {
                    "date": 1720681575720,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -68,12 +68,12 @@\n # load_dataset(data_train.dataset_name)\n # endregion\n \n \n-def generate_random(N):\n+def generate_random():\n     # 生成一个长度为N的随机布尔tensor\n     random_tensor = torch.randint(0, 10)\n     return random_tensor\n-x = generate_boolean_tensor(N)\n-y = generate_boolean_tensor(N)\n+x = generate_boolean_tensor()\n+y = generate_boolean_tensor()\n x_enc = crypten.cryptensor(x, ptype=crypten.mpc.binary)\n y_enc = crypten.cryptensor(y, ptype=crypten.mpc.binary)\n\\ No newline at end of file\n"
                },
                {
                    "date": 1720681582335,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -72,8 +72,8 @@\n def generate_random():\n     # 生成一个长度为N的随机布尔tensor\n     random_tensor = torch.randint(0, 10)\n     return random_tensor\n-x = generate_boolean_tensor()\n-y = generate_boolean_tensor()\n+x = generate_random()\n+y = generate_random()\n x_enc = crypten.cryptensor(x, ptype=crypten.mpc.binary)\n y_enc = crypten.cryptensor(y, ptype=crypten.mpc.binary)\n\\ No newline at end of file\n"
                },
                {
                    "date": 1720681591867,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -75,5 +75,7 @@\n     return random_tensor\n x = generate_random()\n y = generate_random()\n x_enc = crypten.cryptensor(x, ptype=crypten.mpc.binary)\n-y_enc = crypten.cryptensor(y, ptype=crypten.mpc.binary)\n\\ No newline at end of file\n+y_enc = crypten.cryptensor(y, ptype=crypten.mpc.binary)\n+\n+\n"
                },
                {
                    "date": 1720681603829,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,81 @@\n+\n+import crypten\n+import torch\n+import crypten.mpc as mpc\n+import crypten.mpc.primitives.beaver as beaver\n+import crypten.communicator as comm \n+import torch\n+from crypten.mpc import MPCTensor\n+from crypten.mpc.primitives import BinarySharedTensor\n+import time\n+\n+crypten.init()\n+\n+\n+# region \n+# DATASET_DIR = os.path.join(os.path.dirname(__file__), 'dataset')\n+\n+# class DataSetParam:\n+#     def __init__(self, dataset_name):\n+#         self.dataset_name = dataset_name\n+\n+\n+# class DataSet:\n+#     sonar = DataSetParam('sonar.csv')\n+#     sonar_selected = DataSetParam('sonar_selected.csv')\n+    \n+    \n+    \n+# def load_dataset(dataset):\n+#     dataset_path = os.path.join(DATASET_DIR, dataset)\n+\n+#     # 尝试打开并读取CSV文件\n+#     try:\n+#         with open(dataset_path, 'r', encoding='utf-8') as csvfile:\n+#             spamreader = csv.reader(csvfile)\n+#             data = np.array(list(spamreader))\n+#     except FileNotFoundError:\n+#         print(f\"Error: The file {dataset_path} was not found.\")\n+#         return None, None\n+#     except Exception as e:\n+#         print(f\"Error: An error occurred while reading the file: {e}\")\n+#         return None, None\n+\n+#     # 检查数据是否为空\n+#     if data.size == 0:\n+#         print(\"Error: The dataset is empty.\")\n+#         return None, None\n+\n+#     feature = data[:, :-1].astype(np.float64)\n+#     labels = data[:, -1]\n+\n+#     # 创建标签映射\n+#     unique_labels = np.unique(labels)\n+#     label_to_int = {label: idx for idx, label in enumerate(unique_labels)}\n+#     int_labels = np.array([label_to_int[label] for label in labels], dtype=np.uint8)\n+#     labell = int_labels.reshape(-1,1)\n+\n+#     # 将标签转换为独热矩阵\n+#     one_hot_labels = np.zeros((int_labels.size, int_labels.max() + 1), dtype=np.uint8)\n+#     one_hot_labels[np.arange(int_labels.size), int_labels] = 1\n+\n+#     # print(\"======feature_size=====\", feature.shape)\n+#     print(\"======label_size=====\", one_hot_labels)\n+#     return feature, one_hot_labels\n+\n+# data_train = DataSet.sonar\n+\n+# load_dataset(data_train.dataset_name)\n+# endregion\n+\n+\n+def generate_random():\n+    # 生成一个长度为N的随机布尔tensor\n+    random_tensor = torch.randint(0, 10)\n+    return random_tensor\n+x = generate_random()\n+y = generate_random()\n+x_enc = crypten.cryptensor(x, ptype=crypten.mpc.binary)\n+y_enc = crypten.cryptensor(y, ptype=crypten.mpc.binary)\n+\n+@mpc.run_multiprocess(world_size=2)\n"
                },
                {
                    "date": 1720681609433,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -78,85 +78,6 @@\n x_enc = crypten.cryptensor(x, ptype=crypten.mpc.binary)\n y_enc = crypten.cryptensor(y, ptype=crypten.mpc.binary)\n \n @mpc.run_multiprocess(world_size=2)\n-\n-import crypten\n-import torch\n-import crypten.mpc as mpc\n-import crypten.mpc.primitives.beaver as beaver\n-import crypten.communicator as comm \n-import torch\n-from crypten.mpc import MPCTensor\n-from crypten.mpc.primitives import BinarySharedTensor\n-import time\n-\n-crypten.init()\n-\n-\n-# region \n-# DATASET_DIR = os.path.join(os.path.dirname(__file__), 'dataset')\n-\n-# class DataSetParam:\n-#     def __init__(self, dataset_name):\n-#         self.dataset_name = dataset_name\n-\n-\n-# class DataSet:\n-#     sonar = DataSetParam('sonar.csv')\n-#     sonar_selected = DataSetParam('sonar_selected.csv')\n+def main():\n     \n-    \n-    \n-# def load_dataset(dataset):\n-#     dataset_path = os.path.join(DATASET_DIR, dataset)\n-\n-#     # 尝试打开并读取CSV文件\n-#     try:\n-#         with open(dataset_path, 'r', encoding='utf-8') as csvfile:\n-#             spamreader = csv.reader(csvfile)\n-#             data = np.array(list(spamreader))\n-#     except FileNotFoundError:\n-#         print(f\"Error: The file {dataset_path} was not found.\")\n-#         return None, None\n-#     except Exception as e:\n-#         print(f\"Error: An error occurred while reading the file: {e}\")\n-#         return None, None\n-\n-#     # 检查数据是否为空\n-#     if data.size == 0:\n-#         print(\"Error: The dataset is empty.\")\n-#         return None, None\n-\n-#     feature = data[:, :-1].astype(np.float64)\n-#     labels = data[:, -1]\n-\n-#     # 创建标签映射\n-#     unique_labels = np.unique(labels)\n-#     label_to_int = {label: idx for idx, label in enumerate(unique_labels)}\n-#     int_labels = np.array([label_to_int[label] for label in labels], dtype=np.uint8)\n-#     labell = int_labels.reshape(-1,1)\n-\n-#     # 将标签转换为独热矩阵\n-#     one_hot_labels = np.zeros((int_labels.size, int_labels.max() + 1), dtype=np.uint8)\n-#     one_hot_labels[np.arange(int_labels.size), int_labels] = 1\n-\n-#     # print(\"======feature_size=====\", feature.shape)\n-#     print(\"======label_size=====\", one_hot_labels)\n-#     return feature, one_hot_labels\n-\n-# data_train = DataSet.sonar\n-\n-# load_dataset(data_train.dataset_name)\n-# endregion\n-\n-\n-def generate_random():\n-    # 生成一个长度为N的随机布尔tensor\n-    random_tensor = torch.randint(0, 10)\n-    return random_tensor\n-x = generate_random()\n-y = generate_random()\n-x_enc = crypten.cryptensor(x, ptype=crypten.mpc.binary)\n-y_enc = crypten.cryptensor(y, ptype=crypten.mpc.binary)\n-\n-\n"
                },
                {
                    "date": 1720681615927,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -72,8 +72,9 @@\n def generate_random():\n     # 生成一个长度为N的随机布尔tensor\n     random_tensor = torch.randint(0, 10)\n     return random_tensor\n+\n x = generate_random()\n y = generate_random()\n x_enc = crypten.cryptensor(x, ptype=crypten.mpc.binary)\n y_enc = crypten.cryptensor(y, ptype=crypten.mpc.binary)\n"
                },
                {
                    "date": 1720681629758,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -80,5 +80,6 @@\n y_enc = crypten.cryptensor(y, ptype=crypten.mpc.binary)\n \n @mpc.run_multiprocess(world_size=2)\n def main():\n-    \n+    x = generate_random()\n+y = generate_random()\n"
                },
                {
                    "date": 1720681637214,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,87 @@\n+\n+import crypten\n+import torch\n+import crypten.mpc as mpc\n+import crypten.mpc.primitives.beaver as beaver\n+import crypten.communicator as comm \n+import torch\n+from crypten.mpc import MPCTensor\n+from crypten.mpc.primitives import BinarySharedTensor\n+import time\n+\n+crypten.init()\n+\n+\n+# region \n+# DATASET_DIR = os.path.join(os.path.dirname(__file__), 'dataset')\n+\n+# class DataSetParam:\n+#     def __init__(self, dataset_name):\n+#         self.dataset_name = dataset_name\n+\n+\n+# class DataSet:\n+#     sonar = DataSetParam('sonar.csv')\n+#     sonar_selected = DataSetParam('sonar_selected.csv')\n+    \n+    \n+    \n+# def load_dataset(dataset):\n+#     dataset_path = os.path.join(DATASET_DIR, dataset)\n+\n+#     # 尝试打开并读取CSV文件\n+#     try:\n+#         with open(dataset_path, 'r', encoding='utf-8') as csvfile:\n+#             spamreader = csv.reader(csvfile)\n+#             data = np.array(list(spamreader))\n+#     except FileNotFoundError:\n+#         print(f\"Error: The file {dataset_path} was not found.\")\n+#         return None, None\n+#     except Exception as e:\n+#         print(f\"Error: An error occurred while reading the file: {e}\")\n+#         return None, None\n+\n+#     # 检查数据是否为空\n+#     if data.size == 0:\n+#         print(\"Error: The dataset is empty.\")\n+#         return None, None\n+\n+#     feature = data[:, :-1].astype(np.float64)\n+#     labels = data[:, -1]\n+\n+#     # 创建标签映射\n+#     unique_labels = np.unique(labels)\n+#     label_to_int = {label: idx for idx, label in enumerate(unique_labels)}\n+#     int_labels = np.array([label_to_int[label] for label in labels], dtype=np.uint8)\n+#     labell = int_labels.reshape(-1,1)\n+\n+#     # 将标签转换为独热矩阵\n+#     one_hot_labels = np.zeros((int_labels.size, int_labels.max() + 1), dtype=np.uint8)\n+#     one_hot_labels[np.arange(int_labels.size), int_labels] = 1\n+\n+#     # print(\"======feature_size=====\", feature.shape)\n+#     print(\"======label_size=====\", one_hot_labels)\n+#     return feature, one_hot_labels\n+\n+# data_train = DataSet.sonar\n+\n+# load_dataset(data_train.dataset_name)\n+# endregion\n+\n+\n+def generate_random():\n+    # 生成一个长度为N的随机布尔tensor\n+    random_tensor = torch.randint(0, 10)\n+    return random_tensor\n+\n+x = generate_random()\n+y = generate_random()\n+x_enc = crypten.cryptensor(x, ptype=crypten.mpc.binary)\n+y_enc = crypten.cryptensor(y, ptype=crypten.mpc.binary)\n+\n+def secret sharing\n+\n+@mpc.run_multiprocess(world_size=2)\n+def main():\n+    x = generate_random()\n+    y = generate_random()\n"
                },
                {
                    "date": 1720681643545,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -78,95 +78,11 @@\n y = generate_random()\n x_enc = crypten.cryptensor(x, ptype=crypten.mpc.binary)\n y_enc = crypten.cryptensor(y, ptype=crypten.mpc.binary)\n \n-def secret sharing\n+def test():\n+    \n \n @mpc.run_multiprocess(world_size=2)\n def main():\n     x = generate_random()\n     y = generate_random()\n-\n-import crypten\n-import torch\n-import crypten.mpc as mpc\n-import crypten.mpc.primitives.beaver as beaver\n-import crypten.communicator as comm \n-import torch\n-from crypten.mpc import MPCTensor\n-from crypten.mpc.primitives import BinarySharedTensor\n-import time\n-\n-crypten.init()\n-\n-\n-# region \n-# DATASET_DIR = os.path.join(os.path.dirname(__file__), 'dataset')\n-\n-# class DataSetParam:\n-#     def __init__(self, dataset_name):\n-#         self.dataset_name = dataset_name\n-\n-\n-# class DataSet:\n-#     sonar = DataSetParam('sonar.csv')\n-#     sonar_selected = DataSetParam('sonar_selected.csv')\n-    \n-    \n-    \n-# def load_dataset(dataset):\n-#     dataset_path = os.path.join(DATASET_DIR, dataset)\n-\n-#     # 尝试打开并读取CSV文件\n-#     try:\n-#         with open(dataset_path, 'r', encoding='utf-8') as csvfile:\n-#             spamreader = csv.reader(csvfile)\n-#             data = np.array(list(spamreader))\n-#     except FileNotFoundError:\n-#         print(f\"Error: The file {dataset_path} was not found.\")\n-#         return None, None\n-#     except Exception as e:\n-#         print(f\"Error: An error occurred while reading the file: {e}\")\n-#         return None, None\n-\n-#     # 检查数据是否为空\n-#     if data.size == 0:\n-#         print(\"Error: The dataset is empty.\")\n-#         return None, None\n-\n-#     feature = data[:, :-1].astype(np.float64)\n-#     labels = data[:, -1]\n-\n-#     # 创建标签映射\n-#     unique_labels = np.unique(labels)\n-#     label_to_int = {label: idx for idx, label in enumerate(unique_labels)}\n-#     int_labels = np.array([label_to_int[label] for label in labels], dtype=np.uint8)\n-#     labell = int_labels.reshape(-1,1)\n-\n-#     # 将标签转换为独热矩阵\n-#     one_hot_labels = np.zeros((int_labels.size, int_labels.max() + 1), dtype=np.uint8)\n-#     one_hot_labels[np.arange(int_labels.size), int_labels] = 1\n-\n-#     # print(\"======feature_size=====\", feature.shape)\n-#     print(\"======label_size=====\", one_hot_labels)\n-#     return feature, one_hot_labels\n-\n-# data_train = DataSet.sonar\n-\n-# load_dataset(data_train.dataset_name)\n-# endregion\n-\n-\n-def generate_random():\n-    # 生成一个长度为N的随机布尔tensor\n-    random_tensor = torch.randint(0, 10)\n-    return random_tensor\n-\n-x = generate_random()\n-y = generate_random()\n-x_enc = crypten.cryptensor(x, ptype=crypten.mpc.binary)\n-y_enc = crypten.cryptensor(y, ptype=crypten.mpc.binary)\n-\n-@mpc.run_multiprocess(world_size=2)\n-def main():\n-    x = generate_random()\n-y = generate_random()\n"
                },
                {
                    "date": 1720681650107,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -78,10 +78,11 @@\n y = generate_random()\n x_enc = crypten.cryptensor(x, ptype=crypten.mpc.binary)\n y_enc = crypten.cryptensor(y, ptype=crypten.mpc.binary)\n \n-def test():\n-    \n+def test(x,y ):\n+    x_enc = crypten.cryptensor(x, ptype=crypten.mpc.binary)\n+y_enc = crypten.cryptensor(y, ptype=crypten.mpc.binary)\n \n @mpc.run_multiprocess(world_size=2)\n def main():\n     x = generate_random()\n"
                },
                {
                    "date": 1720681655898,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -79,10 +79,10 @@\n x_enc = crypten.cryptensor(x, ptype=crypten.mpc.binary)\n y_enc = crypten.cryptensor(y, ptype=crypten.mpc.binary)\n \n def test(x,y ):\n-    x_enc = crypten.cryptensor(x, ptype=crypten.mpc.binary)\n-y_enc = crypten.cryptensor(y, ptype=crypten.mpc.binary)\n+    x_enc = crypten.cryptensor(x, ptype=crypten.mpc.arithmetic)\n+    y_enc = crypten.cryptensor(y, ptype=crypten.mpc.binary)\n \n @mpc.run_multiprocess(world_size=2)\n def main():\n     x = generate_random()\n"
                },
                {
                    "date": 1720681662992,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -78,11 +78,11 @@\n y = generate_random()\n x_enc = crypten.cryptensor(x, ptype=crypten.mpc.binary)\n y_enc = crypten.cryptensor(y, ptype=crypten.mpc.binary)\n \n-def test(x,y ):\n+def test(x,y):\n     x_enc = crypten.cryptensor(x, ptype=crypten.mpc.arithmetic)\n-    y_enc = crypten.cryptensor(y, ptype=crypten.mpc.binary)\n+    y_enc = crypten.cryptensor(y, ptype=crypten.mpc.arithmetic)\n \n @mpc.run_multiprocess(world_size=2)\n def main():\n     x = generate_random()\n"
                },
                {
                    "date": 1720681669491,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -75,10 +75,8 @@\n     return random_tensor\n \n x = generate_random()\n y = generate_random()\n-x_enc = crypten.cryptensor(x, ptype=crypten.mpc.binary)\n-y_enc = crypten.cryptensor(y, ptype=crypten.mpc.binary)\n \n def test(x,y):\n     x_enc = crypten.cryptensor(x, ptype=crypten.mpc.arithmetic)\n     y_enc = crypten.cryptensor(y, ptype=crypten.mpc.arithmetic)\n@@ -86,4 +84,5 @@\n @mpc.run_multiprocess(world_size=2)\n def main():\n     x = generate_random()\n     y = generate_random()\n+    test()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1720681674576,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -79,10 +79,11 @@\n \n def test(x,y):\n     x_enc = crypten.cryptensor(x, ptype=crypten.mpc.arithmetic)\n     y_enc = crypten.cryptensor(y, ptype=crypten.mpc.arithmetic)\n+    x\n \n @mpc.run_multiprocess(world_size=2)\n def main():\n     x = generate_random()\n     y = generate_random()\n\\ No newline at end of file\n-    test()\n+    test(x,y)\n\\ No newline at end of file\n"
                },
                {
                    "date": 1720681683125,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -79,9 +79,9 @@\n \n def test(x,y):\n     x_enc = crypten.cryptensor(x, ptype=crypten.mpc.arithmetic)\n     y_enc = crypten.cryptensor(y, ptype=crypten.mpc.arithmetic)\n-    x\n+    cmp_result  = \n \n @mpc.run_multiprocess(world_size=2)\n def main():\n     x = generate_random()\n"
                },
                {
                    "date": 1720681688365,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -79,9 +79,9 @@\n \n def test(x,y):\n     x_enc = crypten.cryptensor(x, ptype=crypten.mpc.arithmetic)\n     y_enc = crypten.cryptensor(y, ptype=crypten.mpc.arithmetic)\n-    cmp_result  = \n+    cmp_result  = x_enc.ge()\n \n @mpc.run_multiprocess(world_size=2)\n def main():\n     x = generate_random()\n"
                },
                {
                    "date": 1720681707265,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -79,9 +79,10 @@\n \n def test(x,y):\n     x_enc = crypten.cryptensor(x, ptype=crypten.mpc.arithmetic)\n     y_enc = crypten.cryptensor(y, ptype=crypten.mpc.arithmetic)\n-    cmp_result  = x_enc.ge()\n+    cmp_result  = x_enc.ge(y_enc)\n+    relu\n \n @mpc.run_multiprocess(world_size=2)\n def main():\n     x = generate_random()\n"
                },
                {
                    "date": 1720681714592,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -79,10 +79,10 @@\n \n def test(x,y):\n     x_enc = crypten.cryptensor(x, ptype=crypten.mpc.arithmetic)\n     y_enc = crypten.cryptensor(y, ptype=crypten.mpc.arithmetic)\n-    cmp_result  = x_enc.ge(y_enc)\n-    relu\n+    cmp_  = x_enc.ge(y_enc)\n+    relu_\n \n @mpc.run_multiprocess(world_size=2)\n def main():\n     x = generate_random()\n"
                },
                {
                    "date": 1720681720204,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,90 @@\n+\n+import crypten\n+import torch\n+import crypten.mpc as mpc\n+import crypten.mpc.primitives.beaver as beaver\n+import crypten.communicator as comm \n+import torch\n+from crypten.mpc import MPCTensor\n+from crypten.mpc.primitives import BinarySharedTensor\n+import time\n+\n+crypten.init()\n+\n+\n+# region \n+# DATASET_DIR = os.path.join(os.path.dirname(__file__), 'dataset')\n+\n+# class DataSetParam:\n+#     def __init__(self, dataset_name):\n+#         self.dataset_name = dataset_name\n+\n+\n+# class DataSet:\n+#     sonar = DataSetParam('sonar.csv')\n+#     sonar_selected = DataSetParam('sonar_selected.csv')\n+    \n+    \n+    \n+# def load_dataset(dataset):\n+#     dataset_path = os.path.join(DATASET_DIR, dataset)\n+\n+#     # 尝试打开并读取CSV文件\n+#     try:\n+#         with open(dataset_path, 'r', encoding='utf-8') as csvfile:\n+#             spamreader = csv.reader(csvfile)\n+#             data = np.array(list(spamreader))\n+#     except FileNotFoundError:\n+#         print(f\"Error: The file {dataset_path} was not found.\")\n+#         return None, None\n+#     except Exception as e:\n+#         print(f\"Error: An error occurred while reading the file: {e}\")\n+#         return None, None\n+\n+#     # 检查数据是否为空\n+#     if data.size == 0:\n+#         print(\"Error: The dataset is empty.\")\n+#         return None, None\n+\n+#     feature = data[:, :-1].astype(np.float64)\n+#     labels = data[:, -1]\n+\n+#     # 创建标签映射\n+#     unique_labels = np.unique(labels)\n+#     label_to_int = {label: idx for idx, label in enumerate(unique_labels)}\n+#     int_labels = np.array([label_to_int[label] for label in labels], dtype=np.uint8)\n+#     labell = int_labels.reshape(-1,1)\n+\n+#     # 将标签转换为独热矩阵\n+#     one_hot_labels = np.zeros((int_labels.size, int_labels.max() + 1), dtype=np.uint8)\n+#     one_hot_labels[np.arange(int_labels.size), int_labels] = 1\n+\n+#     # print(\"======feature_size=====\", feature.shape)\n+#     print(\"======label_size=====\", one_hot_labels)\n+#     return feature, one_hot_labels\n+\n+# data_train = DataSet.sonar\n+\n+# load_dataset(data_train.dataset_name)\n+# endregion\n+\n+\n+def generate_random():\n+    # 生成一个长度为N的随机布尔tensor\n+    random_tensor = torch.randint(0, 10)\n+    return random_tensor\n+\n+x = generate_random()\n+y = generate_random()\n+\n+def test(x,y):\n+    x_enc = crypten.cryptensor(x, ptype=crypten.mpc.arithmetic)\n+    y_enc = crypten.cryptensor(y, ptype=crypten.mpc.arithmetic)\n+    cmp_  = x_enc.ge(y_enc)\n+    relu_ = cmp_\n+\n+@mpc.run_multiprocess(world_size=2)\n+def main():\n+    x = generate_random()\n+    y = generate_random()\n+    test(x,y)\n\\ No newline at end of file\n"
                },
                {
                    "date": 1720681738499,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -79,102 +79,13 @@\n \n def test(x,y):\n     x_enc = crypten.cryptensor(x, ptype=crypten.mpc.arithmetic)\n     y_enc = crypten.cryptensor(y, ptype=crypten.mpc.arithmetic)\n+    print()\n     cmp_  = x_enc.ge(y_enc)\n-    relu_ = cmp_\n+    relu_ = cmp_.relu()\n \n @mpc.run_multiprocess(world_size=2)\n def main():\n     x = generate_random()\n     y = generate_random()\n-    test(x,y)\n-\n-import crypten\n-import torch\n-import crypten.mpc as mpc\n-import crypten.mpc.primitives.beaver as beaver\n-import crypten.communicator as comm \n-import torch\n-from crypten.mpc import MPCTensor\n-from crypten.mpc.primitives import BinarySharedTensor\n-import time\n-\n-crypten.init()\n-\n-\n-# region \n-# DATASET_DIR = os.path.join(os.path.dirname(__file__), 'dataset')\n-\n-# class DataSetParam:\n-#     def __init__(self, dataset_name):\n-#         self.dataset_name = dataset_name\n-\n-\n-# class DataSet:\n-#     sonar = DataSetParam('sonar.csv')\n-#     sonar_selected = DataSetParam('sonar_selected.csv')\n-    \n-    \n-    \n-# def load_dataset(dataset):\n-#     dataset_path = os.path.join(DATASET_DIR, dataset)\n-\n-#     # 尝试打开并读取CSV文件\n-#     try:\n-#         with open(dataset_path, 'r', encoding='utf-8') as csvfile:\n-#             spamreader = csv.reader(csvfile)\n-#             data = np.array(list(spamreader))\n-#     except FileNotFoundError:\n-#         print(f\"Error: The file {dataset_path} was not found.\")\n-#         return None, None\n-#     except Exception as e:\n-#         print(f\"Error: An error occurred while reading the file: {e}\")\n-#         return None, None\n-\n-#     # 检查数据是否为空\n-#     if data.size == 0:\n-#         print(\"Error: The dataset is empty.\")\n-#         return None, None\n-\n-#     feature = data[:, :-1].astype(np.float64)\n-#     labels = data[:, -1]\n-\n-#     # 创建标签映射\n-#     unique_labels = np.unique(labels)\n-#     label_to_int = {label: idx for idx, label in enumerate(unique_labels)}\n-#     int_labels = np.array([label_to_int[label] for label in labels], dtype=np.uint8)\n-#     labell = int_labels.reshape(-1,1)\n-\n-#     # 将标签转换为独热矩阵\n-#     one_hot_labels = np.zeros((int_labels.size, int_labels.max() + 1), dtype=np.uint8)\n-#     one_hot_labels[np.arange(int_labels.size), int_labels] = 1\n-\n-#     # print(\"======feature_size=====\", feature.shape)\n-#     print(\"======label_size=====\", one_hot_labels)\n-#     return feature, one_hot_labels\n-\n-# data_train = DataSet.sonar\n-\n-# load_dataset(data_train.dataset_name)\n-# endregion\n-\n-\n-def generate_random():\n-    # 生成一个长度为N的随机布尔tensor\n-    random_tensor = torch.randint(0, 10)\n-    return random_tensor\n-\n-x = generate_random()\n-y = generate_random()\n-\n-def test(x,y):\n-    x_enc = crypten.cryptensor(x, ptype=crypten.mpc.arithmetic)\n-    y_enc = crypten.cryptensor(y, ptype=crypten.mpc.arithmetic)\n-    cmp_  = x_enc.ge(y_enc)\n-    relu_\n-\n-@mpc.run_multiprocess(world_size=2)\n-def main():\n-    x = generate_random()\n-    y = generate_random()\n     test(x,y)\n\\ No newline at end of file\n"
                },
                {
                    "date": 1720681751013,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -79,9 +79,9 @@\n \n def test(x,y):\n     x_enc = crypten.cryptensor(x, ptype=crypten.mpc.arithmetic)\n     y_enc = crypten.cryptensor(y, ptype=crypten.mpc.arithmetic)\n-    print()\n+    cmp_time = time.time()\n     cmp_  = x_enc.ge(y_enc)\n     relu_ = cmp_.relu()\n \n @mpc.run_multiprocess(world_size=2)\n"
                },
                {
                    "date": 1720681765505,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -81,8 +81,10 @@\n     x_enc = crypten.cryptensor(x, ptype=crypten.mpc.arithmetic)\n     y_enc = crypten.cryptensor(y, ptype=crypten.mpc.arithmetic)\n     cmp_time = time.time()\n     cmp_  = x_enc.ge(y_enc)\n+    cmp_time_end = time.time()\n+    cmp_time = \n     relu_ = cmp_.relu()\n \n @mpc.run_multiprocess(world_size=2)\n def main():\n"
                },
                {
                    "date": 1720681772928,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -79,12 +79,12 @@\n \n def test(x,y):\n     x_enc = crypten.cryptensor(x, ptype=crypten.mpc.arithmetic)\n     y_enc = crypten.cryptensor(y, ptype=crypten.mpc.arithmetic)\n-    cmp_time = time.time()\n+    cmp_time_begin = time.time()\n     cmp_  = x_enc.ge(y_enc)\n     cmp_time_end = time.time()\n-    cmp_time = \n+    cmp_time = cmp_time_end - cmp_time_begin\n     relu_ = cmp_.relu()\n \n @mpc.run_multiprocess(world_size=2)\n def main():\n"
                },
                {
                    "date": 1720681778758,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -83,8 +83,10 @@\n     cmp_time_begin = time.time()\n     cmp_  = x_enc.ge(y_enc)\n     cmp_time_end = time.time()\n     cmp_time = cmp_time_end - cmp_time_begin\n+    \n+    cmp_time_begin = time.time()\n     relu_ = cmp_.relu()\n \n @mpc.run_multiprocess(world_size=2)\n def main():\n"
                },
                {
                    "date": 1720681786171,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -84,10 +84,12 @@\n     cmp_  = x_enc.ge(y_enc)\n     cmp_time_end = time.time()\n     cmp_time = cmp_time_end - cmp_time_begin\n     \n-    cmp_time_begin = time.time()\n+    relu_time_begin = time.time()\n     relu_ = cmp_.relu()\n+    cmp_time_end = time.time()\n+    cmp_time = cmp_time_end - cmp_time_begin\n \n @mpc.run_multiprocess(world_size=2)\n def main():\n     x = generate_random()\n"
                },
                {
                    "date": 1720681793813,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -86,10 +86,10 @@\n     cmp_time = cmp_time_end - cmp_time_begin\n     \n     relu_time_begin = time.time()\n     relu_ = cmp_.relu()\n-    cmp_time_end = time.time()\n-    cmp_time = cmp_time_end - cmp_time_begin\n+    relu_time_end = time.time()\n+    relu_time = cmp_time_end - cmp_time_begin\n \n @mpc.run_multiprocess(world_size=2)\n def main():\n     x = generate_random()\n"
                },
                {
                    "date": 1720681935826,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -7,8 +7,9 @@\n import torch\n from crypten.mpc import MPCTensor\n from crypten.mpc.primitives import BinarySharedTensor\n import time\n+crypten.common.functions\n \n crypten.init()\n \n \n@@ -87,9 +88,9 @@\n     \n     relu_time_begin = time.time()\n     relu_ = cmp_.relu()\n     relu_time_end = time.time()\n-    relu_time = cmp_time_end - cmp_time_begin\n+    relu_time = relu_time_end - relu_time_begin\n \n @mpc.run_multiprocess(world_size=2)\n def main():\n     x = generate_random()\n"
                },
                {
                    "date": 1720681967137,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -7,9 +7,9 @@\n import torch\n from crypten.mpc import MPCTensor\n from crypten.mpc.primitives import BinarySharedTensor\n import time\n-crypten.common.functions\n+import crypten.common.functions\n \n crypten.init()\n \n \n@@ -76,9 +76,9 @@\n     return random_tensor\n \n x = generate_random()\n y = generate_random()\n-\n+@mpc.run_multiprocess(world_size=2)\n def test(x,y):\n     x_enc = crypten.cryptensor(x, ptype=crypten.mpc.arithmetic)\n     y_enc = crypten.cryptensor(y, ptype=crypten.mpc.arithmetic)\n     cmp_time_begin = time.time()\n@@ -90,9 +90,9 @@\n     relu_ = cmp_.relu()\n     relu_time_end = time.time()\n     relu_time = relu_time_end - relu_time_begin\n \n-@mpc.run_multiprocess(world_size=2)\n+\n def main():\n     x = generate_random()\n     y = generate_random()\n     test(x,y)\n\\ No newline at end of file\n"
                },
                {
                    "date": 1720681990548,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -71,13 +71,14 @@\n \n \n def generate_random():\n     # 生成一个长度为N的随机布尔tensor\n-    random_tensor = torch.randint(0, 10)\n+    random_tensor = random..randint(0, 10)\n     return random_tensor\n \n x = generate_random()\n y = generate_random()\n+\n @mpc.run_multiprocess(world_size=2)\n def test(x,y):\n     x_enc = crypten.cryptensor(x, ptype=crypten.mpc.arithmetic)\n     y_enc = crypten.cryptensor(y, ptype=crypten.mpc.arithmetic)\n"
                },
                {
                    "date": 1720681997177,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -7,8 +7,9 @@\n import torch\n from crypten.mpc import MPCTensor\n from crypten.mpc.primitives import BinarySharedTensor\n import time\n+import random\n import crypten.common.functions\n \n crypten.init()\n \n@@ -71,9 +72,9 @@\n \n \n def generate_random():\n     # 生成一个长度为N的随机布尔tensor\n-    random_tensor = random..randint(0, 10)\n+    random_tensor = random.randint(0, 10)\n     return random_tensor\n \n x = generate_random()\n y = generate_random()\n"
                },
                {
                    "date": 1720682005278,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -86,8 +86,9 @@\n     cmp_time_begin = time.time()\n     cmp_  = x_enc.ge(y_enc)\n     cmp_time_end = time.time()\n     cmp_time = cmp_time_end - cmp_time_begin\n+    print()\n     \n     relu_time_begin = time.time()\n     relu_ = cmp_.relu()\n     relu_time_end = time.time()\n"
                },
                {
                    "date": 1720682010312,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -86,14 +86,15 @@\n     cmp_time_begin = time.time()\n     cmp_  = x_enc.ge(y_enc)\n     cmp_time_end = time.time()\n     cmp_time = cmp_time_end - cmp_time_begin\n-    print()\n+    print(cmp_time)\n     \n     relu_time_begin = time.time()\n     relu_ = cmp_.relu()\n     relu_time_end = time.time()\n     relu_time = relu_time_end - relu_time_begin\n+    print(re)\n \n \n def main():\n     x = generate_random()\n"
                },
                {
                    "date": 1720682033411,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,102 @@\n+\n+import crypten\n+import torch\n+import crypten.mpc as mpc\n+import crypten.mpc.primitives.beaver as beaver\n+import crypten.communicator as comm \n+import torch\n+from crypten.mpc import MPCTensor\n+from crypten.mpc.primitives import BinarySharedTensor\n+import time\n+import random\n+import crypten.common.functions\n+\n+crypten.init()\n+\n+\n+# region \n+# DATASET_DIR = os.path.join(os.path.dirname(__file__), 'dataset')\n+\n+# class DataSetParam:\n+#     def __init__(self, dataset_name):\n+#         self.dataset_name = dataset_name\n+\n+\n+# class DataSet:\n+#     sonar = DataSetParam('sonar.csv')\n+#     sonar_selected = DataSetParam('sonar_selected.csv')\n+    \n+    \n+    \n+# def load_dataset(dataset):\n+#     dataset_path = os.path.join(DATASET_DIR, dataset)\n+\n+#     # 尝试打开并读取CSV文件\n+#     try:\n+#         with open(dataset_path, 'r', encoding='utf-8') as csvfile:\n+#             spamreader = csv.reader(csvfile)\n+#             data = np.array(list(spamreader))\n+#     except FileNotFoundError:\n+#         print(f\"Error: The file {dataset_path} was not found.\")\n+#         return None, None\n+#     except Exception as e:\n+#         print(f\"Error: An error occurred while reading the file: {e}\")\n+#         return None, None\n+\n+#     # 检查数据是否为空\n+#     if data.size == 0:\n+#         print(\"Error: The dataset is empty.\")\n+#         return None, None\n+\n+#     feature = data[:, :-1].astype(np.float64)\n+#     labels = data[:, -1]\n+\n+#     # 创建标签映射\n+#     unique_labels = np.unique(labels)\n+#     label_to_int = {label: idx for idx, label in enumerate(unique_labels)}\n+#     int_labels = np.array([label_to_int[label] for label in labels], dtype=np.uint8)\n+#     labell = int_labels.reshape(-1,1)\n+\n+#     # 将标签转换为独热矩阵\n+#     one_hot_labels = np.zeros((int_labels.size, int_labels.max() + 1), dtype=np.uint8)\n+#     one_hot_labels[np.arange(int_labels.size), int_labels] = 1\n+\n+#     # print(\"======feature_size=====\", feature.shape)\n+#     print(\"======label_size=====\", one_hot_labels)\n+#     return feature, one_hot_labels\n+\n+# data_train = DataSet.sonar\n+\n+# load_dataset(data_train.dataset_name)\n+# endregion\n+\n+\n+def generate_random():\n+    # 生成一个长度为N的随机布尔tensor\n+    random_tensor = random.randint(0, 10)\n+    return random_tensor\n+\n+x = generate_random()\n+y = generate_random()\n+\n+@mpc.run_multiprocess(world_size=2)\n+def test(x,y):\n+    x_enc = crypten.cryptensor(x, ptype=crypten.mpc.arithmetic)\n+    y_enc = crypten.cryptensor(y, ptype=crypten.mpc.arithmetic)\n+    cmp_time_begin = time.time()\n+    cmp_  = x_enc.ge(y_enc)\n+    cmp_time_end = time.time()\n+    cmp_time = cmp_time_end - cmp_time_begin\n+    print(\"cmp_time)\n+    \n+    relu_time_begin = time.time()\n+    relu_ = cmp_.relu()\n+    relu_time_end = time.time()\n+    relu_time = relu_time_end - relu_time_begin\n+    print(relu_time)\n+\n+\n+def main():\n+    x = generate_random()\n+    y = generate_random()\n+    test(x,y)\n\\ No newline at end of file\n"
                },
                {
                    "date": 1720682039756,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -86,119 +86,17 @@\n     cmp_time_begin = time.time()\n     cmp_  = x_enc.ge(y_enc)\n     cmp_time_end = time.time()\n     cmp_time = cmp_time_end - cmp_time_begin\n-    print(\"cmp_time)\n+    print(\"cmp_time\", cmp_time)\n     \n     relu_time_begin = time.time()\n     relu_ = cmp_.relu()\n     relu_time_end = time.time()\n     relu_time = relu_time_end - relu_time_begin\n-    print(relu_time)\n+    print(\"r\"elu_time)\n \n \n def main():\n     x = generate_random()\n     y = generate_random()\n-    test(x,y)\n-\n-import crypten\n-import torch\n-import crypten.mpc as mpc\n-import crypten.mpc.primitives.beaver as beaver\n-import crypten.communicator as comm \n-import torch\n-from crypten.mpc import MPCTensor\n-from crypten.mpc.primitives import BinarySharedTensor\n-import time\n-import random\n-import crypten.common.functions\n-\n-crypten.init()\n-\n-\n-# region \n-# DATASET_DIR = os.path.join(os.path.dirname(__file__), 'dataset')\n-\n-# class DataSetParam:\n-#     def __init__(self, dataset_name):\n-#         self.dataset_name = dataset_name\n-\n-\n-# class DataSet:\n-#     sonar = DataSetParam('sonar.csv')\n-#     sonar_selected = DataSetParam('sonar_selected.csv')\n-    \n-    \n-    \n-# def load_dataset(dataset):\n-#     dataset_path = os.path.join(DATASET_DIR, dataset)\n-\n-#     # 尝试打开并读取CSV文件\n-#     try:\n-#         with open(dataset_path, 'r', encoding='utf-8') as csvfile:\n-#             spamreader = csv.reader(csvfile)\n-#             data = np.array(list(spamreader))\n-#     except FileNotFoundError:\n-#         print(f\"Error: The file {dataset_path} was not found.\")\n-#         return None, None\n-#     except Exception as e:\n-#         print(f\"Error: An error occurred while reading the file: {e}\")\n-#         return None, None\n-\n-#     # 检查数据是否为空\n-#     if data.size == 0:\n-#         print(\"Error: The dataset is empty.\")\n-#         return None, None\n-\n-#     feature = data[:, :-1].astype(np.float64)\n-#     labels = data[:, -1]\n-\n-#     # 创建标签映射\n-#     unique_labels = np.unique(labels)\n-#     label_to_int = {label: idx for idx, label in enumerate(unique_labels)}\n-#     int_labels = np.array([label_to_int[label] for label in labels], dtype=np.uint8)\n-#     labell = int_labels.reshape(-1,1)\n-\n-#     # 将标签转换为独热矩阵\n-#     one_hot_labels = np.zeros((int_labels.size, int_labels.max() + 1), dtype=np.uint8)\n-#     one_hot_labels[np.arange(int_labels.size), int_labels] = 1\n-\n-#     # print(\"======feature_size=====\", feature.shape)\n-#     print(\"======label_size=====\", one_hot_labels)\n-#     return feature, one_hot_labels\n-\n-# data_train = DataSet.sonar\n-\n-# load_dataset(data_train.dataset_name)\n-# endregion\n-\n-\n-def generate_random():\n-    # 生成一个长度为N的随机布尔tensor\n-    random_tensor = random.randint(0, 10)\n-    return random_tensor\n-\n-x = generate_random()\n-y = generate_random()\n-\n-@mpc.run_multiprocess(world_size=2)\n-def test(x,y):\n-    x_enc = crypten.cryptensor(x, ptype=crypten.mpc.arithmetic)\n-    y_enc = crypten.cryptensor(y, ptype=crypten.mpc.arithmetic)\n-    cmp_time_begin = time.time()\n-    cmp_  = x_enc.ge(y_enc)\n-    cmp_time_end = time.time()\n-    cmp_time = cmp_time_end - cmp_time_begin\n-    print(cmp_time)\n-    \n-    relu_time_begin = time.time()\n-    relu_ = cmp_.relu()\n-    relu_time_end = time.time()\n-    relu_time = relu_time_end - relu_time_begin\n-    print(re)\n-\n-\n-def main():\n-    x = generate_random()\n-    y = generate_random()\n     test(x,y)\n\\ No newline at end of file\n"
                },
                {
                    "date": 1720682049321,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -92,9 +92,9 @@\n     relu_time_begin = time.time()\n     relu_ = cmp_.relu()\n     relu_time_end = time.time()\n     relu_time = relu_time_end - relu_time_begin\n-    print(\"r\"elu_time)\n+    print(\"relu_time\", relu_time)\n \n \n def main():\n     x = generate_random()\n"
                },
                {
                    "date": 1720682062693,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -75,11 +75,8 @@\n     # 生成一个长度为N的随机布尔tensor\n     random_tensor = random.randint(0, 10)\n     return random_tensor\n \n-x = generate_random()\n-y = generate_random()\n-\n @mpc.run_multiprocess(world_size=2)\n def test(x,y):\n     x_enc = crypten.cryptensor(x, ptype=crypten.mpc.arithmetic)\n     y_enc = crypten.cryptensor(y, ptype=crypten.mpc.arithmetic)\n"
                },
                {
                    "date": 1720682099863,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -95,5 +95,7 @@\n \n def main():\n     x = generate_random()\n     y = generate_random()\n+    print(\"x\", x)\n+    \n     test(x,y)\n\\ No newline at end of file\n"
                },
                {
                    "date": 1720682241729,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -96,6 +96,6 @@\n def main():\n     x = generate_random()\n     y = generate_random()\n     print(\"x\", x)\n-    \n+    print(\"y\", y)\n     test(x,y)\n\\ No newline at end of file\n"
                },
                {
                    "date": 1720682400347,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -85,8 +85,14 @@\n     cmp_time_end = time.time()\n     cmp_time = cmp_time_end - cmp_time_begin\n     print(\"cmp_time\", cmp_time)\n     \n+    cmp_time_begin = time.time()\n+    cmp_  = x_enc.ge(y_enc)\n+    cmp_time_end = time.time()\n+    cmp_time = cmp_time_end - cmp_time_begin\n+    print(\"cmp_time\", cmp_time)\n+    \n     relu_time_begin = time.time()\n     relu_ = cmp_.relu()\n     relu_time_end = time.time()\n     relu_time = relu_time_end - relu_time_begin\n@@ -97,5 +103,7 @@\n     x = generate_random()\n     y = generate_random()\n     print(\"x\", x)\n     print(\"y\", y)\n-    test(x,y)\n\\ No newline at end of file\n+    test(x,y)\n+\n+main()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1720682412750,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -79,16 +79,16 @@\n @mpc.run_multiprocess(world_size=2)\n def test(x,y):\n     x_enc = crypten.cryptensor(x, ptype=crypten.mpc.arithmetic)\n     y_enc = crypten.cryptensor(y, ptype=crypten.mpc.arithmetic)\n-    cmp_time_begin = time.time()\n+    ge_time_begin = time.time()\n     cmp_  = x_enc.ge(y_enc)\n     cmp_time_end = time.time()\n     cmp_time = cmp_time_end - cmp_time_begin\n     print(\"cmp_time\", cmp_time)\n     \n     cmp_time_begin = time.time()\n-    cmp_  = x_enc.ge(y_enc)\n+    cmp_  = x_enc.gt(y_enc)\n     cmp_time_end = time.time()\n     cmp_time = cmp_time_end - cmp_time_begin\n     print(\"cmp_time\", cmp_time)\n     \n"
                },
                {
                    "date": 1720682418505,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -80,11 +80,11 @@\n def test(x,y):\n     x_enc = crypten.cryptensor(x, ptype=crypten.mpc.arithmetic)\n     y_enc = crypten.cryptensor(y, ptype=crypten.mpc.arithmetic)\n     ge_time_begin = time.time()\n-    cmp_  = x_enc.ge(y_enc)\n-    cmp_time_end = time.time()\n-    cmp_time = cmp_time_end - cmp_time_begin\n+    ge_  = x_enc.ge(y_enc)\n+    ge_time_end = time.time()\n+    ge_time = cmp_time_end - cmp_time_begin\n     print(\"cmp_time\", cmp_time)\n     \n     cmp_time_begin = time.time()\n     cmp_  = x_enc.gt(y_enc)\n"
                },
                {
                    "date": 1720682424232,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -82,10 +82,10 @@\n     y_enc = crypten.cryptensor(y, ptype=crypten.mpc.arithmetic)\n     ge_time_begin = time.time()\n     ge_  = x_enc.ge(y_enc)\n     ge_time_end = time.time()\n-    ge_time = cmp_time_end - cmp_time_begin\n-    print(\"cmp_time\", cmp_time)\n+    ge_time = ge_time_end - ge_time_begin\n+    print(\"ge_time\", cmp_time)\n     \n     cmp_time_begin = time.time()\n     cmp_  = x_enc.gt(y_enc)\n     cmp_time_end = time.time()\n"
                },
                {
                    "date": 1720682430528,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -83,11 +83,11 @@\n     ge_time_begin = time.time()\n     ge_  = x_enc.ge(y_enc)\n     ge_time_end = time.time()\n     ge_time = ge_time_end - ge_time_begin\n-    print(\"ge_time\", cmp_time)\n+    print(\"ge_time\", ge_time)\n     \n-    cmp_time_begin = time.time()\n+    gt_time_begin = time.time()\n     cmp_  = x_enc.gt(y_enc)\n     cmp_time_end = time.time()\n     cmp_time = cmp_time_end - cmp_time_begin\n     print(\"cmp_time\", cmp_time)\n"
                },
                {
                    "date": 1720682436794,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -86,11 +86,11 @@\n     ge_time = ge_time_end - ge_time_begin\n     print(\"ge_time\", ge_time)\n     \n     gt_time_begin = time.time()\n-    cmp_  = x_enc.gt(y_enc)\n-    cmp_time_end = time.time()\n-    cmp_time = cmp_time_end - cmp_time_begin\n+    gt_  = x_enc.gt(y_enc)\n+    gt_time_end = time.time()\n+    gt_time = cmp_time_end - cmp_time_begin\n     print(\"cmp_time\", cmp_time)\n     \n     relu_time_begin = time.time()\n     relu_ = cmp_.relu()\n"
                },
                {
                    "date": 1720682443798,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -88,10 +88,10 @@\n     \n     gt_time_begin = time.time()\n     gt_  = x_enc.gt(y_enc)\n     gt_time_end = time.time()\n-    gt_time = cmp_time_end - cmp_time_begin\n-    print(\"cmp_time\", cmp_time)\n+    gt_time = gt_time_end - gt_time_begin\n+    print(\"cmp_time\", gt_time)\n     \n     relu_time_begin = time.time()\n     relu_ = cmp_.relu()\n     relu_time_end = time.time()\n"
                },
                {
                    "date": 1720682452365,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -89,12 +89,12 @@\n     gt_time_begin = time.time()\n     gt_  = x_enc.gt(y_enc)\n     gt_time_end = time.time()\n     gt_time = gt_time_end - gt_time_begin\n-    print(\"cmp_time\", gt_time)\n+    print(\"gt_time\", gt_time)\n     \n     relu_time_begin = time.time()\n-    relu_ = cmp_.relu()\n+    relu_ = ge_.relu()\n     relu_time_end = time.time()\n     relu_time = relu_time_end - relu_time_begin\n     print(\"relu_time\", relu_time)\n \n"
                },
                {
                    "date": 1721117210025,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -77,27 +77,29 @@\n     return random_tensor\n \n @mpc.run_multiprocess(world_size=2)\n def test(x,y):\n-    x_enc = crypten.cryptensor(x, ptype=crypten.mpc.arithmetic)\n-    y_enc = crypten.cryptensor(y, ptype=crypten.mpc.arithmetic)\n-    ge_time_begin = time.time()\n-    ge_  = x_enc.ge(y_enc)\n-    ge_time_end = time.time()\n-    ge_time = ge_time_end - ge_time_begin\n-    print(\"ge_time\", ge_time)\n+# region \n+    # x_enc = crypten.cryptensor(x, ptype=crypten.mpc.arithmetic)\n+    # y_enc = crypten.cryptensor(y, ptype=crypten.mpc.arithmetic)\n+    # ge_time_begin = time.time()\n+    # ge_  = x_enc.ge(y_enc)\n+    # ge_time_end = time.time()\n+    # ge_time = ge_time_end - ge_time_begin\n+    # print(\"ge_time\", ge_time)\n     \n-    gt_time_begin = time.time()\n-    gt_  = x_enc.gt(y_enc)\n-    gt_time_end = time.time()\n-    gt_time = gt_time_end - gt_time_begin\n-    print(\"gt_time\", gt_time)\n+    # gt_time_begin = time.time()\n+    # gt_  = x_enc.gt(y_enc)\n+    # gt_time_end = time.time()\n+    # gt_time = gt_time_end - gt_time_begin\n+    # print(\"gt_time\", gt_time)\n     \n-    relu_time_begin = time.time()\n-    relu_ = ge_.relu()\n-    relu_time_end = time.time()\n-    relu_time = relu_time_end - relu_time_begin\n-    print(\"relu_time\", relu_time)\n+    # relu_time_begin = time.time()\n+    # relu_ = ge_.relu()\n+    # relu_time_end = time.time()\n+    # relu_time = relu_time_end - relu_time_begin\n+    # print(\"relu_time\", relu_time)\n+# endregion\n \n \n def main():\n     x = generate_random()\n"
                },
                {
                    "date": 1721117227715,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -71,9 +71,8 @@\n # endregion\n \n \n def generate_random():\n-    # 生成一个长度为N的随机布尔tensor\n     random_tensor = random.randint(0, 10)\n     return random_tensor\n \n @mpc.run_multiprocess(world_size=2)\n"
                },
                {
                    "date": 1721117233004,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -101,10 +101,10 @@\n \n \n def main():\n     x = generate_random()\n-    y = generate_random()\n+    # y = generate_random()\n     print(\"x\", x)\n-    print(\"y\", y)\n+    # print(\"y\", y)\n     test(x,y)\n \n main()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1721117238141,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,110 @@\n+\n+import crypten\n+import torch\n+import crypten.mpc as mpc\n+import crypten.mpc.primitives.beaver as beaver\n+import crypten.communicator as comm \n+import torch\n+from crypten.mpc import MPCTensor\n+from crypten.mpc.primitives import BinarySharedTensor\n+import time\n+import random\n+import crypten.common.functions\n+\n+crypten.init()\n+\n+\n+# region \n+# DATASET_DIR = os.path.join(os.path.dirname(__file__), 'dataset')\n+\n+# class DataSetParam:\n+#     def __init__(self, dataset_name):\n+#         self.dataset_name = dataset_name\n+\n+\n+# class DataSet:\n+#     sonar = DataSetParam('sonar.csv')\n+#     sonar_selected = DataSetParam('sonar_selected.csv')\n+    \n+    \n+    \n+# def load_dataset(dataset):\n+#     dataset_path = os.path.join(DATASET_DIR, dataset)\n+\n+#     # 尝试打开并读取CSV文件\n+#     try:\n+#         with open(dataset_path, 'r', encoding='utf-8') as csvfile:\n+#             spamreader = csv.reader(csvfile)\n+#             data = np.array(list(spamreader))\n+#     except FileNotFoundError:\n+#         print(f\"Error: The file {dataset_path} was not found.\")\n+#         return None, None\n+#     except Exception as e:\n+#         print(f\"Error: An error occurred while reading the file: {e}\")\n+#         return None, None\n+\n+#     # 检查数据是否为空\n+#     if data.size == 0:\n+#         print(\"Error: The dataset is empty.\")\n+#         return None, None\n+\n+#     feature = data[:, :-1].astype(np.float64)\n+#     labels = data[:, -1]\n+\n+#     # 创建标签映射\n+#     unique_labels = np.unique(labels)\n+#     label_to_int = {label: idx for idx, label in enumerate(unique_labels)}\n+#     int_labels = np.array([label_to_int[label] for label in labels], dtype=np.uint8)\n+#     labell = int_labels.reshape(-1,1)\n+\n+#     # 将标签转换为独热矩阵\n+#     one_hot_labels = np.zeros((int_labels.size, int_labels.max() + 1), dtype=np.uint8)\n+#     one_hot_labels[np.arange(int_labels.size), int_labels] = 1\n+\n+#     # print(\"======feature_size=====\", feature.shape)\n+#     print(\"======label_size=====\", one_hot_labels)\n+#     return feature, one_hot_labels\n+\n+# data_train = DataSet.sonar\n+\n+# load_dataset(data_train.dataset_name)\n+# endregion\n+\n+\n+def generate_random():\n+    random_tensor = random.randint(0, 10)\n+    return random_tensor\n+\n+@mpc.run_multiprocess(world_size=2)\n+def test(x,y):\n+# region \n+    # x_enc = crypten.cryptensor(x, ptype=crypten.mpc.arithmetic)\n+    # y_enc = crypten.cryptensor(y, ptype=crypten.mpc.arithmetic)\n+    # ge_time_begin = time.time()\n+    # ge_  = x_enc.ge(y_enc)\n+    # ge_time_end = time.time()\n+    # ge_time = ge_time_end - ge_time_begin\n+    # print(\"ge_time\", ge_time)\n+    \n+    # gt_time_begin = time.time()\n+    # gt_  = x_enc.gt(y_enc)\n+    # gt_time_end = time.time()\n+    # gt_time = gt_time_end - gt_time_begin\n+    # print(\"gt_time\", gt_time)\n+    \n+    # relu_time_begin = time.time()\n+    # relu_ = ge_.relu()\n+    # relu_time_end = time.time()\n+    # relu_time = relu_time_end - relu_time_begin\n+    # print(\"relu_time\", relu_time)\n+# endregion\n+\n+\n+def main():\n+    x = generate_random()\n+    # y = generate_random()\n+    print(\"x\", x)\n+    print(\"y\", y)\n+    test(x,y)\n+\n+main()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1721117244142,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -73,122 +73,12 @@\n \n def generate_random():\n     random_tensor = random.randint(0, 10)\n     return random_tensor\n-\n+# region \n @mpc.run_multiprocess(world_size=2)\n def test(x,y):\n-# region \n-    # x_enc = crypten.cryptensor(x, ptype=crypten.mpc.arithmetic)\n-    # y_enc = crypten.cryptensor(y, ptype=crypten.mpc.arithmetic)\n-    # ge_time_begin = time.time()\n-    # ge_  = x_enc.ge(y_enc)\n-    # ge_time_end = time.time()\n-    # ge_time = ge_time_end - ge_time_begin\n-    # print(\"ge_time\", ge_time)\n-    \n-    # gt_time_begin = time.time()\n-    # gt_  = x_enc.gt(y_enc)\n-    # gt_time_end = time.time()\n-    # gt_time = gt_time_end - gt_time_begin\n-    # print(\"gt_time\", gt_time)\n-    \n-    # relu_time_begin = time.time()\n-    # relu_ = ge_.relu()\n-    # relu_time_end = time.time()\n-    # relu_time = relu_time_end - relu_time_begin\n-    # print(\"relu_time\", relu_time)\n-# endregion\n \n-\n-def main():\n-    x = generate_random()\n-    # y = generate_random()\n-    print(\"x\", x)\n-    print(\"y\", y)\n-    test(x,y)\n-\n-main()\n-\n-import crypten\n-import torch\n-import crypten.mpc as mpc\n-import crypten.mpc.primitives.beaver as beaver\n-import crypten.communicator as comm \n-import torch\n-from crypten.mpc import MPCTensor\n-from crypten.mpc.primitives import BinarySharedTensor\n-import time\n-import random\n-import crypten.common.functions\n-\n-crypten.init()\n-\n-\n-# region \n-# DATASET_DIR = os.path.join(os.path.dirname(__file__), 'dataset')\n-\n-# class DataSetParam:\n-#     def __init__(self, dataset_name):\n-#         self.dataset_name = dataset_name\n-\n-\n-# class DataSet:\n-#     sonar = DataSetParam('sonar.csv')\n-#     sonar_selected = DataSetParam('sonar_selected.csv')\n-    \n-    \n-    \n-# def load_dataset(dataset):\n-#     dataset_path = os.path.join(DATASET_DIR, dataset)\n-\n-#     # 尝试打开并读取CSV文件\n-#     try:\n-#         with open(dataset_path, 'r', encoding='utf-8') as csvfile:\n-#             spamreader = csv.reader(csvfile)\n-#             data = np.array(list(spamreader))\n-#     except FileNotFoundError:\n-#         print(f\"Error: The file {dataset_path} was not found.\")\n-#         return None, None\n-#     except Exception as e:\n-#         print(f\"Error: An error occurred while reading the file: {e}\")\n-#         return None, None\n-\n-#     # 检查数据是否为空\n-#     if data.size == 0:\n-#         print(\"Error: The dataset is empty.\")\n-#         return None, None\n-\n-#     feature = data[:, :-1].astype(np.float64)\n-#     labels = data[:, -1]\n-\n-#     # 创建标签映射\n-#     unique_labels = np.unique(labels)\n-#     label_to_int = {label: idx for idx, label in enumerate(unique_labels)}\n-#     int_labels = np.array([label_to_int[label] for label in labels], dtype=np.uint8)\n-#     labell = int_labels.reshape(-1,1)\n-\n-#     # 将标签转换为独热矩阵\n-#     one_hot_labels = np.zeros((int_labels.size, int_labels.max() + 1), dtype=np.uint8)\n-#     one_hot_labels[np.arange(int_labels.size), int_labels] = 1\n-\n-#     # print(\"======feature_size=====\", feature.shape)\n-#     print(\"======label_size=====\", one_hot_labels)\n-#     return feature, one_hot_labels\n-\n-# data_train = DataSet.sonar\n-\n-# load_dataset(data_train.dataset_name)\n-# endregion\n-\n-\n-def generate_random():\n-    random_tensor = random.randint(0, 10)\n-    return random_tensor\n-\n-@mpc.run_multiprocess(world_size=2)\n-def test(x,y):\n-# region \n     # x_enc = crypten.cryptensor(x, ptype=crypten.mpc.arithmetic)\n     # y_enc = crypten.cryptensor(y, ptype=crypten.mpc.arithmetic)\n     # ge_time_begin = time.time()\n     # ge_  = x_enc.ge(y_enc)\n"
                },
                {
                    "date": 1721117250122,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -73,12 +73,12 @@\n \n def generate_random():\n     random_tensor = random.randint(0, 10)\n     return random_tensor\n+\n # region \n-@mpc.run_multiprocess(world_size=2)\n-def test(x,y):\n-\n+# @mpc.run_multiprocess(world_size=2)\n+# def test(x,y):\n     # x_enc = crypten.cryptensor(x, ptype=crypten.mpc.arithmetic)\n     # y_enc = crypten.cryptensor(y, ptype=crypten.mpc.arithmetic)\n     # ge_time_begin = time.time()\n     # ge_  = x_enc.ge(y_enc)\n"
                },
                {
                    "date": 1721117256611,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -98,9 +98,14 @@\n     # relu_time = relu_time_end - relu_time_begin\n     # print(\"relu_time\", relu_time)\n # endregion\n \n+# @mpc.run_multiprocess(world_size=2)\n \n+\n+\n+\n+\n def main():\n     x = generate_random()\n     # y = generate_random()\n     print(\"x\", x)\n"
                },
                {
                    "date": 1721117264864,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -98,14 +98,14 @@\n     # relu_time = relu_time_end - relu_time_begin\n     # print(\"relu_time\", relu_time)\n # endregion\n \n-# @mpc.run_multiprocess(world_size=2)\n+@mpc.run_multiprocess(world_size=2)\n+def test()\n \n \n \n \n-\n def main():\n     x = generate_random()\n     # y = generate_random()\n     print(\"x\", x)\n"
                },
                {
                    "date": 1721117271802,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -99,9 +99,11 @@\n     # print(\"relu_time\", relu_time)\n # endregion\n \n @mpc.run_multiprocess(world_size=2)\n-def test()\n+def test(x):\n+    \n+    \n \n \n \n \n@@ -109,7 +111,7 @@\n     x = generate_random()\n     # y = generate_random()\n     print(\"x\", x)\n     # print(\"y\", y)\n-    test(x,y)\n+    test(x)\n \n main()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1721117285568,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,117 @@\n+\n+import crypten\n+import torch\n+import crypten.mpc as mpc\n+import crypten.mpc.primitives.beaver as beaver\n+import crypten.communicator as comm \n+import torch\n+from crypten.mpc import MPCTensor\n+from crypten.mpc.primitives import BinarySharedTensor\n+import time\n+import random\n+import crypten.common.functions\n+\n+crypten.init()\n+\n+\n+# region \n+# DATASET_DIR = os.path.join(os.path.dirname(__file__), 'dataset')\n+\n+# class DataSetParam:\n+#     def __init__(self, dataset_name):\n+#         self.dataset_name = dataset_name\n+\n+\n+# class DataSet:\n+#     sonar = DataSetParam('sonar.csv')\n+#     sonar_selected = DataSetParam('sonar_selected.csv')\n+    \n+    \n+    \n+# def load_dataset(dataset):\n+#     dataset_path = os.path.join(DATASET_DIR, dataset)\n+\n+#     # 尝试打开并读取CSV文件\n+#     try:\n+#         with open(dataset_path, 'r', encoding='utf-8') as csvfile:\n+#             spamreader = csv.reader(csvfile)\n+#             data = np.array(list(spamreader))\n+#     except FileNotFoundError:\n+#         print(f\"Error: The file {dataset_path} was not found.\")\n+#         return None, None\n+#     except Exception as e:\n+#         print(f\"Error: An error occurred while reading the file: {e}\")\n+#         return None, None\n+\n+#     # 检查数据是否为空\n+#     if data.size == 0:\n+#         print(\"Error: The dataset is empty.\")\n+#         return None, None\n+\n+#     feature = data[:, :-1].astype(np.float64)\n+#     labels = data[:, -1]\n+\n+#     # 创建标签映射\n+#     unique_labels = np.unique(labels)\n+#     label_to_int = {label: idx for idx, label in enumerate(unique_labels)}\n+#     int_labels = np.array([label_to_int[label] for label in labels], dtype=np.uint8)\n+#     labell = int_labels.reshape(-1,1)\n+\n+#     # 将标签转换为独热矩阵\n+#     one_hot_labels = np.zeros((int_labels.size, int_labels.max() + 1), dtype=np.uint8)\n+#     one_hot_labels[np.arange(int_labels.size), int_labels] = 1\n+\n+#     # print(\"======feature_size=====\", feature.shape)\n+#     print(\"======label_size=====\", one_hot_labels)\n+#     return feature, one_hot_labels\n+\n+# data_train = DataSet.sonar\n+\n+# load_dataset(data_train.dataset_name)\n+# endregion\n+\n+\n+def generate_random():\n+    random_tensor = random.randint(0, 10)\n+    return random_tensor\n+\n+# region \n+# @mpc.run_multiprocess(world_size=2)\n+# def test(x,y):\n+    # x_enc = crypten.cryptensor(x, ptype=crypten.mpc.arithmetic)\n+    # y_enc = crypten.cryptensor(y, ptype=crypten.mpc.arithmetic)\n+    # ge_time_begin = time.time()\n+    # ge_  = x_enc.ge(y_enc)\n+    # ge_time_end = time.time()\n+    # ge_time = ge_time_end - ge_time_begin\n+    # print(\"ge_time\", ge_time)\n+    \n+    # gt_time_begin = time.time()\n+    # gt_  = x_enc.gt(y_enc)\n+    # gt_time_end = time.time()\n+    # gt_time = gt_time_end - gt_time_begin\n+    # print(\"gt_time\", gt_time)\n+    \n+    # relu_time_begin = time.time()\n+    # relu_ = ge_.relu()\n+    # relu_time_end = time.time()\n+    # relu_time = relu_time_end - relu_time_begin\n+    # print(\"relu_time\", relu_time)\n+# endregion\n+\n+@mpc.run_multiprocess(world_size=2)\n+def test(x):\n+    x\n+    \n+\n+\n+\n+\n+def main():\n+    x = generate_random()\n+    # y = generate_random()\n+    print(\"x\", x)\n+    # print(\"y\", y)\n+    test(x)\n+\n+main()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1721117294558,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -100,9 +100,9 @@\n # endregion\n \n @mpc.run_multiprocess(world_size=2)\n def test(x):\n-    x\n+    x_share = crypten.cr\n     \n \n \n \n@@ -113,122 +113,5 @@\n     print(\"x\", x)\n     # print(\"y\", y)\n     test(x)\n \n-main()\n-\n-import crypten\n-import torch\n-import crypten.mpc as mpc\n-import crypten.mpc.primitives.beaver as beaver\n-import crypten.communicator as comm \n-import torch\n-from crypten.mpc import MPCTensor\n-from crypten.mpc.primitives import BinarySharedTensor\n-import time\n-import random\n-import crypten.common.functions\n-\n-crypten.init()\n-\n-\n-# region \n-# DATASET_DIR = os.path.join(os.path.dirname(__file__), 'dataset')\n-\n-# class DataSetParam:\n-#     def __init__(self, dataset_name):\n-#         self.dataset_name = dataset_name\n-\n-\n-# class DataSet:\n-#     sonar = DataSetParam('sonar.csv')\n-#     sonar_selected = DataSetParam('sonar_selected.csv')\n-    \n-    \n-    \n-# def load_dataset(dataset):\n-#     dataset_path = os.path.join(DATASET_DIR, dataset)\n-\n-#     # 尝试打开并读取CSV文件\n-#     try:\n-#         with open(dataset_path, 'r', encoding='utf-8') as csvfile:\n-#             spamreader = csv.reader(csvfile)\n-#             data = np.array(list(spamreader))\n-#     except FileNotFoundError:\n-#         print(f\"Error: The file {dataset_path} was not found.\")\n-#         return None, None\n-#     except Exception as e:\n-#         print(f\"Error: An error occurred while reading the file: {e}\")\n-#         return None, None\n-\n-#     # 检查数据是否为空\n-#     if data.size == 0:\n-#         print(\"Error: The dataset is empty.\")\n-#         return None, None\n-\n-#     feature = data[:, :-1].astype(np.float64)\n-#     labels = data[:, -1]\n-\n-#     # 创建标签映射\n-#     unique_labels = np.unique(labels)\n-#     label_to_int = {label: idx for idx, label in enumerate(unique_labels)}\n-#     int_labels = np.array([label_to_int[label] for label in labels], dtype=np.uint8)\n-#     labell = int_labels.reshape(-1,1)\n-\n-#     # 将标签转换为独热矩阵\n-#     one_hot_labels = np.zeros((int_labels.size, int_labels.max() + 1), dtype=np.uint8)\n-#     one_hot_labels[np.arange(int_labels.size), int_labels] = 1\n-\n-#     # print(\"======feature_size=====\", feature.shape)\n-#     print(\"======label_size=====\", one_hot_labels)\n-#     return feature, one_hot_labels\n-\n-# data_train = DataSet.sonar\n-\n-# load_dataset(data_train.dataset_name)\n-# endregion\n-\n-\n-def generate_random():\n-    random_tensor = random.randint(0, 10)\n-    return random_tensor\n-\n-# region \n-# @mpc.run_multiprocess(world_size=2)\n-# def test(x,y):\n-    # x_enc = crypten.cryptensor(x, ptype=crypten.mpc.arithmetic)\n-    # y_enc = crypten.cryptensor(y, ptype=crypten.mpc.arithmetic)\n-    # ge_time_begin = time.time()\n-    # ge_  = x_enc.ge(y_enc)\n-    # ge_time_end = time.time()\n-    # ge_time = ge_time_end - ge_time_begin\n-    # print(\"ge_time\", ge_time)\n-    \n-    # gt_time_begin = time.time()\n-    # gt_  = x_enc.gt(y_enc)\n-    # gt_time_end = time.time()\n-    # gt_time = gt_time_end - gt_time_begin\n-    # print(\"gt_time\", gt_time)\n-    \n-    # relu_time_begin = time.time()\n-    # relu_ = ge_.relu()\n-    # relu_time_end = time.time()\n-    # relu_time = relu_time_end - relu_time_begin\n-    # print(\"relu_time\", relu_time)\n-# endregion\n-\n-@mpc.run_multiprocess(world_size=2)\n-def test(x):\n-    \n-    \n-\n-\n-\n-\n-def main():\n-    x = generate_random()\n-    # y = generate_random()\n-    print(\"x\", x)\n-    # print(\"y\", y)\n-    test(x)\n-\n main()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1721117306772,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,6 +1,7 @@\n \n import crypten\n+import crypten.mpc\n import torch\n import crypten.mpc as mpc\n import crypten.mpc.primitives.beaver as beaver\n import crypten.communicator as comm \n@@ -100,9 +101,9 @@\n # endregion\n \n @mpc.run_multiprocess(world_size=2)\n def test(x):\n-    x_share = crypten.cr\n+    x_share = crypten.cryptensor(x, ptype = crypten.mpc.)\n     \n \n \n \n"
                },
                {
                    "date": 1721117313133,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,119 @@\n+\n+import crypten\n+import crypten.mpc\n+import torch\n+import crypten.mpc as mpc\n+import crypten.mpc.primitives.beaver as beaver\n+import crypten.communicator as comm \n+import torch\n+from crypten.mpc import MPCTensor\n+from crypten.mpc.primitives import BinarySharedTensor\n+import time\n+import random\n+import crypten.common.functions\n+\n+crypten.init()\n+\n+\n+# region \n+# DATASET_DIR = os.path.join(os.path.dirname(__file__), 'dataset')\n+\n+# class DataSetParam:\n+#     def __init__(self, dataset_name):\n+#         self.dataset_name = dataset_name\n+\n+\n+# class DataSet:\n+#     sonar = DataSetParam('sonar.csv')\n+#     sonar_selected = DataSetParam('sonar_selected.csv')\n+    \n+    \n+    \n+# def load_dataset(dataset):\n+#     dataset_path = os.path.join(DATASET_DIR, dataset)\n+\n+#     # 尝试打开并读取CSV文件\n+#     try:\n+#         with open(dataset_path, 'r', encoding='utf-8') as csvfile:\n+#             spamreader = csv.reader(csvfile)\n+#             data = np.array(list(spamreader))\n+#     except FileNotFoundError:\n+#         print(f\"Error: The file {dataset_path} was not found.\")\n+#         return None, None\n+#     except Exception as e:\n+#         print(f\"Error: An error occurred while reading the file: {e}\")\n+#         return None, None\n+\n+#     # 检查数据是否为空\n+#     if data.size == 0:\n+#         print(\"Error: The dataset is empty.\")\n+#         return None, None\n+\n+#     feature = data[:, :-1].astype(np.float64)\n+#     labels = data[:, -1]\n+\n+#     # 创建标签映射\n+#     unique_labels = np.unique(labels)\n+#     label_to_int = {label: idx for idx, label in enumerate(unique_labels)}\n+#     int_labels = np.array([label_to_int[label] for label in labels], dtype=np.uint8)\n+#     labell = int_labels.reshape(-1,1)\n+\n+#     # 将标签转换为独热矩阵\n+#     one_hot_labels = np.zeros((int_labels.size, int_labels.max() + 1), dtype=np.uint8)\n+#     one_hot_labels[np.arange(int_labels.size), int_labels] = 1\n+\n+#     # print(\"======feature_size=====\", feature.shape)\n+#     print(\"======label_size=====\", one_hot_labels)\n+#     return feature, one_hot_labels\n+\n+# data_train = DataSet.sonar\n+\n+# load_dataset(data_train.dataset_name)\n+# endregion\n+\n+\n+def generate_random():\n+    random_tensor = random.randint(0, 10)\n+    return random_tensor\n+\n+# region \n+# @mpc.run_multiprocess(world_size=2)\n+# def test(x,y):\n+    # x_enc = crypten.cryptensor(x, ptype=crypten.mpc.arithmetic)\n+    # y_enc = crypten.cryptensor(y, ptype=crypten.mpc.arithmetic)\n+    # ge_time_begin = time.time()\n+    # ge_  = x_enc.ge(y_enc)\n+    # ge_time_end = time.time()\n+    # ge_time = ge_time_end - ge_time_begin\n+    # print(\"ge_time\", ge_time)\n+    \n+    # gt_time_begin = time.time()\n+    # gt_  = x_enc.gt(y_enc)\n+    # gt_time_end = time.time()\n+    # gt_time = gt_time_end - gt_time_begin\n+    # print(\"gt_time\", gt_time)\n+    \n+    # relu_time_begin = time.time()\n+    # relu_ = ge_.relu()\n+    # relu_time_end = time.time()\n+    # relu_time = relu_time_end - relu_time_begin\n+    # print(\"relu_time\", relu_time)\n+# endregion\n+\n+@mpc.run_multiprocess(world_size=2)\n+def test(x):\n+    x_share = crypten.cryptensor(x, ptype = crypten.mpc.arithmetic)\n+    \n+    \n+\n+\n+\n+\n+def main():\n+    x = generate_random()\n+    # y = generate_random()\n+    print(\"x\", x)\n+    # print(\"y\", y)\n+    test(x)\n+\n+main()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1721117323692,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -102,10 +102,10 @@\n \n @mpc.run_multiprocess(world_size=2)\n def test(x):\n     x_share = crypten.cryptensor(x, ptype = crypten.mpc.arithmetic)\n+    one-share = \n     \n-    \n \n \n \n \n@@ -115,123 +115,5 @@\n     print(\"x\", x)\n     # print(\"y\", y)\n     test(x)\n \n-main()\n-\n-import crypten\n-import crypten.mpc\n-import torch\n-import crypten.mpc as mpc\n-import crypten.mpc.primitives.beaver as beaver\n-import crypten.communicator as comm \n-import torch\n-from crypten.mpc import MPCTensor\n-from crypten.mpc.primitives import BinarySharedTensor\n-import time\n-import random\n-import crypten.common.functions\n-\n-crypten.init()\n-\n-\n-# region \n-# DATASET_DIR = os.path.join(os.path.dirname(__file__), 'dataset')\n-\n-# class DataSetParam:\n-#     def __init__(self, dataset_name):\n-#         self.dataset_name = dataset_name\n-\n-\n-# class DataSet:\n-#     sonar = DataSetParam('sonar.csv')\n-#     sonar_selected = DataSetParam('sonar_selected.csv')\n-    \n-    \n-    \n-# def load_dataset(dataset):\n-#     dataset_path = os.path.join(DATASET_DIR, dataset)\n-\n-#     # 尝试打开并读取CSV文件\n-#     try:\n-#         with open(dataset_path, 'r', encoding='utf-8') as csvfile:\n-#             spamreader = csv.reader(csvfile)\n-#             data = np.array(list(spamreader))\n-#     except FileNotFoundError:\n-#         print(f\"Error: The file {dataset_path} was not found.\")\n-#         return None, None\n-#     except Exception as e:\n-#         print(f\"Error: An error occurred while reading the file: {e}\")\n-#         return None, None\n-\n-#     # 检查数据是否为空\n-#     if data.size == 0:\n-#         print(\"Error: The dataset is empty.\")\n-#         return None, None\n-\n-#     feature = data[:, :-1].astype(np.float64)\n-#     labels = data[:, -1]\n-\n-#     # 创建标签映射\n-#     unique_labels = np.unique(labels)\n-#     label_to_int = {label: idx for idx, label in enumerate(unique_labels)}\n-#     int_labels = np.array([label_to_int[label] for label in labels], dtype=np.uint8)\n-#     labell = int_labels.reshape(-1,1)\n-\n-#     # 将标签转换为独热矩阵\n-#     one_hot_labels = np.zeros((int_labels.size, int_labels.max() + 1), dtype=np.uint8)\n-#     one_hot_labels[np.arange(int_labels.size), int_labels] = 1\n-\n-#     # print(\"======feature_size=====\", feature.shape)\n-#     print(\"======label_size=====\", one_hot_labels)\n-#     return feature, one_hot_labels\n-\n-# data_train = DataSet.sonar\n-\n-# load_dataset(data_train.dataset_name)\n-# endregion\n-\n-\n-def generate_random():\n-    random_tensor = random.randint(0, 10)\n-    return random_tensor\n-\n-# region \n-# @mpc.run_multiprocess(world_size=2)\n-# def test(x,y):\n-    # x_enc = crypten.cryptensor(x, ptype=crypten.mpc.arithmetic)\n-    # y_enc = crypten.cryptensor(y, ptype=crypten.mpc.arithmetic)\n-    # ge_time_begin = time.time()\n-    # ge_  = x_enc.ge(y_enc)\n-    # ge_time_end = time.time()\n-    # ge_time = ge_time_end - ge_time_begin\n-    # print(\"ge_time\", ge_time)\n-    \n-    # gt_time_begin = time.time()\n-    # gt_  = x_enc.gt(y_enc)\n-    # gt_time_end = time.time()\n-    # gt_time = gt_time_end - gt_time_begin\n-    # print(\"gt_time\", gt_time)\n-    \n-    # relu_time_begin = time.time()\n-    # relu_ = ge_.relu()\n-    # relu_time_end = time.time()\n-    # relu_time = relu_time_end - relu_time_begin\n-    # print(\"relu_time\", relu_time)\n-# endregion\n-\n-@mpc.run_multiprocess(world_size=2)\n-def test(x):\n-    x_share = crypten.cryptensor(x, ptype = crypten.mpc.)\n-    \n-\n-\n-\n-\n-def main():\n-    x = generate_random()\n-    # y = generate_random()\n-    print(\"x\", x)\n-    # print(\"y\", y)\n-    test(x)\n-\n main()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1721117329448,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -102,9 +102,9 @@\n \n @mpc.run_multiprocess(world_size=2)\n def test(x):\n     x_share = crypten.cryptensor(x, ptype = crypten.mpc.arithmetic)\n-    one-share = \n+    one_share = crypten.cryptensor(x, ptype = crypten.mpc.arithmetic)\n     \n \n \n \n"
                },
                {
                    "date": 1721117341485,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -102,9 +102,10 @@\n \n @mpc.run_multiprocess(world_size=2)\n def test(x):\n     x_share = crypten.cryptensor(x, ptype = crypten.mpc.arithmetic)\n-    one_share = crypten.cryptensor(x, ptype = crypten.mpc.arithmetic)\n+    one_share = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n+    x_minus_one = \n     \n \n \n \n"
                },
                {
                    "date": 1721117348040,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -103,10 +103,11 @@\n @mpc.run_multiprocess(world_size=2)\n def test(x):\n     x_share = crypten.cryptensor(x, ptype = crypten.mpc.arithmetic)\n     one_share = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n-    x_minus_one = \n+    x_minus_one = x-x_share - one_share\n     \n+    \n \n \n \n \n"
                },
                {
                    "date": 1721117356077,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -103,9 +103,9 @@\n @mpc.run_multiprocess(world_size=2)\n def test(x):\n     x_share = crypten.cryptensor(x, ptype = crypten.mpc.arithmetic)\n     one_share = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n-    x_minus_one = x-x_share - one_share\n+    x_minus_one = x_share - one_share\n     \n     \n \n \n"
                },
                {
                    "date": 1721117555920,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -104,10 +104,10 @@\n def test(x):\n     x_share = crypten.cryptensor(x, ptype = crypten.mpc.arithmetic)\n     one_share = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n     x_minus_one = x_share - one_share\n+    cmp_result = \n     \n-    \n \n \n \n \n"
                },
                {
                    "date": 1721117567776,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -104,9 +104,9 @@\n def test(x):\n     x_share = crypten.cryptensor(x, ptype = crypten.mpc.arithmetic)\n     one_share = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n     x_minus_one = x_share - one_share\n-    cmp_result = \n+    cmp_result = x_minus_one <1 0\n     \n \n \n \n"
                },
                {
                    "date": 1721117572919,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -104,9 +104,10 @@\n def test(x):\n     x_share = crypten.cryptensor(x, ptype = crypten.mpc.arithmetic)\n     one_share = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n     x_minus_one = x_share - one_share\n-    cmp_result = x_minus_one <1 0\n+    cmp_result = x_minus_one < 0\n+    print()\n     \n \n \n \n"
                },
                {
                    "date": 1721117592979,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -105,9 +105,10 @@\n     x_share = crypten.cryptensor(x, ptype = crypten.mpc.arithmetic)\n     one_share = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n     x_minus_one = x_share - one_share\n     cmp_result = x_minus_one < 0\n-    print()\n+    rank = comm.get().get_rank()\n+    crypten.print(f\"\\nRank {rank}:\\n {x_enc}\\n\", in_order=True)\n     \n \n \n \n"
                },
                {
                    "date": 1721117598358,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -106,9 +106,9 @@\n     one_share = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n     x_minus_one = x_share - one_share\n     cmp_result = x_minus_one < 0\n     rank = comm.get().get_rank()\n-    crypten.print(f\"\\nRank {rank}:\\n {x_enc}\\n\", in_order=True)\n+    crypten.print(f\"\\nRank {rank}:\\n {cmp_result }\\n\", in_order=True)\n     \n \n \n \n"
                },
                {
                    "date": 1721117626081,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -106,14 +106,10 @@\n     one_share = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n     x_minus_one = x_share - one_share\n     cmp_result = x_minus_one < 0\n     rank = comm.get().get_rank()\n-    crypten.print(f\"\\nRank {rank}:\\n {cmp_result }\\n\", in_order=True)\n-    \n+    crypten.print(f\"\\nRank {rank}:\\n {cmp_result.get_plain_text()}\\n\", in_order=True)\n \n-\n-\n-\n def main():\n     x = generate_random()\n     # y = generate_random()\n     print(\"x\", x)\n"
                },
                {
                    "date": 1721117660141,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -104,9 +104,9 @@\n def test(x):\n     x_share = crypten.cryptensor(x, ptype = crypten.mpc.arithmetic)\n     one_share = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n     x_minus_one = x_share - one_share\n-    cmp_result = x_minus_one < 0\n+    cmp_result = x_minus_one > 0\n     rank = comm.get().get_rank()\n     crypten.print(f\"\\nRank {rank}:\\n {cmp_result.get_plain_text()}\\n\", in_order=True)\n \n def main():\n"
                },
                {
                    "date": 1721117675862,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -72,9 +72,9 @@\n # endregion\n \n \n def generate_random():\n-    random_tensor = random.randint(0, 10)\n+    random_tensor = random.randint(-10, 10)\n     return random_tensor\n \n # region \n # @mpc.run_multiprocess(world_size=2)\n"
                },
                {
                    "date": 1721118510327,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -105,8 +105,12 @@\n     x_share = crypten.cryptensor(x, ptype = crypten.mpc.arithmetic)\n     one_share = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n     x_minus_one = x_share - one_share\n     cmp_result = x_minus_one > 0\n+    \n+    \n+    \n+    \n     rank = comm.get().get_rank()\n     crypten.print(f\"\\nRank {rank}:\\n {cmp_result.get_plain_text()}\\n\", in_order=True)\n \n def main():\n"
                },
                {
                    "date": 1721118518218,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -106,11 +106,13 @@\n     one_share = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n     x_minus_one = x_share - one_share\n     cmp_result = x_minus_one > 0\n     \n+    mul\n     \n     \n     \n+    \n     rank = comm.get().get_rank()\n     crypten.print(f\"\\nRank {rank}:\\n {cmp_result.get_plain_text()}\\n\", in_order=True)\n \n def main():\n"
                },
                {
                    "date": 1721118525286,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -106,9 +106,9 @@\n     one_share = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n     x_minus_one = x_share - one_share\n     cmp_result = x_minus_one > 0\n     \n-    mul\n+    mulplex_result = cmp_result\n     \n     \n     \n     \n"
                },
                {
                    "date": 1721118532632,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -106,9 +106,9 @@\n     one_share = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n     x_minus_one = x_share - one_share\n     cmp_result = x_minus_one > 0\n     \n-    mulplex_result = cmp_result\n+    mulplex_result = cmp_result.where(cmp_result)\n     \n     \n     \n     \n"
                },
                {
                    "date": 1721118539901,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -106,9 +106,9 @@\n     one_share = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n     x_minus_one = x_share - one_share\n     cmp_result = x_minus_one > 0\n     \n-    mulplex_result = cmp_result.where(cmp_result)\n+    mulplex_result = x_minus_one.where(cmp_result, x_minus_one)\n     \n     \n     \n     \n"
                },
                {
                    "date": 1721118601556,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -108,11 +108,8 @@\n     cmp_result = x_minus_one > 0\n     \n     mulplex_result = x_minus_one.where(cmp_result, x_minus_one)\n     \n-    \n-    \n-    \n     rank = comm.get().get_rank()\n     crypten.print(f\"\\nRank {rank}:\\n {cmp_result.get_plain_text()}\\n\", in_order=True)\n \n def main():\n"
                },
                {
                    "date": 1721118613590,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -110,8 +110,9 @@\n     mulplex_result = x_minus_one.where(cmp_result, x_minus_one)\n     \n     rank = comm.get().get_rank()\n     crypten.print(f\"\\nRank {rank}:\\n {cmp_result.get_plain_text()}\\n\", in_order=True)\n+    crypten.print(f\"\\nRank {rank}:\\n {cmp_result.get_plain_text()}\\n\", in_order=True)\n \n def main():\n     x = generate_random()\n     # y = generate_random()\n"
                },
                {
                    "date": 1721119134879,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -106,13 +106,13 @@\n     one_share = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n     x_minus_one = x_share - one_share\n     cmp_result = x_minus_one > 0\n     \n-    mulplex_result = x_minus_one.where(cmp_result, x_minus_one)\n+    mulplex_result = crypten.where(cmp_result, x_minus_one)\n     \n     rank = comm.get().get_rank()\n     crypten.print(f\"\\nRank {rank}:\\n {cmp_result.get_plain_text()}\\n\", in_order=True)\n-    crypten.print(f\"\\nRank {rank}:\\n {cmp_result.get_plain_text()}\\n\", in_order=True)\n+    crypten.print(f\"\\nRank {rank}:\\n {mulplex_result.get_plain_text()}\\n\", in_order=True)\n \n def main():\n     x = generate_random()\n     # y = generate_random()\n"
                },
                {
                    "date": 1721119191071,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -104,11 +104,12 @@\n def test(x):\n     x_share = crypten.cryptensor(x, ptype = crypten.mpc.arithmetic)\n     one_share = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n     x_minus_one = x_share - one_share\n+    \n     cmp_result = x_minus_one > 0\n     \n-    mulplex_result = crypten.where(cmp_result, x_minus_one)\n+    mulplex_result = crypten.where(cmp_result, x_minus_one, 0)\n     \n     rank = comm.get().get_rank()\n     crypten.print(f\"\\nRank {rank}:\\n {cmp_result.get_plain_text()}\\n\", in_order=True)\n     crypten.print(f\"\\nRank {rank}:\\n {mulplex_result.get_plain_text()}\\n\", in_order=True)\n"
                },
                {
                    "date": 1721119200669,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -104,9 +104,9 @@\n def test(x):\n     x_share = crypten.cryptensor(x, ptype = crypten.mpc.arithmetic)\n     one_share = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n     x_minus_one = x_share - one_share\n-    \n+    ge_time_begin = time.time()\n     cmp_result = x_minus_one > 0\n     \n     mulplex_result = crypten.where(cmp_result, x_minus_one, 0)\n     \n"
                },
                {
                    "date": 1721119207367,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,126 @@\n+\n+import crypten\n+import crypten.mpc\n+import torch\n+import crypten.mpc as mpc\n+import crypten.mpc.primitives.beaver as beaver\n+import crypten.communicator as comm \n+import torch\n+from crypten.mpc import MPCTensor\n+from crypten.mpc.primitives import BinarySharedTensor\n+import time\n+import random\n+import crypten.common.functions\n+\n+crypten.init()\n+\n+\n+# region \n+# DATASET_DIR = os.path.join(os.path.dirname(__file__), 'dataset')\n+\n+# class DataSetParam:\n+#     def __init__(self, dataset_name):\n+#         self.dataset_name = dataset_name\n+\n+\n+# class DataSet:\n+#     sonar = DataSetParam('sonar.csv')\n+#     sonar_selected = DataSetParam('sonar_selected.csv')\n+    \n+    \n+    \n+# def load_dataset(dataset):\n+#     dataset_path = os.path.join(DATASET_DIR, dataset)\n+\n+#     # 尝试打开并读取CSV文件\n+#     try:\n+#         with open(dataset_path, 'r', encoding='utf-8') as csvfile:\n+#             spamreader = csv.reader(csvfile)\n+#             data = np.array(list(spamreader))\n+#     except FileNotFoundError:\n+#         print(f\"Error: The file {dataset_path} was not found.\")\n+#         return None, None\n+#     except Exception as e:\n+#         print(f\"Error: An error occurred while reading the file: {e}\")\n+#         return None, None\n+\n+#     # 检查数据是否为空\n+#     if data.size == 0:\n+#         print(\"Error: The dataset is empty.\")\n+#         return None, None\n+\n+#     feature = data[:, :-1].astype(np.float64)\n+#     labels = data[:, -1]\n+\n+#     # 创建标签映射\n+#     unique_labels = np.unique(labels)\n+#     label_to_int = {label: idx for idx, label in enumerate(unique_labels)}\n+#     int_labels = np.array([label_to_int[label] for label in labels], dtype=np.uint8)\n+#     labell = int_labels.reshape(-1,1)\n+\n+#     # 将标签转换为独热矩阵\n+#     one_hot_labels = np.zeros((int_labels.size, int_labels.max() + 1), dtype=np.uint8)\n+#     one_hot_labels[np.arange(int_labels.size), int_labels] = 1\n+\n+#     # print(\"======feature_size=====\", feature.shape)\n+#     print(\"======label_size=====\", one_hot_labels)\n+#     return feature, one_hot_labels\n+\n+# data_train = DataSet.sonar\n+\n+# load_dataset(data_train.dataset_name)\n+# endregion\n+\n+\n+def generate_random():\n+    random_tensor = random.randint(-10, 10)\n+    return random_tensor\n+\n+# region \n+# @mpc.run_multiprocess(world_size=2)\n+# def test(x,y):\n+    # x_enc = crypten.cryptensor(x, ptype=crypten.mpc.arithmetic)\n+    # y_enc = crypten.cryptensor(y, ptype=crypten.mpc.arithmetic)\n+    # ge_time_begin = time.time()\n+    # ge_  = x_enc.ge(y_enc)\n+    # ge_time_end = time.time()\n+    # ge_time = ge_time_end - ge_time_begin\n+    # print(\"ge_time\", ge_time)\n+    \n+    # gt_time_begin = time.time()\n+    # gt_  = x_enc.gt(y_enc)\n+    # gt_time_end = time.time()\n+    # gt_time = gt_time_end - gt_time_begin\n+    # print(\"gt_time\", gt_time)\n+    \n+    # relu_time_begin = time.time()\n+    # relu_ = ge_.relu()\n+    # relu_time_end = time.time()\n+    # relu_time = relu_time_end - relu_time_begin\n+    # print(\"relu_time\", relu_time)\n+# endregion\n+\n+@mpc.run_multiprocess(world_size=2)\n+def test(x):\n+    x_share = crypten.cryptensor(x, ptype = crypten.mpc.arithmetic)\n+    one_share = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n+    x_minus_one = x_share - one_share\n+    ge_time_begin = time.time()\n+    cmp_result = x_minus_one > 0\n+    # ge_time_end = time.time()\n+    # ge_time = ge_time_end - ge_time_begin\n+    # print(\"ge_time\", ge_time)\n+    mulplex_result = crypten.where(cmp_result, x_minus_one, 0)\n+    \n+    rank = comm.get().get_rank()\n+    crypten.print(f\"\\nRank {rank}:\\n {cmp_result.get_plain_text()}\\n\", in_order=True)\n+    crypten.print(f\"\\nRank {rank}:\\n {mulplex_result.get_plain_text()}\\n\", in_order=True)\n+\n+def main():\n+    x = generate_random()\n+    # y = generate_random()\n+    print(\"x\", x)\n+    # print(\"y\", y)\n+    test(x)\n+\n+main()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1721119217372,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -106,135 +106,13 @@\n     one_share = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n     x_minus_one = x_share - one_share\n     ge_time_begin = time.time()\n     cmp_result = x_minus_one > 0\n-    # ge_time_end = time.time()\n-    # ge_time = ge_time_end - ge_time_begin\n-    # print(\"ge_time\", ge_time)\n-    mulplex_result = crypten.where(cmp_result, x_minus_one, 0)\n+    ge_time_end = time.time()\n+    ge_time = ge_time_end - ge_time_begin\n+    print(\"ge_time\", ge_time)\n     \n-    rank = comm.get().get_rank()\n-    crypten.print(f\"\\nRank {rank}:\\n {cmp_result.get_plain_text()}\\n\", in_order=True)\n-    crypten.print(f\"\\nRank {rank}:\\n {mulplex_result.get_plain_text()}\\n\", in_order=True)\n-\n-def main():\n-    x = generate_random()\n-    # y = generate_random()\n-    print(\"x\", x)\n-    # print(\"y\", y)\n-    test(x)\n-\n-main()\n-\n-import crypten\n-import crypten.mpc\n-import torch\n-import crypten.mpc as mpc\n-import crypten.mpc.primitives.beaver as beaver\n-import crypten.communicator as comm \n-import torch\n-from crypten.mpc import MPCTensor\n-from crypten.mpc.primitives import BinarySharedTensor\n-import time\n-import random\n-import crypten.common.functions\n-\n-crypten.init()\n-\n-\n-# region \n-# DATASET_DIR = os.path.join(os.path.dirname(__file__), 'dataset')\n-\n-# class DataSetParam:\n-#     def __init__(self, dataset_name):\n-#         self.dataset_name = dataset_name\n-\n-\n-# class DataSet:\n-#     sonar = DataSetParam('sonar.csv')\n-#     sonar_selected = DataSetParam('sonar_selected.csv')\n-    \n-    \n-    \n-# def load_dataset(dataset):\n-#     dataset_path = os.path.join(DATASET_DIR, dataset)\n-\n-#     # 尝试打开并读取CSV文件\n-#     try:\n-#         with open(dataset_path, 'r', encoding='utf-8') as csvfile:\n-#             spamreader = csv.reader(csvfile)\n-#             data = np.array(list(spamreader))\n-#     except FileNotFoundError:\n-#         print(f\"Error: The file {dataset_path} was not found.\")\n-#         return None, None\n-#     except Exception as e:\n-#         print(f\"Error: An error occurred while reading the file: {e}\")\n-#         return None, None\n-\n-#     # 检查数据是否为空\n-#     if data.size == 0:\n-#         print(\"Error: The dataset is empty.\")\n-#         return None, None\n-\n-#     feature = data[:, :-1].astype(np.float64)\n-#     labels = data[:, -1]\n-\n-#     # 创建标签映射\n-#     unique_labels = np.unique(labels)\n-#     label_to_int = {label: idx for idx, label in enumerate(unique_labels)}\n-#     int_labels = np.array([label_to_int[label] for label in labels], dtype=np.uint8)\n-#     labell = int_labels.reshape(-1,1)\n-\n-#     # 将标签转换为独热矩阵\n-#     one_hot_labels = np.zeros((int_labels.size, int_labels.max() + 1), dtype=np.uint8)\n-#     one_hot_labels[np.arange(int_labels.size), int_labels] = 1\n-\n-#     # print(\"======feature_size=====\", feature.shape)\n-#     print(\"======label_size=====\", one_hot_labels)\n-#     return feature, one_hot_labels\n-\n-# data_train = DataSet.sonar\n-\n-# load_dataset(data_train.dataset_name)\n-# endregion\n-\n-\n-def generate_random():\n-    random_tensor = random.randint(-10, 10)\n-    return random_tensor\n-\n-# region \n-# @mpc.run_multiprocess(world_size=2)\n-# def test(x,y):\n-    # x_enc = crypten.cryptensor(x, ptype=crypten.mpc.arithmetic)\n-    # y_enc = crypten.cryptensor(y, ptype=crypten.mpc.arithmetic)\n-    # ge_time_begin = time.time()\n-    # ge_  = x_enc.ge(y_enc)\n-    # ge_time_end = time.time()\n-    # ge_time = ge_time_end - ge_time_begin\n-    # print(\"ge_time\", ge_time)\n-    \n-    # gt_time_begin = time.time()\n-    # gt_  = x_enc.gt(y_enc)\n-    # gt_time_end = time.time()\n-    # gt_time = gt_time_end - gt_time_begin\n-    # print(\"gt_time\", gt_time)\n-    \n-    # relu_time_begin = time.time()\n-    # relu_ = ge_.relu()\n-    # relu_time_end = time.time()\n-    # relu_time = relu_time_end - relu_time_begin\n-    # print(\"relu_time\", relu_time)\n-# endregion\n-\n-@mpc.run_multiprocess(world_size=2)\n-def test(x):\n-    x_share = crypten.cryptensor(x, ptype = crypten.mpc.arithmetic)\n-    one_share = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n-    x_minus_one = x_share - one_share\n-    ge_time_begin = time.time()\n-    cmp_result = x_minus_one > 0\n-    \n+    gt_time_begin = time.time()\n     mulplex_result = crypten.where(cmp_result, x_minus_one, 0)\n     \n     rank = comm.get().get_rank()\n     crypten.print(f\"\\nRank {rank}:\\n {cmp_result.get_plain_text()}\\n\", in_order=True)\n"
                },
                {
                    "date": 1721119224612,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -110,9 +110,9 @@\n     ge_time_end = time.time()\n     ge_time = ge_time_end - ge_time_begin\n     print(\"ge_time\", ge_time)\n     \n-    gt_time_begin = time.time()\n+   mulplex_time_begin = time.time()\n     mulplex_result = crypten.where(cmp_result, x_minus_one, 0)\n     \n     rank = comm.get().get_rank()\n     crypten.print(f\"\\nRank {rank}:\\n {cmp_result.get_plain_text()}\\n\", in_order=True)\n"
                },
                {
                    "date": 1721119233425,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -110,10 +110,13 @@\n     ge_time_end = time.time()\n     ge_time = ge_time_end - ge_time_begin\n     print(\"ge_time\", ge_time)\n     \n-   mulplex_time_begin = time.time()\n+    mulplex_time_begin = time.time()\n     mulplex_result = crypten.where(cmp_result, x_minus_one, 0)\n+        # gt_time_end = time.time()\n+    # gt_time = gt_time_end - gt_time_begin\n+    # print(\"gt_time\", gt_time)\n     \n     rank = comm.get().get_rank()\n     crypten.print(f\"\\nRank {rank}:\\n {cmp_result.get_plain_text()}\\n\", in_order=True)\n     crypten.print(f\"\\nRank {rank}:\\n {mulplex_result.get_plain_text()}\\n\", in_order=True)\n"
                },
                {
                    "date": 1721119238459,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,131 @@\n+\n+import crypten\n+import crypten.mpc\n+import torch\n+import crypten.mpc as mpc\n+import crypten.mpc.primitives.beaver as beaver\n+import crypten.communicator as comm \n+import torch\n+from crypten.mpc import MPCTensor\n+from crypten.mpc.primitives import BinarySharedTensor\n+import time\n+import random\n+import crypten.common.functions\n+\n+crypten.init()\n+\n+\n+# region \n+# DATASET_DIR = os.path.join(os.path.dirname(__file__), 'dataset')\n+\n+# class DataSetParam:\n+#     def __init__(self, dataset_name):\n+#         self.dataset_name = dataset_name\n+\n+\n+# class DataSet:\n+#     sonar = DataSetParam('sonar.csv')\n+#     sonar_selected = DataSetParam('sonar_selected.csv')\n+    \n+    \n+    \n+# def load_dataset(dataset):\n+#     dataset_path = os.path.join(DATASET_DIR, dataset)\n+\n+#     # 尝试打开并读取CSV文件\n+#     try:\n+#         with open(dataset_path, 'r', encoding='utf-8') as csvfile:\n+#             spamreader = csv.reader(csvfile)\n+#             data = np.array(list(spamreader))\n+#     except FileNotFoundError:\n+#         print(f\"Error: The file {dataset_path} was not found.\")\n+#         return None, None\n+#     except Exception as e:\n+#         print(f\"Error: An error occurred while reading the file: {e}\")\n+#         return None, None\n+\n+#     # 检查数据是否为空\n+#     if data.size == 0:\n+#         print(\"Error: The dataset is empty.\")\n+#         return None, None\n+\n+#     feature = data[:, :-1].astype(np.float64)\n+#     labels = data[:, -1]\n+\n+#     # 创建标签映射\n+#     unique_labels = np.unique(labels)\n+#     label_to_int = {label: idx for idx, label in enumerate(unique_labels)}\n+#     int_labels = np.array([label_to_int[label] for label in labels], dtype=np.uint8)\n+#     labell = int_labels.reshape(-1,1)\n+\n+#     # 将标签转换为独热矩阵\n+#     one_hot_labels = np.zeros((int_labels.size, int_labels.max() + 1), dtype=np.uint8)\n+#     one_hot_labels[np.arange(int_labels.size), int_labels] = 1\n+\n+#     # print(\"======feature_size=====\", feature.shape)\n+#     print(\"======label_size=====\", one_hot_labels)\n+#     return feature, one_hot_labels\n+\n+# data_train = DataSet.sonar\n+\n+# load_dataset(data_train.dataset_name)\n+# endregion\n+\n+\n+def generate_random():\n+    random_tensor = random.randint(-10, 10)\n+    return random_tensor\n+\n+# region \n+# @mpc.run_multiprocess(world_size=2)\n+# def test(x,y):\n+    # x_enc = crypten.cryptensor(x, ptype=crypten.mpc.arithmetic)\n+    # y_enc = crypten.cryptensor(y, ptype=crypten.mpc.arithmetic)\n+    # ge_time_begin = time.time()\n+    # ge_  = x_enc.ge(y_enc)\n+    # ge_time_end = time.time()\n+    # ge_time = ge_time_end - ge_time_begin\n+    # print(\"ge_time\", ge_time)\n+    \n+    # gt_time_begin = time.time()\n+    # gt_  = x_enc.gt(y_enc)\n+    # gt_time_end = time.time()\n+    # gt_time = gt_time_end - gt_time_begin\n+    # print(\"gt_time\", gt_time)\n+    \n+    # relu_time_begin = time.time()\n+    # relu_ = ge_.relu()\n+    # relu_time_end = time.time()\n+    # relu_time = relu_time_end - relu_time_begin\n+    # print(\"relu_time\", relu_time)\n+# endregion\n+\n+@mpc.run_multiprocess(world_size=2)\n+def test(x):\n+    x_share = crypten.cryptensor(x, ptype = crypten.mpc.arithmetic)\n+    one_share = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n+    x_minus_one = x_share - one_share\n+    ge_time_begin = time.time()\n+    cmp_result = x_minus_one > 0\n+    ge_time_end = time.time()\n+    ge_time = ge_time_end - ge_time_begin\n+    print(\"ge_time\", ge_time)\n+    \n+    mulplex_time_begin = time.time()\n+    mulplex_result = crypten.where(cmp_result, x_minus_one, 0)\n+    gt_time_end = time.time()\n+    gt_time = gt_time_end - gt_time_begin\n+    print(\"gt_time\", gt_time)\n+    \n+    rank = comm.get().get_rank()\n+    crypten.print(f\"\\nRank {rank}:\\n {cmp_result.get_plain_text()}\\n\", in_order=True)\n+    crypten.print(f\"\\nRank {rank}:\\n {mulplex_result.get_plain_text()}\\n\", in_order=True)\n+\n+def main():\n+    x = generate_random()\n+    # y = generate_random()\n+    print(\"x\", x)\n+    # print(\"y\", y)\n+    test(x)\n+\n+main()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1721119244850,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -112,10 +112,10 @@\n     print(\"ge_time\", ge_time)\n     \n     mulplex_time_begin = time.time()\n     mulplex_result = crypten.where(cmp_result, x_minus_one, 0)\n-    gt_time_end = time.time()\n-    gt_time = gt_time_end - gt_time_begin\n+    mulplex_time_end = time.time()\n+    mulplex_time = mulplex_time_end - gt_time_begin\n     print(\"gt_time\", gt_time)\n     \n     rank = comm.get().get_rank()\n     crypten.print(f\"\\nRank {rank}:\\n {cmp_result.get_plain_text()}\\n\", in_order=True)\n@@ -127,136 +127,5 @@\n     print(\"x\", x)\n     # print(\"y\", y)\n     test(x)\n \n-main()\n-\n-import crypten\n-import crypten.mpc\n-import torch\n-import crypten.mpc as mpc\n-import crypten.mpc.primitives.beaver as beaver\n-import crypten.communicator as comm \n-import torch\n-from crypten.mpc import MPCTensor\n-from crypten.mpc.primitives import BinarySharedTensor\n-import time\n-import random\n-import crypten.common.functions\n-\n-crypten.init()\n-\n-\n-# region \n-# DATASET_DIR = os.path.join(os.path.dirname(__file__), 'dataset')\n-\n-# class DataSetParam:\n-#     def __init__(self, dataset_name):\n-#         self.dataset_name = dataset_name\n-\n-\n-# class DataSet:\n-#     sonar = DataSetParam('sonar.csv')\n-#     sonar_selected = DataSetParam('sonar_selected.csv')\n-    \n-    \n-    \n-# def load_dataset(dataset):\n-#     dataset_path = os.path.join(DATASET_DIR, dataset)\n-\n-#     # 尝试打开并读取CSV文件\n-#     try:\n-#         with open(dataset_path, 'r', encoding='utf-8') as csvfile:\n-#             spamreader = csv.reader(csvfile)\n-#             data = np.array(list(spamreader))\n-#     except FileNotFoundError:\n-#         print(f\"Error: The file {dataset_path} was not found.\")\n-#         return None, None\n-#     except Exception as e:\n-#         print(f\"Error: An error occurred while reading the file: {e}\")\n-#         return None, None\n-\n-#     # 检查数据是否为空\n-#     if data.size == 0:\n-#         print(\"Error: The dataset is empty.\")\n-#         return None, None\n-\n-#     feature = data[:, :-1].astype(np.float64)\n-#     labels = data[:, -1]\n-\n-#     # 创建标签映射\n-#     unique_labels = np.unique(labels)\n-#     label_to_int = {label: idx for idx, label in enumerate(unique_labels)}\n-#     int_labels = np.array([label_to_int[label] for label in labels], dtype=np.uint8)\n-#     labell = int_labels.reshape(-1,1)\n-\n-#     # 将标签转换为独热矩阵\n-#     one_hot_labels = np.zeros((int_labels.size, int_labels.max() + 1), dtype=np.uint8)\n-#     one_hot_labels[np.arange(int_labels.size), int_labels] = 1\n-\n-#     # print(\"======feature_size=====\", feature.shape)\n-#     print(\"======label_size=====\", one_hot_labels)\n-#     return feature, one_hot_labels\n-\n-# data_train = DataSet.sonar\n-\n-# load_dataset(data_train.dataset_name)\n-# endregion\n-\n-\n-def generate_random():\n-    random_tensor = random.randint(-10, 10)\n-    return random_tensor\n-\n-# region \n-# @mpc.run_multiprocess(world_size=2)\n-# def test(x,y):\n-    # x_enc = crypten.cryptensor(x, ptype=crypten.mpc.arithmetic)\n-    # y_enc = crypten.cryptensor(y, ptype=crypten.mpc.arithmetic)\n-    # ge_time_begin = time.time()\n-    # ge_  = x_enc.ge(y_enc)\n-    # ge_time_end = time.time()\n-    # ge_time = ge_time_end - ge_time_begin\n-    # print(\"ge_time\", ge_time)\n-    \n-    # gt_time_begin = time.time()\n-    # gt_  = x_enc.gt(y_enc)\n-    # gt_time_end = time.time()\n-    # gt_time = gt_time_end - gt_time_begin\n-    # print(\"gt_time\", gt_time)\n-    \n-    # relu_time_begin = time.time()\n-    # relu_ = ge_.relu()\n-    # relu_time_end = time.time()\n-    # relu_time = relu_time_end - relu_time_begin\n-    # print(\"relu_time\", relu_time)\n-# endregion\n-\n-@mpc.run_multiprocess(world_size=2)\n-def test(x):\n-    x_share = crypten.cryptensor(x, ptype = crypten.mpc.arithmetic)\n-    one_share = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n-    x_minus_one = x_share - one_share\n-    ge_time_begin = time.time()\n-    cmp_result = x_minus_one > 0\n-    ge_time_end = time.time()\n-    ge_time = ge_time_end - ge_time_begin\n-    print(\"ge_time\", ge_time)\n-    \n-    mulplex_time_begin = time.time()\n-    mulplex_result = crypten.where(cmp_result, x_minus_one, 0)\n-        # gt_time_end = time.time()\n-    # gt_time = gt_time_end - gt_time_begin\n-    # print(\"gt_time\", gt_time)\n-    \n-    rank = comm.get().get_rank()\n-    crypten.print(f\"\\nRank {rank}:\\n {cmp_result.get_plain_text()}\\n\", in_order=True)\n-    crypten.print(f\"\\nRank {rank}:\\n {mulplex_result.get_plain_text()}\\n\", in_order=True)\n-\n-def main():\n-    x = generate_random()\n-    # y = generate_random()\n-    print(\"x\", x)\n-    # print(\"y\", y)\n-    test(x)\n-\n main()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1721119254618,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -113,10 +113,10 @@\n     \n     mulplex_time_begin = time.time()\n     mulplex_result = crypten.where(cmp_result, x_minus_one, 0)\n     mulplex_time_end = time.time()\n-    mulplex_time = mulplex_time_end - gt_time_begin\n-    print(\"gt_time\", gt_time)\n+    mulplex_time = mulplex_time_end - mulplex_time_begin\n+    print(\"mulplex_time\", mulplex_time)\n     \n     rank = comm.get().get_rank()\n     crypten.print(f\"\\nRank {rank}:\\n {cmp_result.get_plain_text()}\\n\", in_order=True)\n     crypten.print(f\"\\nRank {rank}:\\n {mulplex_result.get_plain_text()}\\n\", in_order=True)\n"
                },
                {
                    "date": 1721119310098,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -116,8 +116,9 @@\n     mulplex_time_end = time.time()\n     mulplex_time = mulplex_time_end - mulplex_time_begin\n     print(\"mulplex_time\", mulplex_time)\n     \n+    \n     rank = comm.get().get_rank()\n     crypten.print(f\"\\nRank {rank}:\\n {cmp_result.get_plain_text()}\\n\", in_order=True)\n     crypten.print(f\"\\nRank {rank}:\\n {mulplex_result.get_plain_text()}\\n\", in_order=True)\n \n"
                },
                {
                    "date": 1721119322307,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -116,8 +116,9 @@\n     mulplex_time_end = time.time()\n     mulplex_time = mulplex_time_end - mulplex_time_begin\n     print(\"mulplex_time\", mulplex_time)\n     \n+    result = \n     \n     rank = comm.get().get_rank()\n     crypten.print(f\"\\nRank {rank}:\\n {cmp_result.get_plain_text()}\\n\", in_order=True)\n     crypten.print(f\"\\nRank {rank}:\\n {mulplex_result.get_plain_text()}\\n\", in_order=True)\n"
                },
                {
                    "date": 1721119342547,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -116,8 +116,9 @@\n     mulplex_time_end = time.time()\n     mulplex_time = mulplex_time_end - mulplex_time_begin\n     print(\"mulplex_time\", mulplex_time)\n     \n+    one_share\n     result = \n     \n     rank = comm.get().get_rank()\n     crypten.print(f\"\\nRank {rank}:\\n {cmp_result.get_plain_text()}\\n\", in_order=True)\n"
                },
                {
                    "date": 1721119348223,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -116,9 +116,9 @@\n     mulplex_time_end = time.time()\n     mulplex_time = mulplex_time_end - mulplex_time_begin\n     print(\"mulplex_time\", mulplex_time)\n     \n-    one_share\n+    one_share_again = \n     result = \n     \n     rank = comm.get().get_rank()\n     crypten.print(f\"\\nRank {rank}:\\n {cmp_result.get_plain_text()}\\n\", in_order=True)\n"
                },
                {
                    "date": 1721119357969,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -116,10 +116,10 @@\n     mulplex_time_end = time.time()\n     mulplex_time = mulplex_time_end - mulplex_time_begin\n     print(\"mulplex_time\", mulplex_time)\n     \n-    one_share_again = \n-    result = \n+    one_share_again = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n+    result = x_minus_one + \n     \n     rank = comm.get().get_rank()\n     crypten.print(f\"\\nRank {rank}:\\n {cmp_result.get_plain_text()}\\n\", in_order=True)\n     crypten.print(f\"\\nRank {rank}:\\n {mulplex_result.get_plain_text()}\\n\", in_order=True)\n"
                },
                {
                    "date": 1721119372246,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -117,9 +117,9 @@\n     mulplex_time = mulplex_time_end - mulplex_time_begin\n     print(\"mulplex_time\", mulplex_time)\n     \n     one_share_again = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n-    result = x_minus_one + \n+    result = mulplex_result + one_share_again\n     \n     rank = comm.get().get_rank()\n     crypten.print(f\"\\nRank {rank}:\\n {cmp_result.get_plain_text()}\\n\", in_order=True)\n     crypten.print(f\"\\nRank {rank}:\\n {mulplex_result.get_plain_text()}\\n\", in_order=True)\n"
                },
                {
                    "date": 1721119393820,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -119,8 +119,9 @@\n     \n     one_share_again = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n     result = mulplex_result + one_share_again\n     \n+    \n     rank = comm.get().get_rank()\n     crypten.print(f\"\\nRank {rank}:\\n {cmp_result.get_plain_text()}\\n\", in_order=True)\n     crypten.print(f\"\\nRank {rank}:\\n {mulplex_result.get_plain_text()}\\n\", in_order=True)\n \n"
                },
                {
                    "date": 1721119399291,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -123,8 +123,9 @@\n     \n     rank = comm.get().get_rank()\n     crypten.print(f\"\\nRank {rank}:\\n {cmp_result.get_plain_text()}\\n\", in_order=True)\n     crypten.print(f\"\\nRank {rank}:\\n {mulplex_result.get_plain_text()}\\n\", in_order=True)\n+    crypten.print(f\"\\nRank {rank}:\\n {mulplex_result.get_plain_text()}\\n\", in_order=True)\n \n def main():\n     x = generate_random()\n     # y = generate_random()\n"
                },
                {
                    "date": 1721119408371,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -117,15 +117,15 @@\n     mulplex_time = mulplex_time_end - mulplex_time_begin\n     print(\"mulplex_time\", mulplex_time)\n     \n     one_share_again = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n-    result = mulplex_result + one_share_again\n+    L-sigmod_result = mulplex_result + one_share_again\n     \n     \n     rank = comm.get().get_rank()\n     crypten.print(f\"\\nRank {rank}:\\n {cmp_result.get_plain_text()}\\n\", in_order=True)\n     crypten.print(f\"\\nRank {rank}:\\n {mulplex_result.get_plain_text()}\\n\", in_order=True)\n-    crypten.print(f\"\\nRank {rank}:\\n {mulplex_result.get_plain_text()}\\n\", in_order=True)\n+    crypten.print(f\"\\nRank {rank}:\\n {result.get_plain_text()}\\n\", in_order=True)\n \n def main():\n     x = generate_random()\n     # y = generate_random()\n"
                },
                {
                    "date": 1721119415840,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -117,15 +117,15 @@\n     mulplex_time = mulplex_time_end - mulplex_time_begin\n     print(\"mulplex_time\", mulplex_time)\n     \n     one_share_again = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n-    L-sigmod_result = mulplex_result + one_share_again\n+    L_sigmod_result = mulplex_result + one_share_again\n     \n     \n     rank = comm.get().get_rank()\n     crypten.print(f\"\\nRank {rank}:\\n {cmp_result.get_plain_text()}\\n\", in_order=True)\n     crypten.print(f\"\\nRank {rank}:\\n {mulplex_result.get_plain_text()}\\n\", in_order=True)\n-    crypten.print(f\"\\nRank {rank}:\\n {result.get_plain_text()}\\n\", in_order=True)\n+    crypten.print(f\"\\nRank {rank}:\\n {L-sigmod_result.get_plain_text()}\\n\", in_order=True)\n \n def main():\n     x = generate_random()\n     # y = generate_random()\n"
                },
                {
                    "date": 1721119423462,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -116,16 +116,17 @@\n     mulplex_time_end = time.time()\n     mulplex_time = mulplex_time_end - mulplex_time_begin\n     print(\"mulplex_time\", mulplex_time)\n     \n+    mulplex_time_begin = time.time()\n     one_share_again = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n     L_sigmod_result = mulplex_result + one_share_again\n     \n     \n     rank = comm.get().get_rank()\n     crypten.print(f\"\\nRank {rank}:\\n {cmp_result.get_plain_text()}\\n\", in_order=True)\n     crypten.print(f\"\\nRank {rank}:\\n {mulplex_result.get_plain_text()}\\n\", in_order=True)\n-    crypten.print(f\"\\nRank {rank}:\\n {L-sigmod_result.get_plain_text()}\\n\", in_order=True)\n+    crypten.print(f\"\\nRank {rank}:\\n {L_sigmod_result.get_plain_text()}\\n\", in_order=True)\n \n def main():\n     x = generate_random()\n     # y = generate_random()\n"
                },
                {
                    "date": 1721119432887,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,136 @@\n+\n+import crypten\n+import crypten.mpc\n+import torch\n+import crypten.mpc as mpc\n+import crypten.mpc.primitives.beaver as beaver\n+import crypten.communicator as comm \n+import torch\n+from crypten.mpc import MPCTensor\n+from crypten.mpc.primitives import BinarySharedTensor\n+import time\n+import random\n+import crypten.common.functions\n+\n+crypten.init()\n+\n+\n+# region \n+# DATASET_DIR = os.path.join(os.path.dirname(__file__), 'dataset')\n+\n+# class DataSetParam:\n+#     def __init__(self, dataset_name):\n+#         self.dataset_name = dataset_name\n+\n+\n+# class DataSet:\n+#     sonar = DataSetParam('sonar.csv')\n+#     sonar_selected = DataSetParam('sonar_selected.csv')\n+    \n+    \n+    \n+# def load_dataset(dataset):\n+#     dataset_path = os.path.join(DATASET_DIR, dataset)\n+\n+#     # 尝试打开并读取CSV文件\n+#     try:\n+#         with open(dataset_path, 'r', encoding='utf-8') as csvfile:\n+#             spamreader = csv.reader(csvfile)\n+#             data = np.array(list(spamreader))\n+#     except FileNotFoundError:\n+#         print(f\"Error: The file {dataset_path} was not found.\")\n+#         return None, None\n+#     except Exception as e:\n+#         print(f\"Error: An error occurred while reading the file: {e}\")\n+#         return None, None\n+\n+#     # 检查数据是否为空\n+#     if data.size == 0:\n+#         print(\"Error: The dataset is empty.\")\n+#         return None, None\n+\n+#     feature = data[:, :-1].astype(np.float64)\n+#     labels = data[:, -1]\n+\n+#     # 创建标签映射\n+#     unique_labels = np.unique(labels)\n+#     label_to_int = {label: idx for idx, label in enumerate(unique_labels)}\n+#     int_labels = np.array([label_to_int[label] for label in labels], dtype=np.uint8)\n+#     labell = int_labels.reshape(-1,1)\n+\n+#     # 将标签转换为独热矩阵\n+#     one_hot_labels = np.zeros((int_labels.size, int_labels.max() + 1), dtype=np.uint8)\n+#     one_hot_labels[np.arange(int_labels.size), int_labels] = 1\n+\n+#     # print(\"======feature_size=====\", feature.shape)\n+#     print(\"======label_size=====\", one_hot_labels)\n+#     return feature, one_hot_labels\n+\n+# data_train = DataSet.sonar\n+\n+# load_dataset(data_train.dataset_name)\n+# endregion\n+\n+\n+def generate_random():\n+    random_tensor = random.randint(-10, 10)\n+    return random_tensor\n+\n+# region \n+# @mpc.run_multiprocess(world_size=2)\n+# def test(x,y):\n+    # x_enc = crypten.cryptensor(x, ptype=crypten.mpc.arithmetic)\n+    # y_enc = crypten.cryptensor(y, ptype=crypten.mpc.arithmetic)\n+    # ge_time_begin = time.time()\n+    # ge_  = x_enc.ge(y_enc)\n+    # ge_time_end = time.time()\n+    # ge_time = ge_time_end - ge_time_begin\n+    # print(\"ge_time\", ge_time)\n+    \n+    # gt_time_begin = time.time()\n+    # gt_  = x_enc.gt(y_enc)\n+    # gt_time_end = time.time()\n+    # gt_time = gt_time_end - gt_time_begin\n+    # print(\"gt_time\", gt_time)\n+    \n+    # relu_time_begin = time.time()\n+    # relu_ = ge_.relu()\n+    # relu_time_end = time.time()\n+    # relu_time = relu_time_end - relu_time_begin\n+    # print(\"relu_time\", relu_time)\n+# endregion\n+\n+@mpc.run_multiprocess(world_size=2)\n+def test(x):\n+    x_share = crypten.cryptensor(x, ptype = crypten.mpc.arithmetic)\n+    one_share = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n+    x_minus_one = x_share - one_share\n+    ge_time_begin = time.time()\n+    cmp_result = x_minus_one > 0\n+    ge_time_end = time.time()\n+    ge_time = ge_time_end - ge_time_begin\n+    print(\"ge_time\", ge_time)\n+    \n+    mulplex_time_begin = time.time()\n+    mulplex_result = crypten.where(cmp_result, x_minus_one, 0)\n+    mulplex_time_end = time.time()\n+    mulplex_time = mulplex_time_end - mulplex_time_begin\n+    print(\"mulplex_time\", mulplex_time)\n+    \n+    one_share_again = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n+    L_sigmod_result = mulplex_result + one_share_again\n+    \n+    \n+    rank = comm.get().get_rank()\n+    crypten.print(f\"\\nRank {rank}:\\n {cmp_result.get_plain_text()}\\n\", in_order=True)\n+    crypten.print(f\"\\nRank {rank}:\\n {mulplex_result.get_plain_text()}\\n\", in_order=True)\n+    crypten.print(f\"\\nRank {rank}:\\n {L_sigmod_result.get_plain_text()}\\n\", in_order=True)\n+\n+def main():\n+    x = generate_random()\n+    # y = generate_random()\n+    print(\"x\", x)\n+    # print(\"y\", y)\n+    test(x)\n+\n+main()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1721119824232,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -105,9 +105,9 @@\n     x_share = crypten.cryptensor(x, ptype = crypten.mpc.arithmetic)\n     one_share = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n     x_minus_one = x_share - one_share\n     ge_time_begin = time.time()\n-    cmp_result = x_minus_one > 0\n+    cmp_result = x_minus_one < 0\n     ge_time_end = time.time()\n     ge_time = ge_time_end - ge_time_begin\n     print(\"ge_time\", ge_time)\n     \n@@ -132,142 +132,5 @@\n     print(\"x\", x)\n     # print(\"y\", y)\n     test(x)\n \n-main()\n-\n-import crypten\n-import crypten.mpc\n-import torch\n-import crypten.mpc as mpc\n-import crypten.mpc.primitives.beaver as beaver\n-import crypten.communicator as comm \n-import torch\n-from crypten.mpc import MPCTensor\n-from crypten.mpc.primitives import BinarySharedTensor\n-import time\n-import random\n-import crypten.common.functions\n-\n-crypten.init()\n-\n-\n-# region \n-# DATASET_DIR = os.path.join(os.path.dirname(__file__), 'dataset')\n-\n-# class DataSetParam:\n-#     def __init__(self, dataset_name):\n-#         self.dataset_name = dataset_name\n-\n-\n-# class DataSet:\n-#     sonar = DataSetParam('sonar.csv')\n-#     sonar_selected = DataSetParam('sonar_selected.csv')\n-    \n-    \n-    \n-# def load_dataset(dataset):\n-#     dataset_path = os.path.join(DATASET_DIR, dataset)\n-\n-#     # 尝试打开并读取CSV文件\n-#     try:\n-#         with open(dataset_path, 'r', encoding='utf-8') as csvfile:\n-#             spamreader = csv.reader(csvfile)\n-#             data = np.array(list(spamreader))\n-#     except FileNotFoundError:\n-#         print(f\"Error: The file {dataset_path} was not found.\")\n-#         return None, None\n-#     except Exception as e:\n-#         print(f\"Error: An error occurred while reading the file: {e}\")\n-#         return None, None\n-\n-#     # 检查数据是否为空\n-#     if data.size == 0:\n-#         print(\"Error: The dataset is empty.\")\n-#         return None, None\n-\n-#     feature = data[:, :-1].astype(np.float64)\n-#     labels = data[:, -1]\n-\n-#     # 创建标签映射\n-#     unique_labels = np.unique(labels)\n-#     label_to_int = {label: idx for idx, label in enumerate(unique_labels)}\n-#     int_labels = np.array([label_to_int[label] for label in labels], dtype=np.uint8)\n-#     labell = int_labels.reshape(-1,1)\n-\n-#     # 将标签转换为独热矩阵\n-#     one_hot_labels = np.zeros((int_labels.size, int_labels.max() + 1), dtype=np.uint8)\n-#     one_hot_labels[np.arange(int_labels.size), int_labels] = 1\n-\n-#     # print(\"======feature_size=====\", feature.shape)\n-#     print(\"======label_size=====\", one_hot_labels)\n-#     return feature, one_hot_labels\n-\n-# data_train = DataSet.sonar\n-\n-# load_dataset(data_train.dataset_name)\n-# endregion\n-\n-\n-def generate_random():\n-    random_tensor = random.randint(-10, 10)\n-    return random_tensor\n-\n-# region \n-# @mpc.run_multiprocess(world_size=2)\n-# def test(x,y):\n-    # x_enc = crypten.cryptensor(x, ptype=crypten.mpc.arithmetic)\n-    # y_enc = crypten.cryptensor(y, ptype=crypten.mpc.arithmetic)\n-    # ge_time_begin = time.time()\n-    # ge_  = x_enc.ge(y_enc)\n-    # ge_time_end = time.time()\n-    # ge_time = ge_time_end - ge_time_begin\n-    # print(\"ge_time\", ge_time)\n-    \n-    # gt_time_begin = time.time()\n-    # gt_  = x_enc.gt(y_enc)\n-    # gt_time_end = time.time()\n-    # gt_time = gt_time_end - gt_time_begin\n-    # print(\"gt_time\", gt_time)\n-    \n-    # relu_time_begin = time.time()\n-    # relu_ = ge_.relu()\n-    # relu_time_end = time.time()\n-    # relu_time = relu_time_end - relu_time_begin\n-    # print(\"relu_time\", relu_time)\n-# endregion\n-\n-@mpc.run_multiprocess(world_size=2)\n-def test(x):\n-    x_share = crypten.cryptensor(x, ptype = crypten.mpc.arithmetic)\n-    one_share = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n-    x_minus_one = x_share - one_share\n-    ge_time_begin = time.time()\n-    cmp_result = x_minus_one > 0\n-    ge_time_end = time.time()\n-    ge_time = ge_time_end - ge_time_begin\n-    print(\"ge_time\", ge_time)\n-    \n-    mulplex_time_begin = time.time()\n-    mulplex_result = crypten.where(cmp_result, x_minus_one, 0)\n-    mulplex_time_end = time.time()\n-    mulplex_time = mulplex_time_end - mulplex_time_begin\n-    print(\"mulplex_time\", mulplex_time)\n-    \n-    mulplex_time_begin = time.time()\n-    one_share_again = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n-    L_sigmod_result = mulplex_result + one_share_again\n-    \n-    \n-    rank = comm.get().get_rank()\n-    crypten.print(f\"\\nRank {rank}:\\n {cmp_result.get_plain_text()}\\n\", in_order=True)\n-    crypten.print(f\"\\nRank {rank}:\\n {mulplex_result.get_plain_text()}\\n\", in_order=True)\n-    crypten.print(f\"\\nRank {rank}:\\n {L_sigmod_result.get_plain_text()}\\n\", in_order=True)\n-\n-def main():\n-    x = generate_random()\n-    # y = generate_random()\n-    print(\"x\", x)\n-    # print(\"y\", y)\n-    test(x)\n-\n main()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1721119857474,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -114,9 +114,9 @@\n     mulplex_time_begin = time.time()\n     mulplex_result = crypten.where(cmp_result, x_minus_one, 0)\n     mulplex_time_end = time.time()\n     mulplex_time = mulplex_time_end - mulplex_time_begin\n-    print(\"mulplex_time\", mulplex_time)\n+    # print(\"mulplex_time\", mulplex_time)\n     \n     one_share_again = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n     L_sigmod_result = mulplex_result + one_share_again\n     \n"
                },
                {
                    "date": 1721119896478,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -102,15 +102,16 @@\n \n @mpc.run_multiprocess(world_size=2)\n def test(x):\n     x_share = crypten.cryptensor(x, ptype = crypten.mpc.arithmetic)\n+    \n     one_share = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n     x_minus_one = x_share - one_share\n     ge_time_begin = time.time()\n     cmp_result = x_minus_one < 0\n     ge_time_end = time.time()\n     ge_time = ge_time_end - ge_time_begin\n-    print(\"ge_time\", ge_time)\n+    # print(\"ge_time\", ge_time)\n     \n     mulplex_time_begin = time.time()\n     mulplex_result = crypten.where(cmp_result, x_minus_one, 0)\n     mulplex_time_end = time.time()\n"
                },
                {
                    "date": 1721119902840,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -104,8 +104,10 @@\n def test(x):\n     x_share = crypten.cryptensor(x, ptype = crypten.mpc.arithmetic)\n     \n     one_share = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n+    one_share_again = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n+    \n     x_minus_one = x_share - one_share\n     ge_time_begin = time.time()\n     cmp_result = x_minus_one < 0\n     ge_time_end = time.time()\n@@ -117,9 +119,9 @@\n     mulplex_time_end = time.time()\n     mulplex_time = mulplex_time_end - mulplex_time_begin\n     # print(\"mulplex_time\", mulplex_time)\n     \n-    one_share_again = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n+    \n     L_sigmod_result = mulplex_result + one_share_again\n     \n     \n     rank = comm.get().get_rank()\n"
                },
                {
                    "date": 1721120091735,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -103,8 +103,10 @@\n @mpc.run_multiprocess(world_size=2)\n def test(x):\n     x_share = crypten.cryptensor(x, ptype = crypten.mpc.arithmetic)\n     \n+    \n+    \n     one_share = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n     one_share_again = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n     \n     x_minus_one = x_share - one_share\n@@ -119,12 +121,10 @@\n     mulplex_time_end = time.time()\n     mulplex_time = mulplex_time_end - mulplex_time_begin\n     # print(\"mulplex_time\", mulplex_time)\n     \n-    \n     L_sigmod_result = mulplex_result + one_share_again\n     \n-    \n     rank = comm.get().get_rank()\n     crypten.print(f\"\\nRank {rank}:\\n {cmp_result.get_plain_text()}\\n\", in_order=True)\n     crypten.print(f\"\\nRank {rank}:\\n {mulplex_result.get_plain_text()}\\n\", in_order=True)\n     crypten.print(f\"\\nRank {rank}:\\n {L_sigmod_result.get_plain_text()}\\n\", in_order=True)\n"
                },
                {
                    "date": 1721120101328,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -102,11 +102,12 @@\n \n @mpc.run_multiprocess(world_size=2)\n def test(x):\n     x_share = crypten.cryptensor(x, ptype = crypten.mpc.arithmetic)\n+    # part 1\n     \n     \n-    \n+    # part 2\n     one_share = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n     one_share_again = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n     \n     x_minus_one = x_share - one_share\n"
                },
                {
                    "date": 1721120111764,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -109,9 +109,9 @@\n     # part 2\n     one_share = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n     one_share_again = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n     \n-    x_minus_one = x_share - one_share\n+    \n     ge_time_begin = time.time()\n     cmp_result = x_minus_one < 0\n     ge_time_end = time.time()\n     ge_time = ge_time_end - ge_time_begin\n"
                },
                {
                    "date": 1721120117290,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -102,11 +102,12 @@\n \n @mpc.run_multiprocess(world_size=2)\n def test(x):\n     x_share = crypten.cryptensor(x, ptype = crypten.mpc.arithmetic)\n+    x_minus_one = x_share - one_share\n     # part 1\n+    x_minus_one\n     \n-    \n     # part 2\n     one_share = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n     one_share_again = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n     \n"
                },
                {
                    "date": 1721120126038,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -104,9 +104,9 @@\n def test(x):\n     x_share = crypten.cryptensor(x, ptype = crypten.mpc.arithmetic)\n     x_minus_one = x_share - one_share\n     # part 1\n-    x_minus_one\n+    cmp_result_1 = \n     \n     # part 2\n     one_share = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n     one_share_again = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n"
                },
                {
                    "date": 1721120160027,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -104,9 +104,9 @@\n def test(x):\n     x_share = crypten.cryptensor(x, ptype = crypten.mpc.arithmetic)\n     x_minus_one = x_share - one_share\n     # part 1\n-    cmp_result_1 = \n+    cmp_result_1 = x_minus_one > 0\n     \n     # part 2\n     one_share = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n     one_share_again = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n"
                },
                {
                    "date": 1721120169870,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -106,8 +106,9 @@\n     x_minus_one = x_share - one_share\n     # part 1\n     cmp_result_1 = x_minus_one > 0\n     \n+    \n     # part 2\n     one_share = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n     one_share_again = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n     \n@@ -127,8 +128,9 @@\n     L_sigmod_result = mulplex_result + one_share_again\n     \n     rank = comm.get().get_rank()\n     crypten.print(f\"\\nRank {rank}:\\n {cmp_result.get_plain_text()}\\n\", in_order=True)\n+    crypten.print(f\"\\nRank {rank}:\\n {cmp_result.get_plain_text()}\\n\", in_order=True)\n     crypten.print(f\"\\nRank {rank}:\\n {mulplex_result.get_plain_text()}\\n\", in_order=True)\n     crypten.print(f\"\\nRank {rank}:\\n {L_sigmod_result.get_plain_text()}\\n\", in_order=True)\n \n def main():\n"
                },
                {
                    "date": 1721120178263,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,143 @@\n+\n+import crypten\n+import crypten.mpc\n+import torch\n+import crypten.mpc as mpc\n+import crypten.mpc.primitives.beaver as beaver\n+import crypten.communicator as comm \n+import torch\n+from crypten.mpc import MPCTensor\n+from crypten.mpc.primitives import BinarySharedTensor\n+import time\n+import random\n+import crypten.common.functions\n+\n+crypten.init()\n+\n+\n+# region \n+# DATASET_DIR = os.path.join(os.path.dirname(__file__), 'dataset')\n+\n+# class DataSetParam:\n+#     def __init__(self, dataset_name):\n+#         self.dataset_name = dataset_name\n+\n+\n+# class DataSet:\n+#     sonar = DataSetParam('sonar.csv')\n+#     sonar_selected = DataSetParam('sonar_selected.csv')\n+    \n+    \n+    \n+# def load_dataset(dataset):\n+#     dataset_path = os.path.join(DATASET_DIR, dataset)\n+\n+#     # 尝试打开并读取CSV文件\n+#     try:\n+#         with open(dataset_path, 'r', encoding='utf-8') as csvfile:\n+#             spamreader = csv.reader(csvfile)\n+#             data = np.array(list(spamreader))\n+#     except FileNotFoundError:\n+#         print(f\"Error: The file {dataset_path} was not found.\")\n+#         return None, None\n+#     except Exception as e:\n+#         print(f\"Error: An error occurred while reading the file: {e}\")\n+#         return None, None\n+\n+#     # 检查数据是否为空\n+#     if data.size == 0:\n+#         print(\"Error: The dataset is empty.\")\n+#         return None, None\n+\n+#     feature = data[:, :-1].astype(np.float64)\n+#     labels = data[:, -1]\n+\n+#     # 创建标签映射\n+#     unique_labels = np.unique(labels)\n+#     label_to_int = {label: idx for idx, label in enumerate(unique_labels)}\n+#     int_labels = np.array([label_to_int[label] for label in labels], dtype=np.uint8)\n+#     labell = int_labels.reshape(-1,1)\n+\n+#     # 将标签转换为独热矩阵\n+#     one_hot_labels = np.zeros((int_labels.size, int_labels.max() + 1), dtype=np.uint8)\n+#     one_hot_labels[np.arange(int_labels.size), int_labels] = 1\n+\n+#     # print(\"======feature_size=====\", feature.shape)\n+#     print(\"======label_size=====\", one_hot_labels)\n+#     return feature, one_hot_labels\n+\n+# data_train = DataSet.sonar\n+\n+# load_dataset(data_train.dataset_name)\n+# endregion\n+\n+\n+def generate_random():\n+    random_tensor = random.randint(-10, 10)\n+    return random_tensor\n+\n+# region \n+# @mpc.run_multiprocess(world_size=2)\n+# def test(x,y):\n+    # x_enc = crypten.cryptensor(x, ptype=crypten.mpc.arithmetic)\n+    # y_enc = crypten.cryptensor(y, ptype=crypten.mpc.arithmetic)\n+    # ge_time_begin = time.time()\n+    # ge_  = x_enc.ge(y_enc)\n+    # ge_time_end = time.time()\n+    # ge_time = ge_time_end - ge_time_begin\n+    # print(\"ge_time\", ge_time)\n+    \n+    # gt_time_begin = time.time()\n+    # gt_  = x_enc.gt(y_enc)\n+    # gt_time_end = time.time()\n+    # gt_time = gt_time_end - gt_time_begin\n+    # print(\"gt_time\", gt_time)\n+    \n+    # relu_time_begin = time.time()\n+    # relu_ = ge_.relu()\n+    # relu_time_end = time.time()\n+    # relu_time = relu_time_end - relu_time_begin\n+    # print(\"relu_time\", relu_time)\n+# endregion\n+\n+@mpc.run_multiprocess(world_size=2)\n+def test(x):\n+    x_share = crypten.cryptensor(x, ptype = crypten.mpc.arithmetic)\n+    x_minus_one = x_share - one_share\n+    # part 1\n+    cmp_result_1 = x_minus_one > 0\n+    \n+    \n+    # part 2\n+    one_share = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n+    one_share_again = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n+    \n+    \n+    ge_time_begin = time.time()\n+    cmp_result_2 = x_minus_one < 0\n+    ge_time_end = time.time()\n+    ge_time = ge_time_end - ge_time_begin\n+    # print(\"ge_time\", ge_time)\n+    \n+    mulplex_time_begin = time.time()\n+    mulplex_result = crypten.where(cmp_result, x_minus_one, 0)\n+    mulplex_time_end = time.time()\n+    mulplex_time = mulplex_time_end - mulplex_time_begin\n+    # print(\"mulplex_time\", mulplex_time)\n+    \n+    L_sigmod_result = mulplex_result + one_share_again\n+    \n+    rank = comm.get().get_rank()\n+    crypten.print(f\"\\nRank {rank}:\\n {cmp_result_1.get_plain_text()}\\n\", in_order=True)\n+    crypten.print(f\"\\nRank {rank}:\\n {cmp_result_2.get_plain_text()}\\n\", in_order=True)\n+    crypten.print(f\"\\nRank {rank}:\\n {mulplex_result.get_plain_text()}\\n\", in_order=True)\n+    crypten.print(f\"\\nRank {rank}:\\n {L_sigmod_result.get_plain_text()}\\n\", in_order=True)\n+\n+def main():\n+    x = generate_random()\n+    # y = generate_random()\n+    print(\"x\", x)\n+    # print(\"y\", y)\n+    test(x)\n+\n+main()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1721120203420,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -108,20 +108,18 @@\n     cmp_result_1 = x_minus_one > 0\n     \n     \n     # part 2\n-    one_share = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n-    one_share_again = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n+\n     \n-    \n     ge_time_begin = time.time()\n     cmp_result_2 = x_minus_one < 0\n     ge_time_end = time.time()\n     ge_time = ge_time_end - ge_time_begin\n     # print(\"ge_time\", ge_time)\n     \n     mulplex_time_begin = time.time()\n-    mulplex_result = crypten.where(cmp_result, x_minus_one, 0)\n+    mulplex_result = crypten.where(cmp_result_2, x_minus_one, 0)\n     mulplex_time_end = time.time()\n     mulplex_time = mulplex_time_end - mulplex_time_begin\n     # print(\"mulplex_time\", mulplex_time)\n     \n@@ -139,148 +137,5 @@\n     print(\"x\", x)\n     # print(\"y\", y)\n     test(x)\n \n-main()\n-\n-import crypten\n-import crypten.mpc\n-import torch\n-import crypten.mpc as mpc\n-import crypten.mpc.primitives.beaver as beaver\n-import crypten.communicator as comm \n-import torch\n-from crypten.mpc import MPCTensor\n-from crypten.mpc.primitives import BinarySharedTensor\n-import time\n-import random\n-import crypten.common.functions\n-\n-crypten.init()\n-\n-\n-# region \n-# DATASET_DIR = os.path.join(os.path.dirname(__file__), 'dataset')\n-\n-# class DataSetParam:\n-#     def __init__(self, dataset_name):\n-#         self.dataset_name = dataset_name\n-\n-\n-# class DataSet:\n-#     sonar = DataSetParam('sonar.csv')\n-#     sonar_selected = DataSetParam('sonar_selected.csv')\n-    \n-    \n-    \n-# def load_dataset(dataset):\n-#     dataset_path = os.path.join(DATASET_DIR, dataset)\n-\n-#     # 尝试打开并读取CSV文件\n-#     try:\n-#         with open(dataset_path, 'r', encoding='utf-8') as csvfile:\n-#             spamreader = csv.reader(csvfile)\n-#             data = np.array(list(spamreader))\n-#     except FileNotFoundError:\n-#         print(f\"Error: The file {dataset_path} was not found.\")\n-#         return None, None\n-#     except Exception as e:\n-#         print(f\"Error: An error occurred while reading the file: {e}\")\n-#         return None, None\n-\n-#     # 检查数据是否为空\n-#     if data.size == 0:\n-#         print(\"Error: The dataset is empty.\")\n-#         return None, None\n-\n-#     feature = data[:, :-1].astype(np.float64)\n-#     labels = data[:, -1]\n-\n-#     # 创建标签映射\n-#     unique_labels = np.unique(labels)\n-#     label_to_int = {label: idx for idx, label in enumerate(unique_labels)}\n-#     int_labels = np.array([label_to_int[label] for label in labels], dtype=np.uint8)\n-#     labell = int_labels.reshape(-1,1)\n-\n-#     # 将标签转换为独热矩阵\n-#     one_hot_labels = np.zeros((int_labels.size, int_labels.max() + 1), dtype=np.uint8)\n-#     one_hot_labels[np.arange(int_labels.size), int_labels] = 1\n-\n-#     # print(\"======feature_size=====\", feature.shape)\n-#     print(\"======label_size=====\", one_hot_labels)\n-#     return feature, one_hot_labels\n-\n-# data_train = DataSet.sonar\n-\n-# load_dataset(data_train.dataset_name)\n-# endregion\n-\n-\n-def generate_random():\n-    random_tensor = random.randint(-10, 10)\n-    return random_tensor\n-\n-# region \n-# @mpc.run_multiprocess(world_size=2)\n-# def test(x,y):\n-    # x_enc = crypten.cryptensor(x, ptype=crypten.mpc.arithmetic)\n-    # y_enc = crypten.cryptensor(y, ptype=crypten.mpc.arithmetic)\n-    # ge_time_begin = time.time()\n-    # ge_  = x_enc.ge(y_enc)\n-    # ge_time_end = time.time()\n-    # ge_time = ge_time_end - ge_time_begin\n-    # print(\"ge_time\", ge_time)\n-    \n-    # gt_time_begin = time.time()\n-    # gt_  = x_enc.gt(y_enc)\n-    # gt_time_end = time.time()\n-    # gt_time = gt_time_end - gt_time_begin\n-    # print(\"gt_time\", gt_time)\n-    \n-    # relu_time_begin = time.time()\n-    # relu_ = ge_.relu()\n-    # relu_time_end = time.time()\n-    # relu_time = relu_time_end - relu_time_begin\n-    # print(\"relu_time\", relu_time)\n-# endregion\n-\n-@mpc.run_multiprocess(world_size=2)\n-def test(x):\n-    x_share = crypten.cryptensor(x, ptype = crypten.mpc.arithmetic)\n-    x_minus_one = x_share - one_share\n-    # part 1\n-    cmp_result_1 = x_minus_one > 0\n-    \n-    \n-    # part 2\n-    one_share = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n-    one_share_again = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n-    \n-    \n-    ge_time_begin = time.time()\n-    cmp_result = x_minus_one < 0\n-    ge_time_end = time.time()\n-    ge_time = ge_time_end - ge_time_begin\n-    # print(\"ge_time\", ge_time)\n-    \n-    mulplex_time_begin = time.time()\n-    mulplex_result = crypten.where(cmp_result, x_minus_one, 0)\n-    mulplex_time_end = time.time()\n-    mulplex_time = mulplex_time_end - mulplex_time_begin\n-    # print(\"mulplex_time\", mulplex_time)\n-    \n-    L_sigmod_result = mulplex_result + one_share_again\n-    \n-    rank = comm.get().get_rank()\n-    crypten.print(f\"\\nRank {rank}:\\n {cmp_result.get_plain_text()}\\n\", in_order=True)\n-    crypten.print(f\"\\nRank {rank}:\\n {cmp_result.get_plain_text()}\\n\", in_order=True)\n-    crypten.print(f\"\\nRank {rank}:\\n {mulplex_result.get_plain_text()}\\n\", in_order=True)\n-    crypten.print(f\"\\nRank {rank}:\\n {L_sigmod_result.get_plain_text()}\\n\", in_order=True)\n-\n-def main():\n-    x = generate_random()\n-    # y = generate_random()\n-    print(\"x\", x)\n-    # print(\"y\", y)\n-    test(x)\n-\n main()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1721120209055,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -102,16 +102,16 @@\n \n @mpc.run_multiprocess(world_size=2)\n def test(x):\n     x_share = crypten.cryptensor(x, ptype = crypten.mpc.arithmetic)\n+    one_share = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n+    one_share_again = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n     x_minus_one = x_share - one_share\n     # part 1\n     cmp_result_1 = x_minus_one > 0\n     \n     \n-    # part 2\n-\n-    \n+    # part 2    \n     ge_time_begin = time.time()\n     cmp_result_2 = x_minus_one < 0\n     ge_time_end = time.time()\n     ge_time = ge_time_end - ge_time_begin\n"
                },
                {
                    "date": 1721120214649,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -105,12 +105,12 @@\n     x_share = crypten.cryptensor(x, ptype = crypten.mpc.arithmetic)\n     one_share = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n     one_share_again = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n     x_minus_one = x_share - one_share\n+    \n     # part 1\n     cmp_result_1 = x_minus_one > 0\n     \n-    \n     # part 2    \n     ge_time_begin = time.time()\n     cmp_result_2 = x_minus_one < 0\n     ge_time_end = time.time()\n"
                },
                {
                    "date": 1721120233731,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -125,9 +125,9 @@\n     \n     L_sigmod_result = mulplex_result + one_share_again\n     \n     rank = comm.get().get_rank()\n-    crypten.print(f\"\\nRank {rank}:\\n {cmp_result_1.get_plain_text()}\\n\", in_order=True)\n+    crypten.print(f\"\\nRank {rank}:\\n cmp_result_1{cmp_result_1.get_plain_text()}\\n\", in_order=True)\n     crypten.print(f\"\\nRank {rank}:\\n {cmp_result_2.get_plain_text()}\\n\", in_order=True)\n     crypten.print(f\"\\nRank {rank}:\\n {mulplex_result.get_plain_text()}\\n\", in_order=True)\n     crypten.print(f\"\\nRank {rank}:\\n {L_sigmod_result.get_plain_text()}\\n\", in_order=True)\n \n"
                },
                {
                    "date": 1721120239494,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -125,10 +125,10 @@\n     \n     L_sigmod_result = mulplex_result + one_share_again\n     \n     rank = comm.get().get_rank()\n-    crypten.print(f\"\\nRank {rank}:\\n cmp_result_1{cmp_result_1.get_plain_text()}\\n\", in_order=True)\n-    crypten.print(f\"\\nRank {rank}:\\n {cmp_result_2.get_plain_text()}\\n\", in_order=True)\n+    crypten.print(f\"\\nRank {rank}:\\n cmp_result_1: {cmp_result_1.get_plain_text()}\\n\", in_order=True)\n+    crypten.print(f\"\\nRank {rank}:\\n cmp_result_2: {cmp_result_2.get_plain_text()}\\n\", in_order=True)\n     crypten.print(f\"\\nRank {rank}:\\n {mulplex_result.get_plain_text()}\\n\", in_order=True)\n     crypten.print(f\"\\nRank {rank}:\\n {L_sigmod_result.get_plain_text()}\\n\", in_order=True)\n \n def main():\n"
                },
                {
                    "date": 1721120247807,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -127,10 +127,10 @@\n     \n     rank = comm.get().get_rank()\n     crypten.print(f\"\\nRank {rank}:\\n cmp_result_1: {cmp_result_1.get_plain_text()}\\n\", in_order=True)\n     crypten.print(f\"\\nRank {rank}:\\n cmp_result_2: {cmp_result_2.get_plain_text()}\\n\", in_order=True)\n-    crypten.print(f\"\\nRank {rank}:\\n {mulplex_result.get_plain_text()}\\n\", in_order=True)\n-    crypten.print(f\"\\nRank {rank}:\\n {L_sigmod_result.get_plain_text()}\\n\", in_order=True)\n+    crypten.print(f\"\\nRank {rank}:\\n mulplex_result: {mulplex_result.get_plain_text()}\\n\", in_order=True)\n+    crypten.print(f\"\\nRank {rank}:\\n L_sigmod_result: {L_sigmod_result.get_plain_text()}\\n\", in_order=True)\n \n def main():\n     x = generate_random()\n     # y = generate_random()\n"
                },
                {
                    "date": 1721120312095,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -104,10 +104,10 @@\n def test(x):\n     x_share = crypten.cryptensor(x, ptype = crypten.mpc.arithmetic)\n     one_share = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n     one_share_again = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n-    x_minus_one = x_share - one_share\n     \n+    \n     # part 1\n     cmp_result_1 = x_minus_one > 0\n     \n     # part 2    \n"
                },
                {
                    "date": 1721120318800,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -107,11 +107,12 @@\n     one_share_again = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n     \n     \n     # part 1\n-    cmp_result_1 = x_minus_one > 0\n+    cmp_result_1 = x_share > 0\n     \n     # part 2    \n+    x_minus_one = x_share - one_share\n     ge_time_begin = time.time()\n     cmp_result_2 = x_minus_one < 0\n     ge_time_end = time.time()\n     ge_time = ge_time_end - ge_time_begin\n"
                },
                {
                    "date": 1721120325092,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -105,9 +105,8 @@\n     x_share = crypten.cryptensor(x, ptype = crypten.mpc.arithmetic)\n     one_share = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n     one_share_again = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n     \n-    \n     # part 1\n     cmp_result_1 = x_share > 0\n     \n     # part 2    \n"
                },
                {
                    "date": 1721120515899,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -126,9 +126,9 @@\n     L_sigmod_result = mulplex_result + one_share_again\n     \n     rank = comm.get().get_rank()\n     crypten.print(f\"\\nRank {rank}:\\n cmp_result_1: {cmp_result_1.get_plain_text()}\\n\", in_order=True)\n-    crypten.print(f\"\\nRank {rank}:\\n cmp_result_2: {cmp_result_2.get_plain_text()}\\n\", in_order=True)\n+    crypten.print(f\"\\nRank {rank}:\\n \", in_order=True)\n     crypten.print(f\"\\nRank {rank}:\\n mulplex_result: {mulplex_result.get_plain_text()}\\n\", in_order=True)\n     crypten.print(f\"\\nRank {rank}:\\n L_sigmod_result: {L_sigmod_result.get_plain_text()}\\n\", in_order=True)\n \n def main():\n"
                },
                {
                    "date": 1721120522042,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -125,9 +125,9 @@\n     \n     L_sigmod_result = mulplex_result + one_share_again\n     \n     rank = comm.get().get_rank()\n-    crypten.print(f\"\\nRank {rank}:\\n cmp_result_1: {cmp_result_1.get_plain_text()}\\n\", in_order=True)\n+    crypten.print(f\"\\nRank {rank}:\\n cmp_result_1: {cmp_result_1.get_plain_text()}\\n cmp_result_2: {cmp_result_2.get_plain_text()}\\n\", in_order=True)\n     crypten.print(f\"\\nRank {rank}:\\n \", in_order=True)\n     crypten.print(f\"\\nRank {rank}:\\n mulplex_result: {mulplex_result.get_plain_text()}\\n\", in_order=True)\n     crypten.print(f\"\\nRank {rank}:\\n L_sigmod_result: {L_sigmod_result.get_plain_text()}\\n\", in_order=True)\n \n"
                },
                {
                    "date": 1721120528379,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -125,9 +125,10 @@\n     \n     L_sigmod_result = mulplex_result + one_share_again\n     \n     rank = comm.get().get_rank()\n-    crypten.print(f\"\\nRank {rank}:\\n cmp_result_1: {cmp_result_1.get_plain_text()}\\n cmp_result_2: {cmp_result_2.get_plain_text()}\\n\", in_order=True)\n+    crypten.print(f\"\\nRank {rank}:\\n cmp_result_1: {cmp_result_1.get_plain_text()}\\n \n+                                    cmp_result_2: {cmp_result_2.get_plain_text()}\\n\", in_order=True)\n     crypten.print(f\"\\nRank {rank}:\\n \", in_order=True)\n     crypten.print(f\"\\nRank {rank}:\\n mulplex_result: {mulplex_result.get_plain_text()}\\n\", in_order=True)\n     crypten.print(f\"\\nRank {rank}:\\n L_sigmod_result: {L_sigmod_result.get_plain_text()}\\n\", in_order=True)\n \n"
                },
                {
                    "date": 1721120545423,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -126,9 +126,10 @@\n     L_sigmod_result = mulplex_result + one_share_again\n     \n     rank = comm.get().get_rank()\n     crypten.print(f\"\\nRank {rank}:\\n cmp_result_1: {cmp_result_1.get_plain_text()}\\n \n-                                    cmp_result_2: {cmp_result_2.get_plain_text()}\\n\", in_order=True)\n+                                    cmp_result_2: {cmp_result_2.get_plain_text()}\\n\", \n+                                    mulplex_result: {mulplex_result.get_plain_text()}\\nin_order=True)\n     crypten.print(f\"\\nRank {rank}:\\n \", in_order=True)\n     crypten.print(f\"\\nRank {rank}:\\n mulplex_result: {mulplex_result.get_plain_text()}\\n\", in_order=True)\n     crypten.print(f\"\\nRank {rank}:\\n L_sigmod_result: {L_sigmod_result.get_plain_text()}\\n\", in_order=True)\n \n"
                },
                {
                    "date": 1721120554377,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -126,10 +126,10 @@\n     L_sigmod_result = mulplex_result + one_share_again\n     \n     rank = comm.get().get_rank()\n     crypten.print(f\"\\nRank {rank}:\\n cmp_result_1: {cmp_result_1.get_plain_text()}\\n \n-                                    cmp_result_2: {cmp_result_2.get_plain_text()}\\n\", \n-                                    mulplex_result: {mulplex_result.get_plain_text()}\\nin_order=True)\n+                                    cmp_result_2: {cmp_result_2.get_plain_text()}\\n, \n+                                    mulplex_result: {mulplex_result.get_plain_text()}\\n, in_order=True)\n     crypten.print(f\"\\nRank {rank}:\\n \", in_order=True)\n     crypten.print(f\"\\nRank {rank}:\\n mulplex_result: {mulplex_result.get_plain_text()}\\n\", in_order=True)\n     crypten.print(f\"\\nRank {rank}:\\n L_sigmod_result: {L_sigmod_result.get_plain_text()}\\n\", in_order=True)\n \n"
                },
                {
                    "date": 1721120564527,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -127,9 +127,10 @@\n     \n     rank = comm.get().get_rank()\n     crypten.print(f\"\\nRank {rank}:\\n cmp_result_1: {cmp_result_1.get_plain_text()}\\n \n                                     cmp_result_2: {cmp_result_2.get_plain_text()}\\n, \n-                                    mulplex_result: {mulplex_result.get_plain_text()}\\n, in_order=True)\n+                                    mulplex_result: {mulplex_result.get_plain_text()}\\n, \n+                                    L_sigmod_result: {L_sigmod_result.get_plain_text()}\\n\", in_order=True)\n     crypten.print(f\"\\nRank {rank}:\\n \", in_order=True)\n     crypten.print(f\"\\nRank {rank}:\\n mulplex_result: {mulplex_result.get_plain_text()}\\n\", in_order=True)\n     crypten.print(f\"\\nRank {rank}:\\n L_sigmod_result: {L_sigmod_result.get_plain_text()}\\n\", in_order=True)\n \n"
                },
                {
                    "date": 1721120569686,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -126,9 +126,9 @@\n     L_sigmod_result = mulplex_result + one_share_again\n     \n     rank = comm.get().get_rank()\n     crypten.print(f\"\\nRank {rank}:\\n cmp_result_1: {cmp_result_1.get_plain_text()}\\n \n-                                    cmp_result_2: {cmp_result_2.get_plain_text()}\\n, \n+                                    cmp_result_2: {cmp_result_2.get_plain_text()}\\n\n                                     mulplex_result: {mulplex_result.get_plain_text()}\\n, \n                                     L_sigmod_result: {L_sigmod_result.get_plain_text()}\\n\", in_order=True)\n     crypten.print(f\"\\nRank {rank}:\\n \", in_order=True)\n     crypten.print(f\"\\nRank {rank}:\\n mulplex_result: {mulplex_result.get_plain_text()}\\n\", in_order=True)\n"
                },
                {
                    "date": 1721120592334,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -126,10 +126,10 @@\n     L_sigmod_result = mulplex_result + one_share_again\n     \n     rank = comm.get().get_rank()\n     crypten.print(f\"\\nRank {rank}:\\n cmp_result_1: {cmp_result_1.get_plain_text()}\\n \n-                                    cmp_result_2: {cmp_result_2.get_plain_text()}\\n\n-                                    mulplex_result: {mulplex_result.get_plain_text()}\\n, \n+                                     cmp_result_2: {cmp_result_2.get_plain_text()}\\n\n+                                    mulplex_result: {mulplex_result.get_plain_text()}\\n\n                                     L_sigmod_result: {L_sigmod_result.get_plain_text()}\\n\", in_order=True)\n     crypten.print(f\"\\nRank {rank}:\\n \", in_order=True)\n     crypten.print(f\"\\nRank {rank}:\\n mulplex_result: {mulplex_result.get_plain_text()}\\n\", in_order=True)\n     crypten.print(f\"\\nRank {rank}:\\n L_sigmod_result: {L_sigmod_result.get_plain_text()}\\n\", in_order=True)\n"
                },
                {
                    "date": 1721120604881,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -126,10 +126,9 @@\n     L_sigmod_result = mulplex_result + one_share_again\n     \n     rank = comm.get().get_rank()\n     crypten.print(f\"\\nRank {rank}:\\n cmp_result_1: {cmp_result_1.get_plain_text()}\\n \n-                                     cmp_result_2: {cmp_result_2.get_plain_text()}\\n\n-                                    mulplex_result: {mulplex_result.get_plain_text()}\\n\n+                                    cmp_result_2: {cmp_result_2.get_plain_text()}\\nmulplex_result: {mulplex_result.get_plain_text()}\\n\n                                     L_sigmod_result: {L_sigmod_result.get_plain_text()}\\n\", in_order=True)\n     crypten.print(f\"\\nRank {rank}:\\n \", in_order=True)\n     crypten.print(f\"\\nRank {rank}:\\n mulplex_result: {mulplex_result.get_plain_text()}\\n\", in_order=True)\n     crypten.print(f\"\\nRank {rank}:\\n L_sigmod_result: {L_sigmod_result.get_plain_text()}\\n\", in_order=True)\n"
                },
                {
                    "date": 1721120615277,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -126,10 +126,11 @@\n     L_sigmod_result = mulplex_result + one_share_again\n     \n     rank = comm.get().get_rank()\n     crypten.print(f\"\\nRank {rank}:\\n cmp_result_1: {cmp_result_1.get_plain_text()}\\n \n-                                    cmp_result_2: {cmp_result_2.get_plain_text()}\\nmulplex_result: {mulplex_result.get_plain_text()}\\n\n-                                    L_sigmod_result: {L_sigmod_result.get_plain_text()}\\n\", in_order=True)\n+                                    cmp_result_2: {cmp_result_2.get_plain_text()}\\n \n+                                    mulplex_result: {mulplex_result.get_plain_text()}\\n\n+                                    L_sigmod_result:{L_sigmod_result.get_plain_text()}\\n\", in_order=True)\n     crypten.print(f\"\\nRank {rank}:\\n \", in_order=True)\n     crypten.print(f\"\\nRank {rank}:\\n mulplex_result: {mulplex_result.get_plain_text()}\\n\", in_order=True)\n     crypten.print(f\"\\nRank {rank}:\\n L_sigmod_result: {L_sigmod_result.get_plain_text()}\\n\", in_order=True)\n \n"
                },
                {
                    "date": 1721120620628,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -127,9 +127,9 @@\n     \n     rank = comm.get().get_rank()\n     crypten.print(f\"\\nRank {rank}:\\n cmp_result_1: {cmp_result_1.get_plain_text()}\\n \n                                     cmp_result_2: {cmp_result_2.get_plain_text()}\\n \n-                                    mulplex_result: {mulplex_result.get_plain_text()}\\n\n+                                    mulplex_result: {mulplex_result.get_plain_text()}\\n \n                                     L_sigmod_result:{L_sigmod_result.get_plain_text()}\\n\", in_order=True)\n     crypten.print(f\"\\nRank {rank}:\\n \", in_order=True)\n     crypten.print(f\"\\nRank {rank}:\\n mulplex_result: {mulplex_result.get_plain_text()}\\n\", in_order=True)\n     crypten.print(f\"\\nRank {rank}:\\n L_sigmod_result: {L_sigmod_result.get_plain_text()}\\n\", in_order=True)\n"
                },
                {
                    "date": 1721120648146,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -129,11 +129,8 @@\n     crypten.print(f\"\\nRank {rank}:\\n cmp_result_1: {cmp_result_1.get_plain_text()}\\n \n                                     cmp_result_2: {cmp_result_2.get_plain_text()}\\n \n                                     mulplex_result: {mulplex_result.get_plain_text()}\\n \n                                     L_sigmod_result:{L_sigmod_result.get_plain_text()}\\n\", in_order=True)\n-    crypten.print(f\"\\nRank {rank}:\\n \", in_order=True)\n-    crypten.print(f\"\\nRank {rank}:\\n mulplex_result: {mulplex_result.get_plain_text()}\\n\", in_order=True)\n-    crypten.print(f\"\\nRank {rank}:\\n L_sigmod_result: {L_sigmod_result.get_plain_text()}\\n\", in_order=True)\n \n def main():\n     x = generate_random()\n     # y = generate_random()\n"
                },
                {
                    "date": 1721120654135,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -129,8 +129,11 @@\n     crypten.print(f\"\\nRank {rank}:\\n cmp_result_1: {cmp_result_1.get_plain_text()}\\n \n                                     cmp_result_2: {cmp_result_2.get_plain_text()}\\n \n                                     mulplex_result: {mulplex_result.get_plain_text()}\\n \n                                     L_sigmod_result:{L_sigmod_result.get_plain_text()}\\n\", in_order=True)\n+    crypten.print(f\"\\nRank {rank}:\\n \", in_order=True)\n+    crypten.print(f\"\\nRank {rank}:\\n mulplex_result: {mulplex_result.get_plain_text()}\\n\", in_order=True)\n+    crypten.print(f\"\\nRank {rank}:\\n L_sigmod_result: {L_sigmod_result.get_plain_text()}\\n\", in_order=True)\n \n def main():\n     x = generate_random()\n     # y = generate_random()\n"
                },
                {
                    "date": 1721120661193,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -129,12 +129,10 @@\n     crypten.print(f\"\\nRank {rank}:\\n cmp_result_1: {cmp_result_1.get_plain_text()}\\n \n                                     cmp_result_2: {cmp_result_2.get_plain_text()}\\n \n                                     mulplex_result: {mulplex_result.get_plain_text()}\\n \n                                     L_sigmod_result:{L_sigmod_result.get_plain_text()}\\n\", in_order=True)\n-    crypten.print(f\"\\nRank {rank}:\\n \", in_order=True)\n-    crypten.print(f\"\\nRank {rank}:\\n mulplex_result: {mulplex_result.get_plain_text()}\\n\", in_order=True)\n-    crypten.print(f\"\\nRank {rank}:\\n L_sigmod_result: {L_sigmod_result.get_plain_text()}\\n\", in_order=True)\n \n+\n def main():\n     x = generate_random()\n     # y = generate_random()\n     print(\"x\", x)\n"
                },
                {
                    "date": 1721120701802,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -125,14 +125,16 @@\n     \n     L_sigmod_result = mulplex_result + one_share_again\n     \n     rank = comm.get().get_rank()\n-    crypten.print(f\"\\nRank {rank}:\\n cmp_result_1: {cmp_result_1.get_plain_text()}\\n \n-                                    cmp_result_2: {cmp_result_2.get_plain_text()}\\n \n-                                    mulplex_result: {mulplex_result.get_plain_text()}\\n \n-                                    L_sigmod_result:{L_sigmod_result.get_plain_text()}\\n\", in_order=True)\n+crypten.print(f\"\\nRank {rank}:\\n cmp_result_1: {cmp_result_1.get_plain_text()}\\n\" \\\n+              f\" cmp_result_2: {cmp_result_2.get_plain_text()}\\n\" \\\n+              f\" mulplex_result: {mulplex_result.get_plain_text()}\\n\" \\\n+              f\" L_sigmod_result:{L_sigmod_result.get_plain_text()}\\n\",\n+              in_order=True)\n \n \n+\n def main():\n     x = generate_random()\n     # y = generate_random()\n     print(\"x\", x)\n"
                },
                {
                    "date": 1721120762631,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -72,9 +72,9 @@\n # endregion\n \n \n def generate_random():\n-    random_tensor = random.randint(-10, 10)\n+    random_tensor = random.uniform(-10, 10)\n     return random_tensor\n \n # region \n # @mpc.run_multiprocess(world_size=2)\n@@ -125,13 +125,13 @@\n     \n     L_sigmod_result = mulplex_result + one_share_again\n     \n     rank = comm.get().get_rank()\n-crypten.print(f\"\\nRank {rank}:\\n cmp_result_1: {cmp_result_1.get_plain_text()}\\n\" \\\n-              f\" cmp_result_2: {cmp_result_2.get_plain_text()}\\n\" \\\n-              f\" mulplex_result: {mulplex_result.get_plain_text()}\\n\" \\\n-              f\" L_sigmod_result:{L_sigmod_result.get_plain_text()}\\n\",\n-              in_order=True)\n+    crypten.print(f\"\\nRank {rank}:\\n cmp_result_1: {cmp_result_1.get_plain_text()}\\n\" \\\n+                f\" cmp_result_2: {cmp_result_2.get_plain_text()}\\n\" \\\n+                f\" mulplex_result: {mulplex_result.get_plain_text()}\\n\" \\\n+                f\" L_sigmod_result:{L_sigmod_result.get_plain_text()}\\n\",\n+                in_order=True)\n \n \n \n def main():\n"
                },
                {
                    "date": 1721120808653,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -114,9 +114,9 @@\n     ge_time_begin = time.time()\n     cmp_result_2 = x_minus_one < 0\n     ge_time_end = time.time()\n     ge_time = ge_time_end - ge_time_begin\n-    # print(\"ge_time\", ge_time)\n+    print(\"ge_time\", ge_time)\n     \n     mulplex_time_begin = time.time()\n     mulplex_result = crypten.where(cmp_result_2, x_minus_one, 0)\n     mulplex_time_end = time.time()\n"
                },
                {
                    "date": 1721120814410,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -120,9 +120,9 @@\n     mulplex_time_begin = time.time()\n     mulplex_result = crypten.where(cmp_result_2, x_minus_one, 0)\n     mulplex_time_end = time.time()\n     mulplex_time = mulplex_time_end - mulplex_time_begin\n-    # print(\"mulplex_time\", mulplex_time)\n+    print(\"mulplex_time\", mulplex_time)\n     \n     L_sigmod_result = mulplex_result + one_share_again\n     \n     rank = comm.get().get_rank()\n@@ -130,11 +130,11 @@\n                 f\" cmp_result_2: {cmp_result_2.get_plain_text()}\\n\" \\\n                 f\" mulplex_result: {mulplex_result.get_plain_text()}\\n\" \\\n                 f\" L_sigmod_result:{L_sigmod_result.get_plain_text()}\\n\",\n                 in_order=True)\n+    \n \n \n-\n def main():\n     x = generate_random()\n     # y = generate_random()\n     print(\"x\", x)\n"
                },
                {
                    "date": 1721120825455,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -114,9 +114,9 @@\n     ge_time_begin = time.time()\n     cmp_result_2 = x_minus_one < 0\n     ge_time_end = time.time()\n     ge_time = ge_time_end - ge_time_begin\n-    print(\"ge_time\", ge_time)\n+    # print(\"ge_time\", ge_time)\n     \n     mulplex_time_begin = time.time()\n     mulplex_result = crypten.where(cmp_result_2, x_minus_one, 0)\n     mulplex_time_end = time.time()\n@@ -130,11 +130,11 @@\n                 f\" cmp_result_2: {cmp_result_2.get_plain_text()}\\n\" \\\n                 f\" mulplex_result: {mulplex_result.get_plain_text()}\\n\" \\\n                 f\" L_sigmod_result:{L_sigmod_result.get_plain_text()}\\n\",\n                 in_order=True)\n-    \n \n \n+\n def main():\n     x = generate_random()\n     # y = generate_random()\n     print(\"x\", x)\n"
                },
                {
                    "date": 1721120835352,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -100,9 +100,9 @@\n     # print(\"relu_time\", relu_time)\n # endregion\n \n @mpc.run_multiprocess(world_size=2)\n-def test(x):\n+def L-si(x):\n     x_share = crypten.cryptensor(x, ptype = crypten.mpc.arithmetic)\n     one_share = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n     one_share_again = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n     \n@@ -120,9 +120,9 @@\n     mulplex_time_begin = time.time()\n     mulplex_result = crypten.where(cmp_result_2, x_minus_one, 0)\n     mulplex_time_end = time.time()\n     mulplex_time = mulplex_time_end - mulplex_time_begin\n-    print(\"mulplex_time\", mulplex_time)\n+    # print(\"mulplex_time\", mulplex_time)\n     \n     L_sigmod_result = mulplex_result + one_share_again\n     \n     rank = comm.get().get_rank()\n"
                },
                {
                    "date": 1721120845706,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,144 @@\n+\n+import crypten\n+import crypten.mpc\n+import torch\n+import crypten.mpc as mpc\n+import crypten.mpc.primitives.beaver as beaver\n+import crypten.communicator as comm \n+import torch\n+from crypten.mpc import MPCTensor\n+from crypten.mpc.primitives import BinarySharedTensor\n+import time\n+import random\n+import crypten.common.functions\n+\n+crypten.init()\n+\n+\n+# region \n+# DATASET_DIR = os.path.join(os.path.dirname(__file__), 'dataset')\n+\n+# class DataSetParam:\n+#     def __init__(self, dataset_name):\n+#         self.dataset_name = dataset_name\n+\n+\n+# class DataSet:\n+#     sonar = DataSetParam('sonar.csv')\n+#     sonar_selected = DataSetParam('sonar_selected.csv')\n+    \n+    \n+    \n+# def load_dataset(dataset):\n+#     dataset_path = os.path.join(DATASET_DIR, dataset)\n+\n+#     # 尝试打开并读取CSV文件\n+#     try:\n+#         with open(dataset_path, 'r', encoding='utf-8') as csvfile:\n+#             spamreader = csv.reader(csvfile)\n+#             data = np.array(list(spamreader))\n+#     except FileNotFoundError:\n+#         print(f\"Error: The file {dataset_path} was not found.\")\n+#         return None, None\n+#     except Exception as e:\n+#         print(f\"Error: An error occurred while reading the file: {e}\")\n+#         return None, None\n+\n+#     # 检查数据是否为空\n+#     if data.size == 0:\n+#         print(\"Error: The dataset is empty.\")\n+#         return None, None\n+\n+#     feature = data[:, :-1].astype(np.float64)\n+#     labels = data[:, -1]\n+\n+#     # 创建标签映射\n+#     unique_labels = np.unique(labels)\n+#     label_to_int = {label: idx for idx, label in enumerate(unique_labels)}\n+#     int_labels = np.array([label_to_int[label] for label in labels], dtype=np.uint8)\n+#     labell = int_labels.reshape(-1,1)\n+\n+#     # 将标签转换为独热矩阵\n+#     one_hot_labels = np.zeros((int_labels.size, int_labels.max() + 1), dtype=np.uint8)\n+#     one_hot_labels[np.arange(int_labels.size), int_labels] = 1\n+\n+#     # print(\"======feature_size=====\", feature.shape)\n+#     print(\"======label_size=====\", one_hot_labels)\n+#     return feature, one_hot_labels\n+\n+# data_train = DataSet.sonar\n+\n+# load_dataset(data_train.dataset_name)\n+# endregion\n+\n+\n+def generate_random():\n+    random_tensor = random.uniform(-10, 10)\n+    return random_tensor\n+\n+# region \n+# @mpc.run_multiprocess(world_size=2)\n+# def test(x,y):\n+    # x_enc = crypten.cryptensor(x, ptype=crypten.mpc.arithmetic)\n+    # y_enc = crypten.cryptensor(y, ptype=crypten.mpc.arithmetic)\n+    # ge_time_begin = time.time()\n+    # ge_  = x_enc.ge(y_enc)\n+    # ge_time_end = time.time()\n+    # ge_time = ge_time_end - ge_time_begin\n+    # print(\"ge_time\", ge_time)\n+    \n+    # gt_time_begin = time.time()\n+    # gt_  = x_enc.gt(y_enc)\n+    # gt_time_end = time.time()\n+    # gt_time = gt_time_end - gt_time_begin\n+    # print(\"gt_time\", gt_time)\n+    \n+    # relu_time_begin = time.time()\n+    # relu_ = ge_.relu()\n+    # relu_time_end = time.time()\n+    # relu_time = relu_time_end - relu_time_begin\n+    # print(\"relu_time\", relu_time)\n+# endregion\n+\n+@mpc.run_multiprocess(world_size=2)\n+def L_Sigmoid(x):\n+    x_share = crypten.cryptensor(x, ptype = crypten.mpc.arithmetic)\n+    one_share = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n+    one_share_again = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n+    \n+    # part 1\n+    cmp_result_1 = x_share > 0\n+    \n+    # part 2    \n+    x_minus_one = x_share - one_share\n+    ge_time_begin = time.time()\n+    cmp_result_2 = x_minus_one < 0\n+    ge_time_end = time.time()\n+    ge_time = ge_time_end - ge_time_begin\n+    # print(\"ge_time\", ge_time)\n+    \n+    mulplex_time_begin = time.time()\n+    mulplex_result = crypten.where(cmp_result_2, x_minus_one, 0)\n+    mulplex_time_end = time.time()\n+    mulplex_time = mulplex_time_end - mulplex_time_begin\n+    # print(\"mulplex_time\", mulplex_time)\n+    \n+    L_sigmod_result = mulplex_result + one_share_again\n+    \n+    rank = comm.get().get_rank()\n+    crypten.print(f\"\\nRank {rank}:\\n cmp_result_1: {cmp_result_1.get_plain_text()}\\n\" \\\n+                f\" cmp_result_2: {cmp_result_2.get_plain_text()}\\n\" \\\n+                f\" mulplex_result: {mulplex_result.get_plain_text()}\\n\" \\\n+                f\" L_sigmod_result:{L_sigmod_result.get_plain_text()}\\n\",\n+                in_order=True)\n+\n+\n+\n+def main():\n+    x = generate_random()\n+    # y = generate_random()\n+    print(\"x\", x)\n+    # print(\"y\", y)\n+    L_Sigmoid(x)\n+\n+main()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1721120962625,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -108,8 +108,9 @@\n     \n     # part 1\n     cmp_result_1 = x_share > 0\n     \n+    \n     # part 2    \n     x_minus_one = x_share - one_share\n     ge_time_begin = time.time()\n     cmp_result_2 = x_minus_one < 0\n@@ -140,149 +141,5 @@\n     print(\"x\", x)\n     # print(\"y\", y)\n     L_Sigmoid(x)\n \n-main()\n-\n-import crypten\n-import crypten.mpc\n-import torch\n-import crypten.mpc as mpc\n-import crypten.mpc.primitives.beaver as beaver\n-import crypten.communicator as comm \n-import torch\n-from crypten.mpc import MPCTensor\n-from crypten.mpc.primitives import BinarySharedTensor\n-import time\n-import random\n-import crypten.common.functions\n-\n-crypten.init()\n-\n-\n-# region \n-# DATASET_DIR = os.path.join(os.path.dirname(__file__), 'dataset')\n-\n-# class DataSetParam:\n-#     def __init__(self, dataset_name):\n-#         self.dataset_name = dataset_name\n-\n-\n-# class DataSet:\n-#     sonar = DataSetParam('sonar.csv')\n-#     sonar_selected = DataSetParam('sonar_selected.csv')\n-    \n-    \n-    \n-# def load_dataset(dataset):\n-#     dataset_path = os.path.join(DATASET_DIR, dataset)\n-\n-#     # 尝试打开并读取CSV文件\n-#     try:\n-#         with open(dataset_path, 'r', encoding='utf-8') as csvfile:\n-#             spamreader = csv.reader(csvfile)\n-#             data = np.array(list(spamreader))\n-#     except FileNotFoundError:\n-#         print(f\"Error: The file {dataset_path} was not found.\")\n-#         return None, None\n-#     except Exception as e:\n-#         print(f\"Error: An error occurred while reading the file: {e}\")\n-#         return None, None\n-\n-#     # 检查数据是否为空\n-#     if data.size == 0:\n-#         print(\"Error: The dataset is empty.\")\n-#         return None, None\n-\n-#     feature = data[:, :-1].astype(np.float64)\n-#     labels = data[:, -1]\n-\n-#     # 创建标签映射\n-#     unique_labels = np.unique(labels)\n-#     label_to_int = {label: idx for idx, label in enumerate(unique_labels)}\n-#     int_labels = np.array([label_to_int[label] for label in labels], dtype=np.uint8)\n-#     labell = int_labels.reshape(-1,1)\n-\n-#     # 将标签转换为独热矩阵\n-#     one_hot_labels = np.zeros((int_labels.size, int_labels.max() + 1), dtype=np.uint8)\n-#     one_hot_labels[np.arange(int_labels.size), int_labels] = 1\n-\n-#     # print(\"======feature_size=====\", feature.shape)\n-#     print(\"======label_size=====\", one_hot_labels)\n-#     return feature, one_hot_labels\n-\n-# data_train = DataSet.sonar\n-\n-# load_dataset(data_train.dataset_name)\n-# endregion\n-\n-\n-def generate_random():\n-    random_tensor = random.uniform(-10, 10)\n-    return random_tensor\n-\n-# region \n-# @mpc.run_multiprocess(world_size=2)\n-# def test(x,y):\n-    # x_enc = crypten.cryptensor(x, ptype=crypten.mpc.arithmetic)\n-    # y_enc = crypten.cryptensor(y, ptype=crypten.mpc.arithmetic)\n-    # ge_time_begin = time.time()\n-    # ge_  = x_enc.ge(y_enc)\n-    # ge_time_end = time.time()\n-    # ge_time = ge_time_end - ge_time_begin\n-    # print(\"ge_time\", ge_time)\n-    \n-    # gt_time_begin = time.time()\n-    # gt_  = x_enc.gt(y_enc)\n-    # gt_time_end = time.time()\n-    # gt_time = gt_time_end - gt_time_begin\n-    # print(\"gt_time\", gt_time)\n-    \n-    # relu_time_begin = time.time()\n-    # relu_ = ge_.relu()\n-    # relu_time_end = time.time()\n-    # relu_time = relu_time_end - relu_time_begin\n-    # print(\"relu_time\", relu_time)\n-# endregion\n-\n-@mpc.run_multiprocess(world_size=2)\n-def L-si(x):\n-    x_share = crypten.cryptensor(x, ptype = crypten.mpc.arithmetic)\n-    one_share = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n-    one_share_again = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n-    \n-    # part 1\n-    cmp_result_1 = x_share > 0\n-    \n-    # part 2    \n-    x_minus_one = x_share - one_share\n-    ge_time_begin = time.time()\n-    cmp_result_2 = x_minus_one < 0\n-    ge_time_end = time.time()\n-    ge_time = ge_time_end - ge_time_begin\n-    # print(\"ge_time\", ge_time)\n-    \n-    mulplex_time_begin = time.time()\n-    mulplex_result = crypten.where(cmp_result_2, x_minus_one, 0)\n-    mulplex_time_end = time.time()\n-    mulplex_time = mulplex_time_end - mulplex_time_begin\n-    # print(\"mulplex_time\", mulplex_time)\n-    \n-    L_sigmod_result = mulplex_result + one_share_again\n-    \n-    rank = comm.get().get_rank()\n-    crypten.print(f\"\\nRank {rank}:\\n cmp_result_1: {cmp_result_1.get_plain_text()}\\n\" \\\n-                f\" cmp_result_2: {cmp_result_2.get_plain_text()}\\n\" \\\n-                f\" mulplex_result: {mulplex_result.get_plain_text()}\\n\" \\\n-                f\" L_sigmod_result:{L_sigmod_result.get_plain_text()}\\n\",\n-                in_order=True)\n-\n-\n-\n-def main():\n-    x = generate_random()\n-    # y = generate_random()\n-    print(\"x\", x)\n-    # print(\"y\", y)\n-    test(x)\n-\n main()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1721120970893,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -107,10 +107,10 @@\n     one_share_again = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n     \n     # part 1\n     cmp_result_1 = x_share > 0\n+    cmp_result_1_arith = \n     \n-    \n     # part 2    \n     x_minus_one = x_share - one_share\n     ge_time_begin = time.time()\n     cmp_result_2 = x_minus_one < 0\n"
                },
                {
                    "date": 1721120977307,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -107,9 +107,9 @@\n     one_share_again = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n     \n     # part 1\n     cmp_result_1 = x_share > 0\n-    cmp_result_1_arith = \n+    cmp_result_1_arith = cmp_result_1.to(c)\n     \n     # part 2    \n     x_minus_one = x_share - one_share\n     ge_time_begin = time.time()\n"
                },
                {
                    "date": 1721120990866,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -107,9 +107,9 @@\n     one_share_again = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n     \n     # part 1\n     cmp_result_1 = x_share > 0\n-    cmp_result_1_arith = cmp_result_1.to(c)\n+    cmp_result_1_arith = cmp_result_1.to(crypten.mpc.binary\n     \n     # part 2    \n     x_minus_one = x_share - one_share\n     ge_time_begin = time.time()\n"
                },
                {
                    "date": 1721121000678,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -107,9 +107,9 @@\n     one_share_again = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n     \n     # part 1\n     cmp_result_1 = x_share > 0\n-    cmp_result_1_arith = cmp_result_1.to(crypten.mpc.binary\n+    cmp_result_1_arith = cmp_result_1.to(crypten.mpc.binary)\n     \n     # part 2    \n     x_minus_one = x_share - one_share\n     ge_time_begin = time.time()\n@@ -125,8 +125,9 @@\n     # print(\"mulplex_time\", mulplex_time)\n     \n     L_sigmod_result = mulplex_result + one_share_again\n     \n+    \n     rank = comm.get().get_rank()\n     crypten.print(f\"\\nRank {rank}:\\n cmp_result_1: {cmp_result_1.get_plain_text()}\\n\" \\\n                 f\" cmp_result_2: {cmp_result_2.get_plain_text()}\\n\" \\\n                 f\" mulplex_result: {mulplex_result.get_plain_text()}\\n\" \\\n"
                },
                {
                    "date": 1721121006734,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -123,9 +123,9 @@\n     mulplex_time_end = time.time()\n     mulplex_time = mulplex_time_end - mulplex_time_begin\n     # print(\"mulplex_time\", mulplex_time)\n     \n-    L_sigmod_result = mulplex_result + one_share_again\n+    result_2 = mulplex_result + one_share_again\n     \n     \n     rank = comm.get().get_rank()\n     crypten.print(f\"\\nRank {rank}:\\n cmp_result_1: {cmp_result_1.get_plain_text()}\\n\" \\\n"
                },
                {
                    "date": 1721121012746,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -107,9 +107,9 @@\n     one_share_again = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n     \n     # part 1\n     cmp_result_1 = x_share > 0\n-    cmp_result_1_arith = cmp_result_1.to(crypten.mpc.binary)\n+    result_1 = cmp_result_1.to(crypten.mpc.binary)\n     \n     # part 2    \n     x_minus_one = x_share - one_share\n     ge_time_begin = time.time()\n"
                },
                {
                    "date": 1721121018094,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -125,8 +125,9 @@\n     # print(\"mulplex_time\", mulplex_time)\n     \n     result_2 = mulplex_result + one_share_again\n     \n+    resu\n     \n     rank = comm.get().get_rank()\n     crypten.print(f\"\\nRank {rank}:\\n cmp_result_1: {cmp_result_1.get_plain_text()}\\n\" \\\n                 f\" cmp_result_2: {cmp_result_2.get_plain_text()}\\n\" \\\n"
                },
                {
                    "date": 1721121027543,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -125,9 +125,9 @@\n     # print(\"mulplex_time\", mulplex_time)\n     \n     result_2 = mulplex_result + one_share_again\n     \n-    resu\n+    result = result_1 + result\n     \n     rank = comm.get().get_rank()\n     crypten.print(f\"\\nRank {rank}:\\n cmp_result_1: {cmp_result_1.get_plain_text()}\\n\" \\\n                 f\" cmp_result_2: {cmp_result_2.get_plain_text()}\\n\" \\\n"
                },
                {
                    "date": 1721121037599,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -125,9 +125,9 @@\n     # print(\"mulplex_time\", mulplex_time)\n     \n     result_2 = mulplex_result + one_share_again\n     \n-    result = result_1 + result\n+    L_sigmod_result = result_1 + result_2\n     \n     rank = comm.get().get_rank()\n     crypten.print(f\"\\nRank {rank}:\\n cmp_result_1: {cmp_result_1.get_plain_text()}\\n\" \\\n                 f\" cmp_result_2: {cmp_result_2.get_plain_text()}\\n\" \\\n"
                },
                {
                    "date": 1721121043004,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -132,8 +132,9 @@\n     crypten.print(f\"\\nRank {rank}:\\n cmp_result_1: {cmp_result_1.get_plain_text()}\\n\" \\\n                 f\" cmp_result_2: {cmp_result_2.get_plain_text()}\\n\" \\\n                 f\" mulplex_result: {mulplex_result.get_plain_text()}\\n\" \\\n                 f\" L_sigmod_result:{L_sigmod_result.get_plain_text()}\\n\",\n+                f\" L_sigmod_result:{L_sigmod_result.get_plain_text()}\\n\",\n                 in_order=True)\n \n \n \n"
                },
                {
                    "date": 1721121054927,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -131,10 +131,10 @@\n     rank = comm.get().get_rank()\n     crypten.print(f\"\\nRank {rank}:\\n cmp_result_1: {cmp_result_1.get_plain_text()}\\n\" \\\n                 f\" cmp_result_2: {cmp_result_2.get_plain_text()}\\n\" \\\n                 f\" mulplex_result: {mulplex_result.get_plain_text()}\\n\" \\\n+                f\" L_sigmod_result:{result.get_plain_text()}\\n\",\\\n                 f\" L_sigmod_result:{L_sigmod_result.get_plain_text()}\\n\",\n-                f\" L_sigmod_result:{L_sigmod_result.get_plain_text()}\\n\",\n                 in_order=True)\n \n \n \n"
                },
                {
                    "date": 1721121061282,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,148 @@\n+\n+import crypten\n+import crypten.mpc\n+import torch\n+import crypten.mpc as mpc\n+import crypten.mpc.primitives.beaver as beaver\n+import crypten.communicator as comm \n+import torch\n+from crypten.mpc import MPCTensor\n+from crypten.mpc.primitives import BinarySharedTensor\n+import time\n+import random\n+import crypten.common.functions\n+\n+crypten.init()\n+\n+\n+# region \n+# DATASET_DIR = os.path.join(os.path.dirname(__file__), 'dataset')\n+\n+# class DataSetParam:\n+#     def __init__(self, dataset_name):\n+#         self.dataset_name = dataset_name\n+\n+\n+# class DataSet:\n+#     sonar = DataSetParam('sonar.csv')\n+#     sonar_selected = DataSetParam('sonar_selected.csv')\n+    \n+    \n+    \n+# def load_dataset(dataset):\n+#     dataset_path = os.path.join(DATASET_DIR, dataset)\n+\n+#     # 尝试打开并读取CSV文件\n+#     try:\n+#         with open(dataset_path, 'r', encoding='utf-8') as csvfile:\n+#             spamreader = csv.reader(csvfile)\n+#             data = np.array(list(spamreader))\n+#     except FileNotFoundError:\n+#         print(f\"Error: The file {dataset_path} was not found.\")\n+#         return None, None\n+#     except Exception as e:\n+#         print(f\"Error: An error occurred while reading the file: {e}\")\n+#         return None, None\n+\n+#     # 检查数据是否为空\n+#     if data.size == 0:\n+#         print(\"Error: The dataset is empty.\")\n+#         return None, None\n+\n+#     feature = data[:, :-1].astype(np.float64)\n+#     labels = data[:, -1]\n+\n+#     # 创建标签映射\n+#     unique_labels = np.unique(labels)\n+#     label_to_int = {label: idx for idx, label in enumerate(unique_labels)}\n+#     int_labels = np.array([label_to_int[label] for label in labels], dtype=np.uint8)\n+#     labell = int_labels.reshape(-1,1)\n+\n+#     # 将标签转换为独热矩阵\n+#     one_hot_labels = np.zeros((int_labels.size, int_labels.max() + 1), dtype=np.uint8)\n+#     one_hot_labels[np.arange(int_labels.size), int_labels] = 1\n+\n+#     # print(\"======feature_size=====\", feature.shape)\n+#     print(\"======label_size=====\", one_hot_labels)\n+#     return feature, one_hot_labels\n+\n+# data_train = DataSet.sonar\n+\n+# load_dataset(data_train.dataset_name)\n+# endregion\n+\n+\n+def generate_random():\n+    random_tensor = random.uniform(-10, 10)\n+    return random_tensor\n+\n+# region \n+# @mpc.run_multiprocess(world_size=2)\n+# def test(x,y):\n+    # x_enc = crypten.cryptensor(x, ptype=crypten.mpc.arithmetic)\n+    # y_enc = crypten.cryptensor(y, ptype=crypten.mpc.arithmetic)\n+    # ge_time_begin = time.time()\n+    # ge_  = x_enc.ge(y_enc)\n+    # ge_time_end = time.time()\n+    # ge_time = ge_time_end - ge_time_begin\n+    # print(\"ge_time\", ge_time)\n+    \n+    # gt_time_begin = time.time()\n+    # gt_  = x_enc.gt(y_enc)\n+    # gt_time_end = time.time()\n+    # gt_time = gt_time_end - gt_time_begin\n+    # print(\"gt_time\", gt_time)\n+    \n+    # relu_time_begin = time.time()\n+    # relu_ = ge_.relu()\n+    # relu_time_end = time.time()\n+    # relu_time = relu_time_end - relu_time_begin\n+    # print(\"relu_time\", relu_time)\n+# endregion\n+\n+@mpc.run_multiprocess(world_size=2)\n+def L_Sigmoid(x):\n+    x_share = crypten.cryptensor(x, ptype = crypten.mpc.arithmetic)\n+    one_share = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n+    one_share_again = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n+    \n+    # part 1\n+    cmp_result_1 = x_share > 0\n+    result_1 = cmp_result_1.to(crypten.mpc.binary)\n+    \n+    # part 2    \n+    x_minus_one = x_share - one_share\n+    ge_time_begin = time.time()\n+    cmp_result_2 = x_minus_one < 0\n+    ge_time_end = time.time()\n+    ge_time = ge_time_end - ge_time_begin\n+    # print(\"ge_time\", ge_time)\n+    \n+    mulplex_time_begin = time.time()\n+    mulplex_result = crypten.where(cmp_result_2, x_minus_one, 0)\n+    mulplex_time_end = time.time()\n+    mulplex_time = mulplex_time_end - mulplex_time_begin\n+    # print(\"mulplex_time\", mulplex_time)\n+    \n+    result_2 = mulplex_result + one_share_again\n+    \n+    L_sigmod_result = result_1 + result_2\n+    \n+    rank = comm.get().get_rank()\n+    crypten.print(f\"\\nRank {rank}:\\n cmp_result_1: {cmp_result_1.get_plain_text()}\\n\" \\\n+                f\" cmp_result_2: {cmp_result_2.get_plain_text()}\\n\" \\\n+                f\" mulplex_result: {mulplex_result.get_plain_text()}\\n\" \\\n+                f\" L_sigmod_result:{result_1.get_plain_text()}\\n\",\\\n+                f\" L_sigmod_result:{L_sigmod_result.get_plain_text()}\\n\",\n+                in_order=True)\n+\n+\n+\n+def main():\n+    x = generate_random()\n+    # y = generate_random()\n+    print(\"x\", x)\n+    # print(\"y\", y)\n+    L_Sigmoid(x)\n+\n+main()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1721121066932,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -132,8 +132,9 @@\n     crypten.print(f\"\\nRank {rank}:\\n cmp_result_1: {cmp_result_1.get_plain_text()}\\n\" \\\n                 f\" cmp_result_2: {cmp_result_2.get_plain_text()}\\n\" \\\n                 f\" mulplex_result: {mulplex_result.get_plain_text()}\\n\" \\\n                 f\" L_sigmod_result:{result_1.get_plain_text()}\\n\",\\\n+                    f\" L_sigmod_result:{result_1.get_plain_text()}\\n\",\\\n                 f\" L_sigmod_result:{L_sigmod_result.get_plain_text()}\\n\",\n                 in_order=True)\n \n \n@@ -144,153 +145,5 @@\n     print(\"x\", x)\n     # print(\"y\", y)\n     L_Sigmoid(x)\n \n-main()\n-\n-import crypten\n-import crypten.mpc\n-import torch\n-import crypten.mpc as mpc\n-import crypten.mpc.primitives.beaver as beaver\n-import crypten.communicator as comm \n-import torch\n-from crypten.mpc import MPCTensor\n-from crypten.mpc.primitives import BinarySharedTensor\n-import time\n-import random\n-import crypten.common.functions\n-\n-crypten.init()\n-\n-\n-# region \n-# DATASET_DIR = os.path.join(os.path.dirname(__file__), 'dataset')\n-\n-# class DataSetParam:\n-#     def __init__(self, dataset_name):\n-#         self.dataset_name = dataset_name\n-\n-\n-# class DataSet:\n-#     sonar = DataSetParam('sonar.csv')\n-#     sonar_selected = DataSetParam('sonar_selected.csv')\n-    \n-    \n-    \n-# def load_dataset(dataset):\n-#     dataset_path = os.path.join(DATASET_DIR, dataset)\n-\n-#     # 尝试打开并读取CSV文件\n-#     try:\n-#         with open(dataset_path, 'r', encoding='utf-8') as csvfile:\n-#             spamreader = csv.reader(csvfile)\n-#             data = np.array(list(spamreader))\n-#     except FileNotFoundError:\n-#         print(f\"Error: The file {dataset_path} was not found.\")\n-#         return None, None\n-#     except Exception as e:\n-#         print(f\"Error: An error occurred while reading the file: {e}\")\n-#         return None, None\n-\n-#     # 检查数据是否为空\n-#     if data.size == 0:\n-#         print(\"Error: The dataset is empty.\")\n-#         return None, None\n-\n-#     feature = data[:, :-1].astype(np.float64)\n-#     labels = data[:, -1]\n-\n-#     # 创建标签映射\n-#     unique_labels = np.unique(labels)\n-#     label_to_int = {label: idx for idx, label in enumerate(unique_labels)}\n-#     int_labels = np.array([label_to_int[label] for label in labels], dtype=np.uint8)\n-#     labell = int_labels.reshape(-1,1)\n-\n-#     # 将标签转换为独热矩阵\n-#     one_hot_labels = np.zeros((int_labels.size, int_labels.max() + 1), dtype=np.uint8)\n-#     one_hot_labels[np.arange(int_labels.size), int_labels] = 1\n-\n-#     # print(\"======feature_size=====\", feature.shape)\n-#     print(\"======label_size=====\", one_hot_labels)\n-#     return feature, one_hot_labels\n-\n-# data_train = DataSet.sonar\n-\n-# load_dataset(data_train.dataset_name)\n-# endregion\n-\n-\n-def generate_random():\n-    random_tensor = random.uniform(-10, 10)\n-    return random_tensor\n-\n-# region \n-# @mpc.run_multiprocess(world_size=2)\n-# def test(x,y):\n-    # x_enc = crypten.cryptensor(x, ptype=crypten.mpc.arithmetic)\n-    # y_enc = crypten.cryptensor(y, ptype=crypten.mpc.arithmetic)\n-    # ge_time_begin = time.time()\n-    # ge_  = x_enc.ge(y_enc)\n-    # ge_time_end = time.time()\n-    # ge_time = ge_time_end - ge_time_begin\n-    # print(\"ge_time\", ge_time)\n-    \n-    # gt_time_begin = time.time()\n-    # gt_  = x_enc.gt(y_enc)\n-    # gt_time_end = time.time()\n-    # gt_time = gt_time_end - gt_time_begin\n-    # print(\"gt_time\", gt_time)\n-    \n-    # relu_time_begin = time.time()\n-    # relu_ = ge_.relu()\n-    # relu_time_end = time.time()\n-    # relu_time = relu_time_end - relu_time_begin\n-    # print(\"relu_time\", relu_time)\n-# endregion\n-\n-@mpc.run_multiprocess(world_size=2)\n-def L_Sigmoid(x):\n-    x_share = crypten.cryptensor(x, ptype = crypten.mpc.arithmetic)\n-    one_share = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n-    one_share_again = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n-    \n-    # part 1\n-    cmp_result_1 = x_share > 0\n-    result_1 = cmp_result_1.to(crypten.mpc.binary)\n-    \n-    # part 2    \n-    x_minus_one = x_share - one_share\n-    ge_time_begin = time.time()\n-    cmp_result_2 = x_minus_one < 0\n-    ge_time_end = time.time()\n-    ge_time = ge_time_end - ge_time_begin\n-    # print(\"ge_time\", ge_time)\n-    \n-    mulplex_time_begin = time.time()\n-    mulplex_result = crypten.where(cmp_result_2, x_minus_one, 0)\n-    mulplex_time_end = time.time()\n-    mulplex_time = mulplex_time_end - mulplex_time_begin\n-    # print(\"mulplex_time\", mulplex_time)\n-    \n-    result_2 = mulplex_result + one_share_again\n-    \n-    L_sigmod_result = result_1 + result_2\n-    \n-    rank = comm.get().get_rank()\n-    crypten.print(f\"\\nRank {rank}:\\n cmp_result_1: {cmp_result_1.get_plain_text()}\\n\" \\\n-                f\" cmp_result_2: {cmp_result_2.get_plain_text()}\\n\" \\\n-                f\" mulplex_result: {mulplex_result.get_plain_text()}\\n\" \\\n-                f\" L_sigmod_result:{result.get_plain_text()}\\n\",\\\n-                f\" L_sigmod_result:{L_sigmod_result.get_plain_text()}\\n\",\n-                in_order=True)\n-\n-\n-\n-def main():\n-    x = generate_random()\n-    # y = generate_random()\n-    print(\"x\", x)\n-    # print(\"y\", y)\n-    L_Sigmoid(x)\n-\n main()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1721121072608,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -131,10 +131,10 @@\n     rank = comm.get().get_rank()\n     crypten.print(f\"\\nRank {rank}:\\n cmp_result_1: {cmp_result_1.get_plain_text()}\\n\" \\\n                 f\" cmp_result_2: {cmp_result_2.get_plain_text()}\\n\" \\\n                 f\" mulplex_result: {mulplex_result.get_plain_text()}\\n\" \\\n+                f\" result_1:{result_1.get_plain_text()}\\n\",\\\n                 f\" L_sigmod_result:{result_1.get_plain_text()}\\n\",\\\n-                    f\" L_sigmod_result:{result_1.get_plain_text()}\\n\",\\\n                 f\" L_sigmod_result:{L_sigmod_result.get_plain_text()}\\n\",\n                 in_order=True)\n \n \n"
                },
                {
                    "date": 1721121078282,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -132,9 +132,9 @@\n     crypten.print(f\"\\nRank {rank}:\\n cmp_result_1: {cmp_result_1.get_plain_text()}\\n\" \\\n                 f\" cmp_result_2: {cmp_result_2.get_plain_text()}\\n\" \\\n                 f\" mulplex_result: {mulplex_result.get_plain_text()}\\n\" \\\n                 f\" result_1:{result_1.get_plain_text()}\\n\",\\\n-                f\" L_sigmod_result:{result_1.get_plain_text()}\\n\",\\\n+                f\" result_2:{result_2.get_plain_text()}\\n\",\\\n                 f\" L_sigmod_result:{L_sigmod_result.get_plain_text()}\\n\",\n                 in_order=True)\n \n \n"
                },
                {
                    "date": 1721121085125,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -125,9 +125,9 @@\n     # print(\"mulplex_time\", mulplex_time)\n     \n     result_2 = mulplex_result + one_share_again\n     \n-    L_sigmod_result = result_1 + result_2\n+    L_sigmod_result = result_1  result_2\n     \n     rank = comm.get().get_rank()\n     crypten.print(f\"\\nRank {rank}:\\n cmp_result_1: {cmp_result_1.get_plain_text()}\\n\" \\\n                 f\" cmp_result_2: {cmp_result_2.get_plain_text()}\\n\" \\\n"
                },
                {
                    "date": 1721121095911,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -125,9 +125,9 @@\n     # print(\"mulplex_time\", mulplex_time)\n     \n     result_2 = mulplex_result + one_share_again\n     \n-    L_sigmod_result = result_1  result_2\n+    L_sigmod_result = result_1 * result_2\n     \n     rank = comm.get().get_rank()\n     crypten.print(f\"\\nRank {rank}:\\n cmp_result_1: {cmp_result_1.get_plain_text()}\\n\" \\\n                 f\" cmp_result_2: {cmp_result_2.get_plain_text()}\\n\" \\\n"
                },
                {
                    "date": 1721121101978,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -125,17 +125,17 @@\n     # print(\"mulplex_time\", mulplex_time)\n     \n     result_2 = mulplex_result + one_share_again\n     \n-    L_sigmod_result = result_1 * result_2\n+    # L_sigmod_result = result_1 * result_2\n     \n     rank = comm.get().get_rank()\n     crypten.print(f\"\\nRank {rank}:\\n cmp_result_1: {cmp_result_1.get_plain_text()}\\n\" \\\n                 f\" cmp_result_2: {cmp_result_2.get_plain_text()}\\n\" \\\n                 f\" mulplex_result: {mulplex_result.get_plain_text()}\\n\" \\\n                 f\" result_1:{result_1.get_plain_text()}\\n\",\\\n                 f\" result_2:{result_2.get_plain_text()}\\n\",\\\n-                f\" L_sigmod_result:{L_sigmod_result.get_plain_text()}\\n\",\n+                # f\" L_sigmod_result:{L_sigmod_result.get_plain_text()}\\n\",\n                 in_order=True)\n \n \n \n"
                },
                {
                    "date": 1721121148284,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -125,9 +125,9 @@\n     # print(\"mulplex_time\", mulplex_time)\n     \n     result_2 = mulplex_result + one_share_again\n     \n-    # L_sigmod_result = result_1 * result_2\n+    L_sigmod_result = result_1 * result_2\n     \n     rank = comm.get().get_rank()\n     crypten.print(f\"\\nRank {rank}:\\n cmp_result_1: {cmp_result_1.get_plain_text()}\\n\" \\\n                 f\" cmp_result_2: {cmp_result_2.get_plain_text()}\\n\" \\\n"
                },
                {
                    "date": 1721121198128,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -107,9 +107,9 @@\n     one_share_again = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n     \n     # part 1\n     cmp_result_1 = x_share > 0\n-    result_1 = cmp_result_1.to(crypten.mpc.binary)\n+    result_1 = cmp_result_1.to(crypten.mpc.arithmetic)\n     \n     # part 2    \n     x_minus_one = x_share - one_share\n     ge_time_begin = time.time()\n"
                },
                {
                    "date": 1721121219128,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -131,8 +131,9 @@\n     rank = comm.get().get_rank()\n     crypten.print(f\"\\nRank {rank}:\\n cmp_result_1: {cmp_result_1.get_plain_text()}\\n\" \\\n                 f\" cmp_result_2: {cmp_result_2.get_plain_text()}\\n\" \\\n                 f\" mulplex_result: {mulplex_result.get_plain_text()}\\n\" \\\n+                    \n                 f\" result_1:{result_1.get_plain_text()}\\n\",\\\n                 f\" result_2:{result_2.get_plain_text()}\\n\",\\\n                 # f\" L_sigmod_result:{L_sigmod_result.get_plain_text()}\\n\",\n                 in_order=True)\n"
                },
                {
                    "date": 1721121225438,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -131,9 +131,9 @@\n     rank = comm.get().get_rank()\n     crypten.print(f\"\\nRank {rank}:\\n cmp_result_1: {cmp_result_1.get_plain_text()}\\n\" \\\n                 f\" cmp_result_2: {cmp_result_2.get_plain_text()}\\n\" \\\n                 f\" mulplex_result: {mulplex_result.get_plain_text()}\\n\" \\\n-                    \n+                f\" result_1:{result_1}\\n\",\\\n                 f\" result_1:{result_1.get_plain_text()}\\n\",\\\n                 f\" result_2:{result_2.get_plain_text()}\\n\",\\\n                 # f\" L_sigmod_result:{L_sigmod_result.get_plain_text()}\\n\",\n                 in_order=True)\n"
                },
                {
                    "date": 1721121233439,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -131,9 +131,8 @@\n     rank = comm.get().get_rank()\n     crypten.print(f\"\\nRank {rank}:\\n cmp_result_1: {cmp_result_1.get_plain_text()}\\n\" \\\n                 f\" cmp_result_2: {cmp_result_2.get_plain_text()}\\n\" \\\n                 f\" mulplex_result: {mulplex_result.get_plain_text()}\\n\" \\\n-                f\" result_1:{result_1}\\n\",\\\n                 f\" result_1:{result_1.get_plain_text()}\\n\",\\\n                 f\" result_2:{result_2.get_plain_text()}\\n\",\\\n                 # f\" L_sigmod_result:{L_sigmod_result.get_plain_text()}\\n\",\n                 in_order=True)\n"
                },
                {
                    "date": 1721121255201,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -72,9 +72,9 @@\n # endregion\n \n \n def generate_random():\n-    random_tensor = random.uniform(-10, 10)\n+    random_tensor = random.uniform(-1, 10)\n     return random_tensor\n \n # region \n # @mpc.run_multiprocess(world_size=2)\n@@ -133,9 +133,9 @@\n                 f\" cmp_result_2: {cmp_result_2.get_plain_text()}\\n\" \\\n                 f\" mulplex_result: {mulplex_result.get_plain_text()}\\n\" \\\n                 f\" result_1:{result_1.get_plain_text()}\\n\",\\\n                 f\" result_2:{result_2.get_plain_text()}\\n\",\\\n-                # f\" L_sigmod_result:{L_sigmod_result.get_plain_text()}\\n\",\n+                f\" L_sigmod_result:{L_sigmod_result.get_plain_text()}\\n\",\n                 in_order=True)\n \n \n \n"
                },
                {
                    "date": 1721121269929,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -72,9 +72,9 @@\n # endregion\n \n \n def generate_random():\n-    random_tensor = random.uniform(-1, 10)\n+    random_tensor = random.uniform(-10, 10)\n     return random_tensor\n \n # region \n # @mpc.run_multiprocess(world_size=2)\n"
                },
                {
                    "date": 1721135217306,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -100,9 +100,9 @@\n     # print(\"relu_time\", relu_time)\n # endregion\n \n @mpc.run_multiprocess(world_size=2)\n-def L_Sigmoid(x):\n+def L_Sigmoid(x,):\n     x_share = crypten.cryptensor(x, ptype = crypten.mpc.arithmetic)\n     one_share = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n     one_share_again = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n     \n"
                },
                {
                    "date": 1721135252381,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -100,11 +100,11 @@\n     # print(\"relu_time\", relu_time)\n # endregion\n \n @mpc.run_multiprocess(world_size=2)\n-def L_Sigmoid(x,):\n+def L_Sigmoid(x):\n     x_share = crypten.cryptensor(x, ptype = crypten.mpc.arithmetic)\n-    one_share = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n+    one_share = crypten.cryptensor(-11, ptype = crypten.mpc.arithmetic)\n     one_share_again = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n     \n     # part 1\n     cmp_result_1 = x_share > 0\n"
                },
                {
                    "date": 1721135257796,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -102,17 +102,17 @@\n \n @mpc.run_multiprocess(world_size=2)\n def L_Sigmoid(x):\n     x_share = crypten.cryptensor(x, ptype = crypten.mpc.arithmetic)\n-    one_share = crypten.cryptensor(-11, ptype = crypten.mpc.arithmetic)\n+    one_share = crypten.cryptensor(-1, ptype = crypten.mpc.arithmetic)\n     one_share_again = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n     \n     # part 1\n     cmp_result_1 = x_share > 0\n     result_1 = cmp_result_1.to(crypten.mpc.arithmetic)\n     \n     # part 2    \n-    x_minus_one = x_share - one_share\n+    x_minus_one = x_share + one_share\n     ge_time_begin = time.time()\n     cmp_result_2 = x_minus_one < 0\n     ge_time_end = time.time()\n     ge_time = ge_time_end - ge_time_begin\n"
                },
                {
                    "date": 1721135325854,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -72,9 +72,9 @@\n # endregion\n \n \n def generate_random():\n-    random_tensor = random.uniform(-10, 10)\n+    random_tensor = random.uniform(-1, 1)\n     return random_tensor\n \n # region \n # @mpc.run_multiprocess(world_size=2)\n"
                },
                {
                    "date": 1721135380682,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -100,9 +100,9 @@\n     # print(\"relu_time\", relu_time)\n # endregion\n \n @mpc.run_multiprocess(world_size=2)\n-def L_Sigmoid(x):\n+def L_Sigmoid(x, min):\n     x_share = crypten.cryptensor(x, ptype = crypten.mpc.arithmetic)\n     one_share = crypten.cryptensor(-1, ptype = crypten.mpc.arithmetic)\n     one_share_again = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n     \n"
                },
                {
                    "date": 1721135385753,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -100,9 +100,9 @@\n     # print(\"relu_time\", relu_time)\n # endregion\n \n @mpc.run_multiprocess(world_size=2)\n-def L_Sigmoid(x, min):\n+def L_Sigmoid(x, min_value, max_value):\n     x_share = crypten.cryptensor(x, ptype = crypten.mpc.arithmetic)\n     one_share = crypten.cryptensor(-1, ptype = crypten.mpc.arithmetic)\n     one_share_again = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n     \n"
                },
                {
                    "date": 1721135392648,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -102,10 +102,10 @@\n \n @mpc.run_multiprocess(world_size=2)\n def L_Sigmoid(x, min_value, max_value):\n     x_share = crypten.cryptensor(x, ptype = crypten.mpc.arithmetic)\n-    one_share = crypten.cryptensor(-1, ptype = crypten.mpc.arithmetic)\n-    one_share_again = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n+    one_share = crypten.cryptensor(min_value, ptype = crypten.mpc.arithmetic)\n+    one_share_again = crypten.cryptensor(max_value, ptype = crypten.mpc.arithmetic)\n     \n     # part 1\n     cmp_result_1 = x_share > 0\n     result_1 = cmp_result_1.to(crypten.mpc.arithmetic)\n"
                },
                {
                    "date": 1721135431519,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -143,7 +143,7 @@\n     x = generate_random()\n     # y = generate_random()\n     print(\"x\", x)\n     # print(\"y\", y)\n-    L_Sigmoid(x)\n+    L_Sigmoid(x, -1, 1)\n \n main()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1721135464508,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -102,9 +102,9 @@\n \n @mpc.run_multiprocess(world_size=2)\n def L_Sigmoid(x, min_value, max_value):\n     x_share = crypten.cryptensor(x, ptype = crypten.mpc.arithmetic)\n-    one_share = crypten.cryptensor(min_value, ptype = crypten.mpc.arithmetic)\n+    min_share = crypten.cryptensor(min_value, ptype = crypten.mpc.arithmetic)\n     one_share_again = crypten.cryptensor(max_value, ptype = crypten.mpc.arithmetic)\n     \n     # part 1\n     cmp_result_1 = x_share > 0\n"
                },
                {
                    "date": 1721135579125,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -102,17 +102,17 @@\n \n @mpc.run_multiprocess(world_size=2)\n def L_Sigmoid(x, min_value, max_value):\n     x_share = crypten.cryptensor(x, ptype = crypten.mpc.arithmetic)\n-    min_share = crypten.cryptensor(min_value, ptype = crypten.mpc.arithmetic)\n+    min_value_share = crypten.cryptensor(min_value, ptype = crypten.mpc.arithmetic)\n     one_share_again = crypten.cryptensor(max_value, ptype = crypten.mpc.arithmetic)\n     \n     # part 1\n     cmp_result_1 = x_share > 0\n     result_1 = cmp_result_1.to(crypten.mpc.arithmetic)\n     \n     # part 2    \n-    x_minus_one = x_share + one_share\n+    x_minus_one = x_share + min_value_share\n     ge_time_begin = time.time()\n     cmp_result_2 = x_minus_one < 0\n     ge_time_end = time.time()\n     ge_time = ge_time_end - ge_time_begin\n"
                },
                {
                    "date": 1721135588405,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -103,9 +103,9 @@\n @mpc.run_multiprocess(world_size=2)\n def L_Sigmoid(x, min_value, max_value):\n     x_share = crypten.cryptensor(x, ptype = crypten.mpc.arithmetic)\n     min_value_share = crypten.cryptensor(min_value, ptype = crypten.mpc.arithmetic)\n-    one_share_again = crypten.cryptensor(max_value, ptype = crypten.mpc.arithmetic)\n+    max_value = crypten.cryptensor(max_value, ptype = crypten.mpc.arithmetic)\n     \n     # part 1\n     cmp_result_1 = x_share > 0\n     result_1 = cmp_result_1.to(crypten.mpc.arithmetic)\n"
                },
                {
                    "date": 1721135594198,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -103,9 +103,9 @@\n @mpc.run_multiprocess(world_size=2)\n def L_Sigmoid(x, min_value, max_value):\n     x_share = crypten.cryptensor(x, ptype = crypten.mpc.arithmetic)\n     min_value_share = crypten.cryptensor(min_value, ptype = crypten.mpc.arithmetic)\n-    max_value = crypten.cryptensor(max_value, ptype = crypten.mpc.arithmetic)\n+    max_value_share = crypten.cryptensor(max_value, ptype = crypten.mpc.arithmetic)\n     \n     # part 1\n     cmp_result_1 = x_share > 0\n     result_1 = cmp_result_1.to(crypten.mpc.arithmetic)\n@@ -123,9 +123,9 @@\n     mulplex_time_end = time.time()\n     mulplex_time = mulplex_time_end - mulplex_time_begin\n     # print(\"mulplex_time\", mulplex_time)\n     \n-    result_2 = mulplex_result + one_share_again\n+    result_2 = mulplex_result + max_value_share\n     \n     L_sigmod_result = result_1 * result_2\n     \n     rank = comm.get().get_rank()\n"
                },
                {
                    "date": 1721135615801,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -106,9 +106,9 @@\n     min_value_share = crypten.cryptensor(min_value, ptype = crypten.mpc.arithmetic)\n     max_value_share = crypten.cryptensor(max_value, ptype = crypten.mpc.arithmetic)\n     \n     # part 1\n-    cmp_result_1 = x_share > 0\n+    cmp_result_1 = x_share > min_value_share\n     result_1 = cmp_result_1.to(crypten.mpc.arithmetic)\n     \n     # part 2    \n     x_minus_one = x_share + min_value_share\n"
                },
                {
                    "date": 1721135635939,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -72,9 +72,9 @@\n # endregion\n \n \n def generate_random():\n-    random_tensor = random.uniform(-1, 1)\n+    random_tensor = random.uniform(-2, 1)\n     return random_tensor\n \n # region \n # @mpc.run_multiprocess(world_size=2)\n"
                },
                {
                    "date": 1721135688571,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -143,7 +143,8 @@\n     x = generate_random()\n     # y = generate_random()\n     print(\"x\", x)\n     # print(\"y\", y)\n+    a = \n     L_Sigmoid(x, -1, 1)\n \n main()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1721135706091,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -143,8 +143,7 @@\n     x = generate_random()\n     # y = generate_random()\n     print(\"x\", x)\n     # print(\"y\", y)\n-    a = \n     L_Sigmoid(x, -1, 1)\n \n main()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1721139643646,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -143,7 +143,7 @@\n     x = generate_random()\n     # y = generate_random()\n     print(\"x\", x)\n     # print(\"y\", y)\n-    L_Sigmoid(x, -1, 1)\n+    L_Sigmoid(x, -1, 2)\n \n main()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1721139729205,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -72,9 +72,9 @@\n # endregion\n \n \n def generate_random():\n-    random_tensor = random.uniform(-2, 1)\n+    random_tensor = random.uniform(-2, 2)\n     return random_tensor\n \n # region \n # @mpc.run_multiprocess(world_size=2)\n"
                },
                {
                    "date": 1721139739082,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -103,9 +103,9 @@\n @mpc.run_multiprocess(world_size=2)\n def L_Sigmoid(x, min_value, max_value):\n     x_share = crypten.cryptensor(x, ptype = crypten.mpc.arithmetic)\n     min_value_share = crypten.cryptensor(min_value, ptype = crypten.mpc.arithmetic)\n-    max_value_share = crypten.cryptensor(max_value, ptype = crypten.mpc.arithmetic)\n+    # max_value_share = crypten.cryptensor(max_value, ptype = crypten.mpc.arithmetic)\n     \n     # part 1\n     cmp_result_1 = x_share > min_value_share\n     result_1 = cmp_result_1.to(crypten.mpc.arithmetic)\n"
                },
                {
                    "date": 1721139753022,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -72,9 +72,9 @@\n # endregion\n \n \n def generate_random():\n-    random_tensor = random.uniform(-2, 2)\n+    random_tensor = random.uniform(-2, 1)\n     return random_tensor\n \n # region \n # @mpc.run_multiprocess(world_size=2)\n@@ -103,9 +103,9 @@\n @mpc.run_multiprocess(world_size=2)\n def L_Sigmoid(x, min_value, max_value):\n     x_share = crypten.cryptensor(x, ptype = crypten.mpc.arithmetic)\n     min_value_share = crypten.cryptensor(min_value, ptype = crypten.mpc.arithmetic)\n-    # max_value_share = crypten.cryptensor(max_value, ptype = crypten.mpc.arithmetic)\n+    max_value_share = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n     \n     # part 1\n     cmp_result_1 = x_share > min_value_share\n     result_1 = cmp_result_1.to(crypten.mpc.arithmetic)\n"
                },
                {
                    "date": 1721140923918,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -99,9 +99,9 @@\n     # relu_time = relu_time_end - relu_time_begin\n     # print(\"relu_time\", relu_time)\n # endregion\n \n-@mpc.run_multiprocess(world_size=2)\n+@mpc.run_multiprocess(world_size=3)\n def L_Sigmoid(x, min_value, max_value):\n     x_share = crypten.cryptensor(x, ptype = crypten.mpc.arithmetic)\n     min_value_share = crypten.cryptensor(min_value, ptype = crypten.mpc.arithmetic)\n     max_value_share = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n"
                },
                {
                    "date": 1721141048045,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -103,9 +103,9 @@\n @mpc.run_multiprocess(world_size=3)\n def L_Sigmoid(x, min_value, max_value):\n     x_share = crypten.cryptensor(x, ptype = crypten.mpc.arithmetic)\n     min_value_share = crypten.cryptensor(min_value, ptype = crypten.mpc.arithmetic)\n-    max_value_share = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n+    one_share = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n     \n     # part 1\n     cmp_result_1 = x_share > min_value_share\n     result_1 = cmp_result_1.to(crypten.mpc.arithmetic)\n"
                },
                {
                    "date": 1721141145475,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -122,11 +122,11 @@\n     mulplex_result = crypten.where(cmp_result_2, x_minus_one, 0)\n     mulplex_time_end = time.time()\n     mulplex_time = mulplex_time_end - mulplex_time_begin\n     # print(\"mulplex_time\", mulplex_time)\n+\n+    result_2 = mulplex_result + one_share\n     \n-    result_2 = mulplex_result + max_value_share\n-    \n     L_sigmod_result = result_1 * result_2\n     \n     rank = comm.get().get_rank()\n     crypten.print(f\"\\nRank {rank}:\\n cmp_result_1: {cmp_result_1.get_plain_text()}\\n\" \\\n"
                },
                {
                    "date": 1721141163582,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -99,44 +99,44 @@\n     # relu_time = relu_time_end - relu_time_begin\n     # print(\"relu_time\", relu_time)\n # endregion\n \n-@mpc.run_multiprocess(world_size=3)\n-def L_Sigmoid(x, min_value, max_value):\n-    x_share = crypten.cryptensor(x, ptype = crypten.mpc.arithmetic)\n-    min_value_share = crypten.cryptensor(min_value, ptype = crypten.mpc.arithmetic)\n-    one_share = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n+# @mpc.run_multiprocess(world_size=3)\n+# def L_Sigmoid(x, min_value, max_value):\n+#     x_share = crypten.cryptensor(x, ptype = crypten.mpc.arithmetic)\n+#     min_value_share = crypten.cryptensor(min_value, ptype = crypten.mpc.arithmetic)\n+#     one_share = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n     \n-    # part 1\n-    cmp_result_1 = x_share > min_value_share\n-    result_1 = cmp_result_1.to(crypten.mpc.arithmetic)\n+#     # part 1\n+#     cmp_result_1 = x_share > min_value_share\n+#     result_1 = cmp_result_1.to(crypten.mpc.arithmetic)\n     \n-    # part 2    \n-    x_minus_one = x_share + min_value_share\n-    ge_time_begin = time.time()\n-    cmp_result_2 = x_minus_one < 0\n-    ge_time_end = time.time()\n-    ge_time = ge_time_end - ge_time_begin\n-    # print(\"ge_time\", ge_time)\n+#     # part 2    \n+#     x_minus_one = x_share + min_value_share\n+#     ge_time_begin = time.time()\n+#     cmp_result_2 = x_minus_one < 0\n+#     ge_time_end = time.time()\n+#     ge_time = ge_time_end - ge_time_begin\n+#     # print(\"ge_time\", ge_time)\n     \n-    mulplex_time_begin = time.time()\n-    mulplex_result = crypten.where(cmp_result_2, x_minus_one, 0)\n-    mulplex_time_end = time.time()\n-    mulplex_time = mulplex_time_end - mulplex_time_begin\n-    # print(\"mulplex_time\", mulplex_time)\n-\n-    result_2 = mulplex_result + one_share\n+#     mulplex_time_begin = time.time()\n+#     mulplex_result = crypten.where(cmp_result_2, x_minus_one, 0)\n+#     mulplex_time_end = time.time()\n+#     mulplex_time = mulplex_time_end - mulplex_time_begin\n+#     # print(\"mulplex_time\", mulplex_time)\n     \n-    L_sigmod_result = result_1 * result_2\n+#     result_2 = mulplex_result + one_share\n     \n-    rank = comm.get().get_rank()\n-    crypten.print(f\"\\nRank {rank}:\\n cmp_result_1: {cmp_result_1.get_plain_text()}\\n\" \\\n-                f\" cmp_result_2: {cmp_result_2.get_plain_text()}\\n\" \\\n-                f\" mulplex_result: {mulplex_result.get_plain_text()}\\n\" \\\n-                f\" result_1:{result_1.get_plain_text()}\\n\",\\\n-                f\" result_2:{result_2.get_plain_text()}\\n\",\\\n-                f\" L_sigmod_result:{L_sigmod_result.get_plain_text()}\\n\",\n-                in_order=True)\n+#     L_sigmod_result = result_1 * result_2\n+    \n+#     rank = comm.get().get_rank()\n+#     crypten.print(f\"\\nRank {rank}:\\n cmp_result_1: {cmp_result_1.get_plain_text()}\\n\" \\\n+#                 f\" cmp_result_2: {cmp_result_2.get_plain_text()}\\n\" \\\n+#                 f\" mulplex_result: {mulplex_result.get_plain_text()}\\n\" \\\n+#                 f\" result_1:{result_1.get_plain_text()}\\n\",\\\n+#                 f\" result_2:{result_2.get_plain_text()}\\n\",\\\n+#                 f\" L_sigmod_result:{L_sigmod_result.get_plain_text()}\\n\",\n+#                 in_order=True)\n \n \n \n def main():\n"
                },
                {
                    "date": 1721141171591,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -99,8 +99,9 @@\n     # relu_time = relu_time_end - relu_time_begin\n     # print(\"relu_time\", relu_time)\n # endregion\n \n+# region \n # @mpc.run_multiprocess(world_size=3)\n # def L_Sigmoid(x, min_value, max_value):\n #     x_share = crypten.cryptensor(x, ptype = crypten.mpc.arithmetic)\n #     min_value_share = crypten.cryptensor(min_value, ptype = crypten.mpc.arithmetic)\n@@ -135,11 +136,12 @@\n #                 f\" result_1:{result_1.get_plain_text()}\\n\",\\\n #                 f\" result_2:{result_2.get_plain_text()}\\n\",\\\n #                 f\" L_sigmod_result:{L_sigmod_result.get_plain_text()}\\n\",\n #                 in_order=True)\n+# endregion\n \n+# @mpc.run_multiprocess(world_size=3)\n \n-\n def main():\n     x = generate_random()\n     # y = generate_random()\n     print(\"x\", x)\n"
                },
                {
                    "date": 1721141178636,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -138,9 +138,10 @@\n #                 f\" L_sigmod_result:{L_sigmod_result.get_plain_text()}\\n\",\n #                 in_order=True)\n # endregion\n \n-# @mpc.run_multiprocess(world_size=3)\n+@mpc.run_multiprocess(world_size=3)\n+def test(x)\n \n def main():\n     x = generate_random()\n     # y = generate_random()\n"
                },
                {
                    "date": 1721141185377,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,152 @@\n+\n+import crypten\n+import crypten.mpc\n+import torch\n+import crypten.mpc as mpc\n+import crypten.mpc.primitives.beaver as beaver\n+import crypten.communicator as comm \n+import torch\n+from crypten.mpc import MPCTensor\n+from crypten.mpc.primitives import BinarySharedTensor\n+import time\n+import random\n+import crypten.common.functions\n+\n+crypten.init()\n+\n+\n+# region \n+# DATASET_DIR = os.path.join(os.path.dirname(__file__), 'dataset')\n+\n+# class DataSetParam:\n+#     def __init__(self, dataset_name):\n+#         self.dataset_name = dataset_name\n+\n+\n+# class DataSet:\n+#     sonar = DataSetParam('sonar.csv')\n+#     sonar_selected = DataSetParam('sonar_selected.csv')\n+    \n+    \n+    \n+# def load_dataset(dataset):\n+#     dataset_path = os.path.join(DATASET_DIR, dataset)\n+\n+#     # 尝试打开并读取CSV文件\n+#     try:\n+#         with open(dataset_path, 'r', encoding='utf-8') as csvfile:\n+#             spamreader = csv.reader(csvfile)\n+#             data = np.array(list(spamreader))\n+#     except FileNotFoundError:\n+#         print(f\"Error: The file {dataset_path} was not found.\")\n+#         return None, None\n+#     except Exception as e:\n+#         print(f\"Error: An error occurred while reading the file: {e}\")\n+#         return None, None\n+\n+#     # 检查数据是否为空\n+#     if data.size == 0:\n+#         print(\"Error: The dataset is empty.\")\n+#         return None, None\n+\n+#     feature = data[:, :-1].astype(np.float64)\n+#     labels = data[:, -1]\n+\n+#     # 创建标签映射\n+#     unique_labels = np.unique(labels)\n+#     label_to_int = {label: idx for idx, label in enumerate(unique_labels)}\n+#     int_labels = np.array([label_to_int[label] for label in labels], dtype=np.uint8)\n+#     labell = int_labels.reshape(-1,1)\n+\n+#     # 将标签转换为独热矩阵\n+#     one_hot_labels = np.zeros((int_labels.size, int_labels.max() + 1), dtype=np.uint8)\n+#     one_hot_labels[np.arange(int_labels.size), int_labels] = 1\n+\n+#     # print(\"======feature_size=====\", feature.shape)\n+#     print(\"======label_size=====\", one_hot_labels)\n+#     return feature, one_hot_labels\n+\n+# data_train = DataSet.sonar\n+\n+# load_dataset(data_train.dataset_name)\n+# endregion\n+\n+\n+def generate_random():\n+    random_tensor = random.uniform(-2, 1)\n+    return random_tensor\n+\n+# region \n+# @mpc.run_multiprocess(world_size=2)\n+# def test(x,y):\n+    # x_enc = crypten.cryptensor(x, ptype=crypten.mpc.arithmetic)\n+    # y_enc = crypten.cryptensor(y, ptype=crypten.mpc.arithmetic)\n+    # ge_time_begin = time.time()\n+    # ge_  = x_enc.ge(y_enc)\n+    # ge_time_end = time.time()\n+    # ge_time = ge_time_end - ge_time_begin\n+    # print(\"ge_time\", ge_time)\n+    \n+    # gt_time_begin = time.time()\n+    # gt_  = x_enc.gt(y_enc)\n+    # gt_time_end = time.time()\n+    # gt_time = gt_time_end - gt_time_begin\n+    # print(\"gt_time\", gt_time)\n+    \n+    # relu_time_begin = time.time()\n+    # relu_ = ge_.relu()\n+    # relu_time_end = time.time()\n+    # relu_time = relu_time_end - relu_time_begin\n+    # print(\"relu_time\", relu_time)\n+# endregion\n+\n+# region \n+# @mpc.run_multiprocess(world_size=3)\n+# def L_Sigmoid(x, min_value, max_value):\n+#     x_share = crypten.cryptensor(x, ptype = crypten.mpc.arithmetic)\n+#     min_value_share = crypten.cryptensor(min_value, ptype = crypten.mpc.arithmetic)\n+#     one_share = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n+    \n+#     # part 1\n+#     cmp_result_1 = x_share > min_value_share\n+#     result_1 = cmp_result_1.to(crypten.mpc.arithmetic)\n+    \n+#     # part 2    \n+#     x_minus_one = x_share + min_value_share\n+#     ge_time_begin = time.time()\n+#     cmp_result_2 = x_minus_one < 0\n+#     ge_time_end = time.time()\n+#     ge_time = ge_time_end - ge_time_begin\n+#     # print(\"ge_time\", ge_time)\n+    \n+#     mulplex_time_begin = time.time()\n+#     mulplex_result = crypten.where(cmp_result_2, x_minus_one, 0)\n+#     mulplex_time_end = time.time()\n+#     mulplex_time = mulplex_time_end - mulplex_time_begin\n+#     # print(\"mulplex_time\", mulplex_time)\n+    \n+#     result_2 = mulplex_result + one_share\n+    \n+#     L_sigmod_result = result_1 * result_2\n+    \n+#     rank = comm.get().get_rank()\n+#     crypten.print(f\"\\nRank {rank}:\\n cmp_result_1: {cmp_result_1.get_plain_text()}\\n\" \\\n+#                 f\" cmp_result_2: {cmp_result_2.get_plain_text()}\\n\" \\\n+#                 f\" mulplex_result: {mulplex_result.get_plain_text()}\\n\" \\\n+#                 f\" result_1:{result_1.get_plain_text()}\\n\",\\\n+#                 f\" result_2:{result_2.get_plain_text()}\\n\",\\\n+#                 f\" L_sigmod_result:{L_sigmod_result.get_plain_text()}\\n\",\n+#                 in_order=True)\n+# endregion\n+\n+@mpc.run_multiprocess(world_size=3)\n+\n+\n+def main():\n+    x = generate_random()\n+    # y = generate_random()\n+    print(\"x\", x)\n+    # print(\"y\", y)\n+    L_Sigmoid(x, -1, 2)\n+\n+main()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1721141193941,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -139,166 +139,14 @@\n #                 in_order=True)\n # endregion\n \n @mpc.run_multiprocess(world_size=3)\n+def L_Sigmoid(x, min_value, max_value):\n \n-\n def main():\n     x = generate_random()\n     # y = generate_random()\n     print(\"x\", x)\n     # print(\"y\", y)\n     L_Sigmoid(x, -1, 2)\n \n-main()\n-\n-import crypten\n-import crypten.mpc\n-import torch\n-import crypten.mpc as mpc\n-import crypten.mpc.primitives.beaver as beaver\n-import crypten.communicator as comm \n-import torch\n-from crypten.mpc import MPCTensor\n-from crypten.mpc.primitives import BinarySharedTensor\n-import time\n-import random\n-import crypten.common.functions\n-\n-crypten.init()\n-\n-\n-# region \n-# DATASET_DIR = os.path.join(os.path.dirname(__file__), 'dataset')\n-\n-# class DataSetParam:\n-#     def __init__(self, dataset_name):\n-#         self.dataset_name = dataset_name\n-\n-\n-# class DataSet:\n-#     sonar = DataSetParam('sonar.csv')\n-#     sonar_selected = DataSetParam('sonar_selected.csv')\n-    \n-    \n-    \n-# def load_dataset(dataset):\n-#     dataset_path = os.path.join(DATASET_DIR, dataset)\n-\n-#     # 尝试打开并读取CSV文件\n-#     try:\n-#         with open(dataset_path, 'r', encoding='utf-8') as csvfile:\n-#             spamreader = csv.reader(csvfile)\n-#             data = np.array(list(spamreader))\n-#     except FileNotFoundError:\n-#         print(f\"Error: The file {dataset_path} was not found.\")\n-#         return None, None\n-#     except Exception as e:\n-#         print(f\"Error: An error occurred while reading the file: {e}\")\n-#         return None, None\n-\n-#     # 检查数据是否为空\n-#     if data.size == 0:\n-#         print(\"Error: The dataset is empty.\")\n-#         return None, None\n-\n-#     feature = data[:, :-1].astype(np.float64)\n-#     labels = data[:, -1]\n-\n-#     # 创建标签映射\n-#     unique_labels = np.unique(labels)\n-#     label_to_int = {label: idx for idx, label in enumerate(unique_labels)}\n-#     int_labels = np.array([label_to_int[label] for label in labels], dtype=np.uint8)\n-#     labell = int_labels.reshape(-1,1)\n-\n-#     # 将标签转换为独热矩阵\n-#     one_hot_labels = np.zeros((int_labels.size, int_labels.max() + 1), dtype=np.uint8)\n-#     one_hot_labels[np.arange(int_labels.size), int_labels] = 1\n-\n-#     # print(\"======feature_size=====\", feature.shape)\n-#     print(\"======label_size=====\", one_hot_labels)\n-#     return feature, one_hot_labels\n-\n-# data_train = DataSet.sonar\n-\n-# load_dataset(data_train.dataset_name)\n-# endregion\n-\n-\n-def generate_random():\n-    random_tensor = random.uniform(-2, 1)\n-    return random_tensor\n-\n-# region \n-# @mpc.run_multiprocess(world_size=2)\n-# def test(x,y):\n-    # x_enc = crypten.cryptensor(x, ptype=crypten.mpc.arithmetic)\n-    # y_enc = crypten.cryptensor(y, ptype=crypten.mpc.arithmetic)\n-    # ge_time_begin = time.time()\n-    # ge_  = x_enc.ge(y_enc)\n-    # ge_time_end = time.time()\n-    # ge_time = ge_time_end - ge_time_begin\n-    # print(\"ge_time\", ge_time)\n-    \n-    # gt_time_begin = time.time()\n-    # gt_  = x_enc.gt(y_enc)\n-    # gt_time_end = time.time()\n-    # gt_time = gt_time_end - gt_time_begin\n-    # print(\"gt_time\", gt_time)\n-    \n-    # relu_time_begin = time.time()\n-    # relu_ = ge_.relu()\n-    # relu_time_end = time.time()\n-    # relu_time = relu_time_end - relu_time_begin\n-    # print(\"relu_time\", relu_time)\n-# endregion\n-\n-# region \n-# @mpc.run_multiprocess(world_size=3)\n-# def L_Sigmoid(x, min_value, max_value):\n-#     x_share = crypten.cryptensor(x, ptype = crypten.mpc.arithmetic)\n-#     min_value_share = crypten.cryptensor(min_value, ptype = crypten.mpc.arithmetic)\n-#     one_share = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n-    \n-#     # part 1\n-#     cmp_result_1 = x_share > min_value_share\n-#     result_1 = cmp_result_1.to(crypten.mpc.arithmetic)\n-    \n-#     # part 2    \n-#     x_minus_one = x_share + min_value_share\n-#     ge_time_begin = time.time()\n-#     cmp_result_2 = x_minus_one < 0\n-#     ge_time_end = time.time()\n-#     ge_time = ge_time_end - ge_time_begin\n-#     # print(\"ge_time\", ge_time)\n-    \n-#     mulplex_time_begin = time.time()\n-#     mulplex_result = crypten.where(cmp_result_2, x_minus_one, 0)\n-#     mulplex_time_end = time.time()\n-#     mulplex_time = mulplex_time_end - mulplex_time_begin\n-#     # print(\"mulplex_time\", mulplex_time)\n-    \n-#     result_2 = mulplex_result + one_share\n-    \n-#     L_sigmod_result = result_1 * result_2\n-    \n-#     rank = comm.get().get_rank()\n-#     crypten.print(f\"\\nRank {rank}:\\n cmp_result_1: {cmp_result_1.get_plain_text()}\\n\" \\\n-#                 f\" cmp_result_2: {cmp_result_2.get_plain_text()}\\n\" \\\n-#                 f\" mulplex_result: {mulplex_result.get_plain_text()}\\n\" \\\n-#                 f\" result_1:{result_1.get_plain_text()}\\n\",\\\n-#                 f\" result_2:{result_2.get_plain_text()}\\n\",\\\n-#                 f\" L_sigmod_result:{L_sigmod_result.get_plain_text()}\\n\",\n-#                 in_order=True)\n-# endregion\n-\n-@mpc.run_multiprocess(world_size=3)\n-def test(x)\n-\n-def main():\n-    x = generate_random()\n-    # y = generate_random()\n-    print(\"x\", x)\n-    # print(\"y\", y)\n-    L_Sigmoid(x, -1, 2)\n-\n main()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1721141208972,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -140,8 +140,16 @@\n # endregion\n \n @mpc.run_multiprocess(world_size=3)\n def L_Sigmoid(x, min_value, max_value):\n+    x_share = crypten.cryptensor(x, ptype = crypten.mpc.arithmetic)\n+#     min_value_share = crypten.cryptensor(min_value, ptype = crypten.mpc.arithmetic)\n+#     one_share = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n+    \n+#     # part 1\n+#     cmp_result_1 = x_share > min_value_share\n+#     result_1 = cmp_result_1.to(crypten.mpc.arithmetic)\n+    \n \n def main():\n     x = generate_random()\n     # y = generate_random()\n"
                },
                {
                    "date": 1721141355122,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -138,11 +138,11 @@\n #                 f\" L_sigmod_result:{L_sigmod_result.get_plain_text()}\\n\",\n #                 in_order=True)\n # endregion\n \n-@mpc.run_multiprocess(world_size=3)\n-def L_Sigmoid(x, min_value, max_value):\n-    x_share = crypten.cryptensor(x, ptype = crypten.mpc.arithmetic)\n+# @mpc.run_multiprocess(world_size=3)\n+# def L_Sigmoid(x, min_value, max_value):\n+#     x_share = crypten.cryptensor(x, ptype = crypten.mpc.arithmetic)\n #     min_value_share = crypten.cryptensor(min_value, ptype = crypten.mpc.arithmetic)\n #     one_share = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n     \n #     # part 1\n"
                },
                {
                    "date": 1721141368826,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -100,44 +100,44 @@\n     # print(\"relu_time\", relu_time)\n # endregion\n \n # region \n-# @mpc.run_multiprocess(world_size=3)\n-# def L_Sigmoid(x, min_value, max_value):\n-#     x_share = crypten.cryptensor(x, ptype = crypten.mpc.arithmetic)\n-#     min_value_share = crypten.cryptensor(min_value, ptype = crypten.mpc.arithmetic)\n-#     one_share = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n+@mpc.run_multiprocess(world_size=3)\n+def L_Sigmoid(x, min_value, max_value):\n+    x_share = crypten.cryptensor(x, ptype = crypten.mpc.arithmetic)\n+    min_value_share = crypten.cryptensor(min_value, ptype = crypten.mpc.arithmetic)\n+    one_share = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n     \n-#     # part 1\n-#     cmp_result_1 = x_share > min_value_share\n-#     result_1 = cmp_result_1.to(crypten.mpc.arithmetic)\n+    # part 1\n+    cmp_result_1 = x_share > min_value_share\n+    result_1 = cmp_result_1.to(crypten.mpc.arithmetic)\n     \n-#     # part 2    \n-#     x_minus_one = x_share + min_value_share\n-#     ge_time_begin = time.time()\n-#     cmp_result_2 = x_minus_one < 0\n-#     ge_time_end = time.time()\n-#     ge_time = ge_time_end - ge_time_begin\n-#     # print(\"ge_time\", ge_time)\n+    # part 2    \n+    x_minus_one = x_share + min_value_share\n+    ge_time_begin = time.time()\n+    cmp_result_2 = x_minus_one < 0\n+    ge_time_end = time.time()\n+    ge_time = ge_time_end - ge_time_begin\n+    # print(\"ge_time\", ge_time)\n     \n-#     mulplex_time_begin = time.time()\n-#     mulplex_result = crypten.where(cmp_result_2, x_minus_one, 0)\n-#     mulplex_time_end = time.time()\n-#     mulplex_time = mulplex_time_end - mulplex_time_begin\n-#     # print(\"mulplex_time\", mulplex_time)\n+    mulplex_time_begin = time.time()\n+    mulplex_result = crypten.where(cmp_result_2, x_minus_one, 0)\n+    mulplex_time_end = time.time()\n+    mulplex_time = mulplex_time_end - mulplex_time_begin\n+    # print(\"mulplex_time\", mulplex_time)\n     \n-#     result_2 = mulplex_result + one_share\n+    result_2 = mulplex_result + one_share\n     \n-#     L_sigmod_result = result_1 * result_2\n+    L_sigmod_result = result_1 * result_2\n     \n-#     rank = comm.get().get_rank()\n-#     crypten.print(f\"\\nRank {rank}:\\n cmp_result_1: {cmp_result_1.get_plain_text()}\\n\" \\\n-#                 f\" cmp_result_2: {cmp_result_2.get_plain_text()}\\n\" \\\n-#                 f\" mulplex_result: {mulplex_result.get_plain_text()}\\n\" \\\n-#                 f\" result_1:{result_1.get_plain_text()}\\n\",\\\n-#                 f\" result_2:{result_2.get_plain_text()}\\n\",\\\n-#                 f\" L_sigmod_result:{L_sigmod_result.get_plain_text()}\\n\",\n-#                 in_order=True)\n+    rank = comm.get().get_rank()\n+    crypten.print(f\"\\nRank {rank}:\\n cmp_result_1: {cmp_result_1.get_plain_text()}\\n\" \\\n+                f\" cmp_result_2: {cmp_result_2.get_plain_text()}\\n\" \\\n+                f\" mulplex_result: {mulplex_result.get_plain_text()}\\n\" \\\n+                f\" result_1:{result_1.get_plain_text()}\\n\",\\\n+                f\" result_2:{result_2.get_plain_text()}\\n\",\\\n+                f\" L_sigmod_result:{L_sigmod_result.get_plain_text()}\\n\",\n+                in_order=True)\n # endregion\n \n # @mpc.run_multiprocess(world_size=3)\n # def L_Sigmoid(x, min_value, max_value):\n"
                },
                {
                    "date": 1721141414757,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -112,13 +112,9 @@\n     result_1 = cmp_result_1.to(crypten.mpc.arithmetic)\n     \n     # part 2    \n     x_minus_one = x_share + min_value_share\n-    ge_time_begin = time.time()\n     cmp_result_2 = x_minus_one < 0\n-    ge_time_end = time.time()\n-    ge_time = ge_time_end - ge_time_begin\n-    # print(\"ge_time\", ge_time)\n     \n     mulplex_time_begin = time.time()\n     mulplex_result = crypten.where(cmp_result_2, x_minus_one, 0)\n     mulplex_time_end = time.time()\n"
                },
                {
                    "date": 1721141420332,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -114,13 +114,9 @@\n     # part 2    \n     x_minus_one = x_share + min_value_share\n     cmp_result_2 = x_minus_one < 0\n     \n-    mulplex_time_begin = time.time()\n     mulplex_result = crypten.where(cmp_result_2, x_minus_one, 0)\n-    mulplex_time_end = time.time()\n-    mulplex_time = mulplex_time_end - mulplex_time_begin\n-    # print(\"mulplex_time\", mulplex_time)\n     \n     result_2 = mulplex_result + one_share\n     \n     L_sigmod_result = result_1 * result_2\n"
                },
                {
                    "date": 1721141426594,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -113,11 +113,9 @@\n     \n     # part 2    \n     x_minus_one = x_share + min_value_share\n     cmp_result_2 = x_minus_one < 0\n-    \n     mulplex_result = crypten.where(cmp_result_2, x_minus_one, 0)\n-    \n     result_2 = mulplex_result + one_share\n     \n     L_sigmod_result = result_1 * result_2\n     \n"
                },
                {
                    "date": 1721141435654,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -117,9 +117,9 @@\n     mulplex_result = crypten.where(cmp_result_2, x_minus_one, 0)\n     result_2 = mulplex_result + one_share\n     \n     L_sigmod_result = result_1 * result_2\n-    \n+   \n     rank = comm.get().get_rank()\n     crypten.print(f\"\\nRank {rank}:\\n cmp_result_1: {cmp_result_1.get_plain_text()}\\n\" \\\n                 f\" cmp_result_2: {cmp_result_2.get_plain_text()}\\n\" \\\n                 f\" mulplex_result: {mulplex_result.get_plain_text()}\\n\" \\\n"
                },
                {
                    "date": 1721141447152,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -106,8 +106,9 @@\n     x_share = crypten.cryptensor(x, ptype = crypten.mpc.arithmetic)\n     min_value_share = crypten.cryptensor(min_value, ptype = crypten.mpc.arithmetic)\n     one_share = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n     \n+    \n     # part 1\n     cmp_result_1 = x_share > min_value_share\n     result_1 = cmp_result_1.to(crypten.mpc.arithmetic)\n     \n"
                },
                {
                    "date": 1721141453729,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -106,9 +106,9 @@\n     x_share = crypten.cryptensor(x, ptype = crypten.mpc.arithmetic)\n     min_value_share = crypten.cryptensor(min_value, ptype = crypten.mpc.arithmetic)\n     one_share = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n     \n-    \n+    begin_time = time.\n     # part 1\n     cmp_result_1 = x_share > min_value_share\n     result_1 = cmp_result_1.to(crypten.mpc.arithmetic)\n     \n"
                },
                {
                    "date": 1721141459158,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -106,9 +106,9 @@\n     x_share = crypten.cryptensor(x, ptype = crypten.mpc.arithmetic)\n     min_value_share = crypten.cryptensor(min_value, ptype = crypten.mpc.arithmetic)\n     one_share = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n     \n-    begin_time = time.\n+    begin_time = time.time()\n     # part 1\n     cmp_result_1 = x_share > min_value_share\n     result_1 = cmp_result_1.to(crypten.mpc.arithmetic)\n     \n@@ -118,9 +118,10 @@\n     mulplex_result = crypten.where(cmp_result_2, x_minus_one, 0)\n     result_2 = mulplex_result + one_share\n     \n     L_sigmod_result = result_1 * result_2\n-   \n+    \n+    \n     rank = comm.get().get_rank()\n     crypten.print(f\"\\nRank {rank}:\\n cmp_result_1: {cmp_result_1.get_plain_text()}\\n\" \\\n                 f\" cmp_result_2: {cmp_result_2.get_plain_text()}\\n\" \\\n                 f\" mulplex_result: {mulplex_result.get_plain_text()}\\n\" \\\n"
                },
                {
                    "date": 1721141464955,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,154 @@\n+\n+import crypten\n+import crypten.mpc\n+import torch\n+import crypten.mpc as mpc\n+import crypten.mpc.primitives.beaver as beaver\n+import crypten.communicator as comm \n+import torch\n+from crypten.mpc import MPCTensor\n+from crypten.mpc.primitives import BinarySharedTensor\n+import time\n+import random\n+import crypten.common.functions\n+\n+crypten.init()\n+\n+\n+# region \n+# DATASET_DIR = os.path.join(os.path.dirname(__file__), 'dataset')\n+\n+# class DataSetParam:\n+#     def __init__(self, dataset_name):\n+#         self.dataset_name = dataset_name\n+\n+\n+# class DataSet:\n+#     sonar = DataSetParam('sonar.csv')\n+#     sonar_selected = DataSetParam('sonar_selected.csv')\n+    \n+    \n+    \n+# def load_dataset(dataset):\n+#     dataset_path = os.path.join(DATASET_DIR, dataset)\n+\n+#     # 尝试打开并读取CSV文件\n+#     try:\n+#         with open(dataset_path, 'r', encoding='utf-8') as csvfile:\n+#             spamreader = csv.reader(csvfile)\n+#             data = np.array(list(spamreader))\n+#     except FileNotFoundError:\n+#         print(f\"Error: The file {dataset_path} was not found.\")\n+#         return None, None\n+#     except Exception as e:\n+#         print(f\"Error: An error occurred while reading the file: {e}\")\n+#         return None, None\n+\n+#     # 检查数据是否为空\n+#     if data.size == 0:\n+#         print(\"Error: The dataset is empty.\")\n+#         return None, None\n+\n+#     feature = data[:, :-1].astype(np.float64)\n+#     labels = data[:, -1]\n+\n+#     # 创建标签映射\n+#     unique_labels = np.unique(labels)\n+#     label_to_int = {label: idx for idx, label in enumerate(unique_labels)}\n+#     int_labels = np.array([label_to_int[label] for label in labels], dtype=np.uint8)\n+#     labell = int_labels.reshape(-1,1)\n+\n+#     # 将标签转换为独热矩阵\n+#     one_hot_labels = np.zeros((int_labels.size, int_labels.max() + 1), dtype=np.uint8)\n+#     one_hot_labels[np.arange(int_labels.size), int_labels] = 1\n+\n+#     # print(\"======feature_size=====\", feature.shape)\n+#     print(\"======label_size=====\", one_hot_labels)\n+#     return feature, one_hot_labels\n+\n+# data_train = DataSet.sonar\n+\n+# load_dataset(data_train.dataset_name)\n+# endregion\n+\n+\n+def generate_random():\n+    random_tensor = random.uniform(-2, 1)\n+    return random_tensor\n+\n+# region \n+# @mpc.run_multiprocess(world_size=2)\n+# def test(x,y):\n+    # x_enc = crypten.cryptensor(x, ptype=crypten.mpc.arithmetic)\n+    # y_enc = crypten.cryptensor(y, ptype=crypten.mpc.arithmetic)\n+    # ge_time_begin = time.time()\n+    # ge_  = x_enc.ge(y_enc)\n+    # ge_time_end = time.time()\n+    # ge_time = ge_time_end - ge_time_begin\n+    # print(\"ge_time\", ge_time)\n+    \n+    # gt_time_begin = time.time()\n+    # gt_  = x_enc.gt(y_enc)\n+    # gt_time_end = time.time()\n+    # gt_time = gt_time_end - gt_time_begin\n+    # print(\"gt_time\", gt_time)\n+    \n+    # relu_time_begin = time.time()\n+    # relu_ = ge_.relu()\n+    # relu_time_end = time.time()\n+    # relu_time = relu_time_end - relu_time_begin\n+    # print(\"relu_time\", relu_time)\n+# endregion\n+\n+# region \n+@mpc.run_multiprocess(world_size=3)\n+def L_Sigmoid(x, min_value, max_value):\n+    x_share = crypten.cryptensor(x, ptype = crypten.mpc.arithmetic)\n+    min_value_share = crypten.cryptensor(min_value, ptype = crypten.mpc.arithmetic)\n+    one_share = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n+    \n+    begin_time = time.time()\n+    # part 1\n+    cmp_result_1 = x_share > min_value_share\n+    result_1 = cmp_result_1.to(crypten.mpc.arithmetic)\n+    \n+    # part 2    \n+    x_minus_one = x_share + min_value_share\n+    cmp_result_2 = x_minus_one < 0\n+    mulplex_result = crypten.where(cmp_result_2, x_minus_one, 0)\n+    result_2 = mulplex_result + one_share\n+    \n+    L_sigmod_result = result_1 * result_2\n+    \n+    end_time = time.time()\n+    \n+    \n+    rank = comm.get().get_rank()\n+    crypten.print(f\"\\nRank {rank}:\\n cmp_result_1: {cmp_result_1.get_plain_text()}\\n\" \\\n+                f\" cmp_result_2: {cmp_result_2.get_plain_text()}\\n\" \\\n+                f\" mulplex_result: {mulplex_result.get_plain_text()}\\n\" \\\n+                f\" result_1:{result_1.get_plain_text()}\\n\",\\\n+                f\" result_2:{result_2.get_plain_text()}\\n\",\\\n+                f\" L_sigmod_result:{L_sigmod_result.get_plain_text()}\\n\",\n+                in_order=True)\n+# endregion\n+\n+# @mpc.run_multiprocess(world_size=3)\n+# def L_Sigmoid(x, min_value, max_value):\n+#     x_share = crypten.cryptensor(x, ptype = crypten.mpc.arithmetic)\n+#     min_value_share = crypten.cryptensor(min_value, ptype = crypten.mpc.arithmetic)\n+#     one_share = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n+    \n+#     # part 1\n+#     cmp_result_1 = x_share > min_value_share\n+#     result_1 = cmp_result_1.to(crypten.mpc.arithmetic)\n+    \n+\n+def main():\n+    x = generate_random()\n+    # y = generate_random()\n+    print(\"x\", x)\n+    # print(\"y\", y)\n+    L_Sigmoid(x, -1, 2)\n+\n+main()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1721141484005,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -120,10 +120,10 @@\n     \n     L_sigmod_result = result_1 * result_2\n     \n     end_time = time.time()\n+    time\n     \n-    \n     rank = comm.get().get_rank()\n     crypten.print(f\"\\nRank {rank}:\\n cmp_result_1: {cmp_result_1.get_plain_text()}\\n\" \\\n                 f\" cmp_result_2: {cmp_result_2.get_plain_text()}\\n\" \\\n                 f\" mulplex_result: {mulplex_result.get_plain_text()}\\n\" \\\n@@ -150,157 +150,5 @@\n     print(\"x\", x)\n     # print(\"y\", y)\n     L_Sigmoid(x, -1, 2)\n \n-main()\n-\n-import crypten\n-import crypten.mpc\n-import torch\n-import crypten.mpc as mpc\n-import crypten.mpc.primitives.beaver as beaver\n-import crypten.communicator as comm \n-import torch\n-from crypten.mpc import MPCTensor\n-from crypten.mpc.primitives import BinarySharedTensor\n-import time\n-import random\n-import crypten.common.functions\n-\n-crypten.init()\n-\n-\n-# region \n-# DATASET_DIR = os.path.join(os.path.dirname(__file__), 'dataset')\n-\n-# class DataSetParam:\n-#     def __init__(self, dataset_name):\n-#         self.dataset_name = dataset_name\n-\n-\n-# class DataSet:\n-#     sonar = DataSetParam('sonar.csv')\n-#     sonar_selected = DataSetParam('sonar_selected.csv')\n-    \n-    \n-    \n-# def load_dataset(dataset):\n-#     dataset_path = os.path.join(DATASET_DIR, dataset)\n-\n-#     # 尝试打开并读取CSV文件\n-#     try:\n-#         with open(dataset_path, 'r', encoding='utf-8') as csvfile:\n-#             spamreader = csv.reader(csvfile)\n-#             data = np.array(list(spamreader))\n-#     except FileNotFoundError:\n-#         print(f\"Error: The file {dataset_path} was not found.\")\n-#         return None, None\n-#     except Exception as e:\n-#         print(f\"Error: An error occurred while reading the file: {e}\")\n-#         return None, None\n-\n-#     # 检查数据是否为空\n-#     if data.size == 0:\n-#         print(\"Error: The dataset is empty.\")\n-#         return None, None\n-\n-#     feature = data[:, :-1].astype(np.float64)\n-#     labels = data[:, -1]\n-\n-#     # 创建标签映射\n-#     unique_labels = np.unique(labels)\n-#     label_to_int = {label: idx for idx, label in enumerate(unique_labels)}\n-#     int_labels = np.array([label_to_int[label] for label in labels], dtype=np.uint8)\n-#     labell = int_labels.reshape(-1,1)\n-\n-#     # 将标签转换为独热矩阵\n-#     one_hot_labels = np.zeros((int_labels.size, int_labels.max() + 1), dtype=np.uint8)\n-#     one_hot_labels[np.arange(int_labels.size), int_labels] = 1\n-\n-#     # print(\"======feature_size=====\", feature.shape)\n-#     print(\"======label_size=====\", one_hot_labels)\n-#     return feature, one_hot_labels\n-\n-# data_train = DataSet.sonar\n-\n-# load_dataset(data_train.dataset_name)\n-# endregion\n-\n-\n-def generate_random():\n-    random_tensor = random.uniform(-2, 1)\n-    return random_tensor\n-\n-# region \n-# @mpc.run_multiprocess(world_size=2)\n-# def test(x,y):\n-    # x_enc = crypten.cryptensor(x, ptype=crypten.mpc.arithmetic)\n-    # y_enc = crypten.cryptensor(y, ptype=crypten.mpc.arithmetic)\n-    # ge_time_begin = time.time()\n-    # ge_  = x_enc.ge(y_enc)\n-    # ge_time_end = time.time()\n-    # ge_time = ge_time_end - ge_time_begin\n-    # print(\"ge_time\", ge_time)\n-    \n-    # gt_time_begin = time.time()\n-    # gt_  = x_enc.gt(y_enc)\n-    # gt_time_end = time.time()\n-    # gt_time = gt_time_end - gt_time_begin\n-    # print(\"gt_time\", gt_time)\n-    \n-    # relu_time_begin = time.time()\n-    # relu_ = ge_.relu()\n-    # relu_time_end = time.time()\n-    # relu_time = relu_time_end - relu_time_begin\n-    # print(\"relu_time\", relu_time)\n-# endregion\n-\n-# region \n-@mpc.run_multiprocess(world_size=3)\n-def L_Sigmoid(x, min_value, max_value):\n-    x_share = crypten.cryptensor(x, ptype = crypten.mpc.arithmetic)\n-    min_value_share = crypten.cryptensor(min_value, ptype = crypten.mpc.arithmetic)\n-    one_share = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n-    \n-    begin_time = time.time()\n-    # part 1\n-    cmp_result_1 = x_share > min_value_share\n-    result_1 = cmp_result_1.to(crypten.mpc.arithmetic)\n-    \n-    # part 2    \n-    x_minus_one = x_share + min_value_share\n-    cmp_result_2 = x_minus_one < 0\n-    mulplex_result = crypten.where(cmp_result_2, x_minus_one, 0)\n-    result_2 = mulplex_result + one_share\n-    \n-    L_sigmod_result = result_1 * result_2\n-    \n-    \n-    rank = comm.get().get_rank()\n-    crypten.print(f\"\\nRank {rank}:\\n cmp_result_1: {cmp_result_1.get_plain_text()}\\n\" \\\n-                f\" cmp_result_2: {cmp_result_2.get_plain_text()}\\n\" \\\n-                f\" mulplex_result: {mulplex_result.get_plain_text()}\\n\" \\\n-                f\" result_1:{result_1.get_plain_text()}\\n\",\\\n-                f\" result_2:{result_2.get_plain_text()}\\n\",\\\n-                f\" L_sigmod_result:{L_sigmod_result.get_plain_text()}\\n\",\n-                in_order=True)\n-# endregion\n-\n-# @mpc.run_multiprocess(world_size=3)\n-# def L_Sigmoid(x, min_value, max_value):\n-#     x_share = crypten.cryptensor(x, ptype = crypten.mpc.arithmetic)\n-#     min_value_share = crypten.cryptensor(min_value, ptype = crypten.mpc.arithmetic)\n-#     one_share = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n-    \n-#     # part 1\n-#     cmp_result_1 = x_share > min_value_share\n-#     result_1 = cmp_result_1.to(crypten.mpc.arithmetic)\n-    \n-\n-def main():\n-    x = generate_random()\n-    # y = generate_random()\n-    print(\"x\", x)\n-    # print(\"y\", y)\n-    L_Sigmoid(x, -1, 2)\n-\n main()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1721141489990,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -120,9 +120,9 @@\n     \n     L_sigmod_result = result_1 * result_2\n     \n     end_time = time.time()\n-    time\n+    L-time = end_time - begin_time\n     \n     rank = comm.get().get_rank()\n     crypten.print(f\"\\nRank {rank}:\\n cmp_result_1: {cmp_result_1.get_plain_text()}\\n\" \\\n                 f\" cmp_result_2: {cmp_result_2.get_plain_text()}\\n\" \\\n"
                },
                {
                    "date": 1721141495777,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -128,9 +128,10 @@\n                 f\" cmp_result_2: {cmp_result_2.get_plain_text()}\\n\" \\\n                 f\" mulplex_result: {mulplex_result.get_plain_text()}\\n\" \\\n                 f\" result_1:{result_1.get_plain_text()}\\n\",\\\n                 f\" result_2:{result_2.get_plain_text()}\\n\",\\\n-                f\" L_sigmod_result:{L_sigmod_result.get_plain_text()}\\n\",\n+                f\" L_sigmod_result:{L_sigmod_result.get_plain_text()}\\n\",\\\n+                    \n                 in_order=True)\n # endregion\n \n # @mpc.run_multiprocess(world_size=3)\n"
                },
                {
                    "date": 1721141504453,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -129,9 +129,9 @@\n                 f\" mulplex_result: {mulplex_result.get_plain_text()}\\n\" \\\n                 f\" result_1:{result_1.get_plain_text()}\\n\",\\\n                 f\" result_2:{result_2.get_plain_text()}\\n\",\\\n                 f\" L_sigmod_result:{L_sigmod_result.get_plain_text()}\\n\",\\\n-                    \n+                f\" L-time:{L_sigmod_result.get_plain_text()}\\n\",\\   \n                 in_order=True)\n # endregion\n \n # @mpc.run_multiprocess(world_size=3)\n"
                },
                {
                    "date": 1721141509507,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -120,18 +120,18 @@\n     \n     L_sigmod_result = result_1 * result_2\n     \n     end_time = time.time()\n-    L-time = end_time - begin_time\n+    L_time = end_time - begin_time\n     \n     rank = comm.get().get_rank()\n     crypten.print(f\"\\nRank {rank}:\\n cmp_result_1: {cmp_result_1.get_plain_text()}\\n\" \\\n                 f\" cmp_result_2: {cmp_result_2.get_plain_text()}\\n\" \\\n                 f\" mulplex_result: {mulplex_result.get_plain_text()}\\n\" \\\n                 f\" result_1:{result_1.get_plain_text()}\\n\",\\\n                 f\" result_2:{result_2.get_plain_text()}\\n\",\\\n                 f\" L_sigmod_result:{L_sigmod_result.get_plain_text()}\\n\",\\\n-                f\" L-time:{L_sigmod_result.get_plain_text()}\\n\",\\   \n+                f\" L_time:{L_sigmod_result.get_plain_text()}\\n\",\\   \n                 in_order=True)\n # endregion\n \n # @mpc.run_multiprocess(world_size=3)\n"
                },
                {
                    "date": 1721141518018,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -129,9 +129,9 @@\n                 f\" mulplex_result: {mulplex_result.get_plain_text()}\\n\" \\\n                 f\" result_1:{result_1.get_plain_text()}\\n\",\\\n                 f\" result_2:{result_2.get_plain_text()}\\n\",\\\n                 f\" L_sigmod_result:{L_sigmod_result.get_plain_text()}\\n\",\\\n-                f\" L_time:{L_sigmod_result.get_plain_text()}\\n\",\\   \n+                f\" L_time:{L_time}\\n\",\\   \n                 in_order=True)\n # endregion\n \n # @mpc.run_multiprocess(world_size=3)\n"
                },
                {
                    "date": 1721141565269,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -100,39 +100,39 @@\n     # print(\"relu_time\", relu_time)\n # endregion\n \n # region \n-@mpc.run_multiprocess(world_size=3)\n-def L_Sigmoid(x, min_value, max_value):\n-    x_share = crypten.cryptensor(x, ptype = crypten.mpc.arithmetic)\n-    min_value_share = crypten.cryptensor(min_value, ptype = crypten.mpc.arithmetic)\n-    one_share = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n+# @mpc.run_multiprocess(world_size=3)\n+# def L_Sigmoid(x, min_value, max_value):\n+#     x_share = crypten.cryptensor(x, ptype = crypten.mpc.arithmetic)\n+#     min_value_share = crypten.cryptensor(min_value, ptype = crypten.mpc.arithmetic)\n+#     one_share = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n     \n-    begin_time = time.time()\n-    # part 1\n-    cmp_result_1 = x_share > min_value_share\n-    result_1 = cmp_result_1.to(crypten.mpc.arithmetic)\n+#     begin_time = time.time()\n+#     # part 1\n+#     cmp_result_1 = x_share > min_value_share\n+#     result_1 = cmp_result_1.to(crypten.mpc.arithmetic)\n     \n-    # part 2    \n-    x_minus_one = x_share + min_value_share\n-    cmp_result_2 = x_minus_one < 0\n-    mulplex_result = crypten.where(cmp_result_2, x_minus_one, 0)\n-    result_2 = mulplex_result + one_share\n+#     # part 2    \n+#     x_minus_one = x_share + min_value_share\n+#     cmp_result_2 = x_minus_one < 0\n+#     mulplex_result = crypten.where(cmp_result_2, x_minus_one, 0)\n+#     result_2 = mulplex_result + one_share\n     \n-    L_sigmod_result = result_1 * result_2\n+#     L_sigmod_result = result_1 * result_2\n     \n-    end_time = time.time()\n-    L_time = end_time - begin_time\n+#     end_time = time.time()\n+#     L_time = end_time - begin_time\n     \n-    rank = comm.get().get_rank()\n-    crypten.print(f\"\\nRank {rank}:\\n cmp_result_1: {cmp_result_1.get_plain_text()}\\n\" \\\n-                f\" cmp_result_2: {cmp_result_2.get_plain_text()}\\n\" \\\n-                f\" mulplex_result: {mulplex_result.get_plain_text()}\\n\" \\\n-                f\" result_1:{result_1.get_plain_text()}\\n\",\\\n-                f\" result_2:{result_2.get_plain_text()}\\n\",\\\n-                f\" L_sigmod_result:{L_sigmod_result.get_plain_text()}\\n\",\\\n-                f\" L_time:{L_time}\\n\",\\   \n-                in_order=True)\n+#     rank = comm.get().get_rank()\n+#     crypten.print(f\"\\nRank {rank}:\\n cmp_result_1: {cmp_result_1.get_plain_text()}\\n\" \\\n+#                 f\" cmp_result_2: {cmp_result_2.get_plain_text()}\\n\" \\\n+#                 f\" mulplex_result: {mulplex_result.get_plain_text()}\\n\" \\\n+#                 f\" result_1:{result_1.get_plain_text()}\\n\",\\\n+#                 f\" result_2:{result_2.get_plain_text()}\\n\",\\\n+#                 f\" L_sigmod_result:{L_sigmod_result.get_plain_text()}\\n\",\\\n+#                 f\" L_time:{L_time}\\n\",\n+#                 in_order=True)\n # endregion\n \n # @mpc.run_multiprocess(world_size=3)\n # def L_Sigmoid(x, min_value, max_value):\n"
                },
                {
                    "date": 1721141573372,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -133,17 +133,17 @@\n #                 f\" L_time:{L_time}\\n\",\n #                 in_order=True)\n # endregion\n \n-# @mpc.run_multiprocess(world_size=3)\n-# def L_Sigmoid(x, min_value, max_value):\n-#     x_share = crypten.cryptensor(x, ptype = crypten.mpc.arithmetic)\n-#     min_value_share = crypten.cryptensor(min_value, ptype = crypten.mpc.arithmetic)\n-#     one_share = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n+@mpc.run_multiprocess(world_size=3)\n+def L_Sigmoid(x, min_value, max_value):\n+    x_share = crypten.cryptensor(x, ptype = crypten.mpc.arithmetic)\n+    min_value_share = crypten.cryptensor(min_value, ptype = crypten.mpc.arithmetic)\n+    one_share = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n     \n-#     # part 1\n-#     cmp_result_1 = x_share > min_value_share\n-#     result_1 = cmp_result_1.to(crypten.mpc.arithmetic)\n+    # part 1\n+    cmp_result_1 = x_share > min_value_share\n+    result_1 = cmp_result_1.to(crypten.mpc.arithmetic)\n     \n \n def main():\n     x = generate_random()\n"
                },
                {
                    "date": 1721141580045,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -143,8 +143,10 @@\n     # part 1\n     cmp_result_1 = x_share > min_value_share\n     result_1 = cmp_result_1.to(crypten.mpc.arithmetic)\n     \n+    \n+    \n \n def main():\n     x = generate_random()\n     # y = generate_random()\n"
                },
                {
                    "date": 1721141593848,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -143,10 +143,11 @@\n     # part 1\n     cmp_result_1 = x_share > min_value_share\n     result_1 = cmp_result_1.to(crypten.mpc.arithmetic)\n     \n+    # result 2\n+    temp = \n     \n-    \n \n def main():\n     x = generate_random()\n     # y = generate_random()\n"
                },
                {
                    "date": 1721141607888,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -144,10 +144,11 @@\n     cmp_result_1 = x_share > min_value_share\n     result_1 = cmp_result_1.to(crypten.mpc.arithmetic)\n     \n     # result 2\n-    temp = \n+    temp = -x_share - one_share\n     \n+    \n \n def main():\n     x = generate_random()\n     # y = generate_random()\n"
                },
                {
                    "date": 1721141617861,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -145,10 +145,10 @@\n     result_1 = cmp_result_1.to(crypten.mpc.arithmetic)\n     \n     # result 2\n     temp = -x_share - one_share\n+    relu_result = \n     \n-    \n \n def main():\n     x = generate_random()\n     # y = generate_random()\n"
                },
                {
                    "date": 1721141656060,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -145,9 +145,9 @@\n     result_1 = cmp_result_1.to(crypten.mpc.arithmetic)\n     \n     # result 2\n     temp = -x_share - one_share\n-    relu_result = \n+    relu_result = temp\n     \n \n def main():\n     x = generate_random()\n"
                },
                {
                    "date": 1721141661492,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -145,9 +145,9 @@\n     result_1 = cmp_result_1.to(crypten.mpc.arithmetic)\n     \n     # result 2\n     temp = -x_share - one_share\n-    relu_result = temp\n+    relu_result = temp.relu()\n     \n \n def main():\n     x = generate_random()\n"
                },
                {
                    "date": 1721141719649,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -147,8 +147,9 @@\n     # result 2\n     temp = -x_share - one_share\n     relu_result = temp.relu()\n     \n+    \n \n def main():\n     x = generate_random()\n     # y = generate_random()\n"
                },
                {
                    "date": 1721141772069,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -146,10 +146,10 @@\n     \n     # result 2\n     temp = -x_share - one_share\n     relu_result = temp.relu()\n+    result_2 = \n     \n-    \n \n def main():\n     x = generate_random()\n     # y = generate_random()\n"
                },
                {
                    "date": 1721141779137,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,161 @@\n+\n+import crypten\n+import crypten.mpc\n+import torch\n+import crypten.mpc as mpc\n+import crypten.mpc.primitives.beaver as beaver\n+import crypten.communicator as comm \n+import torch\n+from crypten.mpc import MPCTensor\n+from crypten.mpc.primitives import BinarySharedTensor\n+import time\n+import random\n+import crypten.common.functions\n+\n+crypten.init()\n+\n+\n+# region \n+# DATASET_DIR = os.path.join(os.path.dirname(__file__), 'dataset')\n+\n+# class DataSetParam:\n+#     def __init__(self, dataset_name):\n+#         self.dataset_name = dataset_name\n+\n+\n+# class DataSet:\n+#     sonar = DataSetParam('sonar.csv')\n+#     sonar_selected = DataSetParam('sonar_selected.csv')\n+    \n+    \n+    \n+# def load_dataset(dataset):\n+#     dataset_path = os.path.join(DATASET_DIR, dataset)\n+\n+#     # 尝试打开并读取CSV文件\n+#     try:\n+#         with open(dataset_path, 'r', encoding='utf-8') as csvfile:\n+#             spamreader = csv.reader(csvfile)\n+#             data = np.array(list(spamreader))\n+#     except FileNotFoundError:\n+#         print(f\"Error: The file {dataset_path} was not found.\")\n+#         return None, None\n+#     except Exception as e:\n+#         print(f\"Error: An error occurred while reading the file: {e}\")\n+#         return None, None\n+\n+#     # 检查数据是否为空\n+#     if data.size == 0:\n+#         print(\"Error: The dataset is empty.\")\n+#         return None, None\n+\n+#     feature = data[:, :-1].astype(np.float64)\n+#     labels = data[:, -1]\n+\n+#     # 创建标签映射\n+#     unique_labels = np.unique(labels)\n+#     label_to_int = {label: idx for idx, label in enumerate(unique_labels)}\n+#     int_labels = np.array([label_to_int[label] for label in labels], dtype=np.uint8)\n+#     labell = int_labels.reshape(-1,1)\n+\n+#     # 将标签转换为独热矩阵\n+#     one_hot_labels = np.zeros((int_labels.size, int_labels.max() + 1), dtype=np.uint8)\n+#     one_hot_labels[np.arange(int_labels.size), int_labels] = 1\n+\n+#     # print(\"======feature_size=====\", feature.shape)\n+#     print(\"======label_size=====\", one_hot_labels)\n+#     return feature, one_hot_labels\n+\n+# data_train = DataSet.sonar\n+\n+# load_dataset(data_train.dataset_name)\n+# endregion\n+\n+\n+def generate_random():\n+    random_tensor = random.uniform(-2, 1)\n+    return random_tensor\n+\n+# region \n+# @mpc.run_multiprocess(world_size=2)\n+# def test(x,y):\n+    # x_enc = crypten.cryptensor(x, ptype=crypten.mpc.arithmetic)\n+    # y_enc = crypten.cryptensor(y, ptype=crypten.mpc.arithmetic)\n+    # ge_time_begin = time.time()\n+    # ge_  = x_enc.ge(y_enc)\n+    # ge_time_end = time.time()\n+    # ge_time = ge_time_end - ge_time_begin\n+    # print(\"ge_time\", ge_time)\n+    \n+    # gt_time_begin = time.time()\n+    # gt_  = x_enc.gt(y_enc)\n+    # gt_time_end = time.time()\n+    # gt_time = gt_time_end - gt_time_begin\n+    # print(\"gt_time\", gt_time)\n+    \n+    # relu_time_begin = time.time()\n+    # relu_ = ge_.relu()\n+    # relu_time_end = time.time()\n+    # relu_time = relu_time_end - relu_time_begin\n+    # print(\"relu_time\", relu_time)\n+# endregion\n+\n+# region \n+# @mpc.run_multiprocess(world_size=3)\n+# def L_Sigmoid(x, min_value, max_value):\n+#     x_share = crypten.cryptensor(x, ptype = crypten.mpc.arithmetic)\n+#     min_value_share = crypten.cryptensor(min_value, ptype = crypten.mpc.arithmetic)\n+#     one_share = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n+    \n+#     begin_time = time.time()\n+#     # part 1\n+#     cmp_result_1 = x_share > min_value_share\n+#     result_1 = cmp_result_1.to(crypten.mpc.arithmetic)\n+    \n+#     # part 2    \n+#     x_minus_one = x_share + min_value_share\n+#     cmp_result_2 = x_minus_one < 0\n+#     mulplex_result = crypten.where(cmp_result_2, x_minus_one, 0)\n+#     result_2 = mulplex_result + one_share\n+    \n+#     L_sigmod_result = result_1 * result_2\n+    \n+#     end_time = time.time()\n+#     L_time = end_time - begin_time\n+    \n+#     rank = comm.get().get_rank()\n+#     crypten.print(f\"\\nRank {rank}:\\n cmp_result_1: {cmp_result_1.get_plain_text()}\\n\" \\\n+#                 f\" cmp_result_2: {cmp_result_2.get_plain_text()}\\n\" \\\n+#                 f\" mulplex_result: {mulplex_result.get_plain_text()}\\n\" \\\n+#                 f\" result_1:{result_1.get_plain_text()}\\n\",\\\n+#                 f\" result_2:{result_2.get_plain_text()}\\n\",\\\n+#                 f\" L_sigmod_result:{L_sigmod_result.get_plain_text()}\\n\",\\\n+#                 f\" L_time:{L_time}\\n\",\n+#                 in_order=True)\n+# endregion\n+\n+@mpc.run_multiprocess(world_size=3)\n+def L_Sigmoid(x, min_value, max_value):\n+    x_share = crypten.cryptensor(x, ptype = crypten.mpc.arithmetic)\n+    min_value_share = crypten.cryptensor(min_value, ptype = crypten.mpc.arithmetic)\n+    one_share = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n+    one_share_again = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n+    \n+    # part 1\n+    cmp_result_1 = x_share > min_value_share\n+    result_1 = cmp_result_1.to(crypten.mpc.arithmetic)\n+    \n+    # result 2\n+    temp = -x_share - one_share\n+    relu_result = temp.relu()\n+    result_2 = \n+    \n+\n+def main():\n+    x = generate_random()\n+    # y = generate_random()\n+    print(\"x\", x)\n+    # print(\"y\", y)\n+    L_Sigmoid(x, -1, 2)\n+\n+main()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1721141785458,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -147,9 +147,9 @@\n     \n     # result 2\n     temp = -x_share - one_share\n     relu_result = temp.relu()\n-    result_2 = \n+    result_2 = one_share_again  - \n     \n \n def main():\n     x = generate_random()\n@@ -157,165 +157,5 @@\n     print(\"x\", x)\n     # print(\"y\", y)\n     L_Sigmoid(x, -1, 2)\n \n-main()\n-\n-import crypten\n-import crypten.mpc\n-import torch\n-import crypten.mpc as mpc\n-import crypten.mpc.primitives.beaver as beaver\n-import crypten.communicator as comm \n-import torch\n-from crypten.mpc import MPCTensor\n-from crypten.mpc.primitives import BinarySharedTensor\n-import time\n-import random\n-import crypten.common.functions\n-\n-crypten.init()\n-\n-\n-# region \n-# DATASET_DIR = os.path.join(os.path.dirname(__file__), 'dataset')\n-\n-# class DataSetParam:\n-#     def __init__(self, dataset_name):\n-#         self.dataset_name = dataset_name\n-\n-\n-# class DataSet:\n-#     sonar = DataSetParam('sonar.csv')\n-#     sonar_selected = DataSetParam('sonar_selected.csv')\n-    \n-    \n-    \n-# def load_dataset(dataset):\n-#     dataset_path = os.path.join(DATASET_DIR, dataset)\n-\n-#     # 尝试打开并读取CSV文件\n-#     try:\n-#         with open(dataset_path, 'r', encoding='utf-8') as csvfile:\n-#             spamreader = csv.reader(csvfile)\n-#             data = np.array(list(spamreader))\n-#     except FileNotFoundError:\n-#         print(f\"Error: The file {dataset_path} was not found.\")\n-#         return None, None\n-#     except Exception as e:\n-#         print(f\"Error: An error occurred while reading the file: {e}\")\n-#         return None, None\n-\n-#     # 检查数据是否为空\n-#     if data.size == 0:\n-#         print(\"Error: The dataset is empty.\")\n-#         return None, None\n-\n-#     feature = data[:, :-1].astype(np.float64)\n-#     labels = data[:, -1]\n-\n-#     # 创建标签映射\n-#     unique_labels = np.unique(labels)\n-#     label_to_int = {label: idx for idx, label in enumerate(unique_labels)}\n-#     int_labels = np.array([label_to_int[label] for label in labels], dtype=np.uint8)\n-#     labell = int_labels.reshape(-1,1)\n-\n-#     # 将标签转换为独热矩阵\n-#     one_hot_labels = np.zeros((int_labels.size, int_labels.max() + 1), dtype=np.uint8)\n-#     one_hot_labels[np.arange(int_labels.size), int_labels] = 1\n-\n-#     # print(\"======feature_size=====\", feature.shape)\n-#     print(\"======label_size=====\", one_hot_labels)\n-#     return feature, one_hot_labels\n-\n-# data_train = DataSet.sonar\n-\n-# load_dataset(data_train.dataset_name)\n-# endregion\n-\n-\n-def generate_random():\n-    random_tensor = random.uniform(-2, 1)\n-    return random_tensor\n-\n-# region \n-# @mpc.run_multiprocess(world_size=2)\n-# def test(x,y):\n-    # x_enc = crypten.cryptensor(x, ptype=crypten.mpc.arithmetic)\n-    # y_enc = crypten.cryptensor(y, ptype=crypten.mpc.arithmetic)\n-    # ge_time_begin = time.time()\n-    # ge_  = x_enc.ge(y_enc)\n-    # ge_time_end = time.time()\n-    # ge_time = ge_time_end - ge_time_begin\n-    # print(\"ge_time\", ge_time)\n-    \n-    # gt_time_begin = time.time()\n-    # gt_  = x_enc.gt(y_enc)\n-    # gt_time_end = time.time()\n-    # gt_time = gt_time_end - gt_time_begin\n-    # print(\"gt_time\", gt_time)\n-    \n-    # relu_time_begin = time.time()\n-    # relu_ = ge_.relu()\n-    # relu_time_end = time.time()\n-    # relu_time = relu_time_end - relu_time_begin\n-    # print(\"relu_time\", relu_time)\n-# endregion\n-\n-# region \n-# @mpc.run_multiprocess(world_size=3)\n-# def L_Sigmoid(x, min_value, max_value):\n-#     x_share = crypten.cryptensor(x, ptype = crypten.mpc.arithmetic)\n-#     min_value_share = crypten.cryptensor(min_value, ptype = crypten.mpc.arithmetic)\n-#     one_share = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n-    \n-#     begin_time = time.time()\n-#     # part 1\n-#     cmp_result_1 = x_share > min_value_share\n-#     result_1 = cmp_result_1.to(crypten.mpc.arithmetic)\n-    \n-#     # part 2    \n-#     x_minus_one = x_share + min_value_share\n-#     cmp_result_2 = x_minus_one < 0\n-#     mulplex_result = crypten.where(cmp_result_2, x_minus_one, 0)\n-#     result_2 = mulplex_result + one_share\n-    \n-#     L_sigmod_result = result_1 * result_2\n-    \n-#     end_time = time.time()\n-#     L_time = end_time - begin_time\n-    \n-#     rank = comm.get().get_rank()\n-#     crypten.print(f\"\\nRank {rank}:\\n cmp_result_1: {cmp_result_1.get_plain_text()}\\n\" \\\n-#                 f\" cmp_result_2: {cmp_result_2.get_plain_text()}\\n\" \\\n-#                 f\" mulplex_result: {mulplex_result.get_plain_text()}\\n\" \\\n-#                 f\" result_1:{result_1.get_plain_text()}\\n\",\\\n-#                 f\" result_2:{result_2.get_plain_text()}\\n\",\\\n-#                 f\" L_sigmod_result:{L_sigmod_result.get_plain_text()}\\n\",\\\n-#                 f\" L_time:{L_time}\\n\",\n-#                 in_order=True)\n-# endregion\n-\n-@mpc.run_multiprocess(world_size=3)\n-def L_Sigmoid(x, min_value, max_value):\n-    x_share = crypten.cryptensor(x, ptype = crypten.mpc.arithmetic)\n-    min_value_share = crypten.cryptensor(min_value, ptype = crypten.mpc.arithmetic)\n-    one_share = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n-    \n-    # part 1\n-    cmp_result_1 = x_share > min_value_share\n-    result_1 = cmp_result_1.to(crypten.mpc.arithmetic)\n-    \n-    # result 2\n-    temp = -x_share - one_share\n-    relu_result = temp.relu()\n-    result_2 = \n-    \n-\n-def main():\n-    x = generate_random()\n-    # y = generate_random()\n-    print(\"x\", x)\n-    # print(\"y\", y)\n-    L_Sigmoid(x, -1, 2)\n-\n main()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1721141792911,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,161 @@\n+\n+import crypten\n+import crypten.mpc\n+import torch\n+import crypten.mpc as mpc\n+import crypten.mpc.primitives.beaver as beaver\n+import crypten.communicator as comm \n+import torch\n+from crypten.mpc import MPCTensor\n+from crypten.mpc.primitives import BinarySharedTensor\n+import time\n+import random\n+import crypten.common.functions\n+\n+crypten.init()\n+\n+\n+# region \n+# DATASET_DIR = os.path.join(os.path.dirname(__file__), 'dataset')\n+\n+# class DataSetParam:\n+#     def __init__(self, dataset_name):\n+#         self.dataset_name = dataset_name\n+\n+\n+# class DataSet:\n+#     sonar = DataSetParam('sonar.csv')\n+#     sonar_selected = DataSetParam('sonar_selected.csv')\n+    \n+    \n+    \n+# def load_dataset(dataset):\n+#     dataset_path = os.path.join(DATASET_DIR, dataset)\n+\n+#     # 尝试打开并读取CSV文件\n+#     try:\n+#         with open(dataset_path, 'r', encoding='utf-8') as csvfile:\n+#             spamreader = csv.reader(csvfile)\n+#             data = np.array(list(spamreader))\n+#     except FileNotFoundError:\n+#         print(f\"Error: The file {dataset_path} was not found.\")\n+#         return None, None\n+#     except Exception as e:\n+#         print(f\"Error: An error occurred while reading the file: {e}\")\n+#         return None, None\n+\n+#     # 检查数据是否为空\n+#     if data.size == 0:\n+#         print(\"Error: The dataset is empty.\")\n+#         return None, None\n+\n+#     feature = data[:, :-1].astype(np.float64)\n+#     labels = data[:, -1]\n+\n+#     # 创建标签映射\n+#     unique_labels = np.unique(labels)\n+#     label_to_int = {label: idx for idx, label in enumerate(unique_labels)}\n+#     int_labels = np.array([label_to_int[label] for label in labels], dtype=np.uint8)\n+#     labell = int_labels.reshape(-1,1)\n+\n+#     # 将标签转换为独热矩阵\n+#     one_hot_labels = np.zeros((int_labels.size, int_labels.max() + 1), dtype=np.uint8)\n+#     one_hot_labels[np.arange(int_labels.size), int_labels] = 1\n+\n+#     # print(\"======feature_size=====\", feature.shape)\n+#     print(\"======label_size=====\", one_hot_labels)\n+#     return feature, one_hot_labels\n+\n+# data_train = DataSet.sonar\n+\n+# load_dataset(data_train.dataset_name)\n+# endregion\n+\n+\n+def generate_random():\n+    random_tensor = random.uniform(-2, 1)\n+    return random_tensor\n+\n+# region \n+# @mpc.run_multiprocess(world_size=2)\n+# def test(x,y):\n+    # x_enc = crypten.cryptensor(x, ptype=crypten.mpc.arithmetic)\n+    # y_enc = crypten.cryptensor(y, ptype=crypten.mpc.arithmetic)\n+    # ge_time_begin = time.time()\n+    # ge_  = x_enc.ge(y_enc)\n+    # ge_time_end = time.time()\n+    # ge_time = ge_time_end - ge_time_begin\n+    # print(\"ge_time\", ge_time)\n+    \n+    # gt_time_begin = time.time()\n+    # gt_  = x_enc.gt(y_enc)\n+    # gt_time_end = time.time()\n+    # gt_time = gt_time_end - gt_time_begin\n+    # print(\"gt_time\", gt_time)\n+    \n+    # relu_time_begin = time.time()\n+    # relu_ = ge_.relu()\n+    # relu_time_end = time.time()\n+    # relu_time = relu_time_end - relu_time_begin\n+    # print(\"relu_time\", relu_time)\n+# endregion\n+\n+# region \n+# @mpc.run_multiprocess(world_size=3)\n+# def L_Sigmoid(x, min_value, max_value):\n+#     x_share = crypten.cryptensor(x, ptype = crypten.mpc.arithmetic)\n+#     min_value_share = crypten.cryptensor(min_value, ptype = crypten.mpc.arithmetic)\n+#     one_share = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n+    \n+#     begin_time = time.time()\n+#     # part 1\n+#     cmp_result_1 = x_share > min_value_share\n+#     result_1 = cmp_result_1.to(crypten.mpc.arithmetic)\n+    \n+#     # part 2    \n+#     x_minus_one = x_share + min_value_share\n+#     cmp_result_2 = x_minus_one < 0\n+#     mulplex_result = crypten.where(cmp_result_2, x_minus_one, 0)\n+#     result_2 = mulplex_result + one_share\n+    \n+#     L_sigmod_result = result_1 * result_2\n+    \n+#     end_time = time.time()\n+#     L_time = end_time - begin_time\n+    \n+#     rank = comm.get().get_rank()\n+#     crypten.print(f\"\\nRank {rank}:\\n cmp_result_1: {cmp_result_1.get_plain_text()}\\n\" \\\n+#                 f\" cmp_result_2: {cmp_result_2.get_plain_text()}\\n\" \\\n+#                 f\" mulplex_result: {mulplex_result.get_plain_text()}\\n\" \\\n+#                 f\" result_1:{result_1.get_plain_text()}\\n\",\\\n+#                 f\" result_2:{result_2.get_plain_text()}\\n\",\\\n+#                 f\" L_sigmod_result:{L_sigmod_result.get_plain_text()}\\n\",\\\n+#                 f\" L_time:{L_time}\\n\",\n+#                 in_order=True)\n+# endregion\n+\n+@mpc.run_multiprocess(world_size=3)\n+def L_Sigmoid(x, min_value, max_value):\n+    x_share = crypten.cryptensor(x, ptype = crypten.mpc.arithmetic)\n+    min_value_share = crypten.cryptensor(min_value, ptype = crypten.mpc.arithmetic)\n+    one_share = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n+    one_share_again = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n+    \n+    # part 1\n+    cmp_result_1 = x_share > min_value_share\n+    result_1 = cmp_result_1.to(crypten.mpc.arithmetic)\n+    \n+    # result 2\n+    temp = -x_share - one_share\n+    relu_result = temp.relu()\n+    result_2 = one_share_again  - rel\n+    \n+\n+def main():\n+    x = generate_random()\n+    # y = generate_random()\n+    print(\"x\", x)\n+    # print(\"y\", y)\n+    L_Sigmoid(x, -1, 2)\n+\n+main()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1721141855484,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -147,172 +147,13 @@\n     \n     # result 2\n     temp = -x_share - one_share\n     relu_result = temp.relu()\n-    result_2 = one_share_again  - rel\n+    result_2 = one_share  - relu_result\n     \n-\n-def main():\n-    x = generate_random()\n-    # y = generate_random()\n-    print(\"x\", x)\n-    # print(\"y\", y)\n-    L_Sigmoid(x, -1, 2)\n-\n-main()\n-\n-import crypten\n-import crypten.mpc\n-import torch\n-import crypten.mpc as mpc\n-import crypten.mpc.primitives.beaver as beaver\n-import crypten.communicator as comm \n-import torch\n-from crypten.mpc import MPCTensor\n-from crypten.mpc.primitives import BinarySharedTensor\n-import time\n-import random\n-import crypten.common.functions\n-\n-crypten.init()\n-\n-\n-# region \n-# DATASET_DIR = os.path.join(os.path.dirname(__file__), 'dataset')\n-\n-# class DataSetParam:\n-#     def __init__(self, dataset_name):\n-#         self.dataset_name = dataset_name\n-\n-\n-# class DataSet:\n-#     sonar = DataSetParam('sonar.csv')\n-#     sonar_selected = DataSetParam('sonar_selected.csv')\n     \n     \n-    \n-# def load_dataset(dataset):\n-#     dataset_path = os.path.join(DATASET_DIR, dataset)\n \n-#     # 尝试打开并读取CSV文件\n-#     try:\n-#         with open(dataset_path, 'r', encoding='utf-8') as csvfile:\n-#             spamreader = csv.reader(csvfile)\n-#             data = np.array(list(spamreader))\n-#     except FileNotFoundError:\n-#         print(f\"Error: The file {dataset_path} was not found.\")\n-#         return None, None\n-#     except Exception as e:\n-#         print(f\"Error: An error occurred while reading the file: {e}\")\n-#         return None, None\n-\n-#     # 检查数据是否为空\n-#     if data.size == 0:\n-#         print(\"Error: The dataset is empty.\")\n-#         return None, None\n-\n-#     feature = data[:, :-1].astype(np.float64)\n-#     labels = data[:, -1]\n-\n-#     # 创建标签映射\n-#     unique_labels = np.unique(labels)\n-#     label_to_int = {label: idx for idx, label in enumerate(unique_labels)}\n-#     int_labels = np.array([label_to_int[label] for label in labels], dtype=np.uint8)\n-#     labell = int_labels.reshape(-1,1)\n-\n-#     # 将标签转换为独热矩阵\n-#     one_hot_labels = np.zeros((int_labels.size, int_labels.max() + 1), dtype=np.uint8)\n-#     one_hot_labels[np.arange(int_labels.size), int_labels] = 1\n-\n-#     # print(\"======feature_size=====\", feature.shape)\n-#     print(\"======label_size=====\", one_hot_labels)\n-#     return feature, one_hot_labels\n-\n-# data_train = DataSet.sonar\n-\n-# load_dataset(data_train.dataset_name)\n-# endregion\n-\n-\n-def generate_random():\n-    random_tensor = random.uniform(-2, 1)\n-    return random_tensor\n-\n-# region \n-# @mpc.run_multiprocess(world_size=2)\n-# def test(x,y):\n-    # x_enc = crypten.cryptensor(x, ptype=crypten.mpc.arithmetic)\n-    # y_enc = crypten.cryptensor(y, ptype=crypten.mpc.arithmetic)\n-    # ge_time_begin = time.time()\n-    # ge_  = x_enc.ge(y_enc)\n-    # ge_time_end = time.time()\n-    # ge_time = ge_time_end - ge_time_begin\n-    # print(\"ge_time\", ge_time)\n-    \n-    # gt_time_begin = time.time()\n-    # gt_  = x_enc.gt(y_enc)\n-    # gt_time_end = time.time()\n-    # gt_time = gt_time_end - gt_time_begin\n-    # print(\"gt_time\", gt_time)\n-    \n-    # relu_time_begin = time.time()\n-    # relu_ = ge_.relu()\n-    # relu_time_end = time.time()\n-    # relu_time = relu_time_end - relu_time_begin\n-    # print(\"relu_time\", relu_time)\n-# endregion\n-\n-# region \n-# @mpc.run_multiprocess(world_size=3)\n-# def L_Sigmoid(x, min_value, max_value):\n-#     x_share = crypten.cryptensor(x, ptype = crypten.mpc.arithmetic)\n-#     min_value_share = crypten.cryptensor(min_value, ptype = crypten.mpc.arithmetic)\n-#     one_share = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n-    \n-#     begin_time = time.time()\n-#     # part 1\n-#     cmp_result_1 = x_share > min_value_share\n-#     result_1 = cmp_result_1.to(crypten.mpc.arithmetic)\n-    \n-#     # part 2    \n-#     x_minus_one = x_share + min_value_share\n-#     cmp_result_2 = x_minus_one < 0\n-#     mulplex_result = crypten.where(cmp_result_2, x_minus_one, 0)\n-#     result_2 = mulplex_result + one_share\n-    \n-#     L_sigmod_result = result_1 * result_2\n-    \n-#     end_time = time.time()\n-#     L_time = end_time - begin_time\n-    \n-#     rank = comm.get().get_rank()\n-#     crypten.print(f\"\\nRank {rank}:\\n cmp_result_1: {cmp_result_1.get_plain_text()}\\n\" \\\n-#                 f\" cmp_result_2: {cmp_result_2.get_plain_text()}\\n\" \\\n-#                 f\" mulplex_result: {mulplex_result.get_plain_text()}\\n\" \\\n-#                 f\" result_1:{result_1.get_plain_text()}\\n\",\\\n-#                 f\" result_2:{result_2.get_plain_text()}\\n\",\\\n-#                 f\" L_sigmod_result:{L_sigmod_result.get_plain_text()}\\n\",\\\n-#                 f\" L_time:{L_time}\\n\",\n-#                 in_order=True)\n-# endregion\n-\n-@mpc.run_multiprocess(world_size=3)\n-def L_Sigmoid(x, min_value, max_value):\n-    x_share = crypten.cryptensor(x, ptype = crypten.mpc.arithmetic)\n-    min_value_share = crypten.cryptensor(min_value, ptype = crypten.mpc.arithmetic)\n-    one_share = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n-    one_share_again = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n-    \n-    # part 1\n-    cmp_result_1 = x_share > min_value_share\n-    result_1 = cmp_result_1.to(crypten.mpc.arithmetic)\n-    \n-    # result 2\n-    temp = -x_share - one_share\n-    relu_result = temp.relu()\n-    result_2 = one_share_again  - \n-    \n-\n def main():\n     x = generate_random()\n     # y = generate_random()\n     print(\"x\", x)\n"
                },
                {
                    "date": 1721141863485,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -137,11 +137,12 @@\n @mpc.run_multiprocess(world_size=3)\n def L_Sigmoid(x, min_value, max_value):\n     x_share = crypten.cryptensor(x, ptype = crypten.mpc.arithmetic)\n     min_value_share = crypten.cryptensor(min_value, ptype = crypten.mpc.arithmetic)\n+    max_v_again = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n     one_share = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n-    one_share_again = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n     \n+    \n     # part 1\n     cmp_result_1 = x_share > min_value_share\n     result_1 = cmp_result_1.to(crypten.mpc.arithmetic)\n     \n"
                },
                {
                    "date": 1721141871677,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -137,9 +137,9 @@\n @mpc.run_multiprocess(world_size=3)\n def L_Sigmoid(x, min_value, max_value):\n     x_share = crypten.cryptensor(x, ptype = crypten.mpc.arithmetic)\n     min_value_share = crypten.cryptensor(min_value, ptype = crypten.mpc.arithmetic)\n-    max_v_again = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n+    max_value_share = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n     one_share = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n     \n     \n     # part 1\n"
                },
                {
                    "date": 1721141877624,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -137,9 +137,9 @@\n @mpc.run_multiprocess(world_size=3)\n def L_Sigmoid(x, min_value, max_value):\n     x_share = crypten.cryptensor(x, ptype = crypten.mpc.arithmetic)\n     min_value_share = crypten.cryptensor(min_value, ptype = crypten.mpc.arithmetic)\n-    max_value_share = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n+    max_value_share = crypten.cryptensor(max_value, ptype = crypten.mpc.arithmetic)\n     one_share = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n     \n     \n     # part 1\n"
                },
                {
                    "date": 1721141924193,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -133,24 +133,24 @@\n #                 f\" L_time:{L_time}\\n\",\n #                 in_order=True)\n # endregion\n \n-@mpc.run_multiprocess(world_size=3)\n-def L_Sigmoid(x, min_value, max_value):\n-    x_share = crypten.cryptensor(x, ptype = crypten.mpc.arithmetic)\n-    min_value_share = crypten.cryptensor(min_value, ptype = crypten.mpc.arithmetic)\n-    max_value_share = crypten.cryptensor(max_value, ptype = crypten.mpc.arithmetic)\n-    one_share = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n+# @mpc.run_multiprocess(world_size=3)\n+# def L_Sigmoid(x, min_value, max_value):\n+#     x_share = crypten.cryptensor(x, ptype = crypten.mpc.arithmetic)\n+#     min_value_share = crypten.cryptensor(min_value, ptype = crypten.mpc.arithmetic)\n+#     max_value_share = crypten.cryptensor(max_value, ptype = crypten.mpc.arithmetic)\n+#     one_share = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n     \n     \n-    # part 1\n-    cmp_result_1 = x_share > min_value_share\n-    result_1 = cmp_result_1.to(crypten.mpc.arithmetic)\n+#     # part 1\n+#     cmp_result_1 = x_share > min_value_share\n+#     result_1 = cmp_result_1.to(crypten.mpc.arithmetic)\n     \n-    # result 2\n-    temp = -x_share - one_share\n-    relu_result = temp.relu()\n-    result_2 = one_share  - relu_result\n+#     # result 2\n+#     temp = -x_share - one_share\n+#     relu_result = temp.relu()\n+#     result_2 = one_share  - relu_result\n     \n     \n     \n \n"
                },
                {
                    "date": 1721141935539,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -100,39 +100,40 @@\n     # print(\"relu_time\", relu_time)\n # endregion\n \n # region \n-# @mpc.run_multiprocess(world_size=3)\n-# def L_Sigmoid(x, min_value, max_value):\n-#     x_share = crypten.cryptensor(x, ptype = crypten.mpc.arithmetic)\n-#     min_value_share = crypten.cryptensor(min_value, ptype = crypten.mpc.arithmetic)\n-#     one_share = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n+@mpc.run_multiprocess(world_size=3)\n+def L_Sigmoid(x, min_value, max_value):\n+    x_share = crypten.cryptensor(x, ptype = crypten.mpc.arithmetic)\n+    min_value_share = crypten.cryptensor(min_value, ptype = crypten.mpc.arithmetic)\n+    min_value_share = crypten.cryptensor(min_value, ptype = crypten.mpc.arithmetic)\n+    one_share = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n     \n-#     begin_time = time.time()\n-#     # part 1\n-#     cmp_result_1 = x_share > min_value_share\n-#     result_1 = cmp_result_1.to(crypten.mpc.arithmetic)\n+    begin_time = time.time()\n+    # part 1\n+    cmp_result_1 = x_share > min_value_share\n+    result_1 = cmp_result_1.to(crypten.mpc.arithmetic)\n     \n-#     # part 2    \n-#     x_minus_one = x_share + min_value_share\n-#     cmp_result_2 = x_minus_one < 0\n-#     mulplex_result = crypten.where(cmp_result_2, x_minus_one, 0)\n-#     result_2 = mulplex_result + one_share\n+    # part 2    \n+    x_minus_one = x_share + min_value_share\n+    cmp_result_2 = x_minus_one < 0\n+    mulplex_result = crypten.where(cmp_result_2, x_minus_one, 0)\n+    result_2 = mulplex_result + one_share\n     \n-#     L_sigmod_result = result_1 * result_2\n+    L_sigmod_result = result_1 * result_2\n     \n-#     end_time = time.time()\n-#     L_time = end_time - begin_time\n+    end_time = time.time()\n+    L_time = end_time - begin_time\n     \n-#     rank = comm.get().get_rank()\n-#     crypten.print(f\"\\nRank {rank}:\\n cmp_result_1: {cmp_result_1.get_plain_text()}\\n\" \\\n-#                 f\" cmp_result_2: {cmp_result_2.get_plain_text()}\\n\" \\\n-#                 f\" mulplex_result: {mulplex_result.get_plain_text()}\\n\" \\\n-#                 f\" result_1:{result_1.get_plain_text()}\\n\",\\\n-#                 f\" result_2:{result_2.get_plain_text()}\\n\",\\\n-#                 f\" L_sigmod_result:{L_sigmod_result.get_plain_text()}\\n\",\\\n-#                 f\" L_time:{L_time}\\n\",\n-#                 in_order=True)\n+    rank = comm.get().get_rank()\n+    crypten.print(f\"\\nRank {rank}:\\n cmp_result_1: {cmp_result_1.get_plain_text()}\\n\" \\\n+                f\" cmp_result_2: {cmp_result_2.get_plain_text()}\\n\" \\\n+                f\" mulplex_result: {mulplex_result.get_plain_text()}\\n\" \\\n+                f\" result_1:{result_1.get_plain_text()}\\n\",\\\n+                f\" result_2:{result_2.get_plain_text()}\\n\",\\\n+                f\" L_sigmod_result:{L_sigmod_result.get_plain_text()}\\n\",\\\n+                f\" L_time:{L_time}\\n\",\n+                in_order=True)\n # endregion\n \n # @mpc.run_multiprocess(world_size=3)\n # def L_Sigmoid(x, min_value, max_value):\n"
                },
                {
                    "date": 1721141949383,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -104,9 +104,9 @@\n @mpc.run_multiprocess(world_size=3)\n def L_Sigmoid(x, min_value, max_value):\n     x_share = crypten.cryptensor(x, ptype = crypten.mpc.arithmetic)\n     min_value_share = crypten.cryptensor(min_value, ptype = crypten.mpc.arithmetic)\n-    min_value_share = crypten.cryptensor(min_value, ptype = crypten.mpc.arithmetic)\n+    max_value_share = crypten.cryptensor(min_value, ptype = crypten.mpc.arithmetic)\n     one_share = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n     \n     begin_time = time.time()\n     # part 1\n"
                },
                {
                    "date": 1721141958657,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -104,18 +104,18 @@\n @mpc.run_multiprocess(world_size=3)\n def L_Sigmoid(x, min_value, max_value):\n     x_share = crypten.cryptensor(x, ptype = crypten.mpc.arithmetic)\n     min_value_share = crypten.cryptensor(min_value, ptype = crypten.mpc.arithmetic)\n-    max_value_share = crypten.cryptensor(min_value, ptype = crypten.mpc.arithmetic)\n+    max_value_share = crypten.cryptensor(max_value, ptype = crypten.mpc.arithmetic)\n     one_share = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n     \n     begin_time = time.time()\n     # part 1\n     cmp_result_1 = x_share > min_value_share\n     result_1 = cmp_result_1.to(crypten.mpc.arithmetic)\n     \n     # part 2    \n-    x_minus_one = x_share + min_value_share\n+    x_minus_one = x_share - min_value_share\n     cmp_result_2 = x_minus_one < 0\n     mulplex_result = crypten.where(cmp_result_2, x_minus_one, 0)\n     result_2 = mulplex_result + one_share\n     \n"
                },
                {
                    "date": 1721141977897,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -113,9 +113,9 @@\n     cmp_result_1 = x_share > min_value_share\n     result_1 = cmp_result_1.to(crypten.mpc.arithmetic)\n     \n     # part 2    \n-    x_minus_one = x_share - min_value_share\n+    x_minus_max = x_share - max_value_share\n     cmp_result_2 = x_minus_one < 0\n     mulplex_result = crypten.where(cmp_result_2, x_minus_one, 0)\n     result_2 = mulplex_result + one_share\n     \n"
                },
                {
                    "date": 1721141985189,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -114,10 +114,10 @@\n     result_1 = cmp_result_1.to(crypten.mpc.arithmetic)\n     \n     # part 2    \n     x_minus_max = x_share - max_value_share\n-    cmp_result_2 = x_minus_one < 0\n-    mulplex_result = crypten.where(cmp_result_2, x_minus_one, 0)\n+    cmp_result_2 = x_minus_max < 0\n+    mulplex_result = crypten.where(cmp_result_2, x_minus_ma, 0)\n     result_2 = mulplex_result + one_share\n     \n     L_sigmod_result = result_1 * result_2\n     \n"
                },
                {
                    "date": 1721142000968,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -115,9 +115,9 @@\n     \n     # part 2    \n     x_minus_max = x_share - max_value_share\n     cmp_result_2 = x_minus_max < 0\n-    mulplex_result = crypten.where(cmp_result_2, x_minus_ma, 0)\n+    mulplex_result = crypten.where(cmp_result_2, x_minus_max, 0)\n     result_2 = mulplex_result + one_share\n     \n     L_sigmod_result = result_1 * result_2\n     \n@@ -130,9 +130,9 @@\n                 f\" mulplex_result: {mulplex_result.get_plain_text()}\\n\" \\\n                 f\" result_1:{result_1.get_plain_text()}\\n\",\\\n                 f\" result_2:{result_2.get_plain_text()}\\n\",\\\n                 f\" L_sigmod_result:{L_sigmod_result.get_plain_text()}\\n\",\\\n-                f\" L_time:{L_time}\\n\",\n+                # f\" L_time:{L_time}\\n\",\n                 in_order=True)\n # endregion\n \n # @mpc.run_multiprocess(world_size=3)\n"
                },
                {
                    "date": 1721142019555,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -117,8 +117,9 @@\n     x_minus_max = x_share - max_value_share\n     cmp_result_2 = x_minus_max < 0\n     mulplex_result = crypten.where(cmp_result_2, x_minus_max, 0)\n     result_2 = mulplex_result + one_share\n+    result_2 = mulplex_result + one_share\n     \n     L_sigmod_result = result_1 * result_2\n     \n     end_time = time.time()\n@@ -129,9 +130,9 @@\n                 f\" cmp_result_2: {cmp_result_2.get_plain_text()}\\n\" \\\n                 f\" mulplex_result: {mulplex_result.get_plain_text()}\\n\" \\\n                 f\" result_1:{result_1.get_plain_text()}\\n\",\\\n                 f\" result_2:{result_2.get_plain_text()}\\n\",\\\n-                f\" L_sigmod_result:{L_sigmod_result.get_plain_text()}\\n\",\\\n+                f\" L_sigmod_result:{L_sigmod_result.get_plain_text()}\\n\",\n                 # f\" L_time:{L_time}\\n\",\n                 in_order=True)\n # endregion\n \n"
                },
                {
                    "date": 1721142856636,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -100,41 +100,9 @@\n     # print(\"relu_time\", relu_time)\n # endregion\n \n # region \n-@mpc.run_multiprocess(world_size=3)\n-def L_Sigmoid(x, min_value, max_value):\n-    x_share = crypten.cryptensor(x, ptype = crypten.mpc.arithmetic)\n-    min_value_share = crypten.cryptensor(min_value, ptype = crypten.mpc.arithmetic)\n-    max_value_share = crypten.cryptensor(max_value, ptype = crypten.mpc.arithmetic)\n-    one_share = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n-    \n-    begin_time = time.time()\n-    # part 1\n-    cmp_result_1 = x_share > min_value_share\n-    result_1 = cmp_result_1.to(crypten.mpc.arithmetic)\n-    \n-    # part 2    \n-    x_minus_max = x_share - max_value_share\n-    cmp_result_2 = x_minus_max < 0\n-    mulplex_result = crypten.where(cmp_result_2, x_minus_max, 0)\n-    result_2 = mulplex_result + one_share\n-    result_2 = mulplex_result + one_share\n-    \n-    L_sigmod_result = result_1 * result_2\n-    \n-    end_time = time.time()\n-    L_time = end_time - begin_time\n-    \n-    rank = comm.get().get_rank()\n-    crypten.print(f\"\\nRank {rank}:\\n cmp_result_1: {cmp_result_1.get_plain_text()}\\n\" \\\n-                f\" cmp_result_2: {cmp_result_2.get_plain_text()}\\n\" \\\n-                f\" mulplex_result: {mulplex_result.get_plain_text()}\\n\" \\\n-                f\" result_1:{result_1.get_plain_text()}\\n\",\\\n-                f\" result_2:{result_2.get_plain_text()}\\n\",\\\n-                f\" L_sigmod_result:{L_sigmod_result.get_plain_text()}\\n\",\n-                # f\" L_time:{L_time}\\n\",\n-                in_order=True)\n+/\n # endregion\n \n # @mpc.run_multiprocess(world_size=3)\n # def L_Sigmoid(x, min_value, max_value):\n"
                },
                {
                    "date": 1721142863517,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -100,31 +100,62 @@\n     # print(\"relu_time\", relu_time)\n # endregion\n \n # region \n-/\n-# endregion\n-\n # @mpc.run_multiprocess(world_size=3)\n # def L_Sigmoid(x, min_value, max_value):\n #     x_share = crypten.cryptensor(x, ptype = crypten.mpc.arithmetic)\n #     min_value_share = crypten.cryptensor(min_value, ptype = crypten.mpc.arithmetic)\n #     max_value_share = crypten.cryptensor(max_value, ptype = crypten.mpc.arithmetic)\n #     one_share = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n     \n-    \n+#     begin_time = time.time()\n #     # part 1\n #     cmp_result_1 = x_share > min_value_share\n #     result_1 = cmp_result_1.to(crypten.mpc.arithmetic)\n     \n-#     # result 2\n-#     temp = -x_share - one_share\n-#     relu_result = temp.relu()\n-#     result_2 = one_share  - relu_result\n+#     # part 2    \n+#     x_minus_max = x_share - max_value_share\n+#     cmp_result_2 = x_minus_max < 0\n+#     mulplex_result = crypten.where(cmp_result_2, x_minus_max, 0)\n+#     result_2 = mulplex_result + one_share\n     \n+#     L_sigmod_result = result_1 * result_2\n     \n+#     end_time = time.time()\n+#     L_time = end_time - begin_time\n     \n+#     rank = comm.get().get_rank()\n+#     crypten.print(f\"\\nRank {rank}:\\n cmp_result_1: {cmp_result_1.get_plain_text()}\\n\" \\\n+#                 f\" cmp_result_2: {cmp_result_2.get_plain_text()}\\n\" \\\n+#                 f\" mulplex_result: {mulplex_result.get_plain_text()}\\n\" \\\n+#                 f\" result_1:{result_1.get_plain_text()}\\n\",\\\n+#                 f\" result_2:{result_2.get_plain_text()}\\n\",\\\n+#                 f\" L_sigmod_result:{L_sigmod_result.get_plain_text()}\\n\",\n+#                 # f\" L_time:{L_time}\\n\",\n+#                 in_order=True)\n+# endregion\n \n+@mpc.run_multiprocess(world_size=3)\n+def L_Sigmoid(x, min_value, max_value):\n+    x_share = crypten.cryptensor(x, ptype = crypten.mpc.arithmetic)\n+    min_value_share = crypten.cryptensor(min_value, ptype = crypten.mpc.arithmetic)\n+    max_value_share = crypten.cryptensor(max_value, ptype = crypten.mpc.arithmetic)\n+    one_share = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n+    \n+    \n+    # part 1\n+    cmp_result_1 = x_share > min_value_share\n+    result_1 = cmp_result_1.to(crypten.mpc.arithmetic)\n+    \n+    # result 2\n+    temp = -x_share - one_share\n+    relu_result = temp.relu()\n+    result_2 = one_share  - relu_result\n+    \n+    \n+    \n+\n def main():\n     x = generate_random()\n     # y = generate_random()\n     print(\"x\", x)\n"
                },
                {
                    "date": 1721142913611,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -147,9 +147,9 @@\n     cmp_result_1 = x_share > min_value_share\n     result_1 = cmp_result_1.to(crypten.mpc.arithmetic)\n     \n     # result 2\n-    temp = -x_share - one_share\n+    temp = -x_share - max_value_share\n     relu_result = temp.relu()\n     result_2 = one_share  - relu_result\n     \n     \n"
                },
                {
                    "date": 1721142954025,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -147,14 +147,16 @@\n     cmp_result_1 = x_share > min_value_share\n     result_1 = cmp_result_1.to(crypten.mpc.arithmetic)\n     \n     # result 2\n-    temp = -x_share - max_value_share\n+    temp = - x_share - max_value_share\n     relu_result = temp.relu()\n     result_2 = one_share  - relu_result\n     \n+    L-sig\n     \n     \n+    \n \n def main():\n     x = generate_random()\n     # y = generate_random()\n"
                },
                {
                    "date": 1721142964247,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -151,9 +151,9 @@\n     temp = - x_share - max_value_share\n     relu_result = temp.relu()\n     result_2 = one_share  - relu_result\n     \n-    L-sig\n+    L-Sigmod \n     \n     \n     \n \n"
                },
                {
                    "date": 1721142971108,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -151,9 +151,9 @@\n     temp = - x_share - max_value_share\n     relu_result = temp.relu()\n     result_2 = one_share  - relu_result\n     \n-    L-Sigmod \n+    L-Sigmod = result_1 * re\n     \n     \n     \n \n"
                },
                {
                    "date": 1721142976847,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -151,12 +151,13 @@\n     temp = - x_share - max_value_share\n     relu_result = temp.relu()\n     result_2 = one_share  - relu_result\n     \n-    L-Sigmod = result_1 * re\n+    L_Sigmod = result_1 * result_2\n     \n     \n     \n+    \n \n def main():\n     x = generate_random()\n     # y = generate_random()\n"
                },
                {
                    "date": 1721142990811,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -152,8 +152,17 @@\n     relu_result = temp.relu()\n     result_2 = one_share  - relu_result\n     \n     L_Sigmod = result_1 * result_2\n+    rank = comm.get().get_rank()\n+#     crypten.print(f\"\\nRank {rank}:\\n cmp_result_1: {cmp_result_1.get_plain_text()}\\n\" \\\n+#                 f\" cmp_result_2: {cmp_result_2.get_plain_text()}\\n\" \\\n+#                 f\" mulplex_result: {mulplex_result.get_plain_text()}\\n\" \\\n+#                 f\" result_1:{result_1.get_plain_text()}\\n\",\\\n+#                 f\" result_2:{result_2.get_plain_text()}\\n\",\\\n+#                 f\" L_sigmod_result:{L_sigmod_result.get_plain_text()}\\n\",\n+#                 # f\" L_time:{L_time}\\n\",\n+#                 in_order=True)\n     \n     \n     \n     \n"
                },
                {
                    "date": 1721142999291,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -153,16 +153,14 @@\n     result_2 = one_share  - relu_result\n     \n     L_Sigmod = result_1 * result_2\n     rank = comm.get().get_rank()\n-#     crypten.print(f\"\\nRank {rank}:\\n cmp_result_1: {cmp_result_1.get_plain_text()}\\n\" \\\n-#                 f\" cmp_result_2: {cmp_result_2.get_plain_text()}\\n\" \\\n-#                 f\" mulplex_result: {mulplex_result.get_plain_text()}\\n\" \\\n-#                 f\" result_1:{result_1.get_plain_text()}\\n\",\\\n-#                 f\" result_2:{result_2.get_plain_text()}\\n\",\\\n-#                 f\" L_sigmod_result:{L_sigmod_result.get_plain_text()}\\n\",\n-#                 # f\" L_time:{L_time}\\n\",\n-#                 in_order=True)\n+    crypten.print(f\"\\nRank {rank}:\\n cmp_result_1: {cmp_result_1.get_plain_text()}\\n\" \\\n+                f\" result_1:{result_1.get_plain_text()}\\n\",\\\n+                f\" result_2:{result_2.get_plain_text()}\\n\",\\\n+                f\" L_sigmod_result:{L_sigmod_result.get_plain_text()}\\n\",\n+                # f\" L_time:{L_time}\\n\",\n+                in_order=True)\n     \n     \n     \n     \n"
                },
                {
                    "date": 1721143030207,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -156,9 +156,9 @@\n     rank = comm.get().get_rank()\n     crypten.print(f\"\\nRank {rank}:\\n cmp_result_1: {cmp_result_1.get_plain_text()}\\n\" \\\n                 f\" result_1:{result_1.get_plain_text()}\\n\",\\\n                 f\" result_2:{result_2.get_plain_text()}\\n\",\\\n-                f\" L_sigmod_result:{L_sigmod_result.get_plain_text()}\\n\",\n+                f\" L_sigmod_result:{L_Sigmod.get_plain_text()}\\n\",\n                 # f\" L_time:{L_time}\\n\",\n                 in_order=True)\n     \n     \n"
                },
                {
                    "date": 1721143042274,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -72,9 +72,9 @@\n # endregion\n \n \n def generate_random():\n-    random_tensor = random.uniform(-2, 1)\n+    random_tensor = random.uniform(-2, 2)\n     return random_tensor\n \n # region \n # @mpc.run_multiprocess(world_size=2)\n"
                },
                {
                    "date": 1721143165102,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -153,9 +153,9 @@\n     result_2 = one_share  - relu_result\n     \n     L_Sigmod = result_1 * result_2\n     rank = comm.get().get_rank()\n-    crypten.print(f\"\\nRank {rank}:\\n cmp_result_1: {cmp_result_1.get_plain_text()}\\n\" \\\n+    crypten.print(f\"\\nRank {rank}:\\n cmp_result_1: {relu_result.get_plain_text()}\\n\" \\\n                 f\" result_1:{result_1.get_plain_text()}\\n\",\\\n                 f\" result_2:{result_2.get_plain_text()}\\n\",\\\n                 f\" L_sigmod_result:{L_Sigmod.get_plain_text()}\\n\",\n                 # f\" L_time:{L_time}\\n\",\n"
                },
                {
                    "date": 1721143173180,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -153,9 +153,9 @@\n     result_2 = one_share  - relu_result\n     \n     L_Sigmod = result_1 * result_2\n     rank = comm.get().get_rank()\n-    crypten.print(f\"\\nRank {rank}:\\n cmp_result_1: {relu_result.get_plain_text()}\\n\" \\\n+    crypten.print(f\"\\nRank {rank}:\\n relu_result: {relu_result.get_plain_text()}\\n\" \\\n                 f\" result_1:{result_1.get_plain_text()}\\n\",\\\n                 f\" result_2:{result_2.get_plain_text()}\\n\",\\\n                 f\" L_sigmod_result:{L_Sigmod.get_plain_text()}\\n\",\n                 # f\" L_time:{L_time}\\n\",\n"
                },
                {
                    "date": 1721143414982,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -134,33 +134,33 @@\n #                 # f\" L_time:{L_time}\\n\",\n #                 in_order=True)\n # endregion\n \n-@mpc.run_multiprocess(world_size=3)\n-def L_Sigmoid(x, min_value, max_value):\n-    x_share = crypten.cryptensor(x, ptype = crypten.mpc.arithmetic)\n-    min_value_share = crypten.cryptensor(min_value, ptype = crypten.mpc.arithmetic)\n-    max_value_share = crypten.cryptensor(max_value, ptype = crypten.mpc.arithmetic)\n-    one_share = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n+# @mpc.run_multiprocess(world_size=3)\n+# def L_Sigmoid(x, min_value, max_value):\n+#     x_share = crypten.cryptensor(x, ptype = crypten.mpc.arithmetic)\n+#     min_value_share = crypten.cryptensor(min_value, ptype = crypten.mpc.arithmetic)\n+#     max_value_share = crypten.cryptensor(max_value, ptype = crypten.mpc.arithmetic)\n+#     one_share = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n     \n     \n-    # part 1\n-    cmp_result_1 = x_share > min_value_share\n-    result_1 = cmp_result_1.to(crypten.mpc.arithmetic)\n+#     # part 1\n+#     cmp_result_1 = x_share > min_value_share\n+#     result_1 = cmp_result_1.to(crypten.mpc.arithmetic)\n     \n-    # result 2\n-    temp = - x_share - max_value_share\n-    relu_result = temp.relu()\n-    result_2 = one_share  - relu_result\n+#     # result 2\n+#     temp = - x_share - max_value_share\n+#     relu_result = temp.relu()\n+#     result_2 = one_share  - relu_result\n     \n-    L_Sigmod = result_1 * result_2\n-    rank = comm.get().get_rank()\n-    crypten.print(f\"\\nRank {rank}:\\n relu_result: {relu_result.get_plain_text()}\\n\" \\\n-                f\" result_1:{result_1.get_plain_text()}\\n\",\\\n-                f\" result_2:{result_2.get_plain_text()}\\n\",\\\n-                f\" L_sigmod_result:{L_Sigmod.get_plain_text()}\\n\",\n-                # f\" L_time:{L_time}\\n\",\n-                in_order=True)\n+#     L_Sigmod = result_1 * result_2\n+#     rank = comm.get().get_rank()\n+#     crypten.print(f\"\\nRank {rank}:\\n relu_result: {relu_result.get_plain_text()}\\n\" \\\n+#                 f\" result_1:{result_1.get_plain_text()}\\n\",\\\n+#                 f\" result_2:{result_2.get_plain_text()}\\n\",\\\n+#                 f\" L_sigmod_result:{L_Sigmod.get_plain_text()}\\n\",\n+#                 # f\" L_time:{L_time}\\n\",\n+#                 in_order=True)\n     \n     \n     \n     \n"
                },
                {
                    "date": 1721143424139,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -160,11 +160,13 @@\n #                 f\" L_sigmod_result:{L_Sigmod.get_plain_text()}\\n\",\n #                 # f\" L_time:{L_time}\\n\",\n #                 in_order=True)\n     \n+ # @mpc.run_multiprocess(world_size=3)\n+# def L_Sigmoid(x, min_value, max_value):\n+#     x_share = crypten.cryptensor(x, ptype = crypten.mpc.arithmetic)\n     \n     \n-    \n \n def main():\n     x = generate_random()\n     # y = generate_random()\n"
                },
                {
                    "date": 1721143469662,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -160,13 +160,14 @@\n #                 f\" L_sigmod_result:{L_Sigmod.get_plain_text()}\\n\",\n #                 # f\" L_time:{L_time}\\n\",\n #                 in_order=True)\n     \n- # @mpc.run_multiprocess(world_size=3)\n-# def L_Sigmoid(x, min_value, max_value):\n-#     x_share = crypten.cryptensor(x, ptype = crypten.mpc.arithmetic)\n+@mpc.run_multiprocess(world_size=3)\n+def L_Sigmoid(x, min_value, max_value):\n+    x_share = crypten.cryptensor(x, ptype = crypten.mpc.arithmetic)\n+    rank = comm.get().get_rank()\n+    crypten.\n     \n-    \n \n def main():\n     x = generate_random()\n     # y = generate_random()\n"
                },
                {
                    "date": 1721143482162,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -164,9 +164,9 @@\n @mpc.run_multiprocess(world_size=3)\n def L_Sigmoid(x, min_value, max_value):\n     x_share = crypten.cryptensor(x, ptype = crypten.mpc.arithmetic)\n     rank = comm.get().get_rank()\n-    crypten.\n+    crypten.print(f\"\\nRank {rank}:\\n relu_result: {relu_result.get_plain_text()}\\n\", )\n     \n \n def main():\n     x = generate_random()\n"
                },
                {
                    "date": 1721143490113,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -163,10 +163,11 @@\n     \n @mpc.run_multiprocess(world_size=3)\n def L_Sigmoid(x, min_value, max_value):\n     x_share = crypten.cryptensor(x, ptype = crypten.mpc.arithmetic)\n+    x\n     rank = comm.get().get_rank()\n-    crypten.print(f\"\\nRank {rank}:\\n relu_result: {relu_result.get_plain_text()}\\n\", )\n+    crypten.print(f\"\\nRank {rank}:\\n relu_result: {relu_result.get_plain_text()}\\n\", in_order=True)\n     \n \n def main():\n     x = generate_random()\n"
                },
                {
                    "date": 1721143495957,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -163,9 +163,9 @@\n     \n @mpc.run_multiprocess(world_size=3)\n def L_Sigmoid(x, min_value, max_value):\n     x_share = crypten.cryptensor(x, ptype = crypten.mpc.arithmetic)\n-    x\n+    y = \n     rank = comm.get().get_rank()\n     crypten.print(f\"\\nRank {rank}:\\n relu_result: {relu_result.get_plain_text()}\\n\", in_order=True)\n     \n \n"
                },
                {
                    "date": 1721143505227,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -163,11 +163,11 @@\n     \n @mpc.run_multiprocess(world_size=3)\n def L_Sigmoid(x, min_value, max_value):\n     x_share = crypten.cryptensor(x, ptype = crypten.mpc.arithmetic)\n-    y = \n+    y = -x_share \n     rank = comm.get().get_rank()\n-    crypten.print(f\"\\nRank {rank}:\\n relu_result: {relu_result.get_plain_text()}\\n\", in_order=True)\n+    crypten.print(f\"\\nRank {rank}:\\n relu_result: {.get_plain_text()}\\n\", in_order=True)\n     \n \n def main():\n     x = generate_random()\n"
                },
                {
                    "date": 1721143514913,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -165,9 +165,9 @@\n def L_Sigmoid(x, min_value, max_value):\n     x_share = crypten.cryptensor(x, ptype = crypten.mpc.arithmetic)\n     y = -x_share \n     rank = comm.get().get_rank()\n-    crypten.print(f\"\\nRank {rank}:\\n relu_result: {.get_plain_text()}\\n\", in_order=True)\n+    crypten.print(f\"\\nRank {rank}:\\n y: {y.get_plain_text()}\\n\", in_order=True)\n     \n \n def main():\n     x = generate_random()\n"
                },
                {
                    "date": 1721143532943,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -159,16 +159,10 @@\n #                 f\" result_2:{result_2.get_plain_text()}\\n\",\\\n #                 f\" L_sigmod_result:{L_Sigmod.get_plain_text()}\\n\",\n #                 # f\" L_time:{L_time}\\n\",\n #                 in_order=True)\n+\n     \n-@mpc.run_multiprocess(world_size=3)\n-def L_Sigmoid(x, min_value, max_value):\n-    x_share = crypten.cryptensor(x, ptype = crypten.mpc.arithmetic)\n-    y = -x_share \n-    rank = comm.get().get_rank()\n-    crypten.print(f\"\\nRank {rank}:\\n y: {y.get_plain_text()}\\n\", in_order=True)\n-    \n \n def main():\n     x = generate_random()\n     # y = generate_random()\n"
                },
                {
                    "date": 1721227778668,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -134,33 +134,33 @@\n #                 # f\" L_time:{L_time}\\n\",\n #                 in_order=True)\n # endregion\n \n-# @mpc.run_multiprocess(world_size=3)\n-# def L_Sigmoid(x, min_value, max_value):\n-#     x_share = crypten.cryptensor(x, ptype = crypten.mpc.arithmetic)\n-#     min_value_share = crypten.cryptensor(min_value, ptype = crypten.mpc.arithmetic)\n-#     max_value_share = crypten.cryptensor(max_value, ptype = crypten.mpc.arithmetic)\n-#     one_share = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n+@mpc.run_multiprocess(world_size=3)\n+def L_Sigmoid(x, min_value, max_value):\n+    x_share = crypten.cryptensor(x, ptype = crypten.mpc.arithmetic)\n+    min_value_share = crypten.cryptensor(min_value, ptype = crypten.mpc.arithmetic)\n+    max_value_share = crypten.cryptensor(max_value, ptype = crypten.mpc.arithmetic)\n+    one_share = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n     \n     \n-#     # part 1\n-#     cmp_result_1 = x_share > min_value_share\n-#     result_1 = cmp_result_1.to(crypten.mpc.arithmetic)\n+    # part 1\n+    cmp_result_1 = x_share > min_value_share\n+    result_1 = cmp_result_1.to(crypten.mpc.arithmetic)\n     \n-#     # result 2\n-#     temp = - x_share - max_value_share\n-#     relu_result = temp.relu()\n-#     result_2 = one_share  - relu_result\n+    # result 2\n+    temp = - x_share + max_value_share\n+    relu_result = temp.relu()\n+    result_2 = one_share  - relu_result\n     \n-#     L_Sigmod = result_1 * result_2\n-#     rank = comm.get().get_rank()\n-#     crypten.print(f\"\\nRank {rank}:\\n relu_result: {relu_result.get_plain_text()}\\n\" \\\n-#                 f\" result_1:{result_1.get_plain_text()}\\n\",\\\n-#                 f\" result_2:{result_2.get_plain_text()}\\n\",\\\n-#                 f\" L_sigmod_result:{L_Sigmod.get_plain_text()}\\n\",\n-#                 # f\" L_time:{L_time}\\n\",\n-#                 in_order=True)\n+    L_Sigmod = result_1 * result_2\n+    rank = comm.get().get_rank()\n+    crypten.print(f\"\\nRank {rank}:\\n relu_result: {relu_result.get_plain_text()}\\n\" \\\n+                f\" result_1:{result_1.get_plain_text()}\\n\",\\\n+                f\" result_2:{result_2.get_plain_text()}\\n\",\\\n+                f\" L_sigmod_result:{L_Sigmod.get_plain_text()}\\n\",\n+                # f\" L_time:{L_time}\\n\",\n+                in_order=True)\n \n     \n \n def main():\n"
                },
                {
                    "date": 1721227799628,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -147,9 +147,9 @@\n     cmp_result_1 = x_share > min_value_share\n     result_1 = cmp_result_1.to(crypten.mpc.arithmetic)\n     \n     # result 2\n-    temp = - x_share + max_value_share\n+    temp = - x_share - max_value_share\n     relu_result = temp.relu()\n     result_2 = one_share  - relu_result\n     \n     L_Sigmod = result_1 * result_2\n"
                },
                {
                    "date": 1721227831324,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -167,7 +167,7 @@\n     x = generate_random()\n     # y = generate_random()\n     print(\"x\", x)\n     # print(\"y\", y)\n-    L_Sigmoid(x, -1, 2)\n+    L_Sigmoid(x, -2, 2)\n \n main()\n\\ No newline at end of file\n"
                },
                {
                    "date": 1721270410853,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -147,9 +147,9 @@\n     cmp_result_1 = x_share > min_value_share\n     result_1 = cmp_result_1.to(crypten.mpc.arithmetic)\n     \n     # result 2\n-    temp = - x_share - max_value_share\n+    temp = - x_share  max_value_share\n     relu_result = temp.relu()\n     result_2 = one_share  - relu_result\n     \n     L_Sigmod = result_1 * result_2\n"
                },
                {
                    "date": 1721270557099,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -148,9 +148,9 @@\n     result_1 = cmp_result_1.to(crypten.mpc.arithmetic)\n     \n     # result 2\n     temp = - x_share > max_value_share\n-    relu_result = temp.relu()\n+    relu_result = temp.where\n     result_2 = one_share  - relu_result\n     \n     L_Sigmod = result_1 * result_2\n     rank = comm.get().get_rank()\n"
                },
                {
                    "date": 1721270593361,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,174 @@\n+\n+import crypten\n+import crypten.mpc\n+import torch\n+import crypten.mpc as mpc\n+import crypten.mpc.primitives.beaver as beaver\n+import crypten.communicator as comm \n+import torch\n+from crypten.mpc import MPCTensor\n+from crypten.mpc.primitives import BinarySharedTensor\n+import time\n+import random\n+import crypten.common.functions\n+\n+crypten.init()\n+\n+\n+# region \n+# DATASET_DIR = os.path.join(os.path.dirname(__file__), 'dataset')\n+\n+# class DataSetParam:\n+#     def __init__(self, dataset_name):\n+#         self.dataset_name = dataset_name\n+\n+\n+# class DataSet:\n+#     sonar = DataSetParam('sonar.csv')\n+#     sonar_selected = DataSetParam('sonar_selected.csv')\n+    \n+    \n+    \n+# def load_dataset(dataset):\n+#     dataset_path = os.path.join(DATASET_DIR, dataset)\n+\n+#     # 尝试打开并读取CSV文件\n+#     try:\n+#         with open(dataset_path, 'r', encoding='utf-8') as csvfile:\n+#             spamreader = csv.reader(csvfile)\n+#             data = np.array(list(spamreader))\n+#     except FileNotFoundError:\n+#         print(f\"Error: The file {dataset_path} was not found.\")\n+#         return None, None\n+#     except Exception as e:\n+#         print(f\"Error: An error occurred while reading the file: {e}\")\n+#         return None, None\n+\n+#     # 检查数据是否为空\n+#     if data.size == 0:\n+#         print(\"Error: The dataset is empty.\")\n+#         return None, None\n+\n+#     feature = data[:, :-1].astype(np.float64)\n+#     labels = data[:, -1]\n+\n+#     # 创建标签映射\n+#     unique_labels = np.unique(labels)\n+#     label_to_int = {label: idx for idx, label in enumerate(unique_labels)}\n+#     int_labels = np.array([label_to_int[label] for label in labels], dtype=np.uint8)\n+#     labell = int_labels.reshape(-1,1)\n+\n+#     # 将标签转换为独热矩阵\n+#     one_hot_labels = np.zeros((int_labels.size, int_labels.max() + 1), dtype=np.uint8)\n+#     one_hot_labels[np.arange(int_labels.size), int_labels] = 1\n+\n+#     # print(\"======feature_size=====\", feature.shape)\n+#     print(\"======label_size=====\", one_hot_labels)\n+#     return feature, one_hot_labels\n+\n+# data_train = DataSet.sonar\n+\n+# load_dataset(data_train.dataset_name)\n+# endregion\n+\n+\n+def generate_random():\n+    random_tensor = random.uniform(-2, 2)\n+    return random_tensor\n+\n+# region \n+# @mpc.run_multiprocess(world_size=2)\n+# def test(x,y):\n+    # x_enc = crypten.cryptensor(x, ptype=crypten.mpc.arithmetic)\n+    # y_enc = crypten.cryptensor(y, ptype=crypten.mpc.arithmetic)\n+    # ge_time_begin = time.time()\n+    # ge_  = x_enc.ge(y_enc)\n+    # ge_time_end = time.time()\n+    # ge_time = ge_time_end - ge_time_begin\n+    # print(\"ge_time\", ge_time)\n+    \n+    # gt_time_begin = time.time()\n+    # gt_  = x_enc.gt(y_enc)\n+    # gt_time_end = time.time()\n+    # gt_time = gt_time_end - gt_time_begin\n+    # print(\"gt_time\", gt_time)\n+    \n+    # relu_time_begin = time.time()\n+    # relu_ = ge_.relu()\n+    # relu_time_end = time.time()\n+    # relu_time = relu_time_end - relu_time_begin\n+    # print(\"relu_time\", relu_time)\n+# endregion\n+\n+# region \n+# @mpc.run_multiprocess(world_size=3)\n+# def L_Sigmoid(x, min_value, max_value):\n+#     x_share = crypten.cryptensor(x, ptype = crypten.mpc.arithmetic)\n+#     min_value_share = crypten.cryptensor(min_value, ptype = crypten.mpc.arithmetic)\n+#     max_value_share = crypten.cryptensor(max_value, ptype = crypten.mpc.arithmetic)\n+#     one_share = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n+    \n+#     begin_time = time.time()\n+#     # part 1\n+#     cmp_result_1 = x_share > min_value_share\n+#     result_1 = cmp_result_1.to(crypten.mpc.arithmetic)\n+    \n+#     # part 2    \n+#     x_minus_max = x_share - max_value_share\n+#     cmp_result_2 = x_minus_max < 0\n+#     mulplex_result = crypten.where(cmp_result_2, x_minus_max, 0)\n+#     result_2 = mulplex_result + one_share\n+    \n+#     L_sigmod_result = result_1 * result_2\n+    \n+#     end_time = time.time()\n+#     L_time = end_time - begin_time\n+    \n+#     rank = comm.get().get_rank()\n+#     crypten.print(f\"\\nRank {rank}:\\n cmp_result_1: {cmp_result_1.get_plain_text()}\\n\" \\\n+#                 f\" cmp_result_2: {cmp_result_2.get_plain_text()}\\n\" \\\n+#                 f\" mulplex_result: {mulplex_result.get_plain_text()}\\n\" \\\n+#                 f\" result_1:{result_1.get_plain_text()}\\n\",\\\n+#                 f\" result_2:{result_2.get_plain_text()}\\n\",\\\n+#                 f\" L_sigmod_result:{L_sigmod_result.get_plain_text()}\\n\",\n+#                 # f\" L_time:{L_time}\\n\",\n+#                 in_order=True)\n+# endregion\n+\n+@mpc.run_multiprocess(world_size=3)\n+def L_Sigmoid(x, min_value, max_value):\n+    x_share = crypten.cryptensor(x, ptype = crypten.mpc.arithmetic)\n+    min_value_share = crypten.cryptensor(min_value, ptype = crypten.mpc.arithmetic)\n+    max_value_share = crypten.cryptensor(max_value, ptype = crypten.mpc.arithmetic)\n+    one_share = crypten.cryptensor(1, ptype = crypten.mpc.arithmetic)\n+    \n+    \n+    # part 1\n+    cmp_result_1 = x_share > min_value_share\n+    result_1 = cmp_result_1.to(crypten.mpc.arithmetic)\n+    \n+    # result 2\n+    temp = - x_share > max_value_share\n+    x_share_minus_one = x\n+    relu_result = temp.where(temp, )\n+    result_2 = one_share  - relu_result\n+    \n+    L_Sigmod = result_1 * result_2\n+    rank = comm.get().get_rank()\n+    crypten.print(f\"\\nRank {rank}:\\n relu_result: {relu_result.get_plain_text()}\\n\" \\\n+                f\" result_1:{result_1.get_plain_text()}\\n\",\\\n+                f\" result_2:{result_2.get_plain_text()}\\n\",\\\n+                f\" L_sigmod_result:{L_Sigmod.get_plain_text()}\\n\",\n+                # f\" L_time:{L_time}\\n\",\n+                in_order=True)\n+\n+    \n+\n+def main():\n+    x = generate_random()\n+    # y = generate_random()\n+    print(\"x\", x)\n+    # print(\"y\", y)\n+    L_Sigmoid(x, -2, 2)\n+\n+main()\n\\ No newline at end of file\n"
                }
            ],
            "date": 1718610785581,
            "name": "Commit-0",
            "content": "import os\nimport csv\nimport numpy as np\n\nDATASET_DIR = os.path.join(os.path.dirname(__file__), 'dataset')\n\nclass DataSetParam:\n    def __init__(self, dataset_name):\n        self.dataset_name = dataset_name\n\n\nclass DataSet:\n    sonar = DataSetParam('sonar.csv')\n\n\ndef load_dataset(dataset):\n    dataset_path = os.path.join(DATASET_DIR, dataset)\n\n    # 尝试打开并读取CSV文件\n    try:\n        with open(dataset_path, 'r', encoding='utf-8') as csvfile:\n            spamreader = csv.reader(csvfile)\n            data = np.array(list(spamreader))\n    except FileNotFoundError:\n        print(f\"Error: The file {dataset_path} was not found.\")\n        return None, None\n    except Exception as e:\n        print(f\"Error: An error occurred while reading the file: {e}\")\n        return None, None\n\n    # 检查数据是否为空\n    if data.size == 0:\n        print(\"Error: The dataset is empty.\")\n        return None, None\n\n    feature = data[:, :-1].astype(np.float64)\n    labels = data[:, -1]\n\n    # 创建标签映射\n    unique_labels = np.unique(labels)\n    label_to_int = {label: idx for idx, label in enumerate(unique_labels)}\n    int_labels = np.array([label_to_int[label] for label in labels], dtype=np.uint8)\n\n    return feature, int_labels\n\n\ndata_train = DataSet.sonar\nfeature,label = load_dataset(data_train.dataset_name)"
        }
    ]
}