{
    "sourceFile": "relief_mpc/test.py",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 115,
            "patches": [
                {
                    "date": 1718801629257,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                },
                {
                    "date": 1718801659650,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -22,68 +22,14 @@\n \n \n \n \n-def train_linear_svm(features, labels, epochs, lr, print_time=False):\n-    # Initialize random weights\n-    w = features.new(torch.randn(features.size(1),1))\n-    b = features.new(torch.randn(1))\n-    # print(\"==========w========\", w.shape)\n-    # print(\"==========b========\", b.shape)\n-    # print(\"=======features=====\", features.shape)\n-\n-    if print_time:\n-        pt_time = AverageMeter()\n-        end = time.time()\n+def relief_mpc():\n     \n-    filename = \"Accuracy.txt\"\n-    with open(filename, 'a') as f:\n-        for epoch in range(epochs):\n-            # Forward\n-            label_predictions = features.matmul(w).add(b).sign()\n-            # label_predictions = w.matmul(features.T).add(b).sign()\n-            # print(\"=======labels======\", labels.shape)\n-            # print(\"=======label_predictions======\", label_predictions.shape)\n-            # Compute accuracy\n-            correct = label_predictions.mul(labels.view(-1,1))\n-            # print(\"=======correct======\", correct.shape)\n-            accuracy = correct.add(1).div(2).mean()\n-            if crypten.is_encrypted_tensor(accuracy):\n-                accuracy = accuracy.get_plain_text()\n \n-            # Print Accuracy once\n-            if crypten.communicator.get().get_rank() == 0:\n-                # print(\n-                #     f\"Epoch {epoch} --- Training Accuracy %.2f%%\" % (accuracy.item() * 100)\n-                # )\n-                accuracy_str = \"%.2f%%\" % (accuracy * 100)\n-                accuracy_str_without_percent = accuracy_str.replace('%', '')\n-                f.write(accuracy_str_without_percent + \",\")\n \n-            # Backward\n-            loss_grad = -labels * (1 - correct) * 0.5  # Hinge loss\n-            # print(\"=======loss_grad======\\n\", loss_grad.get_plain_text())\n-            b_grad = loss_grad.mean()\n-            # print(\"=======b_grad ======\", b_grad.shape)\n-            w_grad = features.t().matmul(loss_grad).div(loss_grad.size(0))\n-            # print(\"=======w_grad ======\", w_grad.shape)\n-            \n \n-            # Update\n-            w -= w_grad * lr\n-            b -= b_grad * lr\n \n-            if print_time:\n-                iter_time = time.time() - end\n-                pt_time.add(iter_time)\n-                print(\"Time %.6f (%.6f)\" % (iter_time, pt_time.value()))\n-                end = time.time()\n-\n-    return w, b\n-\n-\n-\n-\n def load_dataset(dataset):\n     dataset_path = os.path.join(DATASET_DIR, dataset)\n \n     # 尝试打开并读取CSV文件\n"
                },
                {
                    "date": 1718801667297,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -84,9 +84,9 @@\n     logging.info(\"==================\")\n     logging.info(\"CrypTen Training\")\n     logging.info(\"==================\")\n # NOTE：训练无差异\n-    w, b = train_linear_svm(x, y, epochs=epochs, lr=lr, print_time=True)\n+    w, b = relief_mpc()(x, y, epochs=epochs, lr=lr, print_time=True)\n \n     # if not skip_plaintext:\n     #     logging.info(\"PyTorch Weights  :\")\n     #     logging.info(w_torch)\n"
                },
                {
                    "date": 1718801684748,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,155 @@\n+\n+import logging\n+import time\n+import csv\n+import os\n+import crypten\n+import torch\n+import numpy as np\n+from examples.meters import AverageMeter\n+\n+\n+DATASET_DIR = os.path.join(os.path.dirname(__file__), '../dataset')\n+\n+class DataSetParam:\n+    def __init__(self, dataset_name):\n+        self.dataset_name = dataset_name\n+\n+\n+class DataSet:\n+    sonar = DataSetParam('sonar.csv')\n+    sonar_selected = DataSetParam('sonar_selected.csv')\n+\n+\n+\n+\n+def train_linear_svm(features, labels, epochs, lr, print_time=False):\n+    # Initialize random weights\n+    w = features.new(torch.randn(features.size(1),1))\n+    b = features.new(torch.randn(1))\n+    # print(\"==========w========\", w.shape)\n+    # print(\"==========b========\", b.shape)\n+    # print(\"=======features=====\", features.shape)\n+\n+    if print_time:\n+        pt_time = AverageMeter()\n+        end = time.time()\n+    \n+    filename = \"Accuracy.txt\"\n+    with open(filename, 'a') as f:\n+        for epoch in range(epochs):\n+            # Forward\n+            label_predictions = features.matmul(w).add(b).sign()\n+            # label_predictions = w.matmul(features.T).add(b).sign()\n+            # print(\"=======labels======\", labels.shape)\n+            # print(\"=======label_predictions======\", label_predictions.shape)\n+            # Compute accuracy\n+            correct = label_predictions.mul(labels.view(-1,1))\n+            # print(\"=======correct======\", correct.shape)\n+            accuracy = correct.add(1).div(2).mean()\n+            if crypten.is_encrypted_tensor(accuracy):\n+                accuracy = accuracy.get_plain_text()\n+\n+            # Print Accuracy once\n+            if crypten.communicator.get().get_rank() == 0:\n+                # print(\n+                #     f\"Epoch {epoch} --- Training Accuracy %.2f%%\" % (accuracy.item() * 100)\n+                # )\n+                accuracy_str = \"%.2f%%\" % (accuracy * 100)\n+                accuracy_str_without_percent = accuracy_str.replace('%', '')\n+                f.write(accuracy_str_without_percent + \",\")\n+\n+            # Backward\n+            loss_grad = -labels * (1 - correct) * 0.5  # Hinge loss\n+            # print(\"=======loss_grad======\\n\", loss_grad.get_plain_text())\n+            b_grad = loss_grad.mean()\n+            # print(\"=======b_grad ======\", b_grad.shape)\n+            w_grad = features.t().matmul(loss_grad).div(loss_grad.size(0))\n+            # print(\"=======w_grad ======\", w_grad.shape)\n+            \n+\n+            # Update\n+            w -= w_grad * lr\n+            b -= b_grad * lr\n+\n+            if print_time:\n+                iter_time = time.time() - end\n+                pt_time.add(iter_time)\n+                print(\"Time %.6f (%.6f)\" % (iter_time, pt_time.value()))\n+                end = time.time()\n+\n+    return w, b\n+\n+\n+\n+\n+def load_dataset(dataset):\n+    dataset_path = os.path.join(DATASET_DIR, dataset)\n+\n+    # 尝试打开并读取CSV文件\n+    try:\n+        with open(dataset_path, 'r', encoding='utf-8') as csvfile:\n+            spamreader = csv.reader(csvfile)\n+            data = np.array(list(spamreader))\n+    except FileNotFoundError:\n+        print(f\"Error: The file {dataset_path} was not found.\")\n+        return None, None\n+    except Exception as e:\n+        print(f\"Error: An error occurred while reading the file: {e}\")\n+        return None, None\n+\n+    # 检查数据是否为空\n+    if data.size == 0:\n+        print(\"Error: The dataset is empty.\")\n+        return None, None\n+\n+    feature = data[:, :-1].astype(np.float64)\n+    labels = data[:, -1]\n+\n+    # 创建标签映射\n+    unique_labels = np.unique(labels)\n+    label_to_int = {label: idx for idx, label in enumerate(unique_labels)}\n+    int_labels = np.array([label_to_int[label] for label in labels], dtype=np.uint8)\n+    labell = int_labels.reshape(-1,1)\n+\n+    # print(\"======feature_size=====\", feature.shape)\n+    # print(\"======label_size=====\", labell.shape)\n+    return feature, labell\n+\n+\n+\n+def run_mpc_linear_svm(\n+    epochs=100, lr=0.5\n+):\n+    crypten.init()\n+\n+    # Set random seed for reproducibility\n+    torch.manual_seed(1)\n+\n+    data_train = DataSet.sonar\n+    \n+    x, y = load_dataset(data_train.dataset_name)\n+\n+# NOTE：crypten.cryptensor \n+    # Encrypt features / labels\n+    x = crypten.cryptensor(x)\n+    y = crypten.cryptensor(y)\n+\n+    logging.info(\"==================\")\n+    logging.info(\"CrypTen Training\")\n+    logging.info(\"==================\")\n+# NOTE：训练无差异\n+    w, b = train_linear_svm(x, y, epochs=epochs, lr=lr, print_time=True)\n+\n+    # if not skip_plaintext:\n+    #     logging.info(\"PyTorch Weights  :\")\n+    #     logging.info(w_torch)\n+    # logging.info(\"CrypTen Weights:\")\n+# NOTE：get_plain_text()\n+    # logging.info(w.get_plain_text())\n+\n+    # if not skip_plaintext:\n+    #     logging.info(\"PyTorch Bias  :\")\n+    #     logging.info(b_torch)\n+    # logging.info(\"CrypTen Bias:\")\n+    # logging.info(b.get_plain_text())\n"
                },
                {
                    "date": 1718801997562,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -110,8 +110,12 @@\n     unique_labels = np.unique(labels)\n     label_to_int = {label: idx for idx, label in enumerate(unique_labels)}\n     int_labels = np.array([label_to_int[label] for label in labels], dtype=np.uint8)\n     labell = int_labels.reshape(-1,1)\n+    \n+        # 将标签转换为独热矩阵\n+    one_hot_labels = np.zeros((int_labels.size, int_labels.max() + 1), dtype=np.uint8)\n+    one_hot_labels[np.arange(int_labels.size), int_labels] = 1\n \n     # print(\"======feature_size=====\", feature.shape)\n     # print(\"======label_size=====\", labell.shape)\n     return feature, labell\n@@ -152,105 +156,4 @@\n     #     logging.info(\"PyTorch Bias  :\")\n     #     logging.info(b_torch)\n     # logging.info(\"CrypTen Bias:\")\n     # logging.info(b.get_plain_text())\n-\n-import logging\n-import time\n-import csv\n-import os\n-import crypten\n-import torch\n-import numpy as np\n-from examples.meters import AverageMeter\n-\n-\n-DATASET_DIR = os.path.join(os.path.dirname(__file__), '../dataset')\n-\n-class DataSetParam:\n-    def __init__(self, dataset_name):\n-        self.dataset_name = dataset_name\n-\n-\n-class DataSet:\n-    sonar = DataSetParam('sonar.csv')\n-    sonar_selected = DataSetParam('sonar_selected.csv')\n-\n-\n-\n-\n-def relief_mpc():\n-    \n-\n-\n-\n-\n-def load_dataset(dataset):\n-    dataset_path = os.path.join(DATASET_DIR, dataset)\n-\n-    # 尝试打开并读取CSV文件\n-    try:\n-        with open(dataset_path, 'r', encoding='utf-8') as csvfile:\n-            spamreader = csv.reader(csvfile)\n-            data = np.array(list(spamreader))\n-    except FileNotFoundError:\n-        print(f\"Error: The file {dataset_path} was not found.\")\n-        return None, None\n-    except Exception as e:\n-        print(f\"Error: An error occurred while reading the file: {e}\")\n-        return None, None\n-\n-    # 检查数据是否为空\n-    if data.size == 0:\n-        print(\"Error: The dataset is empty.\")\n-        return None, None\n-\n-    feature = data[:, :-1].astype(np.float64)\n-    labels = data[:, -1]\n-\n-    # 创建标签映射\n-    unique_labels = np.unique(labels)\n-    label_to_int = {label: idx for idx, label in enumerate(unique_labels)}\n-    int_labels = np.array([label_to_int[label] for label in labels], dtype=np.uint8)\n-    labell = int_labels.reshape(-1,1)\n-\n-    # print(\"======feature_size=====\", feature.shape)\n-    # print(\"======label_size=====\", labell.shape)\n-    return feature, labell\n-\n-\n-\n-def run_mpc_linear_svm(\n-    epochs=100, lr=0.5\n-):\n-    crypten.init()\n-\n-    # Set random seed for reproducibility\n-    torch.manual_seed(1)\n-\n-    data_train = DataSet.sonar\n-    \n-    x, y = load_dataset(data_train.dataset_name)\n-\n-# NOTE：crypten.cryptensor \n-    # Encrypt features / labels\n-    x = crypten.cryptensor(x)\n-    y = crypten.cryptensor(y)\n-\n-    logging.info(\"==================\")\n-    logging.info(\"CrypTen Training\")\n-    logging.info(\"==================\")\n-# NOTE：训练无差异\n-    w, b = relief_mpc()(x, y, epochs=epochs, lr=lr, print_time=True)\n-\n-    # if not skip_plaintext:\n-    #     logging.info(\"PyTorch Weights  :\")\n-    #     logging.info(w_torch)\n-    # logging.info(\"CrypTen Weights:\")\n-# NOTE：get_plain_text()\n-    # logging.info(w.get_plain_text())\n-\n-    # if not skip_plaintext:\n-    #     logging.info(\"PyTorch Bias  :\")\n-    #     logging.info(b_torch)\n-    # logging.info(\"CrypTen Bias:\")\n-    # logging.info(b.get_plain_text())\n"
                },
                {
                    "date": 1718802005465,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -111,15 +111,15 @@\n     label_to_int = {label: idx for idx, label in enumerate(unique_labels)}\n     int_labels = np.array([label_to_int[label] for label in labels], dtype=np.uint8)\n     labell = int_labels.reshape(-1,1)\n     \n-        # 将标签转换为独热矩阵\n+    # 将标签转换为独热矩阵\n     one_hot_labels = np.zeros((int_labels.size, int_labels.max() + 1), dtype=np.uint8)\n     one_hot_labels[np.arange(int_labels.size), int_labels] = 1\n \n     # print(\"======feature_size=====\", feature.shape)\n     # print(\"======label_size=====\", labell.shape)\n-    return feature, labell\n+    return feature, one_hot_labels\n \n \n \n def run_mpc_linear_svm(\n"
                },
                {
                    "date": 1718802012313,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -142,9 +142,9 @@\n     logging.info(\"==================\")\n     logging.info(\"CrypTen Training\")\n     logging.info(\"==================\")\n # NOTE：训练无差异\n-    w, b = train_linear_svm(x, y, epochs=epochs, lr=lr, print_time=True)\n+    # w, b = train_linear_svm(x, y, epochs=epochs, lr=lr, print_time=True)\n \n     # if not skip_plaintext:\n     #     logging.info(\"PyTorch Weights  :\")\n     #     logging.info(w_torch)\n"
                },
                {
                    "date": 1718802048424,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -80,10 +80,8 @@\n \n     return w, b\n \n \n-\n-\n def load_dataset(dataset):\n     dataset_path = os.path.join(DATASET_DIR, dataset)\n \n     # 尝试打开并读取CSV文件\n"
                },
                {
                    "date": 1718802072001,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -66,9 +66,8 @@\n             # print(\"=======b_grad ======\", b_grad.shape)\n             w_grad = features.t().matmul(loss_grad).div(loss_grad.size(0))\n             # print(\"=======w_grad ======\", w_grad.shape)\n             \n-\n             # Update\n             w -= w_grad * lr\n             b -= b_grad * lr\n \n@@ -136,9 +135,9 @@\n     # Encrypt features / labels\n     x = crypten.cryptensor(x)\n     y = crypten.cryptensor(y)\n \n-    logging.info(\"==================\")\n+    print()(\"==================\")\n     logging.info(\"CrypTen Training\")\n     logging.info(\"==================\")\n # NOTE：训练无差异\n     # w, b = train_linear_svm(x, y, epochs=epochs, lr=lr, print_time=True)\n"
                },
                {
                    "date": 1718802078428,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -135,11 +135,11 @@\n     # Encrypt features / labels\n     x = crypten.cryptensor(x)\n     y = crypten.cryptensor(y)\n \n-    print()(\"==================\")\n-    logging.info(\"CrypTen Training\")\n-    logging.info(\"==================\")\n+    print(\"==================\")\n+    print(\"CrypTen Training\")\n+    print(\"==================\")\n # NOTE：训练无差异\n     # w, b = train_linear_svm(x, y, epochs=epochs, lr=lr, print_time=True)\n \n     # if not skip_plaintext:\n"
                },
                {
                    "date": 1718802084283,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -138,8 +138,9 @@\n \n     print(\"==================\")\n     print(\"CrypTen Training\")\n     print(\"==================\")\n+    print()\n # NOTE：训练无差异\n     # w, b = train_linear_svm(x, y, epochs=epochs, lr=lr, print_time=True)\n \n     # if not skip_plaintext:\n"
                },
                {
                    "date": 1718802090144,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -138,9 +138,10 @@\n \n     print(\"==================\")\n     print(\"CrypTen Training\")\n     print(\"==================\")\n-    print()\n+    print(x)\n+    \n # NOTE：训练无差异\n     # w, b = train_linear_svm(x, y, epochs=epochs, lr=lr, print_time=True)\n \n     # if not skip_plaintext:\n"
                },
                {
                    "date": 1718802159627,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -119,9 +119,8 @@\n \n \n \n def run_mpc_linear_svm(\n-    epochs=100, lr=0.5\n ):\n     crypten.init()\n \n     # Set random seed for reproducibility\n@@ -138,9 +137,9 @@\n \n     print(\"==================\")\n     print(\"CrypTen Training\")\n     print(\"==================\")\n-    print(x)\n+    print(y)\n     \n # NOTE：训练无差异\n     # w, b = train_linear_svm(x, y, epochs=epochs, lr=lr, print_time=True)\n \n"
                },
                {
                    "date": 1718802255238,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -24,63 +24,10 @@\n \n \n def train_linear_svm(features, labels, epochs, lr, print_time=False):\n     # Initialize random weights\n-    w = features.new(torch.randn(features.size(1),1))\n-    b = features.new(torch.randn(1))\n-    # print(\"==========w========\", w.shape)\n-    # print(\"==========b========\", b.shape)\n-    # print(\"=======features=====\", features.shape)\n \n-    if print_time:\n-        pt_time = AverageMeter()\n-        end = time.time()\n-    \n-    filename = \"Accuracy.txt\"\n-    with open(filename, 'a') as f:\n-        for epoch in range(epochs):\n-            # Forward\n-            label_predictions = features.matmul(w).add(b).sign()\n-            # label_predictions = w.matmul(features.T).add(b).sign()\n-            # print(\"=======labels======\", labels.shape)\n-            # print(\"=======label_predictions======\", label_predictions.shape)\n-            # Compute accuracy\n-            correct = label_predictions.mul(labels.view(-1,1))\n-            # print(\"=======correct======\", correct.shape)\n-            accuracy = correct.add(1).div(2).mean()\n-            if crypten.is_encrypted_tensor(accuracy):\n-                accuracy = accuracy.get_plain_text()\n \n-            # Print Accuracy once\n-            if crypten.communicator.get().get_rank() == 0:\n-                # print(\n-                #     f\"Epoch {epoch} --- Training Accuracy %.2f%%\" % (accuracy.item() * 100)\n-                # )\n-                accuracy_str = \"%.2f%%\" % (accuracy * 100)\n-                accuracy_str_without_percent = accuracy_str.replace('%', '')\n-                f.write(accuracy_str_without_percent + \",\")\n-\n-            # Backward\n-            loss_grad = -labels * (1 - correct) * 0.5  # Hinge loss\n-            # print(\"=======loss_grad======\\n\", loss_grad.get_plain_text())\n-            b_grad = loss_grad.mean()\n-            # print(\"=======b_grad ======\", b_grad.shape)\n-            w_grad = features.t().matmul(loss_grad).div(loss_grad.size(0))\n-            # print(\"=======w_grad ======\", w_grad.shape)\n-            \n-            # Update\n-            w -= w_grad * lr\n-            b -= b_grad * lr\n-\n-            if print_time:\n-                iter_time = time.time() - end\n-                pt_time.add(iter_time)\n-                print(\"Time %.6f (%.6f)\" % (iter_time, pt_time.value()))\n-                end = time.time()\n-\n-    return w, b\n-\n-\n def load_dataset(dataset):\n     dataset_path = os.path.join(DATASET_DIR, dataset)\n \n     # 尝试打开并读取CSV文件\n"
                },
                {
                    "date": 1718802261056,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -22,10 +22,9 @@\n \n \n \n \n-def train_linear_svm(features, labels, epochs, lr, print_time=False):\n-    # Initialize random weights\n+def train_linear_svm():\n \n \n def load_dataset(dataset):\n     dataset_path = os.path.join(DATASET_DIR, dataset)\n"
                },
                {
                    "date": 1718802266518,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -22,9 +22,9 @@\n \n \n \n \n-def train_linear_svm():\n+def relief():\n \n \n def load_dataset(dataset):\n     dataset_path = os.path.join(DATASET_DIR, dataset)\n"
                },
                {
                    "date": 1718802280623,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -22,9 +22,9 @@\n \n \n \n \n-def relief():\n+def relief_mpc():\n \n \n def load_dataset(dataset):\n     dataset_path = os.path.join(DATASET_DIR, dataset)\n@@ -86,9 +86,9 @@\n     print(\"==================\")\n     print(y)\n     \n # NOTE：训练无差异\n-    # w, b = train_linear_svm(x, y, epochs=epochs, lr=lr, print_time=True)\n+    w, b = train_linear_svm(x, y, epochs=epochs, lr=lr, print_time=True)\n \n     # if not skip_plaintext:\n     #     logging.info(\"PyTorch Weights  :\")\n     #     logging.info(w_torch)\n"
                },
                {
                    "date": 1718802286870,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -86,9 +86,9 @@\n     print(\"==================\")\n     print(y)\n     \n # NOTE：训练无差异\n-    w, b = train_linear_svm(x, y, epochs=epochs, lr=lr, print_time=True)\n+    w, b = relief_mpc()\n \n     # if not skip_plaintext:\n     #     logging.info(\"PyTorch Weights  :\")\n     #     logging.info(w_torch)\n"
                },
                {
                    "date": 1718802301106,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -22,9 +22,9 @@\n \n \n \n \n-def relief_mpc():\n+def relief_mpc(data):\n \n \n def load_dataset(dataset):\n     dataset_path = os.path.join(DATASET_DIR, dataset)\n@@ -86,9 +86,9 @@\n     print(\"==================\")\n     print(y)\n     \n # NOTE：训练无差异\n-    w, b = relief_mpc()\n+    w, b = relief_mpc(x,y)\n \n     # if not skip_plaintext:\n     #     logging.info(\"PyTorch Weights  :\")\n     #     logging.info(w_torch)\n"
                },
                {
                    "date": 1718802307680,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -22,9 +22,9 @@\n \n \n \n \n-def relief_mpc(data):\n+def relief_mpc(data_share, label_share):\n \n \n def load_dataset(dataset):\n     dataset_path = os.path.join(DATASET_DIR, dataset)\n"
                },
                {
                    "date": 1718802335906,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -23,8 +23,9 @@\n \n \n \n def relief_mpc(data_share, label_share):\n+    \n \n \n def load_dataset(dataset):\n     dataset_path = os.path.join(DATASET_DIR, dataset)\n"
                },
                {
                    "date": 1718802546000,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -66,8 +66,9 @@\n \n \n \n def run_mpc_linear_svm(\n+    \n ):\n     crypten.init()\n \n     # Set random seed for reproducibility\n"
                },
                {
                    "date": 1718802552761,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -66,9 +66,9 @@\n \n \n \n def run_mpc_linear_svm(\n-    \n+    instance = \n ):\n     crypten.init()\n \n     # Set random seed for reproducibility\n"
                },
                {
                    "date": 1718802558145,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -66,9 +66,9 @@\n \n \n \n def run_mpc_linear_svm(\n-    instance = \n+    instance = 208\n ):\n     crypten.init()\n \n     # Set random seed for reproducibility\n"
                },
                {
                    "date": 1718802563962,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -66,9 +66,9 @@\n \n \n \n def run_mpc_linear_svm(\n-    instance = 208\n+    instance = 208,\n ):\n     crypten.init()\n \n     # Set random seed for reproducibility\n"
                },
                {
                    "date": 1718802641406,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -65,9 +65,9 @@\n     return feature, one_hot_labels\n \n \n \n-def run_mpc_linear_svm(\n+def relief_mpc_linear_svm(\n     instance = 208,\n ):\n     crypten.init()\n \n"
                },
                {
                    "date": 1718802705183,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -65,9 +65,9 @@\n     return feature, one_hot_labels\n \n \n \n-def relief_mpc_linear_svm(\n+def relief_mpc(\n     instance = 208,\n ):\n     crypten.init()\n \n@@ -88,9 +88,9 @@\n     print(\"==================\")\n     print(y)\n     \n # NOTE：训练无差异\n-    w, b = relief_mpc(x,y)\n+    w, b = relief_mpc(x,y, instan)\n \n     # if not skip_plaintext:\n     #     logging.info(\"PyTorch Weights  :\")\n     #     logging.info(w_torch)\n"
                },
                {
                    "date": 1718802713051,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -88,9 +88,9 @@\n     print(\"==================\")\n     print(y)\n     \n # NOTE：训练无差异\n-    w, b = relief_mpc(x,y, instan)\n+    w, b = relief_mpc(x,y, instance)\n \n     # if not skip_plaintext:\n     #     logging.info(\"PyTorch Weights  :\")\n     #     logging.info(w_torch)\n"
                },
                {
                    "date": 1718802722830,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -22,9 +22,9 @@\n \n \n \n \n-def relief_mpc(data_share, label_share):\n+def relief_mpc(instance,data_share, label_share):\n     \n \n \n def load_dataset(dataset):\n"
                },
                {
                    "date": 1718802730189,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -22,9 +22,9 @@\n \n \n \n \n-def relief_mpc(instance,data_share, label_share):\n+def relief_mpc(numbernstance, data_share, label_share):\n     \n \n \n def load_dataset(dataset):\n"
                },
                {
                    "date": 1718802739872,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -22,10 +22,11 @@\n \n \n \n \n-def relief_mpc(numbernstance, data_share, label_share):\n-    \n+def relief_mpc(numberInstance, data_share, label_share):\n+    # 随机选择一个索引\n+    random_index = np.random.randint(0, m)\n \n \n def load_dataset(dataset):\n     dataset_path = os.path.join(DATASET_DIR, dataset)\n"
                },
                {
                    "date": 1718802745649,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -24,9 +24,11 @@\n \n \n def relief_mpc(numberInstance, data_share, label_share):\n     # 随机选择一个索引\n-    random_index = np.random.randint(0, m)\n+    random_index = np.random.randint(0, numberInstance)\n+    \n+    \n \n \n def load_dataset(dataset):\n     dataset_path = os.path.join(DATASET_DIR, dataset)\n"
                },
                {
                    "date": 1718802753747,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,108 @@\n+\n+import logging\n+import time\n+import csv\n+import os\n+import crypten\n+import torch\n+import numpy as np\n+from examples.meters import AverageMeter\n+\n+\n+DATASET_DIR = os.path.join(os.path.dirname(__file__), '../dataset')\n+\n+class DataSetParam:\n+    def __init__(self, dataset_name):\n+        self.dataset_name = dataset_name\n+\n+\n+class DataSet:\n+    sonar = DataSetParam('sonar.csv')\n+    sonar_selected = DataSetParam('sonar_selected.csv')\n+\n+\n+\n+\n+def relief_mpc(numberInstance, data_share, label_share):\n+    # 随机选择一个索引\n+    random_index = np.random.randint(0, numberInstance)\n+    \n+    core_instance = data_share\n+\n+\n+def load_dataset(dataset):\n+    dataset_path = os.path.join(DATASET_DIR, dataset)\n+\n+    # 尝试打开并读取CSV文件\n+    try:\n+        with open(dataset_path, 'r', encoding='utf-8') as csvfile:\n+            spamreader = csv.reader(csvfile)\n+            data = np.array(list(spamreader))\n+    except FileNotFoundError:\n+        print(f\"Error: The file {dataset_path} was not found.\")\n+        return None, None\n+    except Exception as e:\n+        print(f\"Error: An error occurred while reading the file: {e}\")\n+        return None, None\n+\n+    # 检查数据是否为空\n+    if data.size == 0:\n+        print(\"Error: The dataset is empty.\")\n+        return None, None\n+\n+    feature = data[:, :-1].astype(np.float64)\n+    labels = data[:, -1]\n+\n+    # 创建标签映射\n+    unique_labels = np.unique(labels)\n+    label_to_int = {label: idx for idx, label in enumerate(unique_labels)}\n+    int_labels = np.array([label_to_int[label] for label in labels], dtype=np.uint8)\n+    labell = int_labels.reshape(-1,1)\n+    \n+    # 将标签转换为独热矩阵\n+    one_hot_labels = np.zeros((int_labels.size, int_labels.max() + 1), dtype=np.uint8)\n+    one_hot_labels[np.arange(int_labels.size), int_labels] = 1\n+\n+    # print(\"======feature_size=====\", feature.shape)\n+    # print(\"======label_size=====\", labell.shape)\n+    return feature, one_hot_labels\n+\n+\n+\n+def relief_mpc(\n+    instance = 208,\n+):\n+    crypten.init()\n+\n+    # Set random seed for reproducibility\n+    torch.manual_seed(1)\n+\n+    data_train = DataSet.sonar\n+    \n+    x, y = load_dataset(data_train.dataset_name)\n+\n+# NOTE：crypten.cryptensor \n+    # Encrypt features / labels\n+    x = crypten.cryptensor(x)\n+    y = crypten.cryptensor(y)\n+\n+    print(\"==================\")\n+    print(\"CrypTen Training\")\n+    print(\"==================\")\n+    print(y)\n+    \n+# NOTE：训练无差异\n+    w, b = relief_mpc(x,y, instance)\n+\n+    # if not skip_plaintext:\n+    #     logging.info(\"PyTorch Weights  :\")\n+    #     logging.info(w_torch)\n+    # logging.info(\"CrypTen Weights:\")\n+# NOTE：get_plain_text()\n+    # logging.info(w.get_plain_text())\n+\n+    # if not skip_plaintext:\n+    #     logging.info(\"PyTorch Bias  :\")\n+    #     logging.info(b_torch)\n+    # logging.info(\"CrypTen Bias:\")\n+    # logging.info(b.get_plain_text())\n"
                },
                {
                    "date": 1718802760138,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -26,119 +26,12 @@\n def relief_mpc(numberInstance, data_share, label_share):\n     # 随机选择一个索引\n     random_index = np.random.randint(0, numberInstance)\n     \n-    core_instance = data_share\n-\n-\n-def load_dataset(dataset):\n-    dataset_path = os.path.join(DATASET_DIR, dataset)\n-\n-    # 尝试打开并读取CSV文件\n-    try:\n-        with open(dataset_path, 'r', encoding='utf-8') as csvfile:\n-            spamreader = csv.reader(csvfile)\n-            data = np.array(list(spamreader))\n-    except FileNotFoundError:\n-        print(f\"Error: The file {dataset_path} was not found.\")\n-        return None, None\n-    except Exception as e:\n-        print(f\"Error: An error occurred while reading the file: {e}\")\n-        return None, None\n-\n-    # 检查数据是否为空\n-    if data.size == 0:\n-        print(\"Error: The dataset is empty.\")\n-        return None, None\n-\n-    feature = data[:, :-1].astype(np.float64)\n-    labels = data[:, -1]\n-\n-    # 创建标签映射\n-    unique_labels = np.unique(labels)\n-    label_to_int = {label: idx for idx, label in enumerate(unique_labels)}\n-    int_labels = np.array([label_to_int[label] for label in labels], dtype=np.uint8)\n-    labell = int_labels.reshape(-1,1)\n+    core_instance_ = data_share[random_index]\n     \n-    # 将标签转换为独热矩阵\n-    one_hot_labels = np.zeros((int_labels.size, int_labels.max() + 1), dtype=np.uint8)\n-    one_hot_labels[np.arange(int_labels.size), int_labels] = 1\n \n-    # print(\"======feature_size=====\", feature.shape)\n-    # print(\"======label_size=====\", labell.shape)\n-    return feature, one_hot_labels\n \n-\n-\n-def relief_mpc(\n-    instance = 208,\n-):\n-    crypten.init()\n-\n-    # Set random seed for reproducibility\n-    torch.manual_seed(1)\n-\n-    data_train = DataSet.sonar\n-    \n-    x, y = load_dataset(data_train.dataset_name)\n-\n-# NOTE：crypten.cryptensor \n-    # Encrypt features / labels\n-    x = crypten.cryptensor(x)\n-    y = crypten.cryptensor(y)\n-\n-    print(\"==================\")\n-    print(\"CrypTen Training\")\n-    print(\"==================\")\n-    print(y)\n-    \n-# NOTE：训练无差异\n-    w, b = relief_mpc(x,y, instance)\n-\n-    # if not skip_plaintext:\n-    #     logging.info(\"PyTorch Weights  :\")\n-    #     logging.info(w_torch)\n-    # logging.info(\"CrypTen Weights:\")\n-# NOTE：get_plain_text()\n-    # logging.info(w.get_plain_text())\n-\n-    # if not skip_plaintext:\n-    #     logging.info(\"PyTorch Bias  :\")\n-    #     logging.info(b_torch)\n-    # logging.info(\"CrypTen Bias:\")\n-    # logging.info(b.get_plain_text())\n-\n-import logging\n-import time\n-import csv\n-import os\n-import crypten\n-import torch\n-import numpy as np\n-from examples.meters import AverageMeter\n-\n-\n-DATASET_DIR = os.path.join(os.path.dirname(__file__), '../dataset')\n-\n-class DataSetParam:\n-    def __init__(self, dataset_name):\n-        self.dataset_name = dataset_name\n-\n-\n-class DataSet:\n-    sonar = DataSetParam('sonar.csv')\n-    sonar_selected = DataSetParam('sonar_selected.csv')\n-\n-\n-\n-\n-def relief_mpc(numberInstance, data_share, label_share):\n-    # 随机选择一个索引\n-    random_index = np.random.randint(0, numberInstance)\n-    \n-    \n-\n-\n def load_dataset(dataset):\n     dataset_path = os.path.join(DATASET_DIR, dataset)\n \n     # 尝试打开并读取CSV文件\n"
                },
                {
                    "date": 1718802766702,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -22,13 +22,13 @@\n \n \n \n \n-def relief_mpc(numberInstance, data_share, label_share):\n+def relief_mpc(numberInstance, feature_share, label_share):\n     # 随机选择一个索引\n     random_index = np.random.randint(0, numberInstance)\n     \n-    core_instance_ = data_share[random_index]\n+    core_instance_feature = data_share[random_index]\n     \n \n \n def load_dataset(dataset):\n"
                },
                {
                    "date": 1718802775954,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -26,9 +26,10 @@\n def relief_mpc(numberInstance, feature_share, label_share):\n     # 随机选择一个索引\n     random_index = np.random.randint(0, numberInstance)\n     \n-    core_instance_feature = data_share[random_index]\n+    core_instance_feature = feature_share[random_index]\n+    core\n     \n \n \n def load_dataset(dataset):\n"
                },
                {
                    "date": 1718802781192,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -27,9 +27,9 @@\n     # 随机选择一个索引\n     random_index = np.random.randint(0, numberInstance)\n     \n     core_instance_feature = feature_share[random_index]\n-    core\n+    core_instance_label = \n     \n \n \n def load_dataset(dataset):\n"
                },
                {
                    "date": 1718802791248,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -23,14 +23,15 @@\n \n \n \n def relief_mpc(numberInstance, feature_share, label_share):\n-    # 随机选择一个索引\n+\n     random_index = np.random.randint(0, numberInstance)\n     \n     core_instance_feature = feature_share[random_index]\n-    core_instance_label = \n+    core_instance_label = label_share[random_index]\n     \n+    \n \n \n def load_dataset(dataset):\n     dataset_path = os.path.join(DATASET_DIR, dataset)\n"
                },
                {
                    "date": 1718802803403,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -23,9 +23,9 @@\n \n \n \n def relief_mpc(numberInstance, feature_share, label_share):\n-\n+    # 选择目标\n     random_index = np.random.randint(0, numberInstance)\n     \n     core_instance_feature = feature_share[random_index]\n     core_instance_label = label_share[random_index]\n"
                },
                {
                    "date": 1718802810366,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -23,9 +23,9 @@\n \n \n \n def relief_mpc(numberInstance, feature_share, label_share):\n-    # 选择目标\n+    # 选择随机样本\n     random_index = np.random.randint(0, numberInstance)\n     \n     core_instance_feature = feature_share[random_index]\n     core_instance_label = label_share[random_index]\n"
                },
                {
                    "date": 1718802816807,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -23,11 +23,10 @@\n \n \n \n def relief_mpc(numberInstance, feature_share, label_share):\n-    # 选择随机样本\n+    # 随机选择样本\n     random_index = np.random.randint(0, numberInstance)\n-    \n     core_instance_feature = feature_share[random_index]\n     core_instance_label = label_share[random_index]\n     \n     \n"
                },
                {
                    "date": 1718802837699,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -29,8 +29,10 @@\n     core_instance_feature = feature_share[random_index]\n     core_instance_label = label_share[random_index]\n     \n     \n+    \n+    \n \n \n def load_dataset(dataset):\n     dataset_path = os.path.join(DATASET_DIR, dataset)\n"
                },
                {
                    "date": 1718803177136,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -72,8 +72,13 @@\n     return feature, one_hot_labels\n \n \n \n+\n+\n+\n+\n+\n def relief_mpc(\n     instance = 208,\n ):\n     crypten.init()\n"
                },
                {
                    "date": 1718803191175,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -71,14 +71,14 @@\n     # print(\"======label_size=====\", labell.shape)\n     return feature, one_hot_labels\n \n \n+def random_instance()\n \n \n \n \n \n-\n def relief_mpc(\n     instance = 208,\n ):\n     crypten.init()\n"
                },
                {
                    "date": 1718803200220,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -71,9 +71,9 @@\n     # print(\"======label_size=====\", labell.shape)\n     return feature, one_hot_labels\n \n \n-def random_instance()\n+def random_instance(x_share, y_share, )\n \n \n \n \n"
                },
                {
                    "date": 1718803211606,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -71,9 +71,10 @@\n     # print(\"======label_size=====\", labell.shape)\n     return feature, one_hot_labels\n \n \n-def random_instance(x_share, y_share, )\n+def random_instance(x_share, y_share, numberInstance):\n+    \n \n \n \n \n"
                },
                {
                    "date": 1718803217556,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -19,16 +19,8 @@\n class DataSet:\n     sonar = DataSetParam('sonar.csv')\n     sonar_selected = DataSetParam('sonar_selected.csv')\n \n-\n-\n-\n-def relief_mpc(numberInstance, feature_share, label_share):\n-    # 随机选择样本\n-    random_index = np.random.randint(0, numberInstance)\n-    core_instance_feature = feature_share[random_index]\n-    core_instance_label = label_share[random_index]\n     \n     \n     \n     \n"
                },
                {
                    "date": 1718803222880,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -64,14 +64,20 @@\n     return feature, one_hot_labels\n \n \n def random_instance(x_share, y_share, numberInstance):\n-    \n+        random_index = np.random.randint(0, numberInstance)\n+    core_instance_feature = feature_share[random_index]\n+    core_instance_label = label_share[random_index]\n \n \n \n \n+def relief_mpc(numberInstance, feature_share, label_share):\n+    # 随机选择样本\n \n+\n+\n def relief_mpc(\n     instance = 208,\n ):\n     crypten.init()\n"
                },
                {
                    "date": 1718803229145,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -62,22 +62,22 @@\n     # print(\"======feature_size=====\", feature.shape)\n     # print(\"======label_size=====\", labell.shape)\n     return feature, one_hot_labels\n \n-\n+# 随机选择样本\n def random_instance(x_share, y_share, numberInstance):\n-        random_index = np.random.randint(0, numberInstance)\n+    random_index = np.random.randint(0, numberInstance)\n     core_instance_feature = feature_share[random_index]\n     core_instance_label = label_share[random_index]\n \n \n \n \n def relief_mpc(numberInstance, feature_share, label_share):\n-    # 随机选择样本\n \n \n \n+\n def relief_mpc(\n     instance = 208,\n ):\n     crypten.init()\n"
                },
                {
                    "date": 1718803236701,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -63,9 +63,9 @@\n     # print(\"======label_size=====\", labell.shape)\n     return feature, one_hot_labels\n \n # 随机选择样本\n-def random_instance(x_share, y_share, numberInstance):\n+def random_instance(feature_share, y_share, numberInstance):\n     random_index = np.random.randint(0, numberInstance)\n     core_instance_feature = feature_share[random_index]\n     core_instance_label = label_share[random_index]\n \n"
                },
                {
                    "date": 1718803244220,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -63,17 +63,17 @@\n     # print(\"======label_size=====\", labell.shape)\n     return feature, one_hot_labels\n \n # 随机选择样本\n-def random_instance(feature_share, y_share, numberInstance):\n+def random_instance(feature_share, label_share, numberInstance):\n     random_index = np.random.randint(0, numberInstance)\n     core_instance_feature = feature_share[random_index]\n     core_instance_label = label_share[random_index]\n \n \n \n \n-def relief_mpc(numberInstance, feature_share, label_share):\n+def relief_mpc():\n \n \n \n \n"
                },
                {
                    "date": 1718803253498,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -71,9 +71,10 @@\n \n \n \n \n-def relief_mpc():\n+def relief_mpc(feature_share, ):\n+    \n \n \n \n \n"
                },
                {
                    "date": 1718803260140,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,118 @@\n+\n+import logging\n+import time\n+import csv\n+import os\n+import crypten\n+import torch\n+import numpy as np\n+from examples.meters import AverageMeter\n+\n+\n+DATASET_DIR = os.path.join(os.path.dirname(__file__), '../dataset')\n+\n+class DataSetParam:\n+    def __init__(self, dataset_name):\n+        self.dataset_name = dataset_name\n+\n+\n+class DataSet:\n+    sonar = DataSetParam('sonar.csv')\n+    sonar_selected = DataSetParam('sonar_selected.csv')\n+\n+    \n+    \n+    \n+    \n+\n+\n+def load_dataset(dataset):\n+    dataset_path = os.path.join(DATASET_DIR, dataset)\n+\n+    # 尝试打开并读取CSV文件\n+    try:\n+        with open(dataset_path, 'r', encoding='utf-8') as csvfile:\n+            spamreader = csv.reader(csvfile)\n+            data = np.array(list(spamreader))\n+    except FileNotFoundError:\n+        print(f\"Error: The file {dataset_path} was not found.\")\n+        return None, None\n+    except Exception as e:\n+        print(f\"Error: An error occurred while reading the file: {e}\")\n+        return None, None\n+\n+    # 检查数据是否为空\n+    if data.size == 0:\n+        print(\"Error: The dataset is empty.\")\n+        return None, None\n+\n+    feature = data[:, :-1].astype(np.float64)\n+    labels = data[:, -1]\n+\n+    # 创建标签映射\n+    unique_labels = np.unique(labels)\n+    label_to_int = {label: idx for idx, label in enumerate(unique_labels)}\n+    int_labels = np.array([label_to_int[label] for label in labels], dtype=np.uint8)\n+    labell = int_labels.reshape(-1,1)\n+    \n+    # 将标签转换为独热矩阵\n+    one_hot_labels = np.zeros((int_labels.size, int_labels.max() + 1), dtype=np.uint8)\n+    one_hot_labels[np.arange(int_labels.size), int_labels] = 1\n+\n+    # print(\"======feature_size=====\", feature.shape)\n+    # print(\"======label_size=====\", labell.shape)\n+    return feature, one_hot_labels\n+\n+# 随机选择样本\n+def random_instance(feature_share, label_share, numberInstance):\n+    random_index = np.random.randint(0, numberInstance)\n+    core_instance_feature = feature_share[random_index]\n+    core_instance_label = label_share[random_index]\n+\n+\n+\n+\n+def relief_mpc(feature_share, label_share):\n+    \n+    \n+\n+\n+\n+\n+def relief_mpc(\n+    instance = 208,\n+):\n+    crypten.init()\n+\n+    # Set random seed for reproducibility\n+    torch.manual_seed(1)\n+\n+    data_train = DataSet.sonar\n+    \n+    x, y = load_dataset(data_train.dataset_name)\n+\n+# NOTE：crypten.cryptensor \n+    # Encrypt features / labels\n+    x = crypten.cryptensor(x)\n+    y = crypten.cryptensor(y)\n+\n+    print(\"==================\")\n+    print(\"CrypTen Training\")\n+    print(\"==================\")\n+    print(y)\n+    \n+# NOTE：训练无差异\n+    w, b = relief_mpc(x,y, instance)\n+\n+    # if not skip_plaintext:\n+    #     logging.info(\"PyTorch Weights  :\")\n+    #     logging.info(w_torch)\n+    # logging.info(\"CrypTen Weights:\")\n+# NOTE：get_plain_text()\n+    # logging.info(w.get_plain_text())\n+\n+    # if not skip_plaintext:\n+    #     logging.info(\"PyTorch Bias  :\")\n+    #     logging.info(b_torch)\n+    # logging.info(\"CrypTen Bias:\")\n+    # logging.info(b.get_plain_text())\n"
                },
                {
                    "date": 1718803269389,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,119 @@\n+\n+import logging\n+import time\n+import csv\n+import os\n+import crypten\n+import torch\n+import numpy as np\n+from examples.meters import AverageMeter\n+\n+\n+DATASET_DIR = os.path.join(os.path.dirname(__file__), '../dataset')\n+\n+class DataSetParam:\n+    def __init__(self, dataset_name):\n+        self.dataset_name = dataset_name\n+\n+\n+class DataSet:\n+    sonar = DataSetParam('sonar.csv')\n+    sonar_selected = DataSetParam('sonar_selected.csv')\n+\n+    \n+    \n+    \n+    \n+\n+\n+def load_dataset(dataset):\n+    dataset_path = os.path.join(DATASET_DIR, dataset)\n+\n+    # 尝试打开并读取CSV文件\n+    try:\n+        with open(dataset_path, 'r', encoding='utf-8') as csvfile:\n+            spamreader = csv.reader(csvfile)\n+            data = np.array(list(spamreader))\n+    except FileNotFoundError:\n+        print(f\"Error: The file {dataset_path} was not found.\")\n+        return None, None\n+    except Exception as e:\n+        print(f\"Error: An error occurred while reading the file: {e}\")\n+        return None, None\n+\n+    # 检查数据是否为空\n+    if data.size == 0:\n+        print(\"Error: The dataset is empty.\")\n+        return None, None\n+\n+    feature = data[:, :-1].astype(np.float64)\n+    labels = data[:, -1]\n+\n+    # 创建标签映射\n+    unique_labels = np.unique(labels)\n+    label_to_int = {label: idx for idx, label in enumerate(unique_labels)}\n+    int_labels = np.array([label_to_int[label] for label in labels], dtype=np.uint8)\n+    labell = int_labels.reshape(-1,1)\n+    \n+    # 将标签转换为独热矩阵\n+    one_hot_labels = np.zeros((int_labels.size, int_labels.max() + 1), dtype=np.uint8)\n+    one_hot_labels[np.arange(int_labels.size), int_labels] = 1\n+\n+    # print(\"======feature_size=====\", feature.shape)\n+    # print(\"======label_size=====\", labell.shape)\n+    return feature, one_hot_labels\n+\n+# 随机选择样本\n+def random_instance(feature_share, label_share, numberInstance):\n+    random_index = np.random.randint(0, numberInstance)\n+    core_instance_feature = feature_share[random_index]\n+    core_instance_label = label_share[random_index]\n+\n+    return core_instance_feature, \n+\n+\n+\n+def relief_mpc(feature_share, label_share):\n+    \n+    \n+\n+\n+\n+\n+def relief_mpc(\n+    instance = 208,\n+):\n+    crypten.init()\n+\n+    # Set random seed for reproducibility\n+    torch.manual_seed(1)\n+\n+    data_train = DataSet.sonar\n+    \n+    x, y = load_dataset(data_train.dataset_name)\n+\n+# NOTE：crypten.cryptensor \n+    # Encrypt features / labels\n+    x = crypten.cryptensor(x)\n+    y = crypten.cryptensor(y)\n+\n+    print(\"==================\")\n+    print(\"CrypTen Training\")\n+    print(\"==================\")\n+    print(y)\n+    \n+# NOTE：训练无差异\n+    w, b = relief_mpc(x,y, instance)\n+\n+    # if not skip_plaintext:\n+    #     logging.info(\"PyTorch Weights  :\")\n+    #     logging.info(w_torch)\n+    # logging.info(\"CrypTen Weights:\")\n+# NOTE：get_plain_text()\n+    # logging.info(w.get_plain_text())\n+\n+    # if not skip_plaintext:\n+    #     logging.info(\"PyTorch Bias  :\")\n+    #     logging.info(b_torch)\n+    # logging.info(\"CrypTen Bias:\")\n+    # logging.info(b.get_plain_text())\n"
                },
                {
                    "date": 1718803276875,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -68,15 +68,15 @@\n     random_index = np.random.randint(0, numberInstance)\n     core_instance_feature = feature_share[random_index]\n     core_instance_label = label_share[random_index]\n \n-    return core_instance_feature, \n+    return core_instance_feature, core_instance_label\n \n \n \n def relief_mpc(feature_share, label_share):\n+    sample_feature\n     \n-    \n \n \n \n \n@@ -116,239 +116,4 @@\n     #     logging.info(\"PyTorch Bias  :\")\n     #     logging.info(b_torch)\n     # logging.info(\"CrypTen Bias:\")\n     # logging.info(b.get_plain_text())\n-\n-import logging\n-import time\n-import csv\n-import os\n-import crypten\n-import torch\n-import numpy as np\n-from examples.meters import AverageMeter\n-\n-\n-DATASET_DIR = os.path.join(os.path.dirname(__file__), '../dataset')\n-\n-class DataSetParam:\n-    def __init__(self, dataset_name):\n-        self.dataset_name = dataset_name\n-\n-\n-class DataSet:\n-    sonar = DataSetParam('sonar.csv')\n-    sonar_selected = DataSetParam('sonar_selected.csv')\n-\n-    \n-    \n-    \n-    \n-\n-\n-def load_dataset(dataset):\n-    dataset_path = os.path.join(DATASET_DIR, dataset)\n-\n-    # 尝试打开并读取CSV文件\n-    try:\n-        with open(dataset_path, 'r', encoding='utf-8') as csvfile:\n-            spamreader = csv.reader(csvfile)\n-            data = np.array(list(spamreader))\n-    except FileNotFoundError:\n-        print(f\"Error: The file {dataset_path} was not found.\")\n-        return None, None\n-    except Exception as e:\n-        print(f\"Error: An error occurred while reading the file: {e}\")\n-        return None, None\n-\n-    # 检查数据是否为空\n-    if data.size == 0:\n-        print(\"Error: The dataset is empty.\")\n-        return None, None\n-\n-    feature = data[:, :-1].astype(np.float64)\n-    labels = data[:, -1]\n-\n-    # 创建标签映射\n-    unique_labels = np.unique(labels)\n-    label_to_int = {label: idx for idx, label in enumerate(unique_labels)}\n-    int_labels = np.array([label_to_int[label] for label in labels], dtype=np.uint8)\n-    labell = int_labels.reshape(-1,1)\n-    \n-    # 将标签转换为独热矩阵\n-    one_hot_labels = np.zeros((int_labels.size, int_labels.max() + 1), dtype=np.uint8)\n-    one_hot_labels[np.arange(int_labels.size), int_labels] = 1\n-\n-    # print(\"======feature_size=====\", feature.shape)\n-    # print(\"======label_size=====\", labell.shape)\n-    return feature, one_hot_labels\n-\n-# 随机选择样本\n-def random_instance(feature_share, label_share, numberInstance):\n-    random_index = np.random.randint(0, numberInstance)\n-    core_instance_feature = feature_share[random_index]\n-    core_instance_label = label_share[random_index]\n-\n-\n-\n-\n-def relief_mpc(feature_share, label_share):\n-    \n-    \n-\n-\n-\n-\n-def relief_mpc(\n-    instance = 208,\n-):\n-    crypten.init()\n-\n-    # Set random seed for reproducibility\n-    torch.manual_seed(1)\n-\n-    data_train = DataSet.sonar\n-    \n-    x, y = load_dataset(data_train.dataset_name)\n-\n-# NOTE：crypten.cryptensor \n-    # Encrypt features / labels\n-    x = crypten.cryptensor(x)\n-    y = crypten.cryptensor(y)\n-\n-    print(\"==================\")\n-    print(\"CrypTen Training\")\n-    print(\"==================\")\n-    print(y)\n-    \n-# NOTE：训练无差异\n-    w, b = relief_mpc(x,y, instance)\n-\n-    # if not skip_plaintext:\n-    #     logging.info(\"PyTorch Weights  :\")\n-    #     logging.info(w_torch)\n-    # logging.info(\"CrypTen Weights:\")\n-# NOTE：get_plain_text()\n-    # logging.info(w.get_plain_text())\n-\n-    # if not skip_plaintext:\n-    #     logging.info(\"PyTorch Bias  :\")\n-    #     logging.info(b_torch)\n-    # logging.info(\"CrypTen Bias:\")\n-    # logging.info(b.get_plain_text())\n-\n-import logging\n-import time\n-import csv\n-import os\n-import crypten\n-import torch\n-import numpy as np\n-from examples.meters import AverageMeter\n-\n-\n-DATASET_DIR = os.path.join(os.path.dirname(__file__), '../dataset')\n-\n-class DataSetParam:\n-    def __init__(self, dataset_name):\n-        self.dataset_name = dataset_name\n-\n-\n-class DataSet:\n-    sonar = DataSetParam('sonar.csv')\n-    sonar_selected = DataSetParam('sonar_selected.csv')\n-\n-    \n-    \n-    \n-    \n-\n-\n-def load_dataset(dataset):\n-    dataset_path = os.path.join(DATASET_DIR, dataset)\n-\n-    # 尝试打开并读取CSV文件\n-    try:\n-        with open(dataset_path, 'r', encoding='utf-8') as csvfile:\n-            spamreader = csv.reader(csvfile)\n-            data = np.array(list(spamreader))\n-    except FileNotFoundError:\n-        print(f\"Error: The file {dataset_path} was not found.\")\n-        return None, None\n-    except Exception as e:\n-        print(f\"Error: An error occurred while reading the file: {e}\")\n-        return None, None\n-\n-    # 检查数据是否为空\n-    if data.size == 0:\n-        print(\"Error: The dataset is empty.\")\n-        return None, None\n-\n-    feature = data[:, :-1].astype(np.float64)\n-    labels = data[:, -1]\n-\n-    # 创建标签映射\n-    unique_labels = np.unique(labels)\n-    label_to_int = {label: idx for idx, label in enumerate(unique_labels)}\n-    int_labels = np.array([label_to_int[label] for label in labels], dtype=np.uint8)\n-    labell = int_labels.reshape(-1,1)\n-    \n-    # 将标签转换为独热矩阵\n-    one_hot_labels = np.zeros((int_labels.size, int_labels.max() + 1), dtype=np.uint8)\n-    one_hot_labels[np.arange(int_labels.size), int_labels] = 1\n-\n-    # print(\"======feature_size=====\", feature.shape)\n-    # print(\"======label_size=====\", labell.shape)\n-    return feature, one_hot_labels\n-\n-# 随机选择样本\n-def random_instance(feature_share, label_share, numberInstance):\n-    random_index = np.random.randint(0, numberInstance)\n-    core_instance_feature = feature_share[random_index]\n-    core_instance_label = label_share[random_index]\n-\n-\n-\n-\n-def relief_mpc(feature_share, ):\n-    \n-\n-\n-\n-\n-def relief_mpc(\n-    instance = 208,\n-):\n-    crypten.init()\n-\n-    # Set random seed for reproducibility\n-    torch.manual_seed(1)\n-\n-    data_train = DataSet.sonar\n-    \n-    x, y = load_dataset(data_train.dataset_name)\n-\n-# NOTE：crypten.cryptensor \n-    # Encrypt features / labels\n-    x = crypten.cryptensor(x)\n-    y = crypten.cryptensor(y)\n-\n-    print(\"==================\")\n-    print(\"CrypTen Training\")\n-    print(\"==================\")\n-    print(y)\n-    \n-# NOTE：训练无差异\n-    w, b = relief_mpc(x,y, instance)\n-\n-    # if not skip_plaintext:\n-    #     logging.info(\"PyTorch Weights  :\")\n-    #     logging.info(w_torch)\n-    # logging.info(\"CrypTen Weights:\")\n-# NOTE：get_plain_text()\n-    # logging.info(w.get_plain_text())\n-\n-    # if not skip_plaintext:\n-    #     logging.info(\"PyTorch Bias  :\")\n-    #     logging.info(b_torch)\n-    # logging.info(\"CrypTen Bias:\")\n-    # logging.info(b.get_plain_text())\n"
                },
                {
                    "date": 1718803285523,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -73,9 +73,9 @@\n \n \n \n def relief_mpc(feature_share, label_share):\n-    sample_feature\n+    sample_feature, sample_label = random_instance(feature_share, label_share)\n     \n \n \n \n"
                },
                {
                    "date": 1718803293071,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,119 @@\n+\n+import logging\n+import time\n+import csv\n+import os\n+import crypten\n+import torch\n+import numpy as np\n+from examples.meters import AverageMeter\n+\n+\n+DATASET_DIR = os.path.join(os.path.dirname(__file__), '../dataset')\n+\n+class DataSetParam:\n+    def __init__(self, dataset_name):\n+        self.dataset_name = dataset_name\n+\n+\n+class DataSet:\n+    sonar = DataSetParam('sonar.csv')\n+    sonar_selected = DataSetParam('sonar_selected.csv')\n+\n+    \n+    \n+    \n+    \n+\n+\n+def load_dataset(dataset):\n+    dataset_path = os.path.join(DATASET_DIR, dataset)\n+\n+    # 尝试打开并读取CSV文件\n+    try:\n+        with open(dataset_path, 'r', encoding='utf-8') as csvfile:\n+            spamreader = csv.reader(csvfile)\n+            data = np.array(list(spamreader))\n+    except FileNotFoundError:\n+        print(f\"Error: The file {dataset_path} was not found.\")\n+        return None, None\n+    except Exception as e:\n+        print(f\"Error: An error occurred while reading the file: {e}\")\n+        return None, None\n+\n+    # 检查数据是否为空\n+    if data.size == 0:\n+        print(\"Error: The dataset is empty.\")\n+        return None, None\n+\n+    feature = data[:, :-1].astype(np.float64)\n+    labels = data[:, -1]\n+\n+    # 创建标签映射\n+    unique_labels = np.unique(labels)\n+    label_to_int = {label: idx for idx, label in enumerate(unique_labels)}\n+    int_labels = np.array([label_to_int[label] for label in labels], dtype=np.uint8)\n+    labell = int_labels.reshape(-1,1)\n+    \n+    # 将标签转换为独热矩阵\n+    one_hot_labels = np.zeros((int_labels.size, int_labels.max() + 1), dtype=np.uint8)\n+    one_hot_labels[np.arange(int_labels.size), int_labels] = 1\n+\n+    # print(\"======feature_size=====\", feature.shape)\n+    # print(\"======label_size=====\", labell.shape)\n+    return feature, one_hot_labels\n+\n+# 随机选择样本\n+def random_instance(feature_share, label_share, numberInstance):\n+    random_index = np.random.randint(0, numberInstance)\n+    core_instance_feature = feature_share[random_index]\n+    core_instance_label = label_share[random_index]\n+\n+    return core_instance_feature, core_instance_label\n+\n+\n+\n+def relief_mpc(feature_share, label_share):\n+    sample_feature, sample_label = random_instance(feature_share, label_share, numberInstance):\n+    \n+\n+\n+\n+\n+def relief_mpc(\n+    instance = 208,\n+):\n+    crypten.init()\n+\n+    # Set random seed for reproducibility\n+    torch.manual_seed(1)\n+\n+    data_train = DataSet.sonar\n+    \n+    x, y = load_dataset(data_train.dataset_name)\n+\n+# NOTE：crypten.cryptensor \n+    # Encrypt features / labels\n+    x = crypten.cryptensor(x)\n+    y = crypten.cryptensor(y)\n+\n+    print(\"==================\")\n+    print(\"CrypTen Training\")\n+    print(\"==================\")\n+    print(y)\n+    \n+# NOTE：训练无差异\n+    w, b = relief_mpc(x,y, instance)\n+\n+    # if not skip_plaintext:\n+    #     logging.info(\"PyTorch Weights  :\")\n+    #     logging.info(w_torch)\n+    # logging.info(\"CrypTen Weights:\")\n+# NOTE：get_plain_text()\n+    # logging.info(w.get_plain_text())\n+\n+    # if not skip_plaintext:\n+    #     logging.info(\"PyTorch Bias  :\")\n+    #     logging.info(b_torch)\n+    # logging.info(\"CrypTen Bias:\")\n+    # logging.info(b.get_plain_text())\n"
                },
                {
                    "date": 1718803299960,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -73,9 +73,9 @@\n \n \n \n def relief_mpc(feature_share, label_share):\n-    sample_feature, sample_label = random_instance(feature_share, label_share, numberInstance):\n+    sample_feature, sample_label = random_instance(feature_share, label_share):\n     \n \n \n \n@@ -116,123 +116,4 @@\n     #     logging.info(\"PyTorch Bias  :\")\n     #     logging.info(b_torch)\n     # logging.info(\"CrypTen Bias:\")\n     # logging.info(b.get_plain_text())\n-\n-import logging\n-import time\n-import csv\n-import os\n-import crypten\n-import torch\n-import numpy as np\n-from examples.meters import AverageMeter\n-\n-\n-DATASET_DIR = os.path.join(os.path.dirname(__file__), '../dataset')\n-\n-class DataSetParam:\n-    def __init__(self, dataset_name):\n-        self.dataset_name = dataset_name\n-\n-\n-class DataSet:\n-    sonar = DataSetParam('sonar.csv')\n-    sonar_selected = DataSetParam('sonar_selected.csv')\n-\n-    \n-    \n-    \n-    \n-\n-\n-def load_dataset(dataset):\n-    dataset_path = os.path.join(DATASET_DIR, dataset)\n-\n-    # 尝试打开并读取CSV文件\n-    try:\n-        with open(dataset_path, 'r', encoding='utf-8') as csvfile:\n-            spamreader = csv.reader(csvfile)\n-            data = np.array(list(spamreader))\n-    except FileNotFoundError:\n-        print(f\"Error: The file {dataset_path} was not found.\")\n-        return None, None\n-    except Exception as e:\n-        print(f\"Error: An error occurred while reading the file: {e}\")\n-        return None, None\n-\n-    # 检查数据是否为空\n-    if data.size == 0:\n-        print(\"Error: The dataset is empty.\")\n-        return None, None\n-\n-    feature = data[:, :-1].astype(np.float64)\n-    labels = data[:, -1]\n-\n-    # 创建标签映射\n-    unique_labels = np.unique(labels)\n-    label_to_int = {label: idx for idx, label in enumerate(unique_labels)}\n-    int_labels = np.array([label_to_int[label] for label in labels], dtype=np.uint8)\n-    labell = int_labels.reshape(-1,1)\n-    \n-    # 将标签转换为独热矩阵\n-    one_hot_labels = np.zeros((int_labels.size, int_labels.max() + 1), dtype=np.uint8)\n-    one_hot_labels[np.arange(int_labels.size), int_labels] = 1\n-\n-    # print(\"======feature_size=====\", feature.shape)\n-    # print(\"======label_size=====\", labell.shape)\n-    return feature, one_hot_labels\n-\n-# 随机选择样本\n-def random_instance(feature_share, label_share, numberInstance):\n-    random_index = np.random.randint(0, numberInstance)\n-    core_instance_feature = feature_share[random_index]\n-    core_instance_label = label_share[random_index]\n-\n-    return core_instance_feature, core_instance_label\n-\n-\n-\n-def relief_mpc(feature_share, label_share):\n-    sample_feature, sample_label = random_instance(feature_share, label_share)\n-    \n-\n-\n-\n-\n-def relief_mpc(\n-    instance = 208,\n-):\n-    crypten.init()\n-\n-    # Set random seed for reproducibility\n-    torch.manual_seed(1)\n-\n-    data_train = DataSet.sonar\n-    \n-    x, y = load_dataset(data_train.dataset_name)\n-\n-# NOTE：crypten.cryptensor \n-    # Encrypt features / labels\n-    x = crypten.cryptensor(x)\n-    y = crypten.cryptensor(y)\n-\n-    print(\"==================\")\n-    print(\"CrypTen Training\")\n-    print(\"==================\")\n-    print(y)\n-    \n-# NOTE：训练无差异\n-    w, b = relief_mpc(x,y, instance)\n-\n-    # if not skip_plaintext:\n-    #     logging.info(\"PyTorch Weights  :\")\n-    #     logging.info(w_torch)\n-    # logging.info(\"CrypTen Weights:\")\n-# NOTE：get_plain_text()\n-    # logging.info(w.get_plain_text())\n-\n-    # if not skip_plaintext:\n-    #     logging.info(\"PyTorch Bias  :\")\n-    #     logging.info(b_torch)\n-    # logging.info(\"CrypTen Bias:\")\n-    # logging.info(b.get_plain_text())\n"
                },
                {
                    "date": 1718803305953,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -73,9 +73,9 @@\n \n \n \n def relief_mpc(feature_share, label_share):\n-    sample_feature, sample_label = random_instance(feature_share, label_share):\n+    sample_feature, sample_label = random_instance(feature_share, label_share, numberInstance):\n     \n \n \n \n"
                },
                {
                    "date": 1718803320118,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,119 @@\n+\n+import logging\n+import time\n+import csv\n+import os\n+import crypten\n+import torch\n+import numpy as np\n+from examples.meters import AverageMeter\n+\n+\n+DATASET_DIR = os.path.join(os.path.dirname(__file__), '../dataset')\n+\n+class DataSetParam:\n+    def __init__(self, dataset_name):\n+        self.dataset_name = dataset_name\n+\n+\n+class DataSet:\n+    sonar = DataSetParam('sonar.csv')\n+    sonar_selected = DataSetParam('sonar_selected.csv')\n+\n+    \n+    \n+    \n+    \n+\n+\n+def load_dataset(dataset):\n+    dataset_path = os.path.join(DATASET_DIR, dataset)\n+\n+    # 尝试打开并读取CSV文件\n+    try:\n+        with open(dataset_path, 'r', encoding='utf-8') as csvfile:\n+            spamreader = csv.reader(csvfile)\n+            data = np.array(list(spamreader))\n+    except FileNotFoundError:\n+        print(f\"Error: The file {dataset_path} was not found.\")\n+        return None, None\n+    except Exception as e:\n+        print(f\"Error: An error occurred while reading the file: {e}\")\n+        return None, None\n+\n+    # 检查数据是否为空\n+    if data.size == 0:\n+        print(\"Error: The dataset is empty.\")\n+        return None, None\n+\n+    feature = data[:, :-1].astype(np.float64)\n+    labels = data[:, -1]\n+\n+    # 创建标签映射\n+    unique_labels = np.unique(labels)\n+    label_to_int = {label: idx for idx, label in enumerate(unique_labels)}\n+    int_labels = np.array([label_to_int[label] for label in labels], dtype=np.uint8)\n+    labell = int_labels.reshape(-1,1)\n+    \n+    # 将标签转换为独热矩阵\n+    one_hot_labels = np.zeros((int_labels.size, int_labels.max() + 1), dtype=np.uint8)\n+    one_hot_labels[np.arange(int_labels.size), int_labels] = 1\n+\n+    # print(\"======feature_size=====\", feature.shape)\n+    # print(\"======label_size=====\", labell.shape)\n+    return feature, one_hot_labels\n+\n+# 随机选择样本\n+def random_instance(feature_share, label_share, numberInstance):\n+    random_index = np.random.randint(0, numberInstance)\n+    core_instance_feature = feature_share[random_index]\n+    core_instance_label = label_share[random_index]\n+\n+    return core_instance_feature, core_instance_label\n+\n+\n+\n+def relief_mpc(feature_share, label_share, numberInstance):\n+    sample_feature, sample_label = random_instance(feature_share, label_share, numberInstance)\n+    \n+\n+\n+\n+\n+def relief_mpc(\n+    instance = 208,\n+):\n+    crypten.init()\n+\n+    # Set random seed for reproducibility\n+    torch.manual_seed(1)\n+\n+    data_train = DataSet.sonar\n+    \n+    x, y = load_dataset(data_train.dataset_name)\n+\n+# NOTE：crypten.cryptensor \n+    # Encrypt features / labels\n+    x = crypten.cryptensor(x)\n+    y = crypten.cryptensor(y)\n+\n+    print(\"==================\")\n+    print(\"CrypTen Training\")\n+    print(\"==================\")\n+    print(y)\n+    \n+# NOTE：训练无差异\n+    w, b = relief_mpc(x,y, instance)\n+\n+    # if not skip_plaintext:\n+    #     logging.info(\"PyTorch Weights  :\")\n+    #     logging.info(w_torch)\n+    # logging.info(\"CrypTen Weights:\")\n+# NOTE：get_plain_text()\n+    # logging.info(w.get_plain_text())\n+\n+    # if not skip_plaintext:\n+    #     logging.info(\"PyTorch Bias  :\")\n+    #     logging.info(b_torch)\n+    # logging.info(\"CrypTen Bias:\")\n+    # logging.info(b.get_plain_text())\n"
                },
                {
                    "date": 1718803621387,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -74,8 +74,9 @@\n \n \n def relief_mpc(feature_share, label_share, numberInstance):\n     sample_feature, sample_label = random_instance(feature_share, label_share, numberInstance)\n+    class——\n     \n \n \n \n@@ -116,123 +117,4 @@\n     #     logging.info(\"PyTorch Bias  :\")\n     #     logging.info(b_torch)\n     # logging.info(\"CrypTen Bias:\")\n     # logging.info(b.get_plain_text())\n-\n-import logging\n-import time\n-import csv\n-import os\n-import crypten\n-import torch\n-import numpy as np\n-from examples.meters import AverageMeter\n-\n-\n-DATASET_DIR = os.path.join(os.path.dirname(__file__), '../dataset')\n-\n-class DataSetParam:\n-    def __init__(self, dataset_name):\n-        self.dataset_name = dataset_name\n-\n-\n-class DataSet:\n-    sonar = DataSetParam('sonar.csv')\n-    sonar_selected = DataSetParam('sonar_selected.csv')\n-\n-    \n-    \n-    \n-    \n-\n-\n-def load_dataset(dataset):\n-    dataset_path = os.path.join(DATASET_DIR, dataset)\n-\n-    # 尝试打开并读取CSV文件\n-    try:\n-        with open(dataset_path, 'r', encoding='utf-8') as csvfile:\n-            spamreader = csv.reader(csvfile)\n-            data = np.array(list(spamreader))\n-    except FileNotFoundError:\n-        print(f\"Error: The file {dataset_path} was not found.\")\n-        return None, None\n-    except Exception as e:\n-        print(f\"Error: An error occurred while reading the file: {e}\")\n-        return None, None\n-\n-    # 检查数据是否为空\n-    if data.size == 0:\n-        print(\"Error: The dataset is empty.\")\n-        return None, None\n-\n-    feature = data[:, :-1].astype(np.float64)\n-    labels = data[:, -1]\n-\n-    # 创建标签映射\n-    unique_labels = np.unique(labels)\n-    label_to_int = {label: idx for idx, label in enumerate(unique_labels)}\n-    int_labels = np.array([label_to_int[label] for label in labels], dtype=np.uint8)\n-    labell = int_labels.reshape(-1,1)\n-    \n-    # 将标签转换为独热矩阵\n-    one_hot_labels = np.zeros((int_labels.size, int_labels.max() + 1), dtype=np.uint8)\n-    one_hot_labels[np.arange(int_labels.size), int_labels] = 1\n-\n-    # print(\"======feature_size=====\", feature.shape)\n-    # print(\"======label_size=====\", labell.shape)\n-    return feature, one_hot_labels\n-\n-# 随机选择样本\n-def random_instance(feature_share, label_share, numberInstance):\n-    random_index = np.random.randint(0, numberInstance)\n-    core_instance_feature = feature_share[random_index]\n-    core_instance_label = label_share[random_index]\n-\n-    return core_instance_feature, core_instance_label\n-\n-\n-\n-def relief_mpc(feature_share, label_share):\n-    sample_feature, sample_label = random_instance(feature_share, label_share, numberInstance):\n-    \n-\n-\n-\n-\n-def relief_mpc(\n-    instance = 208,\n-):\n-    crypten.init()\n-\n-    # Set random seed for reproducibility\n-    torch.manual_seed(1)\n-\n-    data_train = DataSet.sonar\n-    \n-    x, y = load_dataset(data_train.dataset_name)\n-\n-# NOTE：crypten.cryptensor \n-    # Encrypt features / labels\n-    x = crypten.cryptensor(x)\n-    y = crypten.cryptensor(y)\n-\n-    print(\"==================\")\n-    print(\"CrypTen Training\")\n-    print(\"==================\")\n-    print(y)\n-    \n-# NOTE：训练无差异\n-    w, b = relief_mpc(x,y, instance)\n-\n-    # if not skip_plaintext:\n-    #     logging.info(\"PyTorch Weights  :\")\n-    #     logging.info(w_torch)\n-    # logging.info(\"CrypTen Weights:\")\n-# NOTE：get_plain_text()\n-    # logging.info(w.get_plain_text())\n-\n-    # if not skip_plaintext:\n-    #     logging.info(\"PyTorch Bias  :\")\n-    #     logging.info(b_torch)\n-    # logging.info(\"CrypTen Bias:\")\n-    # logging.info(b.get_plain_text())\n"
                },
                {
                    "date": 1718803626489,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -74,9 +74,9 @@\n \n \n def relief_mpc(feature_share, label_share, numberInstance):\n     sample_feature, sample_label = random_instance(feature_share, label_share, numberInstance)\n-    class——\n+    class_judge = \n     \n \n \n \n"
                },
                {
                    "date": 1718803674518,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -74,9 +74,9 @@\n \n \n def relief_mpc(feature_share, label_share, numberInstance):\n     sample_feature, sample_label = random_instance(feature_share, label_share, numberInstance)\n-    class_judge = \n+    class_judge = sample_label\n     \n \n \n \n"
                },
                {
                    "date": 1718803682265,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -74,9 +74,9 @@\n \n \n def relief_mpc(feature_share, label_share, numberInstance):\n     sample_feature, sample_label = random_instance(feature_share, label_share, numberInstance)\n-    class_judge = sample_label\n+    class_judge = sample_label.dot(label_share)\n     \n \n \n \n"
                },
                {
                    "date": 1718803695959,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -75,8 +75,9 @@\n \n def relief_mpc(feature_share, label_share, numberInstance):\n     sample_feature, sample_label = random_instance(feature_share, label_share, numberInstance)\n     class_judge = sample_label.dot(label_share)\n+    print()\n     \n \n \n \n"
                },
                {
                    "date": 1718803703714,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -75,9 +75,9 @@\n \n def relief_mpc(feature_share, label_share, numberInstance):\n     sample_feature, sample_label = random_instance(feature_share, label_share, numberInstance)\n     class_judge = sample_label.dot(label_share)\n-    print()\n+    print(\"class_judge\", )\n     \n \n \n \n"
                },
                {
                    "date": 1718803712193,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -75,9 +75,9 @@\n \n def relief_mpc(feature_share, label_share, numberInstance):\n     sample_feature, sample_label = random_instance(feature_share, label_share, numberInstance)\n     class_judge = sample_label.dot(label_share)\n-    print(\"class_judge\", )\n+    print(\"class_judge\", class_judge.get_plain_text)\n     \n \n \n \n"
                },
                {
                    "date": 1718803721232,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -101,9 +101,9 @@\n \n     print(\"==================\")\n     print(\"CrypTen Training\")\n     print(\"==================\")\n-    print(y)\n+\n     \n # NOTE：训练无差异\n     w, b = relief_mpc(x,y, instance)\n \n"
                },
                {
                    "date": 1718803783827,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -77,8 +77,10 @@\n     sample_feature, sample_label = random_instance(feature_share, label_share, numberInstance)\n     class_judge = sample_label.dot(label_share)\n     print(\"class_judge\", class_judge.get_plain_text)\n     \n+    return \n+    \n \n \n \n \n"
                },
                {
                    "date": 1718803790685,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -77,9 +77,8 @@\n     sample_feature, sample_label = random_instance(feature_share, label_share, numberInstance)\n     class_judge = sample_label.dot(label_share)\n     print(\"class_judge\", class_judge.get_plain_text)\n     \n-    return \n     \n \n \n \n"
                },
                {
                    "date": 1718803804890,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -105,9 +105,9 @@\n     print(\"==================\")\n \n     \n # NOTE：训练无差异\n-    w, b = relief_mpc(x,y, instance)\n+    relief_mpc(x, y, instance)\n \n     # if not skip_plaintext:\n     #     logging.info(\"PyTorch Weights  :\")\n     #     logging.info(w_torch)\n"
                },
                {
                    "date": 1718803846511,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -71,15 +71,9 @@\n \n     return core_instance_feature, core_instance_label\n \n \n-\n-def relief_mpc(feature_share, label_share, numberInstance):\n-    sample_feature, sample_label = random_instance(feature_share, label_share, numberInstance)\n-    class_judge = sample_label.dot(label_share)\n-    print(\"class_judge\", class_judge.get_plain_text)\n     \n-    \n \n \n \n \n"
                },
                {
                    "date": 1718803861321,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -71,9 +71,15 @@\n \n     return core_instance_feature, core_instance_label\n \n \n+\n+def relief_mpc(feature_share, label_share, numberInstance):\n+    sample_feature, sample_label = random_instance(feature_share, label_share, numberInstance)\n+    class_judge = sample_label.dot(label_share)\n+    print(\"class_judge\", class_judge.get_plain_text)\n     \n+    \n \n \n \n \n"
                },
                {
                    "date": 1718803939881,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -105,9 +105,9 @@\n     print(\"==================\")\n \n     \n # NOTE：训练无差异\n-    relief_mpc(x, y, instance)\n+    relief_mpc(x, y)\n \n     # if not skip_plaintext:\n     #     logging.info(\"PyTorch Weights  :\")\n     #     logging.info(w_torch)\n"
                },
                {
                    "date": 1718803946795,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -72,10 +72,10 @@\n     return core_instance_feature, core_instance_label\n \n \n \n-def relief_mpc(feature_share, label_share, numberInstance):\n-    sample_feature, sample_label = random_instance(feature_share, label_share, numberInstance)\n+def relief_mpc(feature_share, label_share):\n+    sample_feature, sample_label = random_instance(feature_share, label_share, instance)\n     class_judge = sample_label.dot(label_share)\n     print(\"class_judge\", class_judge.get_plain_text)\n     \n     \n"
                },
                {
                    "date": 1718803977286,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -72,10 +72,10 @@\n     return core_instance_feature, core_instance_label\n \n \n \n-def relief_mpc(feature_share, label_share):\n-    sample_feature, sample_label = random_instance(feature_share, label_share, instance)\n+def relief_mpc(feature_share, label_share, numberInstance):\n+    sample_feature, sample_label = random_instance(feature_share, label_share, numberInstance)\n     class_judge = sample_label.dot(label_share)\n     print(\"class_judge\", class_judge.get_plain_text)\n     \n     \n@@ -105,9 +105,9 @@\n     print(\"==================\")\n \n     \n # NOTE：训练无差异\n-    relief_mpc(x, y)\n+    relief_mpc(x, y, inst)\n \n     # if not skip_plaintext:\n     #     logging.info(\"PyTorch Weights  :\")\n     #     logging.info(w_torch)\n"
                },
                {
                    "date": 1718803994019,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -83,9 +83,9 @@\n \n \n \n def relief_mpc(\n-    instance = 208,\n+    instances = 208,\n ):\n     crypten.init()\n \n     # Set random seed for reproducibility\n@@ -105,9 +105,9 @@\n     print(\"==================\")\n \n     \n # NOTE：训练无差异\n-    relief_mpc(x, y, inst)\n+    relief_mpc(x, y, instance=instance)\n \n     # if not skip_plaintext:\n     #     logging.info(\"PyTorch Weights  :\")\n     #     logging.info(w_torch)\n"
                },
                {
                    "date": 1718804024047,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -105,9 +105,9 @@\n     print(\"==================\")\n \n     \n # NOTE：训练无差异\n-    relief_mpc(x, y, instance=instance)\n+    relief_mpc(x, y, instances=instances)\n \n     # if not skip_plaintext:\n     #     logging.info(\"PyTorch Weights  :\")\n     #     logging.info(w_torch)\n"
                },
                {
                    "date": 1718804114018,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,122 @@\n+\n+import logging\n+import time\n+import csv\n+import os\n+import crypten\n+import torch\n+import numpy as np\n+from examples.meters import AverageMeter\n+\n+\n+DATASET_DIR = os.path.join(os.path.dirname(__file__), '../dataset')\n+\n+class DataSetParam:\n+    def __init__(self, dataset_name):\n+        self.dataset_name = dataset_name\n+\n+\n+class DataSet:\n+    sonar = DataSetParam('sonar.csv')\n+    sonar_selected = DataSetParam('sonar_selected.csv')\n+\n+    \n+    \n+    \n+    \n+\n+\n+def load_dataset(dataset):\n+    dataset_path = os.path.join(DATASET_DIR, dataset)\n+\n+    # 尝试打开并读取CSV文件\n+    try:\n+        with open(dataset_path, 'r', encoding='utf-8') as csvfile:\n+            spamreader = csv.reader(csvfile)\n+            data = np.array(list(spamreader))\n+    except FileNotFoundError:\n+        print(f\"Error: The file {dataset_path} was not found.\")\n+        return None, None\n+    except Exception as e:\n+        print(f\"Error: An error occurred while reading the file: {e}\")\n+        return None, None\n+\n+    # 检查数据是否为空\n+    if data.size == 0:\n+        print(\"Error: The dataset is empty.\")\n+        return None, None\n+\n+    feature = data[:, :-1].astype(np.float64)\n+    labels = data[:, -1]\n+\n+    # 创建标签映射\n+    unique_labels = np.unique(labels)\n+    label_to_int = {label: idx for idx, label in enumerate(unique_labels)}\n+    int_labels = np.array([label_to_int[label] for label in labels], dtype=np.uint8)\n+    labell = int_labels.reshape(-1,1)\n+    \n+    # 将标签转换为独热矩阵\n+    one_hot_labels = np.zeros((int_labels.size, int_labels.max() + 1), dtype=np.uint8)\n+    one_hot_labels[np.arange(int_labels.size), int_labels] = 1\n+\n+    # print(\"======feature_size=====\", feature.shape)\n+    # print(\"======label_size=====\", labell.shape)\n+    return feature, one_hot_labels\n+\n+# 随机选择样本\n+def random_instance(feature_share, label_share, numberInstance):\n+    random_index = np.random.randint(0, numberInstance)\n+    core_instance_feature = feature_share[random_index]\n+    core_instance_label = label_share[random_index]\n+\n+    return core_instance_feature, core_instance_label\n+\n+\n+\n+def relief_mpc(feature_share, label_share, numberInstance):\n+    sample_feature, sample_label = random_instance(feature_share, label_share, instance)\n+    class_judge = sample_label.dot(label_share)\n+    print(\"class_judge\", class_judge.get_plain_text)\n+    \n+    \n+\n+\n+\n+\n+def relief_mpc(\n+    instances = 208,\n+):\n+    crypten.init()\n+\n+    # Set random seed for reproducibility\n+    torch.manual_seed(1)\n+\n+    data_train = DataSet.sonar\n+    \n+    x, y = load_dataset(data_train.dataset_name)\n+\n+# NOTE：crypten.cryptensor \n+    # Encrypt features / labels\n+    x = crypten.cryptensor(x)\n+    y = crypten.cryptensor(y)\n+\n+    print(\"==================\")\n+    print(\"CrypTen Training\")\n+    print(\"==================\")\n+\n+    \n+# NOTE：训练无差异\n+    relief_mpc(x, y, instances=instances)\n+\n+    # if not skip_plaintext:\n+    #     logging.info(\"PyTorch Weights  :\")\n+    #     logging.info(w_torch)\n+    # logging.info(\"CrypTen Weights:\")\n+# NOTE：get_plain_text()\n+    # logging.info(w.get_plain_text())\n+\n+    # if not skip_plaintext:\n+    #     logging.info(\"PyTorch Bias  :\")\n+    #     logging.info(b_torch)\n+    # logging.info(\"CrypTen Bias:\")\n+    # logging.info(b.get_plain_text())\n"
                },
                {
                    "date": 1718804120173,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -72,10 +72,10 @@\n     return core_instance_feature, core_instance_label\n \n \n \n-def relief_mpc(feature_share, label_share, numberInstance):\n-    sample_feature, sample_label = random_instance(feature_share, label_share, instance)\n+def relief_mpc(feature_share, label_share, instances):\n+    sample_feature, sample_label = random_instance(feature_share, label_share, instances)\n     class_judge = sample_label.dot(label_share)\n     print(\"class_judge\", class_judge.get_plain_text)\n     \n     \n@@ -119,126 +119,4 @@\n     #     logging.info(\"PyTorch Bias  :\")\n     #     logging.info(b_torch)\n     # logging.info(\"CrypTen Bias:\")\n     # logging.info(b.get_plain_text())\n-\n-import logging\n-import time\n-import csv\n-import os\n-import crypten\n-import torch\n-import numpy as np\n-from examples.meters import AverageMeter\n-\n-\n-DATASET_DIR = os.path.join(os.path.dirname(__file__), '../dataset')\n-\n-class DataSetParam:\n-    def __init__(self, dataset_name):\n-        self.dataset_name = dataset_name\n-\n-\n-class DataSet:\n-    sonar = DataSetParam('sonar.csv')\n-    sonar_selected = DataSetParam('sonar_selected.csv')\n-\n-    \n-    \n-    \n-    \n-\n-\n-def load_dataset(dataset):\n-    dataset_path = os.path.join(DATASET_DIR, dataset)\n-\n-    # 尝试打开并读取CSV文件\n-    try:\n-        with open(dataset_path, 'r', encoding='utf-8') as csvfile:\n-            spamreader = csv.reader(csvfile)\n-            data = np.array(list(spamreader))\n-    except FileNotFoundError:\n-        print(f\"Error: The file {dataset_path} was not found.\")\n-        return None, None\n-    except Exception as e:\n-        print(f\"Error: An error occurred while reading the file: {e}\")\n-        return None, None\n-\n-    # 检查数据是否为空\n-    if data.size == 0:\n-        print(\"Error: The dataset is empty.\")\n-        return None, None\n-\n-    feature = data[:, :-1].astype(np.float64)\n-    labels = data[:, -1]\n-\n-    # 创建标签映射\n-    unique_labels = np.unique(labels)\n-    label_to_int = {label: idx for idx, label in enumerate(unique_labels)}\n-    int_labels = np.array([label_to_int[label] for label in labels], dtype=np.uint8)\n-    labell = int_labels.reshape(-1,1)\n-    \n-    # 将标签转换为独热矩阵\n-    one_hot_labels = np.zeros((int_labels.size, int_labels.max() + 1), dtype=np.uint8)\n-    one_hot_labels[np.arange(int_labels.size), int_labels] = 1\n-\n-    # print(\"======feature_size=====\", feature.shape)\n-    # print(\"======label_size=====\", labell.shape)\n-    return feature, one_hot_labels\n-\n-# 随机选择样本\n-def random_instance(feature_share, label_share, numberInstance):\n-    random_index = np.random.randint(0, numberInstance)\n-    core_instance_feature = feature_share[random_index]\n-    core_instance_label = label_share[random_index]\n-\n-    return core_instance_feature, core_instance_label\n-\n-\n-\n-def relief_mpc(feature_share, label_share, numberInstance):\n-    sample_feature, sample_label = random_instance(feature_share, label_share, numberInstance)\n-    class_judge = sample_label.dot(label_share)\n-    print(\"class_judge\", class_judge.get_plain_text)\n-    \n-    \n-\n-\n-\n-\n-def relief_mpc(\n-    instances = 208,\n-):\n-    crypten.init()\n-\n-    # Set random seed for reproducibility\n-    torch.manual_seed(1)\n-\n-    data_train = DataSet.sonar\n-    \n-    x, y = load_dataset(data_train.dataset_name)\n-\n-# NOTE：crypten.cryptensor \n-    # Encrypt features / labels\n-    x = crypten.cryptensor(x)\n-    y = crypten.cryptensor(y)\n-\n-    print(\"==================\")\n-    print(\"CrypTen Training\")\n-    print(\"==================\")\n-\n-    \n-# NOTE：训练无差异\n-    relief_mpc(x, y, instances=instances)\n-\n-    # if not skip_plaintext:\n-    #     logging.info(\"PyTorch Weights  :\")\n-    #     logging.info(w_torch)\n-    # logging.info(\"CrypTen Weights:\")\n-# NOTE：get_plain_text()\n-    # logging.info(w.get_plain_text())\n-\n-    # if not skip_plaintext:\n-    #     logging.info(\"PyTorch Bias  :\")\n-    #     logging.info(b_torch)\n-    # logging.info(\"CrypTen Bias:\")\n-    # logging.info(b.get_plain_text())\n"
                },
                {
                    "date": 1718804175415,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,122 @@\n+\n+import logging\n+import time\n+import csv\n+import os\n+import crypten\n+import torch\n+import numpy as np\n+from examples.meters import AverageMeter\n+\n+\n+DATASET_DIR = os.path.join(os.path.dirname(__file__), '../dataset')\n+\n+class DataSetParam:\n+    def __init__(self, dataset_name):\n+        self.dataset_name = dataset_name\n+\n+\n+class DataSet:\n+    sonar = DataSetParam('sonar.csv')\n+    sonar_selected = DataSetParam('sonar_selected.csv')\n+\n+    \n+    \n+    \n+    \n+\n+\n+def load_dataset(dataset):\n+    dataset_path = os.path.join(DATASET_DIR, dataset)\n+\n+    # 尝试打开并读取CSV文件\n+    try:\n+        with open(dataset_path, 'r', encoding='utf-8') as csvfile:\n+            spamreader = csv.reader(csvfile)\n+            data = np.array(list(spamreader))\n+    except FileNotFoundError:\n+        print(f\"Error: The file {dataset_path} was not found.\")\n+        return None, None\n+    except Exception as e:\n+        print(f\"Error: An error occurred while reading the file: {e}\")\n+        return None, None\n+\n+    # 检查数据是否为空\n+    if data.size == 0:\n+        print(\"Error: The dataset is empty.\")\n+        return None, None\n+\n+    feature = data[:, :-1].astype(np.float64)\n+    labels = data[:, -1]\n+\n+    # 创建标签映射\n+    unique_labels = np.unique(labels)\n+    label_to_int = {label: idx for idx, label in enumerate(unique_labels)}\n+    int_labels = np.array([label_to_int[label] for label in labels], dtype=np.uint8)\n+    labell = int_labels.reshape(-1,1)\n+    \n+    # 将标签转换为独热矩阵\n+    one_hot_labels = np.zeros((int_labels.size, int_labels.max() + 1), dtype=np.uint8)\n+    one_hot_labels[np.arange(int_labels.size), int_labels] = 1\n+\n+    # print(\"======feature_size=====\", feature.shape)\n+    # print(\"======label_size=====\", labell.shape)\n+    return feature, one_hot_labels\n+\n+# 随机选择样本\n+def random_instance(feature_share, label_share, instances):\n+    random_index = np.random.randint(0, instances)\n+    core_instance_feature = feature_share[random_index]\n+    core_instance_label = label_share[random_index]\n+\n+    return core_instance_feature, core_instance_label\n+\n+\n+\n+def relief_mpc(feature_share, label_share, instances):\n+    sample_feature, sample_label = random_instance(feature_share, label_share, instances)\n+    class_judge = sample_label.dot(label_share)\n+    print(\"class_judge\", class_judge.get_plain_text)\n+    \n+    \n+\n+\n+\n+\n+def relief_mpc(\n+    instance = 208,\n+):\n+    crypten.init()\n+\n+    # Set random seed for reproducibility\n+    torch.manual_seed(1)\n+\n+    data_train = DataSet.sonar\n+    \n+    x, y = load_dataset(data_train.dataset_name)\n+\n+# NOTE：crypten.cryptensor \n+    # Encrypt features / labels\n+    x = crypten.cryptensor(x)\n+    y = crypten.cryptensor(y)\n+\n+    print(\"==================\")\n+    print(\"CrypTen Training\")\n+    print(\"==================\")\n+\n+    \n+# NOTE：训练无差异\n+    relief_mpc(x, y, instances=instances)\n+\n+    # if not skip_plaintext:\n+    #     logging.info(\"PyTorch Weights  :\")\n+    #     logging.info(w_torch)\n+    # logging.info(\"CrypTen Weights:\")\n+# NOTE：get_plain_text()\n+    # logging.info(w.get_plain_text())\n+\n+    # if not skip_plaintext:\n+    #     logging.info(\"PyTorch Bias  :\")\n+    #     logging.info(b_torch)\n+    # logging.info(\"CrypTen Bias:\")\n+    # logging.info(b.get_plain_text())\n"
                },
                {
                    "date": 1718804196013,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -105,9 +105,9 @@\n     print(\"==================\")\n \n     \n # NOTE：训练无差异\n-    relief_mpc(x, y, instances=instances)\n+    relief_mpc(x, y, instance)\n \n     # if not skip_plaintext:\n     #     logging.info(\"PyTorch Weights  :\")\n     #     logging.info(w_torch)\n@@ -119,126 +119,4 @@\n     #     logging.info(\"PyTorch Bias  :\")\n     #     logging.info(b_torch)\n     # logging.info(\"CrypTen Bias:\")\n     # logging.info(b.get_plain_text())\n-\n-import logging\n-import time\n-import csv\n-import os\n-import crypten\n-import torch\n-import numpy as np\n-from examples.meters import AverageMeter\n-\n-\n-DATASET_DIR = os.path.join(os.path.dirname(__file__), '../dataset')\n-\n-class DataSetParam:\n-    def __init__(self, dataset_name):\n-        self.dataset_name = dataset_name\n-\n-\n-class DataSet:\n-    sonar = DataSetParam('sonar.csv')\n-    sonar_selected = DataSetParam('sonar_selected.csv')\n-\n-    \n-    \n-    \n-    \n-\n-\n-def load_dataset(dataset):\n-    dataset_path = os.path.join(DATASET_DIR, dataset)\n-\n-    # 尝试打开并读取CSV文件\n-    try:\n-        with open(dataset_path, 'r', encoding='utf-8') as csvfile:\n-            spamreader = csv.reader(csvfile)\n-            data = np.array(list(spamreader))\n-    except FileNotFoundError:\n-        print(f\"Error: The file {dataset_path} was not found.\")\n-        return None, None\n-    except Exception as e:\n-        print(f\"Error: An error occurred while reading the file: {e}\")\n-        return None, None\n-\n-    # 检查数据是否为空\n-    if data.size == 0:\n-        print(\"Error: The dataset is empty.\")\n-        return None, None\n-\n-    feature = data[:, :-1].astype(np.float64)\n-    labels = data[:, -1]\n-\n-    # 创建标签映射\n-    unique_labels = np.unique(labels)\n-    label_to_int = {label: idx for idx, label in enumerate(unique_labels)}\n-    int_labels = np.array([label_to_int[label] for label in labels], dtype=np.uint8)\n-    labell = int_labels.reshape(-1,1)\n-    \n-    # 将标签转换为独热矩阵\n-    one_hot_labels = np.zeros((int_labels.size, int_labels.max() + 1), dtype=np.uint8)\n-    one_hot_labels[np.arange(int_labels.size), int_labels] = 1\n-\n-    # print(\"======feature_size=====\", feature.shape)\n-    # print(\"======label_size=====\", labell.shape)\n-    return feature, one_hot_labels\n-\n-# 随机选择样本\n-def random_instance(feature_share, label_share, numberInstance):\n-    random_index = np.random.randint(0, numberInstance)\n-    core_instance_feature = feature_share[random_index]\n-    core_instance_label = label_share[random_index]\n-\n-    return core_instance_feature, core_instance_label\n-\n-\n-\n-def relief_mpc(feature_share, label_share, instances):\n-    sample_feature, sample_label = random_instance(feature_share, label_share, instances)\n-    class_judge = sample_label.dot(label_share)\n-    print(\"class_judge\", class_judge.get_plain_text)\n-    \n-    \n-\n-\n-\n-\n-def relief_mpc(\n-    instances = 208,\n-):\n-    crypten.init()\n-\n-    # Set random seed for reproducibility\n-    torch.manual_seed(1)\n-\n-    data_train = DataSet.sonar\n-    \n-    x, y = load_dataset(data_train.dataset_name)\n-\n-# NOTE：crypten.cryptensor \n-    # Encrypt features / labels\n-    x = crypten.cryptensor(x)\n-    y = crypten.cryptensor(y)\n-\n-    print(\"==================\")\n-    print(\"CrypTen Training\")\n-    print(\"==================\")\n-\n-    \n-# NOTE：训练无差异\n-    relief_mpc(x, y, instances=instances)\n-\n-    # if not skip_plaintext:\n-    #     logging.info(\"PyTorch Weights  :\")\n-    #     logging.info(w_torch)\n-    # logging.info(\"CrypTen Weights:\")\n-# NOTE：get_plain_text()\n-    # logging.info(w.get_plain_text())\n-\n-    # if not skip_plaintext:\n-    #     logging.info(\"PyTorch Bias  :\")\n-    #     logging.info(b_torch)\n-    # logging.info(\"CrypTen Bias:\")\n-    # logging.info(b.get_plain_text())\n"
                },
                {
                    "date": 1718804348818,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -103,10 +103,8 @@\n     print(\"==================\")\n     print(\"CrypTen Training\")\n     print(\"==================\")\n \n-    \n-# NOTE：训练无差异\n     relief_mpc(x, y, instance)\n \n     # if not skip_plaintext:\n     #     logging.info(\"PyTorch Weights  :\")\n"
                },
                {
                    "date": 1718804405268,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -72,9 +72,9 @@\n     return core_instance_feature, core_instance_label\n \n \n \n-def relief_mpc(feature_share, label_share, instances):\n+def relief(feature_share, label_share, instances):\n     sample_feature, sample_label = random_instance(feature_share, label_share, instances)\n     class_judge = sample_label.dot(label_share)\n     print(\"class_judge\", class_judge.get_plain_text)\n     \n@@ -94,9 +94,8 @@\n     data_train = DataSet.sonar\n     \n     x, y = load_dataset(data_train.dataset_name)\n \n-# NOTE：crypten.cryptensor \n     # Encrypt features / labels\n     x = crypten.cryptensor(x)\n     y = crypten.cryptensor(y)\n \n"
                },
                {
                    "date": 1718804414565,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -102,9 +102,9 @@\n     print(\"==================\")\n     print(\"CrypTen Training\")\n     print(\"==================\")\n \n-    relief_mpc(x, y, instance)\n+    relief(x, y, instance)\n \n     # if not skip_plaintext:\n     #     logging.info(\"PyTorch Weights  :\")\n     #     logging.info(w_torch)\n"
                },
                {
                    "date": 1718804483063,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -74,9 +74,9 @@\n \n \n def relief(feature_share, label_share, instances):\n     sample_feature, sample_label = random_instance(feature_share, label_share, instances)\n-    class_judge = sample_label.dot(label_share)\n+    class_judge = sample_label.matmul(label_share)\n     print(\"class_judge\", class_judge.get_plain_text)\n     \n     \n \n"
                },
                {
                    "date": 1718804507664,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -58,10 +58,10 @@\n     # 将标签转换为独热矩阵\n     one_hot_labels = np.zeros((int_labels.size, int_labels.max() + 1), dtype=np.uint8)\n     one_hot_labels[np.arange(int_labels.size), int_labels] = 1\n \n-    # print(\"======feature_size=====\", feature.shape)\n-    # print(\"======label_size=====\", labell.shape)\n+    print(\"======feature_size=====\", feature.shape)\n+    print(\"======label_size=====\", labell.shape)\n     return feature, one_hot_labels\n \n # 随机选择样本\n def random_instance(feature_share, label_share, instances):\n"
                },
                {
                    "date": 1718804527913,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -67,8 +67,9 @@\n def random_instance(feature_share, label_share, instances):\n     random_index = np.random.randint(0, instances)\n     core_instance_feature = feature_share[random_index]\n     core_instance_label = label_share[random_index]\n+    print()\n \n     return core_instance_feature, core_instance_label\n \n \n"
                },
                {
                    "date": 1718804534069,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -67,9 +67,9 @@\n def random_instance(feature_share, label_share, instances):\n     random_index = np.random.randint(0, instances)\n     core_instance_feature = feature_share[random_index]\n     core_instance_label = label_share[random_index]\n-    print()\n+    print(\"core\", )\n \n     return core_instance_feature, core_instance_label\n \n \n"
                },
                {
                    "date": 1718804540447,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -67,9 +67,9 @@\n def random_instance(feature_share, label_share, instances):\n     random_index = np.random.randint(0, instances)\n     core_instance_feature = feature_share[random_index]\n     core_instance_label = label_share[random_index]\n-    print(\"core\", )\n+    print(\"random_index=======\", )\n \n     return core_instance_feature, core_instance_label\n \n \n"
                },
                {
                    "date": 1718804547722,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -67,9 +67,10 @@\n def random_instance(feature_share, label_share, instances):\n     random_index = np.random.randint(0, instances)\n     core_instance_feature = feature_share[random_index]\n     core_instance_label = label_share[random_index]\n-    print(\"random_index=======\", )\n+    print(\"========random_index=======\", random_index)\n+    print(\"========random_index=======\", random_index)\n \n     return core_instance_feature, core_instance_label\n \n \n"
                },
                {
                    "date": 1718804553788,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -68,9 +68,9 @@\n     random_index = np.random.randint(0, instances)\n     core_instance_feature = feature_share[random_index]\n     core_instance_label = label_share[random_index]\n     print(\"========random_index=======\", random_index)\n-    print(\"========random_index=======\", random_index)\n+    print(\"========core_instance_feature=======\", random_index)\n \n     return core_instance_feature, core_instance_label\n \n \n"
                },
                {
                    "date": 1718804562469,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -68,9 +68,9 @@\n     random_index = np.random.randint(0, instances)\n     core_instance_feature = feature_share[random_index]\n     core_instance_label = label_share[random_index]\n     print(\"========random_index=======\", random_index)\n-    print(\"========core_instance_feature=======\", random_index)\n+    print(\"========core_instance_feature=======\", core_instance_feature.get_plain_text)\n \n     return core_instance_feature, core_instance_label\n \n \n"
                },
                {
                    "date": 1718804573458,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,122 @@\n+\n+import logging\n+import time\n+import csv\n+import os\n+import crypten\n+import torch\n+import numpy as np\n+from examples.meters import AverageMeter\n+\n+\n+DATASET_DIR = os.path.join(os.path.dirname(__file__), '../dataset')\n+\n+class DataSetParam:\n+    def __init__(self, dataset_name):\n+        self.dataset_name = dataset_name\n+\n+\n+class DataSet:\n+    sonar = DataSetParam('sonar.csv')\n+    sonar_selected = DataSetParam('sonar_selected.csv')\n+\n+    \n+    \n+    \n+    \n+\n+\n+def load_dataset(dataset):\n+    dataset_path = os.path.join(DATASET_DIR, dataset)\n+\n+    # 尝试打开并读取CSV文件\n+    try:\n+        with open(dataset_path, 'r', encoding='utf-8') as csvfile:\n+            spamreader = csv.reader(csvfile)\n+            data = np.array(list(spamreader))\n+    except FileNotFoundError:\n+        print(f\"Error: The file {dataset_path} was not found.\")\n+        return None, None\n+    except Exception as e:\n+        print(f\"Error: An error occurred while reading the file: {e}\")\n+        return None, None\n+\n+    # 检查数据是否为空\n+    if data.size == 0:\n+        print(\"Error: The dataset is empty.\")\n+        return None, None\n+\n+    feature = data[:, :-1].astype(np.float64)\n+    labels = data[:, -1]\n+\n+    # 创建标签映射\n+    unique_labels = np.unique(labels)\n+    label_to_int = {label: idx for idx, label in enumerate(unique_labels)}\n+    int_labels = np.array([label_to_int[label] for label in labels], dtype=np.uint8)\n+    labell = int_labels.reshape(-1,1)\n+    \n+    # 将标签转换为独热矩阵\n+    one_hot_labels = np.zeros((int_labels.size, int_labels.max() + 1), dtype=np.uint8)\n+    one_hot_labels[np.arange(int_labels.size), int_labels] = 1\n+\n+    print(\"======feature_size=====\", feature.shape)\n+    print(\"======label_size=====\", labell.shape)\n+    return feature, one_hot_labels\n+\n+# 随机选择样本\n+def random_instance(feature_share, label_share, instances):\n+    random_index = np.random.randint(0, instances)\n+    core_instance_feature = feature_share[random_index]\n+    core_instance_label = label_share[random_index]\n+    print(\"========random_index=======\", random_index)\n+    print(\"========core_instance_feature=======\", core_instance_feature.get_plain_text)\n+    print(\"========core_instance_feature=======\", core_instance_label.get_plain_text)\n+\n+    return core_instance_feature, core_instance_label\n+\n+\n+\n+def relief(feature_share, label_share, instances):\n+    sample_feature, sample_label = random_instance(feature_share, label_share, instances)\n+    class_judge = sample_label.matmul(label_share)\n+    print(\"class_judge\", class_judge.get_plain_text)\n+    \n+    \n+\n+\n+\n+\n+def relief_mpc(\n+    instance = 208,\n+):\n+    crypten.init()\n+\n+    # Set random seed for reproducibility\n+    torch.manual_seed(1)\n+\n+    data_train = DataSet.sonar\n+    \n+    x, y = load_dataset(data_train.dataset_name)\n+\n+    # Encrypt features / labels\n+    x = crypten.cryptensor(x)\n+    y = crypten.cryptensor(y)\n+\n+    print(\"==================\")\n+    print(\"CrypTen Training\")\n+    print(\"==================\")\n+\n+    relief(x, y, instance)\n+\n+    # if not skip_plaintext:\n+    #     logging.info(\"PyTorch Weights  :\")\n+    #     logging.info(w_torch)\n+    # logging.info(\"CrypTen Weights:\")\n+# NOTE：get_plain_text()\n+    # logging.info(w.get_plain_text())\n+\n+    # if not skip_plaintext:\n+    #     logging.info(\"PyTorch Bias  :\")\n+    #     logging.info(b_torch)\n+    # logging.info(\"CrypTen Bias:\")\n+    # logging.info(b.get_plain_text())\n"
                },
                {
                    "date": 1718804592485,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -68,10 +68,10 @@\n     random_index = np.random.randint(0, instances)\n     core_instance_feature = feature_share[random_index]\n     core_instance_label = label_share[random_index]\n     print(\"========random_index=======\", random_index)\n-    print(\"========core_instance_feature=======\", core_instance_feature.get_plain_text)\n-    print(\"========core_instance_feature=======\", core_instance_label.get_plain_text)\n+    print(\"========core_instance_feature=======\\n\", core_instance_feature.get_plain_text)\n+    print(\"========core_instance_label=======\", core_instance_label.get_plain_text)\n \n     return core_instance_feature, core_instance_label\n \n \n@@ -119,125 +119,4 @@\n     #     logging.info(\"PyTorch Bias  :\")\n     #     logging.info(b_torch)\n     # logging.info(\"CrypTen Bias:\")\n     # logging.info(b.get_plain_text())\n-\n-import logging\n-import time\n-import csv\n-import os\n-import crypten\n-import torch\n-import numpy as np\n-from examples.meters import AverageMeter\n-\n-\n-DATASET_DIR = os.path.join(os.path.dirname(__file__), '../dataset')\n-\n-class DataSetParam:\n-    def __init__(self, dataset_name):\n-        self.dataset_name = dataset_name\n-\n-\n-class DataSet:\n-    sonar = DataSetParam('sonar.csv')\n-    sonar_selected = DataSetParam('sonar_selected.csv')\n-\n-    \n-    \n-    \n-    \n-\n-\n-def load_dataset(dataset):\n-    dataset_path = os.path.join(DATASET_DIR, dataset)\n-\n-    # 尝试打开并读取CSV文件\n-    try:\n-        with open(dataset_path, 'r', encoding='utf-8') as csvfile:\n-            spamreader = csv.reader(csvfile)\n-            data = np.array(list(spamreader))\n-    except FileNotFoundError:\n-        print(f\"Error: The file {dataset_path} was not found.\")\n-        return None, None\n-    except Exception as e:\n-        print(f\"Error: An error occurred while reading the file: {e}\")\n-        return None, None\n-\n-    # 检查数据是否为空\n-    if data.size == 0:\n-        print(\"Error: The dataset is empty.\")\n-        return None, None\n-\n-    feature = data[:, :-1].astype(np.float64)\n-    labels = data[:, -1]\n-\n-    # 创建标签映射\n-    unique_labels = np.unique(labels)\n-    label_to_int = {label: idx for idx, label in enumerate(unique_labels)}\n-    int_labels = np.array([label_to_int[label] for label in labels], dtype=np.uint8)\n-    labell = int_labels.reshape(-1,1)\n-    \n-    # 将标签转换为独热矩阵\n-    one_hot_labels = np.zeros((int_labels.size, int_labels.max() + 1), dtype=np.uint8)\n-    one_hot_labels[np.arange(int_labels.size), int_labels] = 1\n-\n-    print(\"======feature_size=====\", feature.shape)\n-    print(\"======label_size=====\", labell.shape)\n-    return feature, one_hot_labels\n-\n-# 随机选择样本\n-def random_instance(feature_share, label_share, instances):\n-    random_index = np.random.randint(0, instances)\n-    core_instance_feature = feature_share[random_index]\n-    core_instance_label = label_share[random_index]\n-    print(\"========random_index=======\", random_index)\n-    print(\"========core_instance_feature=======\", core_instance_feature.get_plain_text)\n-\n-    return core_instance_feature, core_instance_label\n-\n-\n-\n-def relief(feature_share, label_share, instances):\n-    sample_feature, sample_label = random_instance(feature_share, label_share, instances)\n-    class_judge = sample_label.matmul(label_share)\n-    print(\"class_judge\", class_judge.get_plain_text)\n-    \n-    \n-\n-\n-\n-\n-def relief_mpc(\n-    instance = 208,\n-):\n-    crypten.init()\n-\n-    # Set random seed for reproducibility\n-    torch.manual_seed(1)\n-\n-    data_train = DataSet.sonar\n-    \n-    x, y = load_dataset(data_train.dataset_name)\n-\n-    # Encrypt features / labels\n-    x = crypten.cryptensor(x)\n-    y = crypten.cryptensor(y)\n-\n-    print(\"==================\")\n-    print(\"CrypTen Training\")\n-    print(\"==================\")\n-\n-    relief(x, y, instance)\n-\n-    # if not skip_plaintext:\n-    #     logging.info(\"PyTorch Weights  :\")\n-    #     logging.info(w_torch)\n-    # logging.info(\"CrypTen Weights:\")\n-# NOTE：get_plain_text()\n-    # logging.info(w.get_plain_text())\n-\n-    # if not skip_plaintext:\n-    #     logging.info(\"PyTorch Bias  :\")\n-    #     logging.info(b_torch)\n-    # logging.info(\"CrypTen Bias:\")\n-    # logging.info(b.get_plain_text())\n"
                },
                {
                    "date": 1718804601232,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -67,11 +67,11 @@\n def random_instance(feature_share, label_share, instances):\n     random_index = np.random.randint(0, instances)\n     core_instance_feature = feature_share[random_index]\n     core_instance_label = label_share[random_index]\n-    print(\"========random_index=======\", random_index)\n-    print(\"========core_instance_feature=======\\n\", core_instance_feature.get_plain_text)\n-    print(\"========core_instance_label=======\", core_instance_label.get_plain_text)\n+    print(\"========random_index=======\\n\", random_index)\n+    # print(\"========core_instance_feature=======\\n\", core_instance_feature.get_plain_text)\n+    print(\"========core_instance_label=======\\n\", core_instance_label.get_plain_text)\n \n     return core_instance_feature, core_instance_label\n \n \n"
                },
                {
                    "date": 1718804658104,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -69,9 +69,8 @@\n     core_instance_feature = feature_share[random_index]\n     core_instance_label = label_share[random_index]\n     print(\"========random_index=======\\n\", random_index)\n     # print(\"========core_instance_feature=======\\n\", core_instance_feature.get_plain_text)\n-    print(\"========core_instance_label=======\\n\", core_instance_label.get_plain_text)\n \n     return core_instance_feature, core_instance_label\n \n \n"
                },
                {
                    "date": 1718804664801,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -76,8 +76,9 @@\n \n \n def relief(feature_share, label_share, instances):\n     sample_feature, sample_label = random_instance(feature_share, label_share, instances)\n+    print(\"========core_instance_label=======\\n\", core_instance_label.get_plain_text)\n     class_judge = sample_label.matmul(label_share)\n     print(\"class_judge\", class_judge.get_plain_text)\n     \n     \n"
                },
                {
                    "date": 1718804671521,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -76,9 +76,9 @@\n \n \n def relief(feature_share, label_share, instances):\n     sample_feature, sample_label = random_instance(feature_share, label_share, instances)\n-    print(\"========core_instance_label=======\\n\", core_instance_label.get_plain_text)\n+    print(\"========sample_label=======\\n\", sample_label.get_plain_text)\n     class_judge = sample_label.matmul(label_share)\n     print(\"class_judge\", class_judge.get_plain_text)\n     \n     \n"
                },
                {
                    "date": 1718804726455,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -77,10 +77,10 @@\n \n def relief(feature_share, label_share, instances):\n     sample_feature, sample_label = random_instance(feature_share, label_share, instances)\n     print(\"========sample_label=======\\n\", sample_label.get_plain_text)\n-    class_judge = sample_label.matmul(label_share)\n-    print(\"class_judge\", class_judge.get_plain_text)\n+    # class_judge = sample_label.matmul(label_share)\n+    # print(\"class_judge\", class_judge.get_plain_text)\n     \n     \n \n \n@@ -98,9 +98,9 @@\n     \n     x, y = load_dataset(data_train.dataset_name)\n \n     # Encrypt features / labels\n-    x = crypten.cryptensor(x)\n+    x = crypten.cryptensor(x, , ptype=crypten.mpc.arithmetic)\n     y = crypten.cryptensor(y)\n \n     print(\"==================\")\n     print(\"CrypTen Training\")\n"
                },
                {
                    "date": 1718804734348,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -98,10 +98,10 @@\n     \n     x, y = load_dataset(data_train.dataset_name)\n \n     # Encrypt features / labels\n-    x = crypten.cryptensor(x, , ptype=crypten.mpc.arithmetic)\n-    y = crypten.cryptensor(y)\n+    x = crypten.cryptensor(x, ptype=crypten.mpc.arithmetic)\n+    y = crypten.cryptensor(y, ptype=crypten.mpc.boolean)\n \n     print(\"==================\")\n     print(\"CrypTen Training\")\n     print(\"==================\")\n"
                },
                {
                    "date": 1718804754306,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -99,9 +99,9 @@\n     x, y = load_dataset(data_train.dataset_name)\n \n     # Encrypt features / labels\n     x = crypten.cryptensor(x, ptype=crypten.mpc.arithmetic)\n-    y = crypten.cryptensor(y, ptype=crypten.mpc.boolean)\n+    y = crypten.cryptensor(y, ptype=crypten.mpc.bina)\n \n     print(\"==================\")\n     print(\"CrypTen Training\")\n     print(\"==================\")\n"
                },
                {
                    "date": 1718804783245,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -76,9 +76,9 @@\n \n \n def relief(feature_share, label_share, instances):\n     sample_feature, sample_label = random_instance(feature_share, label_share, instances)\n-    print(\"========sample_label=======\\n\", sample_label.get_plain_text)\n+    print(\"========sample_label=======\\n\", sample_label.get_plain_text())\n     # class_judge = sample_label.matmul(label_share)\n     # print(\"class_judge\", class_judge.get_plain_text)\n     \n     \n@@ -99,9 +99,9 @@\n     x, y = load_dataset(data_train.dataset_name)\n \n     # Encrypt features / labels\n     x = crypten.cryptensor(x, ptype=crypten.mpc.arithmetic)\n-    y = crypten.cryptensor(y, ptype=crypten.mpc.bina)\n+    y = crypten.cryptensor(y, ptype=crypten.mpc.binary)\n \n     print(\"==================\")\n     print(\"CrypTen Training\")\n     print(\"==================\")\n"
                },
                {
                    "date": 1719817188417,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -17,9 +17,8 @@\n \n \n class DataSet:\n     sonar = DataSetParam('sonar.csv')\n-    sonar_selected = DataSetParam('sonar_selected.csv')\n \n     \n     \n     \n"
                },
                {
                    "date": 1719818378887,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -61,9 +61,9 @@\n     print(\"======feature_size=====\", feature.shape)\n     print(\"======label_size=====\", labell.shape)\n     return feature, one_hot_labels\n \n-# 随机选择样本\n+# region 随机选择样本\n def random_instance(feature_share, label_share, instances):\n     random_index = np.random.randint(0, instances)\n     core_instance_feature = feature_share[random_index]\n     core_instance_label = label_share[random_index]\n"
                },
                {
                    "date": 1719818384435,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -70,11 +70,11 @@\n     print(\"========random_index=======\\n\", random_index)\n     # print(\"========core_instance_feature=======\\n\", core_instance_feature.get_plain_text)\n \n     return core_instance_feature, core_instance_label\n+# region\n \n \n-\n def relief(feature_share, label_share, instances):\n     sample_feature, sample_label = random_instance(feature_share, label_share, instances)\n     print(\"========sample_label=======\\n\", sample_label.get_plain_text())\n     # class_judge = sample_label.matmul(label_share)\n"
                },
                {
                    "date": 1719818390586,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -61,18 +61,18 @@\n     print(\"======feature_size=====\", feature.shape)\n     print(\"======label_size=====\", labell.shape)\n     return feature, one_hot_labels\n \n-# region 随机选择样本\n+# begin region 随机选择样本\n def random_instance(feature_share, label_share, instances):\n     random_index = np.random.randint(0, instances)\n     core_instance_feature = feature_share[random_index]\n     core_instance_label = label_share[random_index]\n     print(\"========random_index=======\\n\", random_index)\n     # print(\"========core_instance_feature=======\\n\", core_instance_feature.get_plain_text)\n \n     return core_instance_feature, core_instance_label\n-# region\n+# end region\n \n \n def relief(feature_share, label_share, instances):\n     sample_feature, sample_label = random_instance(feature_share, label_share, instances)\n"
                },
                {
                    "date": 1719818395653,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -61,18 +61,18 @@\n     print(\"======feature_size=====\", feature.shape)\n     print(\"======label_size=====\", labell.shape)\n     return feature, one_hot_labels\n \n-# begin region 随机选择样本\n+# region 随机选择样本\n def random_instance(feature_share, label_share, instances):\n     random_index = np.random.randint(0, instances)\n     core_instance_feature = feature_share[random_index]\n     core_instance_label = label_share[random_index]\n     print(\"========random_index=======\\n\", random_index)\n     # print(\"========core_instance_feature=======\\n\", core_instance_feature.get_plain_text)\n \n     return core_instance_feature, core_instance_label\n-# end region\n+# region\n \n \n def relief(feature_share, label_share, instances):\n     sample_feature, sample_label = random_instance(feature_share, label_share, instances)\n"
                },
                {
                    "date": 1719818403695,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -62,16 +62,16 @@\n     print(\"======label_size=====\", labell.shape)\n     return feature, one_hot_labels\n \n # region 随机选择样本\n-def random_instance(feature_share, label_share, instances):\n-    random_index = np.random.randint(0, instances)\n-    core_instance_feature = feature_share[random_index]\n-    core_instance_label = label_share[random_index]\n-    print(\"========random_index=======\\n\", random_index)\n-    # print(\"========core_instance_feature=======\\n\", core_instance_feature.get_plain_text)\n+# def random_instance(feature_share, label_share, instances):\n+#     random_index = np.random.randint(0, instances)\n+#     core_instance_feature = feature_share[random_index]\n+#     core_instance_label = label_share[random_index]\n+#     print(\"========random_index=======\\n\", random_index)\n+#     # print(\"========core_instance_feature=======\\n\", core_instance_feature.get_plain_text)\n \n-    return core_instance_feature, core_instance_label\n+#     return core_instance_feature, core_instance_label\n # region\n \n \n def relief(feature_share, label_share, instances):\n"
                },
                {
                    "date": 1719818483072,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -70,9 +70,9 @@\n #     print(\"========random_index=======\\n\", random_index)\n #     # print(\"========core_instance_feature=======\\n\", core_instance_feature.get_plain_text)\n \n #     return core_instance_feature, core_instance_label\n-# region\n+# endregion\n \n \n def relief(feature_share, label_share, instances):\n     sample_feature, sample_label = random_instance(feature_share, label_share, instances)\n"
                },
                {
                    "date": 1719818576493,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -61,18 +61,18 @@\n     print(\"======feature_size=====\", feature.shape)\n     print(\"======label_size=====\", labell.shape)\n     return feature, one_hot_labels\n \n-# region 随机选择样本\n-# def random_instance(feature_share, label_share, instances):\n-#     random_index = np.random.randint(0, instances)\n-#     core_instance_feature = feature_share[random_index]\n-#     core_instance_label = label_share[random_index]\n-#     print(\"========random_index=======\\n\", random_index)\n-#     # print(\"========core_instance_feature=======\\n\", core_instance_feature.get_plain_text)\n+region 随机选择样本\n+def random_instance(feature_share, label_share, instances):\n+    random_index = np.random.randint(0, instances)\n+    core_instance_feature = feature_share[random_index]\n+    core_instance_label = label_share[random_index]\n+    print(\"========random_index=======\\n\", random_index)\n+    # print(\"========core_instance_feature=======\\n\", core_instance_feature.get_plain_text)\n \n-#     return core_instance_feature, core_instance_label\n-# endregion\n+    return core_instance_feature, core_instance_label\n+endregion\n \n \n def relief(feature_share, label_share, instances):\n     sample_feature, sample_label = random_instance(feature_share, label_share, instances)\n"
                },
                {
                    "date": 1719818584019,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -61,20 +61,20 @@\n     print(\"======feature_size=====\", feature.shape)\n     print(\"======label_size=====\", labell.shape)\n     return feature, one_hot_labels\n \n-region 随机选择样本\n+# region 随机选择样本\n def random_instance(feature_share, label_share, instances):\n     random_index = np.random.randint(0, instances)\n     core_instance_feature = feature_share[random_index]\n     core_instance_label = label_share[random_index]\n     print(\"========random_index=======\\n\", random_index)\n     # print(\"========core_instance_feature=======\\n\", core_instance_feature.get_plain_text)\n \n     return core_instance_feature, core_instance_label\n-endregion\n \n \n+\n def relief(feature_share, label_share, instances):\n     sample_feature, sample_label = random_instance(feature_share, label_share, instances)\n     print(\"========sample_label=======\\n\", sample_label.get_plain_text())\n     # class_judge = sample_label.matmul(label_share)\n"
                },
                {
                    "date": 1719818598461,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -61,17 +61,19 @@\n     print(\"======feature_size=====\", feature.shape)\n     print(\"======label_size=====\", labell.shape)\n     return feature, one_hot_labels\n \n+\n # region 随机选择样本\n-def random_instance(feature_share, label_share, instances):\n-    random_index = np.random.randint(0, instances)\n-    core_instance_feature = feature_share[random_index]\n-    core_instance_label = label_share[random_index]\n-    print(\"========random_index=======\\n\", random_index)\n-    # print(\"========core_instance_feature=======\\n\", core_instance_feature.get_plain_text)\n+# def random_instance(feature_share, label_share, instances):\n+#     random_index = np.random.randint(0, instances)\n+#     core_instance_feature = feature_share[random_index]\n+#     core_instance_label = label_share[random_index]\n+#     print(\"========random_index=======\\n\", random_index)\n+#     # print(\"========core_instance_feature=======\\n\", core_instance_feature.get_plain_text)\n \n-    return core_instance_feature, core_instance_label\n+#     return core_instance_feature, core_instance_label\n+# endregion\n \n \n \n def relief(feature_share, label_share, instances):\n"
                },
                {
                    "date": 1719818626420,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -76,9 +76,9 @@\n \n \n \n def relief(feature_share, label_share, instances):\n-    sample_feature, sample_label = random_instance(feature_share, label_share, instances)\n+    # sample_feature, sample_label = random_instance(feature_share, label_share, instances)\n     print(\"========sample_label=======\\n\", sample_label.get_plain_text())\n     # class_judge = sample_label.matmul(label_share)\n     # print(\"class_judge\", class_judge.get_plain_text)\n     \n"
                },
                {
                    "date": 1719836553336,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -77,9 +77,9 @@\n \n \n def relief(feature_share, label_share, instances):\n     # sample_feature, sample_label = random_instance(feature_share, label_share, instances)\n-    print(\"========sample_label=======\\n\", sample_label.get_plain_text())\n+    # print(\"========sample_label=======\\n\", sample_label.get_plain_text())\n     # class_judge = sample_label.matmul(label_share)\n     # print(\"class_judge\", class_judge.get_plain_text)\n     \n     \n"
                },
                {
                    "date": 1719836588325,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -75,9 +75,9 @@\n # endregion\n \n \n \n-def relief(feature_share, label_share, instances):\n+# def relief(feature_share, label_share, instances):\n     # sample_feature, sample_label = random_instance(feature_share, label_share, instances)\n     # print(\"========sample_label=======\\n\", sample_label.get_plain_text())\n     # class_judge = sample_label.matmul(label_share)\n     # print(\"class_judge\", class_judge.get_plain_text)\n"
                }
            ],
            "date": 1718801629257,
            "name": "Commit-0",
            "content": "\nimport logging\nimport time\nimport csv\nimport os\nimport crypten\nimport torch\nimport numpy as np\nfrom examples.meters import AverageMeter\n\n\nDATASET_DIR = os.path.join(os.path.dirname(__file__), '../dataset')\n\nclass DataSetParam:\n    def __init__(self, dataset_name):\n        self.dataset_name = dataset_name\n\n\nclass DataSet:\n    sonar = DataSetParam('sonar.csv')\n    sonar_selected = DataSetParam('sonar_selected.csv')\n\n\n\n\ndef train_linear_svm(features, labels, epochs, lr, print_time=False):\n    # Initialize random weights\n    w = features.new(torch.randn(features.size(1),1))\n    b = features.new(torch.randn(1))\n    # print(\"==========w========\", w.shape)\n    # print(\"==========b========\", b.shape)\n    # print(\"=======features=====\", features.shape)\n\n    if print_time:\n        pt_time = AverageMeter()\n        end = time.time()\n    \n    filename = \"Accuracy.txt\"\n    with open(filename, 'a') as f:\n        for epoch in range(epochs):\n            # Forward\n            label_predictions = features.matmul(w).add(b).sign()\n            # label_predictions = w.matmul(features.T).add(b).sign()\n            # print(\"=======labels======\", labels.shape)\n            # print(\"=======label_predictions======\", label_predictions.shape)\n            # Compute accuracy\n            correct = label_predictions.mul(labels.view(-1,1))\n            # print(\"=======correct======\", correct.shape)\n            accuracy = correct.add(1).div(2).mean()\n            if crypten.is_encrypted_tensor(accuracy):\n                accuracy = accuracy.get_plain_text()\n\n            # Print Accuracy once\n            if crypten.communicator.get().get_rank() == 0:\n                # print(\n                #     f\"Epoch {epoch} --- Training Accuracy %.2f%%\" % (accuracy.item() * 100)\n                # )\n                accuracy_str = \"%.2f%%\" % (accuracy * 100)\n                accuracy_str_without_percent = accuracy_str.replace('%', '')\n                f.write(accuracy_str_without_percent + \",\")\n\n            # Backward\n            loss_grad = -labels * (1 - correct) * 0.5  # Hinge loss\n            # print(\"=======loss_grad======\\n\", loss_grad.get_plain_text())\n            b_grad = loss_grad.mean()\n            # print(\"=======b_grad ======\", b_grad.shape)\n            w_grad = features.t().matmul(loss_grad).div(loss_grad.size(0))\n            # print(\"=======w_grad ======\", w_grad.shape)\n            \n\n            # Update\n            w -= w_grad * lr\n            b -= b_grad * lr\n\n            if print_time:\n                iter_time = time.time() - end\n                pt_time.add(iter_time)\n                print(\"Time %.6f (%.6f)\" % (iter_time, pt_time.value()))\n                end = time.time()\n\n    return w, b\n\n\n\n\ndef load_dataset(dataset):\n    dataset_path = os.path.join(DATASET_DIR, dataset)\n\n    # 尝试打开并读取CSV文件\n    try:\n        with open(dataset_path, 'r', encoding='utf-8') as csvfile:\n            spamreader = csv.reader(csvfile)\n            data = np.array(list(spamreader))\n    except FileNotFoundError:\n        print(f\"Error: The file {dataset_path} was not found.\")\n        return None, None\n    except Exception as e:\n        print(f\"Error: An error occurred while reading the file: {e}\")\n        return None, None\n\n    # 检查数据是否为空\n    if data.size == 0:\n        print(\"Error: The dataset is empty.\")\n        return None, None\n\n    feature = data[:, :-1].astype(np.float64)\n    labels = data[:, -1]\n\n    # 创建标签映射\n    unique_labels = np.unique(labels)\n    label_to_int = {label: idx for idx, label in enumerate(unique_labels)}\n    int_labels = np.array([label_to_int[label] for label in labels], dtype=np.uint8)\n    labell = int_labels.reshape(-1,1)\n\n    # print(\"======feature_size=====\", feature.shape)\n    # print(\"======label_size=====\", labell.shape)\n    return feature, labell\n\n\n\ndef run_mpc_linear_svm(\n    epochs=100, lr=0.5\n):\n    crypten.init()\n\n    # Set random seed for reproducibility\n    torch.manual_seed(1)\n\n    data_train = DataSet.sonar\n    \n    x, y = load_dataset(data_train.dataset_name)\n\n# NOTE：crypten.cryptensor \n    # Encrypt features / labels\n    x = crypten.cryptensor(x)\n    y = crypten.cryptensor(y)\n\n    logging.info(\"==================\")\n    logging.info(\"CrypTen Training\")\n    logging.info(\"==================\")\n# NOTE：训练无差异\n    w, b = train_linear_svm(x, y, epochs=epochs, lr=lr, print_time=True)\n\n    # if not skip_plaintext:\n    #     logging.info(\"PyTorch Weights  :\")\n    #     logging.info(w_torch)\n    # logging.info(\"CrypTen Weights:\")\n# NOTE：get_plain_text()\n    # logging.info(w.get_plain_text())\n\n    # if not skip_plaintext:\n    #     logging.info(\"PyTorch Bias  :\")\n    #     logging.info(b_torch)\n    # logging.info(\"CrypTen Bias:\")\n    # logging.info(b.get_plain_text())\n"
        }
    ]
}