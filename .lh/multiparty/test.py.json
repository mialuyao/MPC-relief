{
    "sourceFile": "multiparty/test.py",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 87,
            "patches": [
                {
                    "date": 1718524863171,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                },
                {
                    "date": 1718524882569,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -125,9 +125,9 @@\n if __name__ == '__main__':\n     test_compute_encrypt()\n \n \n-def v2Mr(\n+def test(\n     number = 10,\n     ratio = 0.1,\n ):\n     crypten.init()\n"
                },
                {
                    "date": 1718527617815,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -26,103 +26,10 @@\n \n # @mpc.run_multiprocess(world_size=2)\n def test_compute_encrypt(N, k_N_ratio):\n \n-    # N = 10\n-    # k_N_ratio = 0.4\n-    k = int(N * (1 - k_N_ratio))\n \n-    # a_plain = torch.randint(2, (N,))\n-    \n-    # 设置一定的比例\n-    a_plain = [1] * k + [0] * (N - k)\n-    \n-    # 打乱向量顺序\n-    random.shuffle(a_plain)\n-    \n-    # 转换为PyTorch的tensor\n-    a_plain = torch.tensor(a_plain)\n-    \n-    crypten.print(f'a_plain: {a_plain}')\n \n-    a = BinarySharedTensor(a_plain)\n-    # crypten.print(f'a_encrypt: {a}')\n-\n-    A_plain = torch.diag(a_plain)\n-    # crypten.print(f'A_plain: {A_plain}')\n-    A = BinarySharedTensor(A_plain)\n-    # crypten.print(f'A_encrypt: {A}')\n-\n-    # R = torch.zeros((N, N))\n-    # R = ArithmeticSharedTensor(R)\n-    # R = BinarySharedTensor(R)\n-    R = A\n-    start = time.time()     \n-    for j in range(k):\n-        for ti in range(N-k):\n-            t = ti + k\n-            s = (~a[j]) & a[t]\n-            a[j] = a[j] ^ s\n-            a[t] = a[t] ^ s\n-\n-            # 因为windows上的BinarySharedTensor没有实现get_plain_text方法,所以如果是windows上跑的话在这里需要转为ArithmeticSharedTensor\n-            # 同时R也需要初始化为ArithmeticSharedTensor类型.linux上可以不用转换\n-            # R[j, t] = convert( (A[j, j]) ^ s, crypten.mpc.arithmetic)\n-            # R[t, j] = convert( (A[t, t]) ^ s, crypten.mpc.arithmetic)\n-\n-            R[j, t] = A[j, t] \n-            R[t, j] = ~A[t, j] & s \n-            R[j, j] = A[j, j] & ~s\n-            R[t, t] = A[t, t] & ~s\n-    \n-    total_time = time.time() - start\n-    crypten.print(f'time: {total_time}')\n-    # R = R[:, :k]\n-    R = R[:, :k].get_plain_text()\n-\n-\n-    # 使用明文计算结果,方便后面比对密文结果是否正确\n-    # crypten.print(f'======plain========')\n-    R_plain_result = test_compute_plain(a_plain, N, k_N_ratio)\n-    crypten.print(f'======output========')\n-    crypten.print(f'R:{R}')\n-    crypten.print(f'R_plain_result: {R_plain_result}')\n-    crypten.print(f'R is right to plain: {R.eq(R_plain_result)}')\n-\n-\n-def test_compute_plain(src_a=None, N=10, k_N_ratio=0.4):\n-    k = int(N * (1 - k_N_ratio))\n-\n-    a = torch.randint(2, (N,)) if src_a is None else src_a\n-    A = torch.diag(a)\n-    # crypten.print(f'A\\n: {A}')\n-    R = A\n-    \n-    for j in range(k):\n-        # crypten.print(f'j: {j}')\n-        for ti in range(N-k):\n-            t = ti + k\n-            # crypten.print(f't: {t}')\n-            # crypten.print(f'a[j]: {a[j]}')\n-            # crypten.print(f'a[t]: {a[t]}')\n-            s = (~a[j]) & a[t]\n-            a[j] = a[j] ^ s\n-            a[t] = a[t] ^ s\n-            # crypten.print(f'a: {a}')\n-            # crypten.print(f's: {s}')\n-            # crypten.print(f'A[j, t]: {A[j, t]}')\n-            # crypten.print(f'A[j, t]: {A[j, t]}')\n-            R[j, t] = A[j, t] \n-            R[t, j] = ~A[t, j] & s \n-            R[j, j] = A[j, j] & ~s\n-            R[t, t] = A[t, t] & ~s\n-            # crypten.print(f'R\\n: {R}')\n-\n-    R = R[:, :k]\n-    \n-    return R\n-\n-\n if __name__ == '__main__':\n     test_compute_encrypt()\n \n \n"
                },
                {
                    "date": 1718527632265,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -28,10 +28,10 @@\n def test_compute_encrypt(N, k_N_ratio):\n \n \n \n-if __name__ == '__main__':\n-    test_compute_encrypt()\n+# if __name__ == '__main__':\n+#     test_compute_encrypt()\n \n \n def test(\n     number = 10,\n"
                },
                {
                    "date": 1718527642539,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -24,9 +24,9 @@\n import multiprocessing\n \n \n # @mpc.run_multiprocess(world_size=2)\n-def test_compute_encrypt(N, k_N_ratio):\n+def test_compute_encrypt():\n \n \n \n # if __name__ == '__main__':\n"
                },
                {
                    "date": 1718606392122,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -25,15 +25,21 @@\n \n \n # @mpc.run_multiprocess(world_size=2)\n def test_compute_encrypt():\n+    \n \n \n \n # if __name__ == '__main__':\n #     test_compute_encrypt()\n \n \n+def load_data():\n+    \n+\n+\n+\n def test(\n     number = 10,\n     ratio = 0.1,\n ):\n"
                },
                {
                    "date": 1718606481936,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -51,5 +51,7 @@\n     \n     crypten.print(f'======start======')\n     result =  test_compute_encrypt(number, ratio)\n     crypten.print(f'=====end======')\n-   \n\\ No newline at end of file\n+   \n+   \n+class \n\\ No newline at end of file\n"
                },
                {
                    "date": 1718606490337,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -53,5 +53,17 @@\n     result =  test_compute_encrypt(number, ratio)\n     crypten.print(f'=====end======')\n    \n    \n-class \n\\ No newline at end of file\n+class CSVDataset(Dataset):\n+    def __init__(self, csv_file):\n+        self.data = pd.read_csv(csv_file)\n+        self.features = self.data.iloc[:, :-1].values\n+        self.labels = self.data.iloc[:, -1].values\n+\n+    def __len__(self):\n+        return len(self.data)\n+\n+    def __getitem__(self, idx):\n+        features = torch.tensor(self.features[idx], dtype=torch.float32)\n+        label = torch.tensor(self.labels[idx], dtype=torch.long)\n+        return features, label\n"
                },
                {
                    "date": 1718606501548,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -52,18 +52,4 @@\n     crypten.print(f'======start======')\n     result =  test_compute_encrypt(number, ratio)\n     crypten.print(f'=====end======')\n    \n-   \n-class CSVDataset(Dataset):\n-    def __init__(self, csv_file):\n-        self.data = pd.read_csv(csv_file)\n-        self.features = self.data.iloc[:, :-1].values\n-        self.labels = self.data.iloc[:, -1].values\n-\n-    def __len__(self):\n-        return len(self.data)\n-\n-    def __getitem__(self, idx):\n-        features = torch.tensor(self.features[idx], dtype=torch.float32)\n-        label = torch.tensor(self.labels[idx], dtype=torch.long)\n-        return features, label\n"
                },
                {
                    "date": 1718606536418,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -3,9 +3,9 @@\n import threading\n import time\n import random\n import logging\n-\n+import pandas\n import torch\n from matplotlib import pyplot\n \n import numpy as np\n@@ -23,8 +23,25 @@\n from multiprocessing import Pool\n import multiprocessing\n \n \n+class CSVDataset(Dataset):\n+    def __init__(self, csv_file):\n+        self.data = pd.read_csv(csv_file)\n+        self.features = self.data.iloc[:, :-1].values\n+        self.labels = self.data.iloc[:, -1].values\n+\n+    def __len__(self):\n+        return len(self.data)\n+\n+    def __getitem__(self, idx):\n+        features = torch.tensor(self.features[idx], dtype=torch.float32)\n+        label = torch.tensor(self.labels[idx], dtype=torch.long)\n+        return features, label\n+\n+\n+\n+\n # @mpc.run_multiprocess(world_size=2)\n def test_compute_encrypt():\n     \n \n"
                },
                {
                    "date": 1718606549441,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -3,9 +3,9 @@\n import threading\n import time\n import random\n import logging\n-import pandas\n+import pandas as pd\n import torch\n from matplotlib import pyplot\n \n import numpy as np\n@@ -38,9 +38,20 @@\n         label = torch.tensor(self.labels[idx], dtype=torch.long)\n         return features, label\n \n \n+class SimpleNN(nn.Module):\n+    def __init__(self, input_size, num_classes):\n+        super(SimpleNN, self).__init__()\n+        self.fc1 = nn.Linear(input_size, 128)\n+        self.fc2 = nn.Linear(128, 64)\n+        self.fc3 = nn.Linear(64, num_classes)\n \n+    def forward(self, x):\n+        x = F.relu(self.fc1(x))\n+        x = F.relu(self.fc2(x))\n+        x = self.fc3(x)\n+        return x\n \n # @mpc.run_multiprocess(world_size=2)\n def test_compute_encrypt():\n     \n"
                },
                {
                    "date": 1718606566812,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -11,8 +11,9 @@\n import numpy as np\n import scipy.io as sio\n \n from torch import nn\n+from torch.utils.data import Dataset, DataLoader\n \n import crypten\n import crypten.mpc as mpc\n import crypten.communicator as comm\n"
                },
                {
                    "date": 1718606587999,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -53,9 +53,9 @@\n         x = self.fc3(x)\n         return x\n \n # @mpc.run_multiprocess(world_size=2)\n-def test_compute_encrypt():\n+def train():\n     \n \n \n \n"
                },
                {
                    "date": 1718606597400,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -53,9 +53,9 @@\n         x = self.fc3(x)\n         return x\n \n # @mpc.run_multiprocess(world_size=2)\n-def train():\n+def train_model():\n     \n \n \n \n@@ -78,7 +78,7 @@\n     # Set random seed for reproducibility\n     torch.manual_seed(1)\n     \n     crypten.print(f'======start======')\n-    result =  test_compute_encrypt(number, ratio)\n+    result =  train_model(number, ratio)\n     crypten.print(f'=====end======')\n    \n"
                },
                {
                    "date": 1718606604145,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -53,9 +53,9 @@\n         x = self.fc3(x)\n         return x\n \n # @mpc.run_multiprocess(world_size=2)\n-def train_model():\n+def train_model(model, ):\n     \n \n \n \n"
                },
                {
                    "date": 1718606638518,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -53,9 +53,9 @@\n         x = self.fc3(x)\n         return x\n \n # @mpc.run_multiprocess(world_size=2)\n-def train_model(model, ):\n+def train_model(model, dataloader, ):\n     \n \n \n \n"
                },
                {
                    "date": 1718606675065,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -12,8 +12,9 @@\n import scipy.io as sio\n \n from torch import nn\n from torch.utils.data import Dataset, DataLoader\n+import \n \n import crypten\n import crypten.mpc as mpc\n import crypten.communicator as comm\n"
                },
                {
                    "date": 1718606680324,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -12,9 +12,9 @@\n import scipy.io as sio\n \n from torch import nn\n from torch.utils.data import Dataset, DataLoader\n-import \n+import torch.nn.\n \n import crypten\n import crypten.mpc as mpc\n import crypten.communicator as comm\n"
                },
                {
                    "date": 1718606686619,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -12,9 +12,9 @@\n import scipy.io as sio\n \n from torch import nn\n from torch.utils.data import Dataset, DataLoader\n-import torch.nn.\n+import torch.nn.functional ascii(object)\n \n import crypten\n import crypten.mpc as mpc\n import crypten.communicator as comm\n"
                },
                {
                    "date": 1718606707519,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -40,9 +40,9 @@\n         label = torch.tensor(self.labels[idx], dtype=torch.long)\n         return features, label\n \n \n-class SimpleNN(nn.Module):\n+class classNN(nn.Module):\n     def __init__(self, input_size, num_classes):\n         super(SimpleNN, self).__init__()\n         self.fc1 = nn.Linear(input_size, 128)\n         self.fc2 = nn.Linear(128, 64)\n"
                },
                {
                    "date": 1718606713212,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -12,9 +12,9 @@\n import scipy.io as sio\n \n from torch import nn\n from torch.utils.data import Dataset, DataLoader\n-import torch.nn.functional ascii(object)\n+import torch.nn.functional as F\n \n import crypten\n import crypten.mpc as mpc\n import crypten.communicator as comm\n@@ -42,9 +42,9 @@\n \n \n class classNN(nn.Module):\n     def __init__(self, input_size, num_classes):\n-        super(SimpleNN, self).__init__()\n+        super(classNN, self).__init__()\n         self.fc1 = nn.Linear(input_size, 128)\n         self.fc2 = nn.Linear(128, 64)\n         self.fc3 = nn.Linear(64, num_classes)\n \n"
                },
                {
                    "date": 1718606745799,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -54,9 +54,9 @@\n         x = self.fc3(x)\n         return x\n \n # @mpc.run_multiprocess(world_size=2)\n-def train_model(model, dataloader, ):\n+def train_model(model, dataloader, criterion, optimizer, num_epochs):\n     \n \n \n \n"
                },
                {
                    "date": 1718606753815,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -55,8 +55,10 @@\n         return x\n \n # @mpc.run_multiprocess(world_size=2)\n def train_model(model, dataloader, criterion, optimizer, num_epochs):\n+    for epoch in range(num_epochs):\n+        \n     \n \n \n \n"
                },
                {
                    "date": 1718606759077,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -56,9 +56,9 @@\n \n # @mpc.run_multiprocess(world_size=2)\n def train_model(model, dataloader, criterion, optimizer, num_epochs):\n     for epoch in range(num_epochs):\n-        \n+        running_loss = \n     \n \n \n \n"
                },
                {
                    "date": 1718606868415,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -56,9 +56,10 @@\n \n # @mpc.run_multiprocess(world_size=2)\n def train_model(model, dataloader, criterion, optimizer, num_epochs):\n     for epoch in range(num_epochs):\n-        running_loss = \n+        loss = 0.0\n+        \n     \n \n \n \n"
                },
                {
                    "date": 1718606877661,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -56,9 +56,9 @@\n \n # @mpc.run_multiprocess(world_size=2)\n def train_model(model, dataloader, criterion, optimizer, num_epochs):\n     for epoch in range(num_epochs):\n-        loss = 0.0\n+        runnigloss = 0.0\n         \n     \n \n \n"
                },
                {
                    "date": 1718606888345,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -56,9 +56,10 @@\n \n # @mpc.run_multiprocess(world_size=2)\n def train_model(model, dataloader, criterion, optimizer, num_epochs):\n     for epoch in range(num_epochs):\n-        runnigloss = 0.0\n+        running_loss = 0.0\n+        for inputs\n         \n     \n \n \n"
                },
                {
                    "date": 1718606895405,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -57,9 +57,9 @@\n # @mpc.run_multiprocess(world_size=2)\n def train_model(model, dataloader, criterion, optimizer, num_epochs):\n     for epoch in range(num_epochs):\n         running_loss = 0.0\n-        for inputs\n+        for inputs, labels in dataloader\n         \n     \n \n \n"
                },
                {
                    "date": 1718606900744,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -57,9 +57,10 @@\n # @mpc.run_multiprocess(world_size=2)\n def train_model(model, dataloader, criterion, optimizer, num_epochs):\n     for epoch in range(num_epochs):\n         running_loss = 0.0\n-        for inputs, labels in dataloader\n+        for inputs, labels in dataloader:\n+            optimi\n         \n     \n \n \n"
                },
                {
                    "date": 1718607323126,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -55,12 +55,16 @@\n         return x\n \n # @mpc.run_multiprocess(world_size=2)\n def train_model(model, dataloader, criterion, optimizer, num_epochs):\n+    \n+    \n+    \n     for epoch in range(num_epochs):\n         running_loss = 0.0\n         for inputs, labels in dataloader:\n-            optimi\n+            optimizer.zero_grad()\n+            \n         \n     \n \n \n"
                },
                {
                    "date": 1718607329800,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -55,8 +55,13 @@\n         return x\n \n # @mpc.run_multiprocess(world_size=2)\n def train_model(model, dataloader, criterion, optimizer, num_epochs):\n+    if seed is not None:\n+        random.seed(seed)\n+        torch.manual_seed(seed)\n+\n+    crypten.init()\n     \n     \n     \n     for epoch in range(num_epochs):\n"
                },
                {
                    "date": 1718607346127,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -55,16 +55,12 @@\n         return x\n \n # @mpc.run_multiprocess(world_size=2)\n def train_model(model, dataloader, criterion, optimizer, num_epochs):\n-    if seed is not None:\n-        random.seed(seed)\n-        torch.manual_seed(seed)\n-\n-    crypten.init()\n     \n     \n     \n+    \n     for epoch in range(num_epochs):\n         running_loss = 0.0\n         for inputs, labels in dataloader:\n             optimizer.zero_grad()\n"
                },
                {
                    "date": 1718607353514,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -66,11 +66,11 @@\n             optimizer.zero_grad()\n             \n         \n     \n+def \n \n \n-\n # if __name__ == '__main__':\n #     test_compute_encrypt()\n \n \n"
                },
                {
                    "date": 1718607359279,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -54,9 +54,9 @@\n         x = self.fc3(x)\n         return x\n \n # @mpc.run_multiprocess(world_size=2)\n-def train_model(model, dataloader, criterion, optimizer, num_epochs):\n+def model_train(model, dataloader, criterion, optimizer, num_epochs):\n     \n     \n     \n     \n"
                },
                {
                    "date": 1718607367291,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -66,9 +66,9 @@\n             optimizer.zero_grad()\n             \n         \n     \n-def \n+def class_train():\n \n \n # if __name__ == '__main__':\n #     test_compute_encrypt()\n"
                },
                {
                    "date": 1718607377640,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -66,9 +66,12 @@\n             optimizer.zero_grad()\n             \n         \n     \n-def class_train():\n+def class_train(\n+    epochs=25\n+):\n+    \n \n \n # if __name__ == '__main__':\n #     test_compute_encrypt()\n"
                },
                {
                    "date": 1718607384868,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -67,9 +67,10 @@\n             \n         \n     \n def class_train(\n-    epochs=25\n+    epochs=25,\n+    batch_size=\n ):\n     \n \n \n"
                },
                {
                    "date": 1718607393175,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -68,9 +68,10 @@\n         \n     \n def class_train(\n     epochs=25,\n-    batch_size=\n+    batch_size=32,\n+    lr=0.01\n ):\n     \n \n \n"
                },
                {
                    "date": 1718607400991,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -69,9 +69,10 @@\n     \n def class_train(\n     epochs=25,\n     batch_size=32,\n-    lr=0.01\n+    lr=0.01,\n+    seed=None,\n ):\n     \n \n \n"
                },
                {
                    "date": 1718607409296,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -72,8 +72,13 @@\n     batch_size=32,\n     lr=0.01,\n     seed=None,\n ):\n+    if seed is not None:\n+        random.seed(seed)\n+        torch.manual_seed(seed)\n+\n+    crypten.init()\n     \n \n \n # if __name__ == '__main__':\n"
                },
                {
                    "date": 1718607423181,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -78,8 +78,10 @@\n         torch.manual_seed(seed)\n \n     crypten.init()\n     \n+    model = classNN()\n+    \n \n \n # if __name__ == '__main__':\n #     test_compute_encrypt()\n"
                },
                {
                    "date": 1718607447064,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -79,8 +79,9 @@\n \n     crypten.init()\n     \n     model = classNN()\n+    criterion = nn.CrossEntropyLoss()\n     \n \n \n # if __name__ == '__main__':\n"
                },
                {
                    "date": 1718607455539,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -80,8 +80,9 @@\n     crypten.init()\n     \n     model = classNN()\n     criterion = nn.CrossEntropyLoss()\n+    optimizer = \n     \n \n \n # if __name__ == '__main__':\n"
                },
                {
                    "date": 1718607464264,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -80,9 +80,9 @@\n     crypten.init()\n     \n     model = classNN()\n     criterion = nn.CrossEntropyLoss()\n-    optimizer = \n+    optimizer = torch.optim.Adam\n     \n \n \n # if __name__ == '__main__':\n"
                },
                {
                    "date": 1718607475972,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -80,9 +80,9 @@\n     crypten.init()\n     \n     model = classNN()\n     criterion = nn.CrossEntropyLoss()\n-    optimizer = torch.optim.Adam\n+    optimizer = torch.optim.Adam(model.parameters())\n     \n \n \n # if __name__ == '__main__':\n"
                },
                {
                    "date": 1718607487187,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -80,10 +80,12 @@\n     crypten.init()\n     \n     model = classNN()\n     criterion = nn.CrossEntropyLoss()\n-    optimizer = torch.optim.Adam(model.parameters())\n+    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n     \n+    \n+    \n \n \n # if __name__ == '__main__':\n #     test_compute_encrypt()\n"
                },
                {
                    "date": 1718607534036,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -82,10 +82,10 @@\n     model = classNN()\n     criterion = nn.CrossEntropyLoss()\n     optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n     \n+    feature, label = load_data()\n     \n-    \n \n \n # if __name__ == '__main__':\n #     test_compute_encrypt()\n"
                },
                {
                    "date": 1718607653767,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -25,9 +25,9 @@\n from multiprocessing import Pool\n import multiprocessing\n \n \n-class CSVDataset(Dataset):\n+class Dataset(Dataset):\n     def __init__(self, csv_file):\n         self.data = pd.read_csv(csv_file)\n         self.features = self.data.iloc[:, :-1].values\n         self.labels = self.data.iloc[:, -1].values\n"
                },
                {
                    "date": 1718607665083,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -25,9 +25,9 @@\n from multiprocessing import Pool\n import multiprocessing\n \n \n-class Dataset(Dataset):\n+class DataSet(Dataset):\n     def __init__(self, csv_file):\n         self.data = pd.read_csv(csv_file)\n         self.features = self.data.iloc[:, :-1].values\n         self.labels = self.data.iloc[:, -1].values\n"
                },
                {
                    "date": 1718607672765,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -25,9 +25,9 @@\n from multiprocessing import Pool\n import multiprocessing\n \n \n-class DataSet(Dataset):\n+class DataSet:\n     def __init__(self, csv_file):\n         self.data = pd.read_csv(csv_file)\n         self.features = self.data.iloc[:, :-1].values\n         self.labels = self.data.iloc[:, -1].values\n"
                },
                {
                    "date": 1718607693693,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -25,9 +25,9 @@\n from multiprocessing import Pool\n import multiprocessing\n \n \n-class DataSet:\n+class DataSet(dataset):\n     def __init__(self, csv_file):\n         self.data = pd.read_csv(csv_file)\n         self.features = self.data.iloc[:, :-1].values\n         self.labels = self.data.iloc[:, -1].values\n"
                },
                {
                    "date": 1718607710356,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -25,9 +25,9 @@\n from multiprocessing import Pool\n import multiprocessing\n \n \n-class DataSet(dataset):\n+class DataSet(Dataset):\n     def __init__(self, csv_file):\n         self.data = pd.read_csv(csv_file)\n         self.features = self.data.iloc[:, :-1].values\n         self.labels = self.data.iloc[:, -1].values\n@@ -82,9 +82,9 @@\n     model = classNN()\n     criterion = nn.CrossEntropyLoss()\n     optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n     \n-    feature, label = load_data()\n+    data\n     \n \n \n # if __name__ == '__main__':\n"
                },
                {
                    "date": 1718607725209,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -25,8 +25,10 @@\n from multiprocessing import Pool\n import multiprocessing\n \n \n+DATASET_DIR = os.path.join(os.path.dirname(__file__), '../dataset')\n+\n class DataSet(Dataset):\n     def __init__(self, csv_file):\n         self.data = pd.read_csv(csv_file)\n         self.features = self.data.iloc[:, :-1].values\n@@ -82,9 +84,9 @@\n     model = classNN()\n     criterion = nn.CrossEntropyLoss()\n     optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n     \n-    data\n+    data_file = \"\"\n     \n \n \n # if __name__ == '__main__':\n"
                },
                {
                    "date": 1718607739594,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -27,9 +27,9 @@\n \n \n DATASET_DIR = os.path.join(os.path.dirname(__file__), '../dataset')\n \n-class DataSet(Dataset):\n+class DataSetPa:\n     def __init__(self, csv_file):\n         self.data = pd.read_csv(csv_file)\n         self.features = self.data.iloc[:, :-1].values\n         self.labels = self.data.iloc[:, -1].values\n"
                },
                {
                    "date": 1718607779443,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -27,9 +27,9 @@\n \n \n DATASET_DIR = os.path.join(os.path.dirname(__file__), '../dataset')\n \n-class DataSetPa:\n+class DataSetParam:\n     def __init__(self, csv_file):\n         self.data = pd.read_csv(csv_file)\n         self.features = self.data.iloc[:, :-1].values\n         self.labels = self.data.iloc[:, -1].values\n@@ -41,8 +41,10 @@\n         features = torch.tensor(self.features[idx], dtype=torch.float32)\n         label = torch.tensor(self.labels[idx], dtype=torch.long)\n         return features, label\n \n+class Dataset:\n+    \n \n class classNN(nn.Module):\n     def __init__(self, input_size, num_classes):\n         super(classNN, self).__init__()\n"
                },
                {
                    "date": 1718607787784,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -42,9 +42,9 @@\n         label = torch.tensor(self.labels[idx], dtype=torch.long)\n         return features, label\n \n class Dataset:\n-    \n+    MNIST = \n \n class classNN(nn.Module):\n     def __init__(self, input_size, num_classes):\n         super(classNN, self).__init__()\n"
                },
                {
                    "date": 1718607796370,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -42,9 +42,9 @@\n         label = torch.tensor(self.labels[idx], dtype=torch.long)\n         return features, label\n \n class Dataset:\n-    MNIST = \n+    MNIST = DataSetParam('MNIST.csv')\n \n class classNN(nn.Module):\n     def __init__(self, input_size, num_classes):\n         super(classNN, self).__init__()\n"
                },
                {
                    "date": 1718607810199,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -44,8 +44,10 @@\n \n class Dataset:\n     MNIST = DataSetParam('MNIST.csv')\n \n+\n+\n class classNN(nn.Module):\n     def __init__(self, input_size, num_classes):\n         super(classNN, self).__init__()\n         self.fc1 = nn.Linear(input_size, 128)\n"
                },
                {
                    "date": 1718607815780,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,118 @@\n+import math\n+import os\n+import threading\n+import time\n+import random\n+import logging\n+import pandas as pd\n+import torch\n+from matplotlib import pyplot\n+\n+import numpy as np\n+import scipy.io as sio\n+\n+from torch import nn\n+from torch.utils.data import Dataset, DataLoader\n+import torch.nn.functional as F\n+\n+import crypten\n+import crypten.mpc as mpc\n+import crypten.communicator as comm\n+\n+from crypten.mpc.primitives import BinarySharedTensor, ArithmeticSharedTensor\n+from crypten.mpc.primitives.converters import convert, _B2A\n+\n+from multiprocessing import Pool\n+import multiprocessing\n+\n+\n+DATASET_DIR = os.path.join(os.path.dirname(__file__), '../dataset')\n+\n+class DataSetParam:\n+    def __init__(self, csv_file):\n+        self.data = pd.read_csv(csv_file)\n+        self.features = self.data.iloc[:, :-1].values\n+        self.labels = self.data.iloc[:, -1].values\n+\n+    def __len__(self):\n+        return len(self.data)\n+\n+    def __getitem__(self, idx):\n+        features = torch.tensor(self.features[idx], dtype=torch.float32)\n+        label = torch.tensor(self.labels[idx], dtype=torch.long)\n+        return features, label\n+\n+class Dataset:\n+    MNIST = DataSetParam('MNIST.csv')\n+\n+\n+\n+class classficationNN(nn.Module):\n+    def __init__(self, input_size, num_classes):\n+        super(classNN, self).__init__()\n+        self.fc1 = nn.Linear(input_size, 128)\n+        self.fc2 = nn.Linear(128, 64)\n+        self.fc3 = nn.Linear(64, num_classes)\n+\n+    def forward(self, x):\n+        x = F.relu(self.fc1(x))\n+        x = F.relu(self.fc2(x))\n+        x = self.fc3(x)\n+        return x\n+\n+# @mpc.run_multiprocess(world_size=2)\n+def model_train(model, dataloader, criterion, optimizer, num_epochs):\n+    \n+    \n+    \n+    \n+    for epoch in range(num_epochs):\n+        running_loss = 0.0\n+        for inputs, labels in dataloader:\n+            optimizer.zero_grad()\n+            \n+        \n+    \n+def class_train(\n+    epochs=25,\n+    batch_size=32,\n+    lr=0.01,\n+    seed=None,\n+):\n+    if seed is not None:\n+        random.seed(seed)\n+        torch.manual_seed(seed)\n+\n+    crypten.init()\n+    \n+    model = classNN()\n+    criterion = nn.CrossEntropyLoss()\n+    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n+    \n+    data_file = \"\"\n+    \n+\n+\n+# if __name__ == '__main__':\n+#     test_compute_encrypt()\n+\n+\n+def load_data():\n+    \n+\n+\n+\n+def test(\n+    number = 10,\n+    ratio = 0.1,\n+):\n+    crypten.init()\n+    rank = comm.get().get_rank()\n+    \n+    # Set random seed for reproducibility\n+    torch.manual_seed(1)\n+    \n+    crypten.print(f'======start======')\n+    result =  train_model(number, ratio)\n+    crypten.print(f'=====end======')\n+   \n"
                },
                {
                    "date": 1718607821164,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -48,9 +48,9 @@\n \n \n class classficationNN(nn.Module):\n     def __init__(self, input_size, num_classes):\n-        super(classNN, self).__init__()\n+        super(classficationN, self).__init__()\n         self.fc1 = nn.Linear(input_size, 128)\n         self.fc2 = nn.Linear(128, 64)\n         self.fc3 = nn.Linear(64, num_classes)\n \n@@ -115,122 +115,4 @@\n     crypten.print(f'======start======')\n     result =  train_model(number, ratio)\n     crypten.print(f'=====end======')\n    \n-import math\n-import os\n-import threading\n-import time\n-import random\n-import logging\n-import pandas as pd\n-import torch\n-from matplotlib import pyplot\n-\n-import numpy as np\n-import scipy.io as sio\n-\n-from torch import nn\n-from torch.utils.data import Dataset, DataLoader\n-import torch.nn.functional as F\n-\n-import crypten\n-import crypten.mpc as mpc\n-import crypten.communicator as comm\n-\n-from crypten.mpc.primitives import BinarySharedTensor, ArithmeticSharedTensor\n-from crypten.mpc.primitives.converters import convert, _B2A\n-\n-from multiprocessing import Pool\n-import multiprocessing\n-\n-\n-DATASET_DIR = os.path.join(os.path.dirname(__file__), '../dataset')\n-\n-class DataSetParam:\n-    def __init__(self, csv_file):\n-        self.data = pd.read_csv(csv_file)\n-        self.features = self.data.iloc[:, :-1].values\n-        self.labels = self.data.iloc[:, -1].values\n-\n-    def __len__(self):\n-        return len(self.data)\n-\n-    def __getitem__(self, idx):\n-        features = torch.tensor(self.features[idx], dtype=torch.float32)\n-        label = torch.tensor(self.labels[idx], dtype=torch.long)\n-        return features, label\n-\n-class Dataset:\n-    MNIST = DataSetParam('MNIST.csv')\n-\n-\n-\n-class classNN(nn.Module):\n-    def __init__(self, input_size, num_classes):\n-        super(classNN, self).__init__()\n-        self.fc1 = nn.Linear(input_size, 128)\n-        self.fc2 = nn.Linear(128, 64)\n-        self.fc3 = nn.Linear(64, num_classes)\n-\n-    def forward(self, x):\n-        x = F.relu(self.fc1(x))\n-        x = F.relu(self.fc2(x))\n-        x = self.fc3(x)\n-        return x\n-\n-# @mpc.run_multiprocess(world_size=2)\n-def model_train(model, dataloader, criterion, optimizer, num_epochs):\n-    \n-    \n-    \n-    \n-    for epoch in range(num_epochs):\n-        running_loss = 0.0\n-        for inputs, labels in dataloader:\n-            optimizer.zero_grad()\n-            \n-        \n-    \n-def class_train(\n-    epochs=25,\n-    batch_size=32,\n-    lr=0.01,\n-    seed=None,\n-):\n-    if seed is not None:\n-        random.seed(seed)\n-        torch.manual_seed(seed)\n-\n-    crypten.init()\n-    \n-    model = classNN()\n-    criterion = nn.CrossEntropyLoss()\n-    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n-    \n-    data_file = \"\"\n-    \n-\n-\n-# if __name__ == '__main__':\n-#     test_compute_encrypt()\n-\n-\n-def load_data():\n-    \n-\n-\n-\n-def test(\n-    number = 10,\n-    ratio = 0.1,\n-):\n-    crypten.init()\n-    rank = comm.get().get_rank()\n-    \n-    # Set random seed for reproducibility\n-    torch.manual_seed(1)\n-    \n-    crypten.print(f'======start======')\n-    result =  train_model(number, ratio)\n-    crypten.print(f'=====end======')\n-   \n"
                },
                {
                    "date": 1718607840313,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -48,9 +48,9 @@\n \n \n class classficationNN(nn.Module):\n     def __init__(self, input_size, num_classes):\n-        super(classficationN, self).__init__()\n+        super(classficationNN, self).__init__()\n         self.fc1 = nn.Linear(input_size, 128)\n         self.fc2 = nn.Linear(128, 64)\n         self.fc3 = nn.Linear(64, num_classes)\n \n@@ -84,9 +84,9 @@\n         torch.manual_seed(seed)\n \n     crypten.init()\n     \n-    model = classNN()\n+    model = classficationNN()\n     criterion = nn.CrossEntropyLoss()\n     optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n     \n     data_file = \"\"\n"
                },
                {
                    "date": 1718607847909,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,117 @@\n+import math\n+import os\n+import threading\n+import time\n+import random\n+import logging\n+import pandas as pd\n+import torch\n+from matplotlib import pyplot\n+\n+import numpy as np\n+import scipy.io as sio\n+\n+from torch import nn\n+from torch.utils.data import Dataset, DataLoader\n+import torch.nn.functional as F\n+\n+import crypten\n+import crypten.mpc as mpc\n+import crypten.communicator as comm\n+\n+from crypten.mpc.primitives import BinarySharedTensor, ArithmeticSharedTensor\n+from crypten.mpc.primitives.converters import convert, _B2A\n+\n+from multiprocessing import Pool\n+import multiprocessing\n+\n+\n+DATASET_DIR = os.path.join(os.path.dirname(__file__), '../dataset')\n+\n+class DataSetParam:\n+    def __init__(self, csv_file):\n+        self.data = pd.read_csv(csv_file)\n+        self.features = self.data.iloc[:, :-1].values\n+        self.labels = self.data.iloc[:, -1].values\n+\n+    def __len__(self):\n+        return len(self.data)\n+\n+    def __getitem__(self, idx):\n+        features = torch.tensor(self.features[idx], dtype=torch.float32)\n+        label = torch.tensor(self.labels[idx], dtype=torch.long)\n+        return features, label\n+\n+class Dataset:\n+    MNIST = DataSetParam('MNIST.csv')\n+\n+\n+\n+class classficationNN(nn.Module):\n+    def __init__(self, input_size, num_classes):\n+        super(classficationNN, self).__init__()\n+        self.fc1 = nn.Linear(input_size, 128)\n+        self.fc2 = nn.Linear(128, 64)\n+        self.fc3 = nn.Linear(64, num_classes)\n+\n+    def forward(self, x):\n+        x = F.relu(self.fc1(x))\n+        x = F.relu(self.fc2(x))\n+        x = self.fc3(x)\n+        return x\n+\n+# @mpc.run_multiprocess(world_size=2)\n+def model_train(model, dataloader, criterion, optimizer, num_epochs):\n+    \n+    \n+    \n+    \n+    for epoch in range(num_epochs):\n+        running_loss = 0.0\n+        for inputs, labels in dataloader:\n+            optimizer.zero_grad()\n+            \n+        \n+    \n+def class_train(\n+    epochs=25,\n+    batch_size=32,\n+    lr=0.01,\n+    seed=None,\n+):\n+    if seed is not None:\n+        random.seed(seed)\n+        torch.manual_seed(seed)\n+\n+    crypten.init()\n+    \n+    model = classficationNN()\n+    criterion = nn.CrossEntropyLoss()\n+    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n+    \n+    \n+\n+\n+# if __name__ == '__main__':\n+#     test_compute_encrypt()\n+\n+\n+def load_data():\n+    \n+\n+\n+\n+def test(\n+    number = 10,\n+    ratio = 0.1,\n+):\n+    crypten.init()\n+    rank = comm.get().get_rank()\n+    \n+    # Set random seed for reproducibility\n+    torch.manual_seed(1)\n+    \n+    crypten.print(f'======start======')\n+    result =  train_model(number, ratio)\n+    crypten.print(f'=====end======')\n+   \n"
                },
                {
                    "date": 1718607863398,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -84,130 +84,14 @@\n         torch.manual_seed(seed)\n \n     crypten.init()\n     \n-    model = classficationNN()\n-    criterion = nn.CrossEntropyLoss()\n-    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n+    data_train = Dataset.\n     \n-    \n-\n-\n-# if __name__ == '__main__':\n-#     test_compute_encrypt()\n-\n-\n-def load_data():\n-    \n-\n-\n-\n-def test(\n-    number = 10,\n-    ratio = 0.1,\n-):\n-    crypten.init()\n-    rank = comm.get().get_rank()\n-    \n-    # Set random seed for reproducibility\n-    torch.manual_seed(1)\n-    \n-    crypten.print(f'======start======')\n-    result =  train_model(number, ratio)\n-    crypten.print(f'=====end======')\n-   \n-import math\n-import os\n-import threading\n-import time\n-import random\n-import logging\n-import pandas as pd\n-import torch\n-from matplotlib import pyplot\n-\n-import numpy as np\n-import scipy.io as sio\n-\n-from torch import nn\n-from torch.utils.data import Dataset, DataLoader\n-import torch.nn.functional as F\n-\n-import crypten\n-import crypten.mpc as mpc\n-import crypten.communicator as comm\n-\n-from crypten.mpc.primitives import BinarySharedTensor, ArithmeticSharedTensor\n-from crypten.mpc.primitives.converters import convert, _B2A\n-\n-from multiprocessing import Pool\n-import multiprocessing\n-\n-\n-DATASET_DIR = os.path.join(os.path.dirname(__file__), '../dataset')\n-\n-class DataSetParam:\n-    def __init__(self, csv_file):\n-        self.data = pd.read_csv(csv_file)\n-        self.features = self.data.iloc[:, :-1].values\n-        self.labels = self.data.iloc[:, -1].values\n-\n-    def __len__(self):\n-        return len(self.data)\n-\n-    def __getitem__(self, idx):\n-        features = torch.tensor(self.features[idx], dtype=torch.float32)\n-        label = torch.tensor(self.labels[idx], dtype=torch.long)\n-        return features, label\n-\n-class Dataset:\n-    MNIST = DataSetParam('MNIST.csv')\n-\n-\n-\n-class classficationNN(nn.Module):\n-    def __init__(self, input_size, num_classes):\n-        super(classficationNN, self).__init__()\n-        self.fc1 = nn.Linear(input_size, 128)\n-        self.fc2 = nn.Linear(128, 64)\n-        self.fc3 = nn.Linear(64, num_classes)\n-\n-    def forward(self, x):\n-        x = F.relu(self.fc1(x))\n-        x = F.relu(self.fc2(x))\n-        x = self.fc3(x)\n-        return x\n-\n-# @mpc.run_multiprocess(world_size=2)\n-def model_train(model, dataloader, criterion, optimizer, num_epochs):\n-    \n-    \n-    \n-    \n-    for epoch in range(num_epochs):\n-        running_loss = 0.0\n-        for inputs, labels in dataloader:\n-            optimizer.zero_grad()\n-            \n-        \n-    \n-def class_train(\n-    epochs=25,\n-    batch_size=32,\n-    lr=0.01,\n-    seed=None,\n-):\n-    if seed is not None:\n-        random.seed(seed)\n-        torch.manual_seed(seed)\n-\n-    crypten.init()\n-    \n     model = classficationNN()\n     criterion = nn.CrossEntropyLoss()\n     optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n     \n-    data_file = \"\"\n     \n \n \n # if __name__ == '__main__':\n"
                },
                {
                    "date": 1718607873245,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -41,9 +41,9 @@\n         features = torch.tensor(self.features[idx], dtype=torch.float32)\n         label = torch.tensor(self.labels[idx], dtype=torch.long)\n         return features, label\n \n-class Dataset:\n+class DataSet:\n     MNIST = DataSetParam('MNIST.csv')\n \n \n \n"
                },
                {
                    "date": 1718607879075,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,119 @@\n+import math\n+import os\n+import threading\n+import time\n+import random\n+import logging\n+import pandas as pd\n+import torch\n+from matplotlib import pyplot\n+\n+import numpy as np\n+import scipy.io as sio\n+\n+from torch import nn\n+from torch.utils.data import Dataset, DataLoader\n+import torch.nn.functional as F\n+\n+import crypten\n+import crypten.mpc as mpc\n+import crypten.communicator as comm\n+\n+from crypten.mpc.primitives import BinarySharedTensor, ArithmeticSharedTensor\n+from crypten.mpc.primitives.converters import convert, _B2A\n+\n+from multiprocessing import Pool\n+import multiprocessing\n+\n+\n+DATASET_DIR = os.path.join(os.path.dirname(__file__), '../dataset')\n+\n+class DataSetParam:\n+    def __init__(self, csv_file):\n+        self.data = pd.read_csv(csv_file)\n+        self.features = self.data.iloc[:, :-1].values\n+        self.labels = self.data.iloc[:, -1].values\n+\n+    def __len__(self):\n+        return len(self.data)\n+\n+    def __getitem__(self, idx):\n+        features = torch.tensor(self.features[idx], dtype=torch.float32)\n+        label = torch.tensor(self.labels[idx], dtype=torch.long)\n+        return features, label\n+\n+class DataSet:\n+    MNIST = DataSetParam('MNIST.csv')\n+\n+\n+\n+class classficationNN(nn.Module):\n+    def __init__(self, input_size, num_classes):\n+        super(classficationNN, self).__init__()\n+        self.fc1 = nn.Linear(input_size, 128)\n+        self.fc2 = nn.Linear(128, 64)\n+        self.fc3 = nn.Linear(64, num_classes)\n+\n+    def forward(self, x):\n+        x = F.relu(self.fc1(x))\n+        x = F.relu(self.fc2(x))\n+        x = self.fc3(x)\n+        return x\n+\n+# @mpc.run_multiprocess(world_size=2)\n+def model_train(model, dataloader, criterion, optimizer, num_epochs):\n+    \n+    \n+    \n+    \n+    for epoch in range(num_epochs):\n+        running_loss = 0.0\n+        for inputs, labels in dataloader:\n+            optimizer.zero_grad()\n+            \n+        \n+    \n+def class_train(\n+    epochs=25,\n+    batch_size=32,\n+    lr=0.01,\n+    seed=None,\n+):\n+    if seed is not None:\n+        random.seed(seed)\n+        torch.manual_seed(seed)\n+\n+    crypten.init()\n+    \n+    data_train = DataSet.MNIST\n+    \n+    model = classficationNN()\n+    criterion = nn.CrossEntropyLoss()\n+    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n+    \n+    \n+\n+\n+# if __name__ == '__main__':\n+#     test_compute_encrypt()\n+\n+\n+def load_data():\n+    \n+\n+\n+\n+def test(\n+    number = 10,\n+    ratio = 0.1,\n+):\n+    crypten.init()\n+    rank = comm.get().get_rank()\n+    \n+    # Set random seed for reproducibility\n+    torch.manual_seed(1)\n+    \n+    crypten.print(f'======start======')\n+    result =  train_model(number, ratio)\n+    crypten.print(f'=====end======')\n+   \n"
                },
                {
                    "date": 1718607893328,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -86,127 +86,10 @@\n     crypten.init()\n     \n     data_train = DataSet.MNIST\n     \n-    model = classficationNN()\n-    criterion = nn.CrossEntropyLoss()\n-    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n     \n     \n-\n-\n-# if __name__ == '__main__':\n-#     test_compute_encrypt()\n-\n-\n-def load_data():\n-    \n-\n-\n-\n-def test(\n-    number = 10,\n-    ratio = 0.1,\n-):\n-    crypten.init()\n-    rank = comm.get().get_rank()\n-    \n-    # Set random seed for reproducibility\n-    torch.manual_seed(1)\n-    \n-    crypten.print(f'======start======')\n-    result =  train_model(number, ratio)\n-    crypten.print(f'=====end======')\n-   \n-import math\n-import os\n-import threading\n-import time\n-import random\n-import logging\n-import pandas as pd\n-import torch\n-from matplotlib import pyplot\n-\n-import numpy as np\n-import scipy.io as sio\n-\n-from torch import nn\n-from torch.utils.data import Dataset, DataLoader\n-import torch.nn.functional as F\n-\n-import crypten\n-import crypten.mpc as mpc\n-import crypten.communicator as comm\n-\n-from crypten.mpc.primitives import BinarySharedTensor, ArithmeticSharedTensor\n-from crypten.mpc.primitives.converters import convert, _B2A\n-\n-from multiprocessing import Pool\n-import multiprocessing\n-\n-\n-DATASET_DIR = os.path.join(os.path.dirname(__file__), '../dataset')\n-\n-class DataSetParam:\n-    def __init__(self, csv_file):\n-        self.data = pd.read_csv(csv_file)\n-        self.features = self.data.iloc[:, :-1].values\n-        self.labels = self.data.iloc[:, -1].values\n-\n-    def __len__(self):\n-        return len(self.data)\n-\n-    def __getitem__(self, idx):\n-        features = torch.tensor(self.features[idx], dtype=torch.float32)\n-        label = torch.tensor(self.labels[idx], dtype=torch.long)\n-        return features, label\n-\n-class DataSet:\n-    MNIST = DataSetParam('MNIST.csv')\n-\n-\n-\n-class classficationNN(nn.Module):\n-    def __init__(self, input_size, num_classes):\n-        super(classficationNN, self).__init__()\n-        self.fc1 = nn.Linear(input_size, 128)\n-        self.fc2 = nn.Linear(128, 64)\n-        self.fc3 = nn.Linear(64, num_classes)\n-\n-    def forward(self, x):\n-        x = F.relu(self.fc1(x))\n-        x = F.relu(self.fc2(x))\n-        x = self.fc3(x)\n-        return x\n-\n-# @mpc.run_multiprocess(world_size=2)\n-def model_train(model, dataloader, criterion, optimizer, num_epochs):\n-    \n-    \n-    \n-    \n-    for epoch in range(num_epochs):\n-        running_loss = 0.0\n-        for inputs, labels in dataloader:\n-            optimizer.zero_grad()\n-            \n-        \n-    \n-def class_train(\n-    epochs=25,\n-    batch_size=32,\n-    lr=0.01,\n-    seed=None,\n-):\n-    if seed is not None:\n-        random.seed(seed)\n-        torch.manual_seed(seed)\n-\n-    crypten.init()\n-    \n-    data_train = Dataset.\n-    \n     model = classficationNN()\n     criterion = nn.CrossEntropyLoss()\n     optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n     \n"
                },
                {
                    "date": 1718607916946,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -86,10 +86,10 @@\n     crypten.init()\n     \n     data_train = DataSet.MNIST\n     \n+    feature,label = \n     \n-    \n     model = classficationNN()\n     criterion = nn.CrossEntropyLoss()\n     optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n     \n"
                },
                {
                    "date": 1718607922084,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,121 @@\n+import math\n+import os\n+import threading\n+import time\n+import random\n+import logging\n+import pandas as pd\n+import torch\n+from matplotlib import pyplot\n+\n+import numpy as np\n+import scipy.io as sio\n+\n+from torch import nn\n+from torch.utils.data import Dataset, DataLoader\n+import torch.nn.functional as F\n+\n+import crypten\n+import crypten.mpc as mpc\n+import crypten.communicator as comm\n+\n+from crypten.mpc.primitives import BinarySharedTensor, ArithmeticSharedTensor\n+from crypten.mpc.primitives.converters import convert, _B2A\n+\n+from multiprocessing import Pool\n+import multiprocessing\n+\n+\n+DATASET_DIR = os.path.join(os.path.dirname(__file__), '../dataset')\n+\n+class DataSetParam:\n+    def __init__(self, csv_file):\n+        self.data = pd.read_csv(csv_file)\n+        self.features = self.data.iloc[:, :-1].values\n+        self.labels = self.data.iloc[:, -1].values\n+\n+    def __len__(self):\n+        return len(self.data)\n+\n+    def __getitem__(self, idx):\n+        features = torch.tensor(self.features[idx], dtype=torch.float32)\n+        label = torch.tensor(self.labels[idx], dtype=torch.long)\n+        return features, label\n+\n+class DataSet:\n+    MNIST = DataSetParam('MNIST.csv')\n+\n+\n+\n+class classficationNN(nn.Module):\n+    def __init__(self, input_size, num_classes):\n+        super(classficationNN, self).__init__()\n+        self.fc1 = nn.Linear(input_size, 128)\n+        self.fc2 = nn.Linear(128, 64)\n+        self.fc3 = nn.Linear(64, num_classes)\n+\n+    def forward(self, x):\n+        x = F.relu(self.fc1(x))\n+        x = F.relu(self.fc2(x))\n+        x = self.fc3(x)\n+        return x\n+\n+# @mpc.run_multiprocess(world_size=2)\n+def model_train(model, dataloader, criterion, optimizer, num_epochs):\n+    \n+    \n+    \n+    \n+    for epoch in range(num_epochs):\n+        running_loss = 0.0\n+        for inputs, labels in dataloader:\n+            optimizer.zero_grad()\n+            \n+        \n+    \n+def class_train(\n+    epochs=25,\n+    batch_size=32,\n+    lr=0.01,\n+    seed=None,\n+):\n+    if seed is not None:\n+        random.seed(seed)\n+        torch.manual_seed(seed)\n+\n+    crypten.init()\n+    \n+    data_train = DataSet.MNIST\n+    \n+    feature,label = data_loader()\n+    \n+    model = classficationNN()\n+    criterion = nn.CrossEntropyLoss()\n+    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n+    \n+    \n+\n+\n+# if __name__ == '__main__':\n+#     test_compute_encrypt()\n+\n+\n+def load_data():\n+    \n+\n+\n+\n+def test(\n+    number = 10,\n+    ratio = 0.1,\n+):\n+    crypten.init()\n+    rank = comm.get().get_rank()\n+    \n+    # Set random seed for reproducibility\n+    torch.manual_seed(1)\n+    \n+    crypten.print(f'======start======')\n+    result =  train_model(number, ratio)\n+    crypten.print(f'=====end======')\n+   \n"
                },
                {
                    "date": 1718607929949,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -86,9 +86,9 @@\n     crypten.init()\n     \n     data_train = DataSet.MNIST\n     \n-    feature,label = data_loader()\n+    feature,label = data_loader(data_train.)\n     \n     model = classficationNN()\n     criterion = nn.CrossEntropyLoss()\n     optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n@@ -118,125 +118,4 @@\n     crypten.print(f'======start======')\n     result =  train_model(number, ratio)\n     crypten.print(f'=====end======')\n    \n-import math\n-import os\n-import threading\n-import time\n-import random\n-import logging\n-import pandas as pd\n-import torch\n-from matplotlib import pyplot\n-\n-import numpy as np\n-import scipy.io as sio\n-\n-from torch import nn\n-from torch.utils.data import Dataset, DataLoader\n-import torch.nn.functional as F\n-\n-import crypten\n-import crypten.mpc as mpc\n-import crypten.communicator as comm\n-\n-from crypten.mpc.primitives import BinarySharedTensor, ArithmeticSharedTensor\n-from crypten.mpc.primitives.converters import convert, _B2A\n-\n-from multiprocessing import Pool\n-import multiprocessing\n-\n-\n-DATASET_DIR = os.path.join(os.path.dirname(__file__), '../dataset')\n-\n-class DataSetParam:\n-    def __init__(self, csv_file):\n-        self.data = pd.read_csv(csv_file)\n-        self.features = self.data.iloc[:, :-1].values\n-        self.labels = self.data.iloc[:, -1].values\n-\n-    def __len__(self):\n-        return len(self.data)\n-\n-    def __getitem__(self, idx):\n-        features = torch.tensor(self.features[idx], dtype=torch.float32)\n-        label = torch.tensor(self.labels[idx], dtype=torch.long)\n-        return features, label\n-\n-class DataSet:\n-    MNIST = DataSetParam('MNIST.csv')\n-\n-\n-\n-class classficationNN(nn.Module):\n-    def __init__(self, input_size, num_classes):\n-        super(classficationNN, self).__init__()\n-        self.fc1 = nn.Linear(input_size, 128)\n-        self.fc2 = nn.Linear(128, 64)\n-        self.fc3 = nn.Linear(64, num_classes)\n-\n-    def forward(self, x):\n-        x = F.relu(self.fc1(x))\n-        x = F.relu(self.fc2(x))\n-        x = self.fc3(x)\n-        return x\n-\n-# @mpc.run_multiprocess(world_size=2)\n-def model_train(model, dataloader, criterion, optimizer, num_epochs):\n-    \n-    \n-    \n-    \n-    for epoch in range(num_epochs):\n-        running_loss = 0.0\n-        for inputs, labels in dataloader:\n-            optimizer.zero_grad()\n-            \n-        \n-    \n-def class_train(\n-    epochs=25,\n-    batch_size=32,\n-    lr=0.01,\n-    seed=None,\n-):\n-    if seed is not None:\n-        random.seed(seed)\n-        torch.manual_seed(seed)\n-\n-    crypten.init()\n-    \n-    data_train = DataSet.MNIST\n-    \n-    feature,label = \n-    \n-    model = classficationNN()\n-    criterion = nn.CrossEntropyLoss()\n-    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n-    \n-    \n-\n-\n-# if __name__ == '__main__':\n-#     test_compute_encrypt()\n-\n-\n-def load_data():\n-    \n-\n-\n-\n-def test(\n-    number = 10,\n-    ratio = 0.1,\n-):\n-    crypten.init()\n-    rank = comm.get().get_rank()\n-    \n-    # Set random seed for reproducibility\n-    torch.manual_seed(1)\n-    \n-    crypten.print(f'======start======')\n-    result =  train_model(number, ratio)\n-    crypten.print(f'=====end======')\n-   \n"
                },
                {
                    "date": 1718608010213,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -86,9 +86,9 @@\n     crypten.init()\n     \n     data_train = DataSet.MNIST\n     \n-    feature,label = data_loader(data_train.)\n+    feature,label = data_loader(data_train.csv_file)\n     \n     model = classficationNN()\n     criterion = nn.CrossEntropyLoss()\n     optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n"
                },
                {
                    "date": 1718608039684,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -94,13 +94,11 @@\n     optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n     \n     \n \n+def\n \n-# if __name__ == '__main__':\n-#     test_compute_encrypt()\n \n-\n def load_data():\n     \n \n \n"
                },
                {
                    "date": 1718608385083,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -28,21 +28,16 @@\n \n DATASET_DIR = os.path.join(os.path.dirname(__file__), '../dataset')\n \n class DataSetParam:\n-    def __init__(self, csv_file):\n-        self.data = pd.read_csv(csv_file)\n-        self.features = self.data.iloc[:, :-1].values\n-        self.labels = self.data.iloc[:, -1].values\n+    def __init__(self, dataset_name,  instance_number, learning_rate, epochs_number, batch_size):\n+        self.dataset_name = dataset_name\n+        self.instance_number = instance_number\n+        self.learning_rate = learning_rate\n+        self.epochs_number = epochs_number\n+        self.batch_size = batch_size\n \n-    def __len__(self):\n-        return len(self.data)\n \n-    def __getitem__(self, idx):\n-        features = torch.tensor(self.features[idx], dtype=torch.float32)\n-        label = torch.tensor(self.labels[idx], dtype=torch.long)\n-        return features, label\n-\n class DataSet:\n     MNIST = DataSetParam('MNIST.csv')\n \n \n@@ -94,11 +89,11 @@\n     optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n     \n     \n \n-def\n \n \n+\n def load_data():\n     \n \n \n"
                },
                {
                    "date": 1718608391193,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -28,14 +28,10 @@\n \n DATASET_DIR = os.path.join(os.path.dirname(__file__), '../dataset')\n \n class DataSetParam:\n-    def __init__(self, dataset_name,  instance_number, learning_rate, epochs_number, batch_size):\n+    def __init__(self, dataset_name):\n         self.dataset_name = dataset_name\n-        self.instance_number = instance_number\n-        self.learning_rate = learning_rate\n-        self.epochs_number = epochs_number\n-        self.batch_size = batch_size\n \n \n class DataSet:\n     MNIST = DataSetParam('MNIST.csv')\n"
                },
                {
                    "date": 1718608795576,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -52,12 +52,12 @@\n         return x\n \n # @mpc.run_multiprocess(world_size=2)\n def model_train(model, dataloader, criterion, optimizer, num_epochs):\n+    crypten.init()\n     \n     \n     \n-    \n     for epoch in range(num_epochs):\n         running_loss = 0.0\n         for inputs, labels in dataloader:\n             optimizer.zero_grad()\n"
                },
                {
                    "date": 1718608834159,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -53,11 +53,11 @@\n \n # @mpc.run_multiprocess(world_size=2)\n def model_train(model, dataloader, criterion, optimizer, num_epochs):\n     crypten.init()\n+    feature,label = data_loader(data_train.csv_file)\n     \n     \n-    \n     for epoch in range(num_epochs):\n         running_loss = 0.0\n         for inputs, labels in dataloader:\n             optimizer.zero_grad()\n"
                },
                {
                    "date": 1718608845266,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -53,8 +53,9 @@\n \n # @mpc.run_multiprocess(world_size=2)\n def model_train(model, dataloader, criterion, optimizer, num_epochs):\n     crypten.init()\n+    \n     feature,label = data_loader(data_train.csv_file)\n     \n     \n     for epoch in range(num_epochs):\n@@ -85,16 +86,26 @@\n     optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n     \n     \n \n+def load_dataset(dataset):\n+    dataset_path = os.path.join(DATASET_DIR, dataset)\n \n+    data = sio.loadmat(dataset_path)\n \n+    feature = data[\"data\"]\n+    label = data[\"labels\"][:, 0]\n \n-def load_data():\n-    \n+    # if sample_count is not None:\n+    #     feature = feature[:min(len(feature), sample_count)]\n+    #     label = label[:min(len(label), sample_count)]\n \n+    feature = np.array(feature)\n+    label = np.array(label)\n \n+    return feature, label\n \n+\n def test(\n     number = 10,\n     ratio = 0.1,\n ):\n"
                },
                {
                    "date": 1718608856182,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -78,9 +78,9 @@\n     crypten.init()\n     \n     data_train = DataSet.MNIST\n     \n-    feature,label = data_loader(data_train.csv_file)\n+    feature,label = load_dataset(data_train.csv_file)\n     \n     model = classficationNN()\n     criterion = nn.CrossEntropyLoss()\n     optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n"
                },
                {
                    "date": 1718609027425,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -80,9 +80,9 @@\n     data_train = DataSet.MNIST\n     \n     feature,label = load_dataset(data_train.csv_file)\n     \n-    model = classficationNN()\n+    model = classficationNN(feature, label)\n     criterion = nn.CrossEntropyLoss()\n     optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n     \n     \n"
                },
                {
                    "date": 1718609152117,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -54,8 +54,10 @@\n # @mpc.run_multiprocess(world_size=2)\n def model_train(model, dataloader, criterion, optimizer, num_epochs):\n     crypten.init()\n     \n+    \n+    \n     feature,label = data_loader(data_train.csv_file)\n     \n     \n     for epoch in range(num_epochs):\n"
                },
                {
                    "date": 1718609161548,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -54,10 +54,10 @@\n # @mpc.run_multiprocess(world_size=2)\n def model_train(model, dataloader, criterion, optimizer, num_epochs):\n     crypten.init()\n     \n+data_train = DataSet.MNIST\n     \n-    \n     feature,label = data_loader(data_train.csv_file)\n     \n     \n     for epoch in range(num_epochs):\n"
                },
                {
                    "date": 1718609174961,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -54,11 +54,11 @@\n # @mpc.run_multiprocess(world_size=2)\n def model_train(model, dataloader, criterion, optimizer, num_epochs):\n     crypten.init()\n     \n-data_train = DataSet.MNIST\n+    data_train = DataSet.MNIST\n     \n-    feature,label = data_loader(data_train.csv_file)\n+    feature,label = load_datasetr(data_train.csv_file)\n     \n     \n     for epoch in range(num_epochs):\n         running_loss = 0.0\n"
                },
                {
                    "date": 1718609191485,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -56,10 +56,12 @@\n     crypten.init()\n     \n     data_train = DataSet.MNIST\n     \n-    feature,label = load_datasetr(data_train.csv_file)\n+    feature,label = load_dataset(data_train.csv_file)\n     \n+    feature_enc = crypten.cryptensor(feature)\n+    label_enc = crypten.cryptensor(label_one_hot, requires_grad=True)\n     \n     for epoch in range(num_epochs):\n         running_loss = 0.0\n         for inputs, labels in dataloader:\n"
                },
                {
                    "date": 1718609209261,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -59,10 +59,13 @@\n     \n     feature,label = load_dataset(data_train.csv_file)\n     \n     feature_enc = crypten.cryptensor(feature)\n-    label_enc = crypten.cryptensor(label_one_hot, requires_grad=True)\n+    label_enc = crypten.cryptensor(label, requires_grad=True)\n     \n+    \n+    \n+    \n     for epoch in range(num_epochs):\n         running_loss = 0.0\n         for inputs, labels in dataloader:\n             optimizer.zero_grad()\n"
                },
                {
                    "date": 1718609216129,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -61,11 +61,11 @@\n     \n     feature_enc = crypten.cryptensor(feature)\n     label_enc = crypten.cryptensor(label, requires_grad=True)\n     \n+    model = classficationNN()\n     \n     \n-    \n     for epoch in range(num_epochs):\n         running_loss = 0.0\n         for inputs, labels in dataloader:\n             optimizer.zero_grad()\n"
                },
                {
                    "date": 1718609262837,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -64,8 +64,9 @@\n     \n     model = classficationNN()\n     \n     \n+    \n     for epoch in range(num_epochs):\n         running_loss = 0.0\n         for inputs, labels in dataloader:\n             optimizer.zero_grad()\n"
                },
                {
                    "date": 1718609295876,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -54,8 +54,10 @@\n # @mpc.run_multiprocess(world_size=2)\n def model_train(model, dataloader, criterion, optimizer, num_epochs):\n     crypten.init()\n     \n+    \n+    \n     data_train = DataSet.MNIST\n     \n     feature,label = load_dataset(data_train.csv_file)\n     \n@@ -63,10 +65,10 @@\n     label_enc = crypten.cryptensor(label, requires_grad=True)\n     \n     model = classficationNN()\n     \n+    model.encrypt()\n     \n-    \n     for epoch in range(num_epochs):\n         running_loss = 0.0\n         for inputs, labels in dataloader:\n             optimizer.zero_grad()\n"
                },
                {
                    "date": 1718609307879,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -51,9 +51,9 @@\n         x = self.fc3(x)\n         return x\n \n # @mpc.run_multiprocess(world_size=2)\n-def model_train(model, dataloader, criterion, optimizer, num_epochs):\n+def model_train(model, dataloader, criterion, optimizer, num_epochs, ):\n     crypten.init()\n     \n     learning_rate = 0.001\n     num_epochs = 20\n"
                },
                {
                    "date": 1718609393358,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,112 @@\n+import math\n+import os\n+import threading\n+import time\n+import random\n+import logging\n+import pandas as pd\n+import torch\n+from matplotlib import pyplot\n+\n+import numpy as np\n+import scipy.io as sio\n+\n+from torch import nn\n+from torch.utils.data import Dataset, DataLoader\n+import torch.nn.functional as F\n+\n+import crypten\n+import crypten.mpc as mpc\n+import crypten.communicator as comm\n+\n+from crypten.mpc.primitives import BinarySharedTensor, ArithmeticSharedTensor\n+from crypten.mpc.primitives.converters import convert, _B2A\n+\n+from multiprocessing import Pool\n+import multiprocessing\n+\n+\n+DATASET_DIR = os.path.join(os.path.dirname(__file__), '../dataset')\n+\n+class DataSetParam:\n+    def __init__(self, dataset_name):\n+        self.dataset_name = dataset_name\n+\n+\n+class DataSet:\n+    MNIST = DataSetParam('MNIST.csv')\n+\n+\n+\n+class classficationNN(nn.Module):\n+    def __init__(self, input_size, num_classes):\n+        super(classficationNN, self).__init__()\n+        self.fc1 = nn.Linear(input_size, 128)\n+        self.fc2 = nn.Linear(128, 64)\n+        self.fc3 = nn.Linear(64, num_classes)\n+\n+    def forward(self, x):\n+        x = F.relu(self.fc1(x))\n+        x = F.relu(self.fc2(x))\n+        x = self.fc3(x)\n+        return x\n+\n+# @mpc.run_multiprocess(world_size=2)\n+def model_train(model, dataloader, criterion, optimizer, num_epochs, learning_rate, batch_size):\n+    crypten.init()\n+    \n+    data_train = DataSet.MNIST\n+    \n+    feature,label = load_dataset(data_train.csv_file)\n+    \n+    feature_enc = crypten.cryptensor(feature)\n+    label_enc = crypten.cryptensor(label, requires_grad=True)\n+    \n+    model = classficationNN()\n+    \n+    model.encrypt()\n+    \n+    loss_func = crypten.nn.CrossEntropyLoss()\n+    \n+    \n+\n+\n+\n+\n+\n+\n+\n+               \n+\n+def load_dataset(dataset):\n+    dataset_path = os.path.join(DATASET_DIR, dataset)\n+\n+    data = sio.loadmat(dataset_path)\n+\n+    feature = data[\"data\"]\n+    label = data[\"labels\"][:, 0]\n+\n+    # if sample_count is not None:\n+    #     feature = feature[:min(len(feature), sample_count)]\n+    #     label = label[:min(len(label), sample_count)]\n+\n+    feature = np.array(feature)\n+    label = np.array(label)\n+\n+    return feature, label\n+\n+\n+def test(\n+    number = 10,\n+    ratio = 0.1,\n+):\n+    crypten.init()\n+    rank = comm.get().get_rank()\n+    \n+    # Set random seed for reproducibility\n+    torch.manual_seed(1)\n+    \n+    crypten.print(f'======start======')\n+    result =  train_model(number, ratio)\n+    crypten.print(f'=====end======')\n+   \n"
                }
            ],
            "date": 1718524863171,
            "name": "Commit-0",
            "content": "import math\nimport os\nimport threading\nimport time\nimport random\nimport logging\n\nimport torch\nfrom matplotlib import pyplot\n\nimport numpy as np\nimport scipy.io as sio\n\nfrom torch import nn\n\nimport crypten\nimport crypten.mpc as mpc\nimport crypten.communicator as comm\n\nfrom crypten.mpc.primitives import BinarySharedTensor, ArithmeticSharedTensor\nfrom crypten.mpc.primitives.converters import convert, _B2A\n\nfrom multiprocessing import Pool\nimport multiprocessing\n\n\n# @mpc.run_multiprocess(world_size=2)\ndef test_compute_encrypt(N, k_N_ratio):\n\n    # N = 10\n    # k_N_ratio = 0.4\n    k = int(N * (1 - k_N_ratio))\n\n    # a_plain = torch.randint(2, (N,))\n    \n    # 设置一定的比例\n    a_plain = [1] * k + [0] * (N - k)\n    \n    # 打乱向量顺序\n    random.shuffle(a_plain)\n    \n    # 转换为PyTorch的tensor\n    a_plain = torch.tensor(a_plain)\n    \n    crypten.print(f'a_plain: {a_plain}')\n\n    a = BinarySharedTensor(a_plain)\n    # crypten.print(f'a_encrypt: {a}')\n\n    A_plain = torch.diag(a_plain)\n    # crypten.print(f'A_plain: {A_plain}')\n    A = BinarySharedTensor(A_plain)\n    # crypten.print(f'A_encrypt: {A}')\n\n    # R = torch.zeros((N, N))\n    # R = ArithmeticSharedTensor(R)\n    # R = BinarySharedTensor(R)\n    R = A\n    start = time.time()     \n    for j in range(k):\n        for ti in range(N-k):\n            t = ti + k\n            s = (~a[j]) & a[t]\n            a[j] = a[j] ^ s\n            a[t] = a[t] ^ s\n\n            # 因为windows上的BinarySharedTensor没有实现get_plain_text方法,所以如果是windows上跑的话在这里需要转为ArithmeticSharedTensor\n            # 同时R也需要初始化为ArithmeticSharedTensor类型.linux上可以不用转换\n            # R[j, t] = convert( (A[j, j]) ^ s, crypten.mpc.arithmetic)\n            # R[t, j] = convert( (A[t, t]) ^ s, crypten.mpc.arithmetic)\n\n            R[j, t] = A[j, t] \n            R[t, j] = ~A[t, j] & s \n            R[j, j] = A[j, j] & ~s\n            R[t, t] = A[t, t] & ~s\n    \n    total_time = time.time() - start\n    crypten.print(f'time: {total_time}')\n    # R = R[:, :k]\n    R = R[:, :k].get_plain_text()\n\n\n    # 使用明文计算结果,方便后面比对密文结果是否正确\n    # crypten.print(f'======plain========')\n    R_plain_result = test_compute_plain(a_plain, N, k_N_ratio)\n    crypten.print(f'======output========')\n    crypten.print(f'R:{R}')\n    crypten.print(f'R_plain_result: {R_plain_result}')\n    crypten.print(f'R is right to plain: {R.eq(R_plain_result)}')\n\n\ndef test_compute_plain(src_a=None, N=10, k_N_ratio=0.4):\n    k = int(N * (1 - k_N_ratio))\n\n    a = torch.randint(2, (N,)) if src_a is None else src_a\n    A = torch.diag(a)\n    # crypten.print(f'A\\n: {A}')\n    R = A\n    \n    for j in range(k):\n        # crypten.print(f'j: {j}')\n        for ti in range(N-k):\n            t = ti + k\n            # crypten.print(f't: {t}')\n            # crypten.print(f'a[j]: {a[j]}')\n            # crypten.print(f'a[t]: {a[t]}')\n            s = (~a[j]) & a[t]\n            a[j] = a[j] ^ s\n            a[t] = a[t] ^ s\n            # crypten.print(f'a: {a}')\n            # crypten.print(f's: {s}')\n            # crypten.print(f'A[j, t]: {A[j, t]}')\n            # crypten.print(f'A[j, t]: {A[j, t]}')\n            R[j, t] = A[j, t] \n            R[t, j] = ~A[t, j] & s \n            R[j, j] = A[j, j] & ~s\n            R[t, t] = A[t, t] & ~s\n            # crypten.print(f'R\\n: {R}')\n\n    R = R[:, :k]\n    \n    return R\n\n\nif __name__ == '__main__':\n    test_compute_encrypt()\n\n\ndef v2Mr(\n    number = 10,\n    ratio = 0.1,\n):\n    crypten.init()\n    rank = comm.get().get_rank()\n    \n    # Set random seed for reproducibility\n    torch.manual_seed(1)\n    \n    crypten.print(f'======start======')\n    result =  test_compute_encrypt(number, ratio)\n    crypten.print(f'=====end======')\n   "
        }
    ]
}