{
    "sourceFile": "Dhamming.py",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 4,
            "patches": [
                {
                    "date": 1719836633884,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                },
                {
                    "date": 1719836644231,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,4 +1,28 @@\n+\n+import logging\n+import time\n+import csv\n+import os\n+import crypten\n+import torch\n+import numpy as np\n+from examples.meters import AverageMeter\n+\n+\n+DATASET_DIR = os.path.join(os.path.dirname(__file__), '../dataset')\n+\n+class DataSetParam:\n+    def __init__(self, dataset_name):\n+        self.dataset_name = dataset_name\n+\n+\n+class DataSet:\n+    sonar = DataSetParam('sonar.csv')\n+\n+\n+\n+\n def load_dataset(dataset):\n     dataset_path = os.path.join(DATASET_DIR, dataset)\n \n     # 尝试打开并读取CSV文件\n"
                },
                {
                    "date": 1719836655947,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -8,17 +8,18 @@\n import numpy as np\n from examples.meters import AverageMeter\n \n \n-DATASET_DIR = os.path.join(os.path.dirname(__file__), '../dataset')\n+DATASET_DIR = os.path.join(os.path.dirname(__file__), '/dataset')\n \n class DataSetParam:\n     def __init__(self, dataset_name):\n         self.dataset_name = dataset_name\n \n \n class DataSet:\n     sonar = DataSetParam('sonar.csv')\n+    \n \n \n \n \n"
                },
                {
                    "date": 1719836663181,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -17,9 +17,9 @@\n \n \n class DataSet:\n     sonar = DataSetParam('sonar.csv')\n-    \n+    binary_datastet = \n \n \n \n \n"
                },
                {
                    "date": 1719836672566,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -17,9 +17,9 @@\n \n \n class DataSet:\n     sonar = DataSetParam('sonar.csv')\n-    binary_datastet = \n+    binary_datastet = DataSetParam(\"binary_datastet.csv\")\n \n \n \n \n"
                }
            ],
            "date": 1719836633884,
            "name": "Commit-0",
            "content": "def load_dataset(dataset):\n    dataset_path = os.path.join(DATASET_DIR, dataset)\n\n    # 尝试打开并读取CSV文件\n    try:\n        with open(dataset_path, 'r', encoding='utf-8') as csvfile:\n            spamreader = csv.reader(csvfile)\n            data = np.array(list(spamreader))\n    except FileNotFoundError:\n        print(f\"Error: The file {dataset_path} was not found.\")\n        return None, None\n    except Exception as e:\n        print(f\"Error: An error occurred while reading the file: {e}\")\n        return None, None\n\n    # 检查数据是否为空\n    if data.size == 0:\n        print(\"Error: The dataset is empty.\")\n        return None, None\n\n    feature = data[:, :-1].astype(np.float64)\n    labels = data[:, -1]\n\n    # 创建标签映射\n    unique_labels = np.unique(labels)\n    label_to_int = {label: idx for idx, label in enumerate(unique_labels)}\n    int_labels = np.array([label_to_int[label] for label in labels], dtype=np.uint8)\n    labell = int_labels.reshape(-1,1)\n    \n    # 将标签转换为独热矩阵\n    one_hot_labels = np.zeros((int_labels.size, int_labels.max() + 1), dtype=np.uint8)\n    one_hot_labels[np.arange(int_labels.size), int_labels] = 1\n\n    print(\"======feature_size=====\", feature.shape)\n    print(\"======label_size=====\", labell.shape)\n    return feature, one_hot_labels"
        }
    ]
}