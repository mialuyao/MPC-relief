{
    "sourceFile": "model_train/test.py",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 57,
            "patches": [
                {
                    "date": 1719214452987,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                },
                {
                    "date": 1719215345366,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -136,9 +136,9 @@\n \n     # Set random seed for reproducibility\n     torch.manual_seed(1)\n \n-    data_train = DataSet.sona\n+    data_train = DataSet.sonar\n     \n     x, y = load_dataset(data_train.dataset_name)\n \n # NOTE：crypten.cryptensor \n"
                },
                {
                    "date": 1719215471168,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,166 @@\n+\n+import logging\n+import time\n+import csv\n+import os\n+import crypten\n+import torch\n+import numpy as np\n+from examples.meters import AverageMeter\n+\n+\n+DATASET_DIR = os.path.join(os.path.dirname(__file__), '../dataset')\n+\n+class DataSetParam:\n+    def __init__(self, dataset_name):\n+        self.dataset_name = dataset_name\n+\n+\n+class DataSet:\n+    sonar = DataSetParam('sonar.csv')\n+    sonar_selected = DataSetParam('sonar_selected.csv')\n+\n+\n+\n+\n+def train_linear_svm(features, labels, epochs, lr, print_time=False):\n+    # Initialize random weights\n+    w = features.new(torch.randn(features.size(1),1))\n+    b = features.new(torch.randn(1))\n+    # print(\"==========w========\", w.shape)\n+    # print(\"==========b========\", b.shape)\n+    # print(\"=======features=====\", features.shape)\n+\n+    if print_time:\n+        pt_time = AverageMeter()\n+        end = time.time()\n+    \n+    filename = \"Accuracy.txt\"\n+    with open(filename, 'a') as f:\n+        for epoch in range(epochs):\n+            # Forward\n+            label_predictions = features.matmul(w).add(b).sign()\n+            # label_predictions = w.matmul(features.T).add(b).sign()\n+            # print(\"=======labels======\", labels.shape)\n+            # print(\"=======label_predictions======\", label_predictions.shape)\n+            # Compute accuracy\n+            correct = label_predictions.mul(labels.view(-1,1))\n+            # print(\"=======correct======\", correct.shape)\n+            accuracy = correct.add(1).div(2).mean()\n+            if crypten.is_encrypted_tensor(accuracy):\n+                accuracy = accuracy.get_plain_text()\n+\n+            # Print Accuracy once\n+            if crypten.communicator.get().get_rank() == 0:\n+                # print(\n+                #     f\"Epoch {epoch} --- Training Accuracy %.2f%%\" % (accuracy.item() * 100)\n+                # )\n+                accuracy_str = \"%.2f%%\" % (accuracy * 100)\n+                accuracy_str_without_percent = accuracy_str.replace('%', '')\n+                f.write(accuracy_str_without_percent + \",\")\n+\n+            # Backward\n+            loss_grad = -labels * (1 - correct) * 0.5  # Hinge loss\n+            # print(\"=======loss_grad======\\n\", loss_grad.get_plain_text())\n+            b_grad = loss_grad.mean()\n+            # print(\"=======b_grad ======\", b_grad.shape)\n+            w_grad = features.t().matmul(loss_grad).div(loss_grad.size(0))\n+            # print(\"=======w_grad ======\", w_grad.shape)\n+            \n+\n+            # Update\n+            w -= w_grad * lr\n+            b -= b_grad * lr\n+\n+            if print_time:\n+                iter_time = time.time() - end\n+                pt_time.add(iter_time)\n+                print(\"Time %.6f (%.6f)\" % (iter_time, pt_time.value()))\n+                end = time.time()\n+\n+    return w, b\n+\n+\n+def evaluate_linear_svm(features, labels, w, b):\n+    \"\"\"Compute accuracy on a test set\"\"\"\n+    predictions = w.matmul(features).add(b).sign()\n+    correct = predictions.mul(labels)\n+    accuracy = correct.add(1).div(2).mean().get_plain_text()\n+    if crypten.communicator.get().get_rank() == 0:\n+        # print(\"Test accuracy %.2f%%\" % (accuracy.item() * 100))\n+        accuracy_str = \"%.2f%%\" % (accuracy * 100)\n+        filename = \"Accuracy.txt\"\n+        with open(filename, 'w') as f:\n+            f.write(accuracy_str)\n+\n+\n+def load_dataset(dataset):\n+    dataset_path = os.path.join(DATASET_DIR, dataset)\n+\n+    # 尝试打开并读取CSV文件\n+    try:\n+        with open(dataset_path, 'r', encoding='utf-8') as csvfile:\n+            spamreader = csv.reader(csvfile)\n+            data = np.array(list(spamreader))\n+    except FileNotFoundError:\n+        print(f\"Error: The file {dataset_path} was not found.\")\n+        return None, None\n+    except Exception as e:\n+        print(f\"Error: An error occurred while reading the file: {e}\")\n+        return None, None\n+\n+    # 检查数据是否为空\n+    if data.size == 0:\n+        print(\"Error: The dataset is empty.\")\n+        return None, None\n+\n+    feature = data[:, :-1].astype(np.float64)\n+    labels = data[:, -1]\n+\n+    # 创建标签映射\n+    unique_labels = np.unique(labels)\n+    label_to_int = {label: idx for idx, label in enumerate(unique_labels)}\n+    int_labels = np.array([label_to_int[label] for label in labels], dtype=np.uint8)\n+    labell = int_labels.reshape(-1,1)\n+\n+    # print(\"======feature_size=====\", feature.shape)\n+    # print(\"======label_size=====\", labell.shape)\n+    return feature, labell\n+\n+\n+\n+def run_mpc_linear_svm(\n+    epochs=100, lr=0.5\n+):\n+    crypten.init()\n+\n+    # Set random seed for reproducibility\n+    torch.manual_seed(1)\n+\n+    data_train = DataSet.sonar_selected\n+    \n+    x, y = load_dataset(data_train.dataset_name)\n+\n+# NOTE：crypten.cryptensor \n+    # Encrypt features / labels\n+    x = crypten.cryptensor(x)\n+    y = crypten.cryptensor(y)\n+\n+    logging.info(\"==================\")\n+    logging.info(\"CrypTen Training\")\n+    logging.info(\"==================\")\n+# NOTE：训练无差异\n+    w, b = train_linear_svm(x, y, epochs=epochs, lr=lr, print_time=True)\n+\n+    # if not skip_plaintext:\n+    #     logging.info(\"PyTorch Weights  :\")\n+    #     logging.info(w_torch)\n+    # logging.info(\"CrypTen Weights:\")\n+# NOTE：get_plain_text()\n+    # logging.info(w.get_plain_text())\n+\n+    # if not skip_plaintext:\n+    #     logging.info(\"PyTorch Bias  :\")\n+    #     logging.info(b_torch)\n+    # logging.info(\"CrypTen Bias:\")\n+    # logging.info(b.get_plain_text())\n"
                },
                {
                    "date": 1719215626927,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -71,13 +71,13 @@\n             # Update\n             w -= w_grad * lr\n             b -= b_grad * lr\n \n-            if print_time:\n-                iter_time = time.time() - end\n-                pt_time.add(iter_time)\n-                print(\"Time %.6f (%.6f)\" % (iter_time, pt_time.value()))\n-                end = time.time()\n+            # if print_time:\n+            #     iter_time = time.time() - end\n+            #     pt_time.add(iter_time)\n+            #     print(\"Time %.6f (%.6f)\" % (iter_time, pt_time.value()))\n+            #     end = time.time()\n \n     return w, b\n \n \n@@ -163,170 +163,4 @@\n     #     logging.info(\"PyTorch Bias  :\")\n     #     logging.info(b_torch)\n     # logging.info(\"CrypTen Bias:\")\n     # logging.info(b.get_plain_text())\n-\n-import logging\n-import time\n-import csv\n-import os\n-import crypten\n-import torch\n-import numpy as np\n-from examples.meters import AverageMeter\n-\n-\n-DATASET_DIR = os.path.join(os.path.dirname(__file__), '../dataset')\n-\n-class DataSetParam:\n-    def __init__(self, dataset_name):\n-        self.dataset_name = dataset_name\n-\n-\n-class DataSet:\n-    sonar = DataSetParam('sonar.csv')\n-    sonar_selected = DataSetParam('sonar_selected.csv')\n-\n-\n-\n-\n-def train_linear_svm(features, labels, epochs, lr, print_time=False):\n-    # Initialize random weights\n-    w = features.new(torch.randn(features.size(1),1))\n-    b = features.new(torch.randn(1))\n-    # print(\"==========w========\", w.shape)\n-    # print(\"==========b========\", b.shape)\n-    # print(\"=======features=====\", features.shape)\n-\n-    if print_time:\n-        pt_time = AverageMeter()\n-        end = time.time()\n-    \n-    filename = \"Accuracy.txt\"\n-    with open(filename, 'a') as f:\n-        for epoch in range(epochs):\n-            # Forward\n-            label_predictions = features.matmul(w).add(b).sign()\n-            # label_predictions = w.matmul(features.T).add(b).sign()\n-            # print(\"=======labels======\", labels.shape)\n-            # print(\"=======label_predictions======\", label_predictions.shape)\n-            # Compute accuracy\n-            correct = label_predictions.mul(labels.view(-1,1))\n-            # print(\"=======correct======\", correct.shape)\n-            accuracy = correct.add(1).div(2).mean()\n-            if crypten.is_encrypted_tensor(accuracy):\n-                accuracy = accuracy.get_plain_text()\n-\n-            # Print Accuracy once\n-            if crypten.communicator.get().get_rank() == 0:\n-                # print(\n-                #     f\"Epoch {epoch} --- Training Accuracy %.2f%%\" % (accuracy.item() * 100)\n-                # )\n-                accuracy_str = \"%.2f%%\" % (accuracy * 100)\n-                accuracy_str_without_percent = accuracy_str.replace('%', '')\n-                f.write(accuracy_str_without_percent + \",\")\n-\n-            # Backward\n-            loss_grad = -labels * (1 - correct) * 0.5  # Hinge loss\n-            # print(\"=======loss_grad======\\n\", loss_grad.get_plain_text())\n-            b_grad = loss_grad.mean()\n-            # print(\"=======b_grad ======\", b_grad.shape)\n-            w_grad = features.t().matmul(loss_grad).div(loss_grad.size(0))\n-            # print(\"=======w_grad ======\", w_grad.shape)\n-            \n-\n-            # Update\n-            w -= w_grad * lr\n-            b -= b_grad * lr\n-\n-            if print_time:\n-                iter_time = time.time() - end\n-                pt_time.add(iter_time)\n-                print(\"Time %.6f (%.6f)\" % (iter_time, pt_time.value()))\n-                end = time.time()\n-\n-    return w, b\n-\n-\n-def evaluate_linear_svm(features, labels, w, b):\n-    \"\"\"Compute accuracy on a test set\"\"\"\n-    predictions = w.matmul(features).add(b).sign()\n-    correct = predictions.mul(labels)\n-    accuracy = correct.add(1).div(2).mean().get_plain_text()\n-    if crypten.communicator.get().get_rank() == 0:\n-        # print(\"Test accuracy %.2f%%\" % (accuracy.item() * 100))\n-        accuracy_str = \"%.2f%%\" % (accuracy * 100)\n-        filename = \"Accuracy.txt\"\n-        with open(filename, 'w') as f:\n-            f.write(accuracy_str)\n-\n-\n-def load_dataset(dataset):\n-    dataset_path = os.path.join(DATASET_DIR, dataset)\n-\n-    # 尝试打开并读取CSV文件\n-    try:\n-        with open(dataset_path, 'r', encoding='utf-8') as csvfile:\n-            spamreader = csv.reader(csvfile)\n-            data = np.array(list(spamreader))\n-    except FileNotFoundError:\n-        print(f\"Error: The file {dataset_path} was not found.\")\n-        return None, None\n-    except Exception as e:\n-        print(f\"Error: An error occurred while reading the file: {e}\")\n-        return None, None\n-\n-    # 检查数据是否为空\n-    if data.size == 0:\n-        print(\"Error: The dataset is empty.\")\n-        return None, None\n-\n-    feature = data[:, :-1].astype(np.float64)\n-    labels = data[:, -1]\n-\n-    # 创建标签映射\n-    unique_labels = np.unique(labels)\n-    label_to_int = {label: idx for idx, label in enumerate(unique_labels)}\n-    int_labels = np.array([label_to_int[label] for label in labels], dtype=np.uint8)\n-    labell = int_labels.reshape(-1,1)\n-\n-    # print(\"======feature_size=====\", feature.shape)\n-    # print(\"======label_size=====\", labell.shape)\n-    return feature, labell\n-\n-\n-\n-def run_mpc_linear_svm(\n-    epochs=100, lr=0.5\n-):\n-    crypten.init()\n-\n-    # Set random seed for reproducibility\n-    torch.manual_seed(1)\n-\n-    data_train = DataSet.sonar\n-    \n-    x, y = load_dataset(data_train.dataset_name)\n-\n-# NOTE：crypten.cryptensor \n-    # Encrypt features / labels\n-    x = crypten.cryptensor(x)\n-    y = crypten.cryptensor(y)\n-\n-    logging.info(\"==================\")\n-    logging.info(\"CrypTen Training\")\n-    logging.info(\"==================\")\n-# NOTE：训练无差异\n-    w, b = train_linear_svm(x, y, epochs=epochs, lr=lr, print_time=True)\n-\n-    # if not skip_plaintext:\n-    #     logging.info(\"PyTorch Weights  :\")\n-    #     logging.info(w_torch)\n-    # logging.info(\"CrypTen Weights:\")\n-# NOTE：get_plain_text()\n-    # logging.info(w.get_plain_text())\n-\n-    # if not skip_plaintext:\n-    #     logging.info(\"PyTorch Bias  :\")\n-    #     logging.info(b_torch)\n-    # logging.info(\"CrypTen Bias:\")\n-    # logging.info(b.get_plain_text())\n"
                },
                {
                    "date": 1719215643839,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -30,11 +30,11 @@\n     # print(\"==========w========\", w.shape)\n     # print(\"==========b========\", b.shape)\n     # print(\"=======features=====\", features.shape)\n \n-    if print_time:\n-        pt_time = AverageMeter()\n-        end = time.time()\n+    # if print_time:\n+    #     pt_time = AverageMeter()\n+    #     end = time.time()\n     \n     filename = \"Accuracy.txt\"\n     with open(filename, 'a') as f:\n         for epoch in range(epochs):\n@@ -149,8 +149,9 @@\n     logging.info(\"==================\")\n     logging.info(\"CrypTen Training\")\n     logging.info(\"==================\")\n # NOTE：训练无差异\n+    \n     w, b = train_linear_svm(x, y, epochs=epochs, lr=lr, print_time=True)\n \n     # if not skip_plaintext:\n     #     logging.info(\"PyTorch Weights  :\")\n"
                },
                {
                    "date": 1719215657839,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -149,9 +149,9 @@\n     logging.info(\"==================\")\n     logging.info(\"CrypTen Training\")\n     logging.info(\"==================\")\n # NOTE：训练无差异\n-    \n+    begin_time = time.time()\n     w, b = train_linear_svm(x, y, epochs=epochs, lr=lr, print_time=True)\n \n     # if not skip_plaintext:\n     #     logging.info(\"PyTorch Weights  :\")\n"
                },
                {
                    "date": 1719215668340,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -151,9 +151,11 @@\n     logging.info(\"==================\")\n # NOTE：训练无差异\n     begin_time = time.time()\n     w, b = train_linear_svm(x, y, epochs=epochs, lr=lr, print_time=True)\n-\n+    end_time = time.time()\n+    \n+    time_all = \n     # if not skip_plaintext:\n     #     logging.info(\"PyTorch Weights  :\")\n     #     logging.info(w_torch)\n     # logging.info(\"CrypTen Weights:\")\n"
                },
                {
                    "date": 1719215676909,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -153,9 +153,10 @@\n     begin_time = time.time()\n     w, b = train_linear_svm(x, y, epochs=epochs, lr=lr, print_time=True)\n     end_time = time.time()\n     \n-    time_all = \n+    time_all = end_time - begin_time\n+    print(\"time\")\n     # if not skip_plaintext:\n     #     logging.info(\"PyTorch Weights  :\")\n     #     logging.info(w_torch)\n     # logging.info(\"CrypTen Weights:\")\n"
                },
                {
                    "date": 1719215684827,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -136,9 +136,9 @@\n \n     # Set random seed for reproducibility\n     torch.manual_seed(1)\n \n-    data_train = DataSet.sonar_selected\n+    data_train = DataSet.sonar\n     \n     x, y = load_dataset(data_train.dataset_name)\n \n # NOTE：crypten.cryptensor \n@@ -154,9 +154,9 @@\n     w, b = train_linear_svm(x, y, epochs=epochs, lr=lr, print_time=True)\n     end_time = time.time()\n     \n     time_all = end_time - begin_time\n-    print(\"time\")\n+    print(\"time:\", time_all)\n     # if not skip_plaintext:\n     #     logging.info(\"PyTorch Weights  :\")\n     #     logging.info(w_torch)\n     # logging.info(\"CrypTen Weights:\")\n"
                },
                {
                    "date": 1719215799902,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -17,9 +17,9 @@\n \n \n class DataSet:\n     sonar = DataSetParam('sonar.csv')\n-    sonar_selected = DataSetParam('sonar_selected.csv')\n+    sonar_selected = DataSetParam('sonar_selected_50.csv')\n \n \n \n \n@@ -136,9 +136,9 @@\n \n     # Set random seed for reproducibility\n     torch.manual_seed(1)\n \n-    data_train = DataSet.sonar\n+    data_train = DataSet.sonar_selected\n     \n     x, y = load_dataset(data_train.dataset_name)\n \n # NOTE：crypten.cryptensor \n"
                },
                {
                    "date": 1719215899391,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -17,9 +17,10 @@\n \n \n class DataSet:\n     sonar = DataSetParam('sonar.csv')\n-    sonar_selected = DataSetParam('sonar_selected_50.csv')\n+    sonar_selected_50 = DataSetParam('sonar_selected_50.csv')\n+    sonar_selected_50 = DataSetParam('sonar_selected_50.csv')\n \n \n \n \n"
                },
                {
                    "date": 1719215916186,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -18,9 +18,9 @@\n \n class DataSet:\n     sonar = DataSetParam('sonar.csv')\n     sonar_selected_50 = DataSetParam('sonar_selected_50.csv')\n-    sonar_selected_50 = DataSetParam('sonar_selected_50.csv')\n+    sonar_selected_40 = DataSetParam('sonar_selected_40.csv')\n \n \n \n \n@@ -137,9 +137,9 @@\n \n     # Set random seed for reproducibility\n     torch.manual_seed(1)\n \n-    data_train = DataSet.sonar_selected\n+    data_train = DataSet.sonar_selected_40\n     \n     x, y = load_dataset(data_train.dataset_name)\n \n # NOTE：crypten.cryptensor \n"
                },
                {
                    "date": 1719216090576,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -18,8 +18,9 @@\n \n class DataSet:\n     sonar = DataSetParam('sonar.csv')\n     sonar_selected_50 = DataSetParam('sonar_selected_50.csv')\n+        sonar_selected_40 = DataSetParam('sonar_selected_40.csv')\n     sonar_selected_40 = DataSetParam('sonar_selected_40.csv')\n \n \n \n"
                },
                {
                    "date": 1719216095679,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,172 @@\n+\n+import logging\n+import time\n+import csv\n+import os\n+import crypten\n+import torch\n+import numpy as np\n+from examples.meters import AverageMeter\n+\n+\n+DATASET_DIR = os.path.join(os.path.dirname(__file__), '../dataset')\n+\n+class DataSetParam:\n+    def __init__(self, dataset_name):\n+        self.dataset_name = dataset_name\n+\n+\n+class DataSet:\n+    sonar = DataSetParam('sonar.csv')\n+    sonar_selected_50 = DataSetParam('sonar_selected_50.csv')\n+    sonar_selected_45 = DataSetParam('sonar_selected_45.csv')\n+    sonar_selected_40 = DataSetParam('sonar_selected_40.csv')\n+\n+\n+\n+\n+def train_linear_svm(features, labels, epochs, lr, print_time=False):\n+    # Initialize random weights\n+    w = features.new(torch.randn(features.size(1),1))\n+    b = features.new(torch.randn(1))\n+    # print(\"==========w========\", w.shape)\n+    # print(\"==========b========\", b.shape)\n+    # print(\"=======features=====\", features.shape)\n+\n+    # if print_time:\n+    #     pt_time = AverageMeter()\n+    #     end = time.time()\n+    \n+    filename = \"Accuracy.txt\"\n+    with open(filename, 'a') as f:\n+        for epoch in range(epochs):\n+            # Forward\n+            label_predictions = features.matmul(w).add(b).sign()\n+            # label_predictions = w.matmul(features.T).add(b).sign()\n+            # print(\"=======labels======\", labels.shape)\n+            # print(\"=======label_predictions======\", label_predictions.shape)\n+            # Compute accuracy\n+            correct = label_predictions.mul(labels.view(-1,1))\n+            # print(\"=======correct======\", correct.shape)\n+            accuracy = correct.add(1).div(2).mean()\n+            if crypten.is_encrypted_tensor(accuracy):\n+                accuracy = accuracy.get_plain_text()\n+\n+            # Print Accuracy once\n+            if crypten.communicator.get().get_rank() == 0:\n+                # print(\n+                #     f\"Epoch {epoch} --- Training Accuracy %.2f%%\" % (accuracy.item() * 100)\n+                # )\n+                accuracy_str = \"%.2f%%\" % (accuracy * 100)\n+                accuracy_str_without_percent = accuracy_str.replace('%', '')\n+                f.write(accuracy_str_without_percent + \",\")\n+\n+            # Backward\n+            loss_grad = -labels * (1 - correct) * 0.5  # Hinge loss\n+            # print(\"=======loss_grad======\\n\", loss_grad.get_plain_text())\n+            b_grad = loss_grad.mean()\n+            # print(\"=======b_grad ======\", b_grad.shape)\n+            w_grad = features.t().matmul(loss_grad).div(loss_grad.size(0))\n+            # print(\"=======w_grad ======\", w_grad.shape)\n+            \n+\n+            # Update\n+            w -= w_grad * lr\n+            b -= b_grad * lr\n+\n+            # if print_time:\n+            #     iter_time = time.time() - end\n+            #     pt_time.add(iter_time)\n+            #     print(\"Time %.6f (%.6f)\" % (iter_time, pt_time.value()))\n+            #     end = time.time()\n+\n+    return w, b\n+\n+\n+def evaluate_linear_svm(features, labels, w, b):\n+    \"\"\"Compute accuracy on a test set\"\"\"\n+    predictions = w.matmul(features).add(b).sign()\n+    correct = predictions.mul(labels)\n+    accuracy = correct.add(1).div(2).mean().get_plain_text()\n+    if crypten.communicator.get().get_rank() == 0:\n+        # print(\"Test accuracy %.2f%%\" % (accuracy.item() * 100))\n+        accuracy_str = \"%.2f%%\" % (accuracy * 100)\n+        filename = \"Accuracy.txt\"\n+        with open(filename, 'w') as f:\n+            f.write(accuracy_str)\n+\n+\n+def load_dataset(dataset):\n+    dataset_path = os.path.join(DATASET_DIR, dataset)\n+\n+    # 尝试打开并读取CSV文件\n+    try:\n+        with open(dataset_path, 'r', encoding='utf-8') as csvfile:\n+            spamreader = csv.reader(csvfile)\n+            data = np.array(list(spamreader))\n+    except FileNotFoundError:\n+        print(f\"Error: The file {dataset_path} was not found.\")\n+        return None, None\n+    except Exception as e:\n+        print(f\"Error: An error occurred while reading the file: {e}\")\n+        return None, None\n+\n+    # 检查数据是否为空\n+    if data.size == 0:\n+        print(\"Error: The dataset is empty.\")\n+        return None, None\n+\n+    feature = data[:, :-1].astype(np.float64)\n+    labels = data[:, -1]\n+\n+    # 创建标签映射\n+    unique_labels = np.unique(labels)\n+    label_to_int = {label: idx for idx, label in enumerate(unique_labels)}\n+    int_labels = np.array([label_to_int[label] for label in labels], dtype=np.uint8)\n+    labell = int_labels.reshape(-1,1)\n+\n+    # print(\"======feature_size=====\", feature.shape)\n+    # print(\"======label_size=====\", labell.shape)\n+    return feature, labell\n+\n+\n+\n+def run_mpc_linear_svm(\n+    epochs=100, lr=0.5\n+):\n+    crypten.init()\n+\n+    # Set random seed for reproducibility\n+    torch.manual_seed(1)\n+\n+    data_train = DataSet.sonar_selected_40\n+    \n+    x, y = load_dataset(data_train.dataset_name)\n+\n+# NOTE：crypten.cryptensor \n+    # Encrypt features / labels\n+    x = crypten.cryptensor(x)\n+    y = crypten.cryptensor(y)\n+\n+    logging.info(\"==================\")\n+    logging.info(\"CrypTen Training\")\n+    logging.info(\"==================\")\n+# NOTE：训练无差异\n+    begin_time = time.time()\n+    w, b = train_linear_svm(x, y, epochs=epochs, lr=lr, print_time=True)\n+    end_time = time.time()\n+    \n+    time_all = end_time - begin_time\n+    print(\"time:\", time_all)\n+    # if not skip_plaintext:\n+    #     logging.info(\"PyTorch Weights  :\")\n+    #     logging.info(w_torch)\n+    # logging.info(\"CrypTen Weights:\")\n+# NOTE：get_plain_text()\n+    # logging.info(w.get_plain_text())\n+\n+    # if not skip_plaintext:\n+    #     logging.info(\"PyTorch Bias  :\")\n+    #     logging.info(b_torch)\n+    # logging.info(\"CrypTen Bias:\")\n+    # logging.info(b.get_plain_text())\n"
                },
                {
                    "date": 1719216215763,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -20,180 +20,9 @@\n     sonar = DataSetParam('sonar.csv')\n     sonar_selected_50 = DataSetParam('sonar_selected_50.csv')\n     sonar_selected_45 = DataSetParam('sonar_selected_45.csv')\n     sonar_selected_40 = DataSetParam('sonar_selected_40.csv')\n-\n-\n-\n-\n-def train_linear_svm(features, labels, epochs, lr, print_time=False):\n-    # Initialize random weights\n-    w = features.new(torch.randn(features.size(1),1))\n-    b = features.new(torch.randn(1))\n-    # print(\"==========w========\", w.shape)\n-    # print(\"==========b========\", b.shape)\n-    # print(\"=======features=====\", features.shape)\n-\n-    # if print_time:\n-    #     pt_time = AverageMeter()\n-    #     end = time.time()\n-    \n-    filename = \"Accuracy.txt\"\n-    with open(filename, 'a') as f:\n-        for epoch in range(epochs):\n-            # Forward\n-            label_predictions = features.matmul(w).add(b).sign()\n-            # label_predictions = w.matmul(features.T).add(b).sign()\n-            # print(\"=======labels======\", labels.shape)\n-            # print(\"=======label_predictions======\", label_predictions.shape)\n-            # Compute accuracy\n-            correct = label_predictions.mul(labels.view(-1,1))\n-            # print(\"=======correct======\", correct.shape)\n-            accuracy = correct.add(1).div(2).mean()\n-            if crypten.is_encrypted_tensor(accuracy):\n-                accuracy = accuracy.get_plain_text()\n-\n-            # Print Accuracy once\n-            if crypten.communicator.get().get_rank() == 0:\n-                # print(\n-                #     f\"Epoch {epoch} --- Training Accuracy %.2f%%\" % (accuracy.item() * 100)\n-                # )\n-                accuracy_str = \"%.2f%%\" % (accuracy * 100)\n-                accuracy_str_without_percent = accuracy_str.replace('%', '')\n-                f.write(accuracy_str_without_percent + \",\")\n-\n-            # Backward\n-            loss_grad = -labels * (1 - correct) * 0.5  # Hinge loss\n-            # print(\"=======loss_grad======\\n\", loss_grad.get_plain_text())\n-            b_grad = loss_grad.mean()\n-            # print(\"=======b_grad ======\", b_grad.shape)\n-            w_grad = features.t().matmul(loss_grad).div(loss_grad.size(0))\n-            # print(\"=======w_grad ======\", w_grad.shape)\n-            \n-\n-            # Update\n-            w -= w_grad * lr\n-            b -= b_grad * lr\n-\n-            # if print_time:\n-            #     iter_time = time.time() - end\n-            #     pt_time.add(iter_time)\n-            #     print(\"Time %.6f (%.6f)\" % (iter_time, pt_time.value()))\n-            #     end = time.time()\n-\n-    return w, b\n-\n-\n-def evaluate_linear_svm(features, labels, w, b):\n-    \"\"\"Compute accuracy on a test set\"\"\"\n-    predictions = w.matmul(features).add(b).sign()\n-    correct = predictions.mul(labels)\n-    accuracy = correct.add(1).div(2).mean().get_plain_text()\n-    if crypten.communicator.get().get_rank() == 0:\n-        # print(\"Test accuracy %.2f%%\" % (accuracy.item() * 100))\n-        accuracy_str = \"%.2f%%\" % (accuracy * 100)\n-        filename = \"Accuracy.txt\"\n-        with open(filename, 'w') as f:\n-            f.write(accuracy_str)\n-\n-\n-def load_dataset(dataset):\n-    dataset_path = os.path.join(DATASET_DIR, dataset)\n-\n-    # 尝试打开并读取CSV文件\n-    try:\n-        with open(dataset_path, 'r', encoding='utf-8') as csvfile:\n-            spamreader = csv.reader(csvfile)\n-            data = np.array(list(spamreader))\n-    except FileNotFoundError:\n-        print(f\"Error: The file {dataset_path} was not found.\")\n-        return None, None\n-    except Exception as e:\n-        print(f\"Error: An error occurred while reading the file: {e}\")\n-        return None, None\n-\n-    # 检查数据是否为空\n-    if data.size == 0:\n-        print(\"Error: The dataset is empty.\")\n-        return None, None\n-\n-    feature = data[:, :-1].astype(np.float64)\n-    labels = data[:, -1]\n-\n-    # 创建标签映射\n-    unique_labels = np.unique(labels)\n-    label_to_int = {label: idx for idx, label in enumerate(unique_labels)}\n-    int_labels = np.array([label_to_int[label] for label in labels], dtype=np.uint8)\n-    labell = int_labels.reshape(-1,1)\n-\n-    # print(\"======feature_size=====\", feature.shape)\n-    # print(\"======label_size=====\", labell.shape)\n-    return feature, labell\n-\n-\n-\n-def run_mpc_linear_svm(\n-    epochs=100, lr=0.5\n-):\n-    crypten.init()\n-\n-    # Set random seed for reproducibility\n-    torch.manual_seed(1)\n-\n-    data_train = DataSet.sonar_selected_40\n-    \n-    x, y = load_dataset(data_train.dataset_name)\n-\n-# NOTE：crypten.cryptensor \n-    # Encrypt features / labels\n-    x = crypten.cryptensor(x)\n-    y = crypten.cryptensor(y)\n-\n-    logging.info(\"==================\")\n-    logging.info(\"CrypTen Training\")\n-    logging.info(\"==================\")\n-# NOTE：训练无差异\n-    begin_time = time.time()\n-    w, b = train_linear_svm(x, y, epochs=epochs, lr=lr, print_time=True)\n-    end_time = time.time()\n-    \n-    time_all = end_time - begin_time\n-    print(\"time:\", time_all)\n-    # if not skip_plaintext:\n-    #     logging.info(\"PyTorch Weights  :\")\n-    #     logging.info(w_torch)\n-    # logging.info(\"CrypTen Weights:\")\n-# NOTE：get_plain_text()\n-    # logging.info(w.get_plain_text())\n-\n-    # if not skip_plaintext:\n-    #     logging.info(\"PyTorch Bias  :\")\n-    #     logging.info(b_torch)\n-    # logging.info(\"CrypTen Bias:\")\n-    # logging.info(b.get_plain_text())\n-\n-import logging\n-import time\n-import csv\n-import os\n-import crypten\n-import torch\n-import numpy as np\n-from examples.meters import AverageMeter\n-\n-\n-DATASET_DIR = os.path.join(os.path.dirname(__file__), '../dataset')\n-\n-class DataSetParam:\n-    def __init__(self, dataset_name):\n-        self.dataset_name = dataset_name\n-\n-\n-class DataSet:\n-    sonar = DataSetParam('sonar.csv')\n-    sonar_selected_50 = DataSetParam('sonar_selected_50.csv')\n         sonar_selected_40 = DataSetParam('sonar_selected_40.csv')\n-    sonar_selected_40 = DataSetParam('sonar_selected_40.csv')\n \n \n \n \n"
                },
                {
                    "date": 1719216220937,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -17,12 +17,13 @@\n \n \n class DataSet:\n     sonar = DataSetParam('sonar.csv')\n+        sonar_selected_40 = DataSetParam('sonar_selected_40.csv')\n     sonar_selected_50 = DataSetParam('sonar_selected_50.csv')\n     sonar_selected_45 = DataSetParam('sonar_selected_45.csv')\n     sonar_selected_40 = DataSetParam('sonar_selected_40.csv')\n-        sonar_selected_40 = DataSetParam('sonar_selected_40.csv')\n+    \n \n \n \n \n"
                },
                {
                    "date": 1719216228028,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -17,9 +17,9 @@\n \n \n class DataSet:\n     sonar = DataSetParam('sonar.csv')\n-        sonar_selected_40 = DataSetParam('sonar_selected_40.csv')\n+    sonar_selected_55 = DataSetParam('sonar_selected_55.csv')\n     sonar_selected_50 = DataSetParam('sonar_selected_50.csv')\n     sonar_selected_45 = DataSetParam('sonar_selected_45.csv')\n     sonar_selected_40 = DataSetParam('sonar_selected_40.csv')\n     \n"
                },
                {
                    "date": 1719216237020,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -140,9 +140,9 @@\n \n     # Set random seed for reproducibility\n     torch.manual_seed(1)\n \n-    data_train = DataSet.sonar_selected_40\n+    data_train = DataSet.sonar_selected_55\n     \n     x, y = load_dataset(data_train.dataset_name)\n \n # NOTE：crypten.cryptensor \n"
                },
                {
                    "date": 1719216377999,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,175 @@\n+\n+import logging\n+import time\n+import csv\n+import os\n+import crypten\n+import torch\n+import numpy as np\n+from examples.meters import AverageMeter\n+\n+\n+DATASET_DIR = os.path.join(os.path.dirname(__file__), '../dataset')\n+\n+class DataSetParam:\n+    def __init__(self, dataset_name):\n+        self.dataset_name = dataset_name\n+\n+\n+class DataSet:\n+    sonar = DataSetParam('sonar.csv')\n+    sonar_selected_55 = DataSetParam('sonar_selected_55.csv')\n+    sonar_selected_50 = DataSetParam('sonar_selected_50.csv')\n+    sonar_selected_50 = DataSetParam('sonar_selected_50.csv')\n+    sonar_selected_45 = DataSetParam('sonar_selected_45.csv')\n+    sonar_selected_40 = DataSetParam('sonar_selected_40.csv')\n+    \n+\n+\n+\n+\n+def train_linear_svm(features, labels, epochs, lr, print_time=False):\n+    # Initialize random weights\n+    w = features.new(torch.randn(features.size(1),1))\n+    b = features.new(torch.randn(1))\n+    # print(\"==========w========\", w.shape)\n+    # print(\"==========b========\", b.shape)\n+    # print(\"=======features=====\", features.shape)\n+\n+    # if print_time:\n+    #     pt_time = AverageMeter()\n+    #     end = time.time()\n+    \n+    filename = \"Accuracy.txt\"\n+    with open(filename, 'a') as f:\n+        for epoch in range(epochs):\n+            # Forward\n+            label_predictions = features.matmul(w).add(b).sign()\n+            # label_predictions = w.matmul(features.T).add(b).sign()\n+            # print(\"=======labels======\", labels.shape)\n+            # print(\"=======label_predictions======\", label_predictions.shape)\n+            # Compute accuracy\n+            correct = label_predictions.mul(labels.view(-1,1))\n+            # print(\"=======correct======\", correct.shape)\n+            accuracy = correct.add(1).div(2).mean()\n+            if crypten.is_encrypted_tensor(accuracy):\n+                accuracy = accuracy.get_plain_text()\n+\n+            # Print Accuracy once\n+            if crypten.communicator.get().get_rank() == 0:\n+                # print(\n+                #     f\"Epoch {epoch} --- Training Accuracy %.2f%%\" % (accuracy.item() * 100)\n+                # )\n+                accuracy_str = \"%.2f%%\" % (accuracy * 100)\n+                accuracy_str_without_percent = accuracy_str.replace('%', '')\n+                f.write(accuracy_str_without_percent + \",\")\n+\n+            # Backward\n+            loss_grad = -labels * (1 - correct) * 0.5  # Hinge loss\n+            # print(\"=======loss_grad======\\n\", loss_grad.get_plain_text())\n+            b_grad = loss_grad.mean()\n+            # print(\"=======b_grad ======\", b_grad.shape)\n+            w_grad = features.t().matmul(loss_grad).div(loss_grad.size(0))\n+            # print(\"=======w_grad ======\", w_grad.shape)\n+            \n+\n+            # Update\n+            w -= w_grad * lr\n+            b -= b_grad * lr\n+\n+            # if print_time:\n+            #     iter_time = time.time() - end\n+            #     pt_time.add(iter_time)\n+            #     print(\"Time %.6f (%.6f)\" % (iter_time, pt_time.value()))\n+            #     end = time.time()\n+\n+    return w, b\n+\n+\n+def evaluate_linear_svm(features, labels, w, b):\n+    \"\"\"Compute accuracy on a test set\"\"\"\n+    predictions = w.matmul(features).add(b).sign()\n+    correct = predictions.mul(labels)\n+    accuracy = correct.add(1).div(2).mean().get_plain_text()\n+    if crypten.communicator.get().get_rank() == 0:\n+        # print(\"Test accuracy %.2f%%\" % (accuracy.item() * 100))\n+        accuracy_str = \"%.2f%%\" % (accuracy * 100)\n+        filename = \"Accuracy.txt\"\n+        with open(filename, 'w') as f:\n+            f.write(accuracy_str)\n+\n+\n+def load_dataset(dataset):\n+    dataset_path = os.path.join(DATASET_DIR, dataset)\n+\n+    # 尝试打开并读取CSV文件\n+    try:\n+        with open(dataset_path, 'r', encoding='utf-8') as csvfile:\n+            spamreader = csv.reader(csvfile)\n+            data = np.array(list(spamreader))\n+    except FileNotFoundError:\n+        print(f\"Error: The file {dataset_path} was not found.\")\n+        return None, None\n+    except Exception as e:\n+        print(f\"Error: An error occurred while reading the file: {e}\")\n+        return None, None\n+\n+    # 检查数据是否为空\n+    if data.size == 0:\n+        print(\"Error: The dataset is empty.\")\n+        return None, None\n+\n+    feature = data[:, :-1].astype(np.float64)\n+    labels = data[:, -1]\n+\n+    # 创建标签映射\n+    unique_labels = np.unique(labels)\n+    label_to_int = {label: idx for idx, label in enumerate(unique_labels)}\n+    int_labels = np.array([label_to_int[label] for label in labels], dtype=np.uint8)\n+    labell = int_labels.reshape(-1,1)\n+\n+    # print(\"======feature_size=====\", feature.shape)\n+    # print(\"======label_size=====\", labell.shape)\n+    return feature, labell\n+\n+\n+\n+def run_mpc_linear_svm(\n+    epochs=100, lr=0.5\n+):\n+    crypten.init()\n+\n+    # Set random seed for reproducibility\n+    torch.manual_seed(1)\n+\n+    data_train = DataSet.sonar_selected_55\n+    \n+    x, y = load_dataset(data_train.dataset_name)\n+\n+# NOTE：crypten.cryptensor \n+    # Encrypt features / labels\n+    x = crypten.cryptensor(x)\n+    y = crypten.cryptensor(y)\n+\n+    logging.info(\"==================\")\n+    logging.info(\"CrypTen Training\")\n+    logging.info(\"==================\")\n+# NOTE：训练无差异\n+    begin_time = time.time()\n+    w, b = train_linear_svm(x, y, epochs=epochs, lr=lr, print_time=True)\n+    end_time = time.time()\n+    \n+    time_all = end_time - begin_time\n+    print(\"time:\", time_all)\n+    # if not skip_plaintext:\n+    #     logging.info(\"PyTorch Weights  :\")\n+    #     logging.info(w_torch)\n+    # logging.info(\"CrypTen Weights:\")\n+# NOTE：get_plain_text()\n+    # logging.info(w.get_plain_text())\n+\n+    # if not skip_plaintext:\n+    #     logging.info(\"PyTorch Bias  :\")\n+    #     logging.info(b_torch)\n+    # logging.info(\"CrypTen Bias:\")\n+    # logging.info(b.get_plain_text())\n"
                },
                {
                    "date": 1719216383799,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -19,9 +19,9 @@\n class DataSet:\n     sonar = DataSetParam('sonar.csv')\n     sonar_selected_55 = DataSetParam('sonar_selected_55.csv')\n     sonar_selected_50 = DataSetParam('sonar_selected_50.csv')\n-    sonar_selected_50 = DataSetParam('sonar_selected_50.csv')\n+    sonar_selected_48 = DataSetParam('sonar_selected_48.csv')\n     sonar_selected_45 = DataSetParam('sonar_selected_45.csv')\n     sonar_selected_40 = DataSetParam('sonar_selected_40.csv')\n     \n \n@@ -172,178 +172,4 @@\n     #     logging.info(\"PyTorch Bias  :\")\n     #     logging.info(b_torch)\n     # logging.info(\"CrypTen Bias:\")\n     # logging.info(b.get_plain_text())\n-\n-import logging\n-import time\n-import csv\n-import os\n-import crypten\n-import torch\n-import numpy as np\n-from examples.meters import AverageMeter\n-\n-\n-DATASET_DIR = os.path.join(os.path.dirname(__file__), '../dataset')\n-\n-class DataSetParam:\n-    def __init__(self, dataset_name):\n-        self.dataset_name = dataset_name\n-\n-\n-class DataSet:\n-    sonar = DataSetParam('sonar.csv')\n-    sonar_selected_55 = DataSetParam('sonar_selected_55.csv')\n-    sonar_selected_50 = DataSetParam('sonar_selected_50.csv')\n-    sonar_selected_45 = DataSetParam('sonar_selected_45.csv')\n-    sonar_selected_40 = DataSetParam('sonar_selected_40.csv')\n-    \n-\n-\n-\n-\n-def train_linear_svm(features, labels, epochs, lr, print_time=False):\n-    # Initialize random weights\n-    w = features.new(torch.randn(features.size(1),1))\n-    b = features.new(torch.randn(1))\n-    # print(\"==========w========\", w.shape)\n-    # print(\"==========b========\", b.shape)\n-    # print(\"=======features=====\", features.shape)\n-\n-    # if print_time:\n-    #     pt_time = AverageMeter()\n-    #     end = time.time()\n-    \n-    filename = \"Accuracy.txt\"\n-    with open(filename, 'a') as f:\n-        for epoch in range(epochs):\n-            # Forward\n-            label_predictions = features.matmul(w).add(b).sign()\n-            # label_predictions = w.matmul(features.T).add(b).sign()\n-            # print(\"=======labels======\", labels.shape)\n-            # print(\"=======label_predictions======\", label_predictions.shape)\n-            # Compute accuracy\n-            correct = label_predictions.mul(labels.view(-1,1))\n-            # print(\"=======correct======\", correct.shape)\n-            accuracy = correct.add(1).div(2).mean()\n-            if crypten.is_encrypted_tensor(accuracy):\n-                accuracy = accuracy.get_plain_text()\n-\n-            # Print Accuracy once\n-            if crypten.communicator.get().get_rank() == 0:\n-                # print(\n-                #     f\"Epoch {epoch} --- Training Accuracy %.2f%%\" % (accuracy.item() * 100)\n-                # )\n-                accuracy_str = \"%.2f%%\" % (accuracy * 100)\n-                accuracy_str_without_percent = accuracy_str.replace('%', '')\n-                f.write(accuracy_str_without_percent + \",\")\n-\n-            # Backward\n-            loss_grad = -labels * (1 - correct) * 0.5  # Hinge loss\n-            # print(\"=======loss_grad======\\n\", loss_grad.get_plain_text())\n-            b_grad = loss_grad.mean()\n-            # print(\"=======b_grad ======\", b_grad.shape)\n-            w_grad = features.t().matmul(loss_grad).div(loss_grad.size(0))\n-            # print(\"=======w_grad ======\", w_grad.shape)\n-            \n-\n-            # Update\n-            w -= w_grad * lr\n-            b -= b_grad * lr\n-\n-            # if print_time:\n-            #     iter_time = time.time() - end\n-            #     pt_time.add(iter_time)\n-            #     print(\"Time %.6f (%.6f)\" % (iter_time, pt_time.value()))\n-            #     end = time.time()\n-\n-    return w, b\n-\n-\n-def evaluate_linear_svm(features, labels, w, b):\n-    \"\"\"Compute accuracy on a test set\"\"\"\n-    predictions = w.matmul(features).add(b).sign()\n-    correct = predictions.mul(labels)\n-    accuracy = correct.add(1).div(2).mean().get_plain_text()\n-    if crypten.communicator.get().get_rank() == 0:\n-        # print(\"Test accuracy %.2f%%\" % (accuracy.item() * 100))\n-        accuracy_str = \"%.2f%%\" % (accuracy * 100)\n-        filename = \"Accuracy.txt\"\n-        with open(filename, 'w') as f:\n-            f.write(accuracy_str)\n-\n-\n-def load_dataset(dataset):\n-    dataset_path = os.path.join(DATASET_DIR, dataset)\n-\n-    # 尝试打开并读取CSV文件\n-    try:\n-        with open(dataset_path, 'r', encoding='utf-8') as csvfile:\n-            spamreader = csv.reader(csvfile)\n-            data = np.array(list(spamreader))\n-    except FileNotFoundError:\n-        print(f\"Error: The file {dataset_path} was not found.\")\n-        return None, None\n-    except Exception as e:\n-        print(f\"Error: An error occurred while reading the file: {e}\")\n-        return None, None\n-\n-    # 检查数据是否为空\n-    if data.size == 0:\n-        print(\"Error: The dataset is empty.\")\n-        return None, None\n-\n-    feature = data[:, :-1].astype(np.float64)\n-    labels = data[:, -1]\n-\n-    # 创建标签映射\n-    unique_labels = np.unique(labels)\n-    label_to_int = {label: idx for idx, label in enumerate(unique_labels)}\n-    int_labels = np.array([label_to_int[label] for label in labels], dtype=np.uint8)\n-    labell = int_labels.reshape(-1,1)\n-\n-    # print(\"======feature_size=====\", feature.shape)\n-    # print(\"======label_size=====\", labell.shape)\n-    return feature, labell\n-\n-\n-\n-def run_mpc_linear_svm(\n-    epochs=100, lr=0.5\n-):\n-    crypten.init()\n-\n-    # Set random seed for reproducibility\n-    torch.manual_seed(1)\n-\n-    data_train = DataSet.sonar_selected_55\n-    \n-    x, y = load_dataset(data_train.dataset_name)\n-\n-# NOTE：crypten.cryptensor \n-    # Encrypt features / labels\n-    x = crypten.cryptensor(x)\n-    y = crypten.cryptensor(y)\n-\n-    logging.info(\"==================\")\n-    logging.info(\"CrypTen Training\")\n-    logging.info(\"==================\")\n-# NOTE：训练无差异\n-    begin_time = time.time()\n-    w, b = train_linear_svm(x, y, epochs=epochs, lr=lr, print_time=True)\n-    end_time = time.time()\n-    \n-    time_all = end_time - begin_time\n-    print(\"time:\", time_all)\n-    # if not skip_plaintext:\n-    #     logging.info(\"PyTorch Weights  :\")\n-    #     logging.info(w_torch)\n-    # logging.info(\"CrypTen Weights:\")\n-# NOTE：get_plain_text()\n-    # logging.info(w.get_plain_text())\n-\n-    # if not skip_plaintext:\n-    #     logging.info(\"PyTorch Bias  :\")\n-    #     logging.info(b_torch)\n-    # logging.info(\"CrypTen Bias:\")\n-    # logging.info(b.get_plain_text())\n"
                },
                {
                    "date": 1719216389538,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -141,9 +141,9 @@\n \n     # Set random seed for reproducibility\n     torch.manual_seed(1)\n \n-    data_train = DataSet.sonar_selected_55\n+    data_train = DataSet.sonar_selected_48\n     \n     x, y = load_dataset(data_train.dataset_name)\n \n # NOTE：crypten.cryptensor \n"
                },
                {
                    "date": 1719216577015,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -141,9 +141,9 @@\n \n     # Set random seed for reproducibility\n     torch.manual_seed(1)\n \n-    data_train = DataSet.sonar_selected_48\n+    data_train = DataSet.sonar_selected_45\n     \n     x, y = load_dataset(data_train.dataset_name)\n \n # NOTE：crypten.cryptensor \n"
                },
                {
                    "date": 1719216657915,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -141,9 +141,9 @@\n \n     # Set random seed for reproducibility\n     torch.manual_seed(1)\n \n-    data_train = DataSet.sonar_selected_45\n+    data_train = DataSet.sonar_selected_40\n     \n     x, y = load_dataset(data_train.dataset_name)\n \n # NOTE：crypten.cryptensor \n"
                },
                {
                    "date": 1719216729799,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -141,9 +141,9 @@\n \n     # Set random seed for reproducibility\n     torch.manual_seed(1)\n \n-    data_train = DataSet.sonar_selected_40\n+    data_train = DataSet.sonar_selected_50\n     \n     x, y = load_dataset(data_train.dataset_name)\n \n # NOTE：crypten.cryptensor \n"
                },
                {
                    "date": 1719216795886,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,175 @@\n+\n+import logging\n+import time\n+import csv\n+import os\n+import crypten\n+import torch\n+import numpy as np\n+from examples.meters import AverageMeter\n+\n+\n+DATASET_DIR = os.path.join(os.path.dirname(__file__), '../dataset')\n+\n+class DataSetParam:\n+    def __init__(self, dataset_name):\n+        self.dataset_name = dataset_name\n+\n+\n+class DataSet:\n+    sonar = DataSetParam('sonar.csv')\n+    sonar_selected_55 = DataSetParam('sonar_selected_55.csv')\n+    sonar_selected_50 = DataSetParam('sonar_selected_50.csv')\n+    sonar_selected_48 = DataSetParam('sonar_selected_48.csv')\n+    sonar_selected_45 = DataSetParam('sonar_selected_45.csv')\n+    sonar_selected_40 = DataSetParam('sonar_selected_40.csv')\n+    \n+\n+\n+\n+\n+def train_linear_svm(features, labels, epochs, lr, print_time=False):\n+    # Initialize random weights\n+    w = features.new(torch.randn(features.size(1),1))\n+    b = features.new(torch.randn(1))\n+    # print(\"==========w========\", w.shape)\n+    # print(\"==========b========\", b.shape)\n+    # print(\"=======features=====\", features.shape)\n+\n+    # if print_time:\n+    #     pt_time = AverageMeter()\n+    #     end = time.time()\n+    \n+    filename = \"Accuracy.txt\"\n+    with open(filename, 'a') as f:\n+        for epoch in range(epochs):\n+            # Forward\n+            label_predictions = features.matmul(w).add(b).sign()\n+            # label_predictions = w.matmul(features.T).add(b).sign()\n+            # print(\"=======labels======\", labels.shape)\n+            # print(\"=======label_predictions======\", label_predictions.shape)\n+            # Compute accuracy\n+            correct = label_predictions.mul(labels.view(-1,1))\n+            # print(\"=======correct======\", correct.shape)\n+            accuracy = correct.add(1).div(2).mean()\n+            if crypten.is_encrypted_tensor(accuracy):\n+                accuracy = accuracy.get_plain_text()\n+\n+            # Print Accuracy once\n+            if crypten.communicator.get().get_rank() == 0:\n+                # print(\n+                #     f\"Epoch {epoch} --- Training Accuracy %.2f%%\" % (accuracy.item() * 100)\n+                # )\n+                accuracy_str = \"%.2f%%\" % (accuracy * 100)\n+                accuracy_str_without_percent = accuracy_str.replace('%', '')\n+                f.write(accuracy_str_without_percent + \",\")\n+\n+            # Backward\n+            loss_grad = -labels * (1 - correct) * 0.5  # Hinge loss\n+            # print(\"=======loss_grad======\\n\", loss_grad.get_plain_text())\n+            b_grad = loss_grad.mean()\n+            # print(\"=======b_grad ======\", b_grad.shape)\n+            w_grad = features.t().matmul(loss_grad).div(loss_grad.size(0))\n+            # print(\"=======w_grad ======\", w_grad.shape)\n+            \n+\n+            # Update\n+            w -= w_grad * lr\n+            b -= b_grad * lr\n+\n+            # if print_time:\n+            #     iter_time = time.time() - end\n+            #     pt_time.add(iter_time)\n+            #     print(\"Time %.6f (%.6f)\" % (iter_time, pt_time.value()))\n+            #     end = time.time()\n+\n+    return w, b\n+\n+\n+def evaluate_linear_svm(features, labels, w, b):\n+    \"\"\"Compute accuracy on a test set\"\"\"\n+    predictions = w.matmul(features).add(b).sign()\n+    correct = predictions.mul(labels)\n+    accuracy = correct.add(1).div(2).mean().get_plain_text()\n+    if crypten.communicator.get().get_rank() == 0:\n+        # print(\"Test accuracy %.2f%%\" % (accuracy.item() * 100))\n+        accuracy_str = \"%.2f%%\" % (accuracy * 100)\n+        filename = \"Accuracy.txt\"\n+        with open(filename, 'w') as f:\n+            f.write(accuracy_str)\n+\n+\n+def load_dataset(dataset):\n+    dataset_path = os.path.join(DATASET_DIR, dataset)\n+\n+    # 尝试打开并读取CSV文件\n+    try:\n+        with open(dataset_path, 'r', encoding='utf-8') as csvfile:\n+            spamreader = csv.reader(csvfile)\n+            data = np.array(list(spamreader))\n+    except FileNotFoundError:\n+        print(f\"Error: The file {dataset_path} was not found.\")\n+        return None, None\n+    except Exception as e:\n+        print(f\"Error: An error occurred while reading the file: {e}\")\n+        return None, None\n+\n+    # 检查数据是否为空\n+    if data.size == 0:\n+        print(\"Error: The dataset is empty.\")\n+        return None, None\n+\n+    feature = data[:, :-1].astype(np.float64)\n+    labels = data[:, -1]\n+\n+    # 创建标签映射\n+    unique_labels = np.unique(labels)\n+    label_to_int = {label: idx for idx, label in enumerate(unique_labels)}\n+    int_labels = np.array([label_to_int[label] for label in labels], dtype=np.uint8)\n+    labell = int_labels.reshape(-1,1)\n+\n+    # print(\"======feature_size=====\", feature.shape)\n+    # print(\"======label_size=====\", labell.shape)\n+    return feature, labell\n+\n+\n+\n+def run_mpc_linear_svm(\n+    epochs=100, lr=0.5\n+):\n+    crypten.init()\n+\n+    # Set random seed for reproducibility\n+    torch.manual_seed(1)\n+\n+    data_train = DataSet.sonar_selected_55\n+    \n+    x, y = load_dataset(data_train.dataset_name)\n+\n+# NOTE：crypten.cryptensor \n+    # Encrypt features / labels\n+    x = crypten.cryptensor(x)\n+    y = crypten.cryptensor(y)\n+\n+    logging.info(\"==================\")\n+    logging.info(\"CrypTen Training\")\n+    logging.info(\"==================\")\n+# NOTE：训练无差异\n+    begin_time = time.time()\n+    w, b = train_linear_svm(x, y, epochs=epochs, lr=lr, print_time=True)\n+    end_time = time.time()\n+    \n+    time_all = end_time - begin_time\n+    print(\"time:\", time_all)\n+    # if not skip_plaintext:\n+    #     logging.info(\"PyTorch Weights  :\")\n+    #     logging.info(w_torch)\n+    # logging.info(\"CrypTen Weights:\")\n+# NOTE：get_plain_text()\n+    # logging.info(w.get_plain_text())\n+\n+    # if not skip_plaintext:\n+    #     logging.info(\"PyTorch Bias  :\")\n+    #     logging.info(b_torch)\n+    # logging.info(\"CrypTen Bias:\")\n+    # logging.info(b.get_plain_text())\n"
                },
                {
                    "date": 1719216860346,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -141,9 +141,9 @@\n \n     # Set random seed for reproducibility\n     torch.manual_seed(1)\n \n-    data_train = DataSet.sonar_selected_55\n+    data_train = DataSet.sonar\n     \n     x, y = load_dataset(data_train.dataset_name)\n \n # NOTE：crypten.cryptensor \n@@ -172,179 +172,4 @@\n     #     logging.info(\"PyTorch Bias  :\")\n     #     logging.info(b_torch)\n     # logging.info(\"CrypTen Bias:\")\n     # logging.info(b.get_plain_text())\n-\n-import logging\n-import time\n-import csv\n-import os\n-import crypten\n-import torch\n-import numpy as np\n-from examples.meters import AverageMeter\n-\n-\n-DATASET_DIR = os.path.join(os.path.dirname(__file__), '../dataset')\n-\n-class DataSetParam:\n-    def __init__(self, dataset_name):\n-        self.dataset_name = dataset_name\n-\n-\n-class DataSet:\n-    sonar = DataSetParam('sonar.csv')\n-    sonar_selected_55 = DataSetParam('sonar_selected_55.csv')\n-    sonar_selected_50 = DataSetParam('sonar_selected_50.csv')\n-    sonar_selected_48 = DataSetParam('sonar_selected_48.csv')\n-    sonar_selected_45 = DataSetParam('sonar_selected_45.csv')\n-    sonar_selected_40 = DataSetParam('sonar_selected_40.csv')\n-    \n-\n-\n-\n-\n-def train_linear_svm(features, labels, epochs, lr, print_time=False):\n-    # Initialize random weights\n-    w = features.new(torch.randn(features.size(1),1))\n-    b = features.new(torch.randn(1))\n-    # print(\"==========w========\", w.shape)\n-    # print(\"==========b========\", b.shape)\n-    # print(\"=======features=====\", features.shape)\n-\n-    # if print_time:\n-    #     pt_time = AverageMeter()\n-    #     end = time.time()\n-    \n-    filename = \"Accuracy.txt\"\n-    with open(filename, 'a') as f:\n-        for epoch in range(epochs):\n-            # Forward\n-            label_predictions = features.matmul(w).add(b).sign()\n-            # label_predictions = w.matmul(features.T).add(b).sign()\n-            # print(\"=======labels======\", labels.shape)\n-            # print(\"=======label_predictions======\", label_predictions.shape)\n-            # Compute accuracy\n-            correct = label_predictions.mul(labels.view(-1,1))\n-            # print(\"=======correct======\", correct.shape)\n-            accuracy = correct.add(1).div(2).mean()\n-            if crypten.is_encrypted_tensor(accuracy):\n-                accuracy = accuracy.get_plain_text()\n-\n-            # Print Accuracy once\n-            if crypten.communicator.get().get_rank() == 0:\n-                # print(\n-                #     f\"Epoch {epoch} --- Training Accuracy %.2f%%\" % (accuracy.item() * 100)\n-                # )\n-                accuracy_str = \"%.2f%%\" % (accuracy * 100)\n-                accuracy_str_without_percent = accuracy_str.replace('%', '')\n-                f.write(accuracy_str_without_percent + \",\")\n-\n-            # Backward\n-            loss_grad = -labels * (1 - correct) * 0.5  # Hinge loss\n-            # print(\"=======loss_grad======\\n\", loss_grad.get_plain_text())\n-            b_grad = loss_grad.mean()\n-            # print(\"=======b_grad ======\", b_grad.shape)\n-            w_grad = features.t().matmul(loss_grad).div(loss_grad.size(0))\n-            # print(\"=======w_grad ======\", w_grad.shape)\n-            \n-\n-            # Update\n-            w -= w_grad * lr\n-            b -= b_grad * lr\n-\n-            # if print_time:\n-            #     iter_time = time.time() - end\n-            #     pt_time.add(iter_time)\n-            #     print(\"Time %.6f (%.6f)\" % (iter_time, pt_time.value()))\n-            #     end = time.time()\n-\n-    return w, b\n-\n-\n-def evaluate_linear_svm(features, labels, w, b):\n-    \"\"\"Compute accuracy on a test set\"\"\"\n-    predictions = w.matmul(features).add(b).sign()\n-    correct = predictions.mul(labels)\n-    accuracy = correct.add(1).div(2).mean().get_plain_text()\n-    if crypten.communicator.get().get_rank() == 0:\n-        # print(\"Test accuracy %.2f%%\" % (accuracy.item() * 100))\n-        accuracy_str = \"%.2f%%\" % (accuracy * 100)\n-        filename = \"Accuracy.txt\"\n-        with open(filename, 'w') as f:\n-            f.write(accuracy_str)\n-\n-\n-def load_dataset(dataset):\n-    dataset_path = os.path.join(DATASET_DIR, dataset)\n-\n-    # 尝试打开并读取CSV文件\n-    try:\n-        with open(dataset_path, 'r', encoding='utf-8') as csvfile:\n-            spamreader = csv.reader(csvfile)\n-            data = np.array(list(spamreader))\n-    except FileNotFoundError:\n-        print(f\"Error: The file {dataset_path} was not found.\")\n-        return None, None\n-    except Exception as e:\n-        print(f\"Error: An error occurred while reading the file: {e}\")\n-        return None, None\n-\n-    # 检查数据是否为空\n-    if data.size == 0:\n-        print(\"Error: The dataset is empty.\")\n-        return None, None\n-\n-    feature = data[:, :-1].astype(np.float64)\n-    labels = data[:, -1]\n-\n-    # 创建标签映射\n-    unique_labels = np.unique(labels)\n-    label_to_int = {label: idx for idx, label in enumerate(unique_labels)}\n-    int_labels = np.array([label_to_int[label] for label in labels], dtype=np.uint8)\n-    labell = int_labels.reshape(-1,1)\n-\n-    # print(\"======feature_size=====\", feature.shape)\n-    # print(\"======label_size=====\", labell.shape)\n-    return feature, labell\n-\n-\n-\n-def run_mpc_linear_svm(\n-    epochs=100, lr=0.5\n-):\n-    crypten.init()\n-\n-    # Set random seed for reproducibility\n-    torch.manual_seed(1)\n-\n-    data_train = DataSet.sonar_selected_50\n-    \n-    x, y = load_dataset(data_train.dataset_name)\n-\n-# NOTE：crypten.cryptensor \n-    # Encrypt features / labels\n-    x = crypten.cryptensor(x)\n-    y = crypten.cryptensor(y)\n-\n-    logging.info(\"==================\")\n-    logging.info(\"CrypTen Training\")\n-    logging.info(\"==================\")\n-# NOTE：训练无差异\n-    begin_time = time.time()\n-    w, b = train_linear_svm(x, y, epochs=epochs, lr=lr, print_time=True)\n-    end_time = time.time()\n-    \n-    time_all = end_time - begin_time\n-    print(\"time:\", time_all)\n-    # if not skip_plaintext:\n-    #     logging.info(\"PyTorch Weights  :\")\n-    #     logging.info(w_torch)\n-    # logging.info(\"CrypTen Weights:\")\n-# NOTE：get_plain_text()\n-    # logging.info(w.get_plain_text())\n-\n-    # if not skip_plaintext:\n-    #     logging.info(\"PyTorch Bias  :\")\n-    #     logging.info(b_torch)\n-    # logging.info(\"CrypTen Bias:\")\n-    # logging.info(b.get_plain_text())\n"
                },
                {
                    "date": 1719232169644,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -23,8 +23,9 @@\n     sonar_selected_48 = DataSetParam('sonar_selected_48.csv')\n     sonar_selected_45 = DataSetParam('sonar_selected_45.csv')\n     sonar_selected_40 = DataSetParam('sonar_selected_40.csv')\n     \n+    \n \n \n \n \n"
                },
                {
                    "date": 1719232174854,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -22,10 +22,10 @@\n     sonar_selected_50 = DataSetParam('sonar_selected_50.csv')\n     sonar_selected_48 = DataSetParam('sonar_selected_48.csv')\n     sonar_selected_45 = DataSetParam('sonar_selected_45.csv')\n     sonar_selected_40 = DataSetParam('sonar_selected_40.csv')\n+    leukemia\n     \n-    \n \n \n \n \n"
                },
                {
                    "date": 1719232184458,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -22,9 +22,9 @@\n     sonar_selected_50 = DataSetParam('sonar_selected_50.csv')\n     sonar_selected_48 = DataSetParam('sonar_selected_48.csv')\n     sonar_selected_45 = DataSetParam('sonar_selected_45.csv')\n     sonar_selected_40 = DataSetParam('sonar_selected_40.csv')\n-    leukemia\n+    leukemia = DataSetParam(\"leukemia.csv\")\n     \n \n \n \n"
                },
                {
                    "date": 1719232190134,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -23,8 +23,9 @@\n     sonar_selected_48 = DataSetParam('sonar_selected_48.csv')\n     sonar_selected_45 = DataSetParam('sonar_selected_45.csv')\n     sonar_selected_40 = DataSetParam('sonar_selected_40.csv')\n     leukemia = DataSetParam(\"leukemia.csv\")\n+    leukemia = DataSetParam(\"leukemia.csv\")\n     \n \n \n \n"
                },
                {
                    "date": 1719232195578,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -23,9 +23,9 @@\n     sonar_selected_48 = DataSetParam('sonar_selected_48.csv')\n     sonar_selected_45 = DataSetParam('sonar_selected_45.csv')\n     sonar_selected_40 = DataSetParam('sonar_selected_40.csv')\n     leukemia = DataSetParam(\"leukemia.csv\")\n-    leukemia = DataSetParam(\"leukemia.csv\")\n+    leukemia_selected_ = DataSetParam(\"leukemia.csv\")\n     \n \n \n \n"
                },
                {
                    "date": 1719232203676,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -23,9 +23,9 @@\n     sonar_selected_48 = DataSetParam('sonar_selected_48.csv')\n     sonar_selected_45 = DataSetParam('sonar_selected_45.csv')\n     sonar_selected_40 = DataSetParam('sonar_selected_40.csv')\n     leukemia = DataSetParam(\"leukemia.csv\")\n-    leukemia_selected_ = DataSetParam(\"leukemia.csv\")\n+    leukemia_selected_6k = DataSetParam(\"leukemia_selected_6k.csv\")\n     \n \n \n \n"
                },
                {
                    "date": 1719232277690,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -143,9 +143,9 @@\n \n     # Set random seed for reproducibility\n     torch.manual_seed(1)\n \n-    data_train = DataSet.sonar\n+    data_train = DataSet.le\n     \n     x, y = load_dataset(data_train.dataset_name)\n \n # NOTE：crypten.cryptensor \n"
                },
                {
                    "date": 1719233916408,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -24,8 +24,9 @@\n     sonar_selected_45 = DataSetParam('sonar_selected_45.csv')\n     sonar_selected_40 = DataSetParam('sonar_selected_40.csv')\n     leukemia = DataSetParam(\"leukemia.csv\")\n     leukemia_selected_6k = DataSetParam(\"leukemia_selected_6k.csv\")\n+    leukemia_selected_6k = DataSetParam(\"leukemia_selected_6k.csv\")\n     \n \n \n \n@@ -143,9 +144,9 @@\n \n     # Set random seed for reproducibility\n     torch.manual_seed(1)\n \n-    data_train = DataSet.le\n+    data_train = DataSet.leukemia\n     \n     x, y = load_dataset(data_train.dataset_name)\n \n # NOTE：crypten.cryptensor \n"
                },
                {
                    "date": 1719233922508,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -24,9 +24,9 @@\n     sonar_selected_45 = DataSetParam('sonar_selected_45.csv')\n     sonar_selected_40 = DataSetParam('sonar_selected_40.csv')\n     leukemia = DataSetParam(\"leukemia.csv\")\n     leukemia_selected_6k = DataSetParam(\"leukemia_selected_6k.csv\")\n-    leukemia_selected_6k = DataSetParam(\"leukemia_selected_6k.csv\")\n+    leukemia_selected_half = DataSetParam(\"leukemia_selected_half.csv\")\n     \n \n \n \n"
                },
                {
                    "date": 1719233936314,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -144,9 +144,9 @@\n \n     # Set random seed for reproducibility\n     torch.manual_seed(1)\n \n-    data_train = DataSet.leukemia\n+    data_train = DataSet.leukemia_selected_half\n     \n     x, y = load_dataset(data_train.dataset_name)\n \n # NOTE：crypten.cryptensor \n"
                },
                {
                    "date": 1719234168382,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -144,9 +144,9 @@\n \n     # Set random seed for reproducibility\n     torch.manual_seed(1)\n \n-    data_train = DataSet.leukemia_selected_half\n+    data_train = DataSet.leukemia\n     \n     x, y = load_dataset(data_train.dataset_name)\n \n # NOTE：crypten.cryptensor \n"
                },
                {
                    "date": 1719234334928,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -144,9 +144,9 @@\n \n     # Set random seed for reproducibility\n     torch.manual_seed(1)\n \n-    data_train = DataSet.leukemia\n+    data_train = DataSet.leukemia_\n     \n     x, y = load_dataset(data_train.dataset_name)\n \n # NOTE：crypten.cryptensor \n"
                },
                {
                    "date": 1719234635354,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -25,8 +25,10 @@\n     sonar_selected_40 = DataSetParam('sonar_selected_40.csv')\n     leukemia = DataSetParam(\"leukemia.csv\")\n     leukemia_selected_6k = DataSetParam(\"leukemia_selected_6k.csv\")\n     leukemia_selected_half = DataSetParam(\"leukemia_selected_half.csv\")\n+        leukemia_selected_6k = DataSetParam(\"leukemia_selected_6k.csv\")\n+    leukemia_selected_half = DataSetParam(\"leukemia_selected_half.csv\")\n     \n \n \n \n@@ -144,9 +146,9 @@\n \n     # Set random seed for reproducibility\n     torch.manual_seed(1)\n \n-    data_train = DataSet.leukemia_\n+    data_train = DataSet.leukemia_selected_half\n     \n     x, y = load_dataset(data_train.dataset_name)\n \n # NOTE：crypten.cryptensor \n"
                },
                {
                    "date": 1719234665734,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -23,12 +23,12 @@\n     sonar_selected_48 = DataSetParam('sonar_selected_48.csv')\n     sonar_selected_45 = DataSetParam('sonar_selected_45.csv')\n     sonar_selected_40 = DataSetParam('sonar_selected_40.csv')\n     leukemia = DataSetParam(\"leukemia.csv\")\n+    leukemia_selected_6 = DataSetParam(\"leukemia_selected_6k.csv\")\n+    leukemia_selected_half = DataSetParam(\"leukemia_selected_half.csv\")\n     leukemia_selected_6k = DataSetParam(\"leukemia_selected_6k.csv\")\n     leukemia_selected_half = DataSetParam(\"leukemia_selected_half.csv\")\n-        leukemia_selected_6k = DataSetParam(\"leukemia_selected_6k.csv\")\n-    leukemia_selected_half = DataSetParam(\"leukemia_selected_half.csv\")\n     \n \n \n \n"
                },
                {
                    "date": 1719234673404,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -23,9 +23,9 @@\n     sonar_selected_48 = DataSetParam('sonar_selected_48.csv')\n     sonar_selected_45 = DataSetParam('sonar_selected_45.csv')\n     sonar_selected_40 = DataSetParam('sonar_selected_40.csv')\n     leukemia = DataSetParam(\"leukemia.csv\")\n-    leukemia_selected_6 = DataSetParam(\"leukemia_selected_6k.csv\")\n+    leukemia_selected_60 = DataSetParam(\"leukemia_selected_60%.csv\")\n     leukemia_selected_half = DataSetParam(\"leukemia_selected_half.csv\")\n     leukemia_selected_6k = DataSetParam(\"leukemia_selected_6k.csv\")\n     leukemia_selected_half = DataSetParam(\"leukemia_selected_half.csv\")\n     \n"
                },
                {
                    "date": 1719234679433,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,180 @@\n+\n+import logging\n+import time\n+import csv\n+import os\n+import crypten\n+import torch\n+import numpy as np\n+from examples.meters import AverageMeter\n+\n+\n+DATASET_DIR = os.path.join(os.path.dirname(__file__), '../dataset')\n+\n+class DataSetParam:\n+    def __init__(self, dataset_name):\n+        self.dataset_name = dataset_name\n+\n+\n+class DataSet:\n+    sonar = DataSetParam('sonar.csv')\n+    sonar_selected_55 = DataSetParam('sonar_selected_55.csv')\n+    sonar_selected_50 = DataSetParam('sonar_selected_50.csv')\n+    sonar_selected_48 = DataSetParam('sonar_selected_48.csv')\n+    sonar_selected_45 = DataSetParam('sonar_selected_45.csv')\n+    sonar_selected_40 = DataSetParam('sonar_selected_40.csv')\n+    leukemia = DataSetParam(\"leukemia.csv\")\n+    leukemia_selected_60 = DataSetParam(\"leukemia_selected_60%.csv\")\n+    leukemia_selected_half = DataSetParam(\"leukemia_selected_half.csv\")\n+    leukemia_selected_70 = DataSetParam(\"leukemia_selected_6k.csv\")\n+    leukemia_selected_half = DataSetParam(\"leukemia_selected_half.csv\")\n+    \n+\n+\n+\n+\n+def train_linear_svm(features, labels, epochs, lr, print_time=False):\n+    # Initialize random weights\n+    w = features.new(torch.randn(features.size(1),1))\n+    b = features.new(torch.randn(1))\n+    # print(\"==========w========\", w.shape)\n+    # print(\"==========b========\", b.shape)\n+    # print(\"=======features=====\", features.shape)\n+\n+    # if print_time:\n+    #     pt_time = AverageMeter()\n+    #     end = time.time()\n+    \n+    filename = \"Accuracy.txt\"\n+    with open(filename, 'a') as f:\n+        for epoch in range(epochs):\n+            # Forward\n+            label_predictions = features.matmul(w).add(b).sign()\n+            # label_predictions = w.matmul(features.T).add(b).sign()\n+            # print(\"=======labels======\", labels.shape)\n+            # print(\"=======label_predictions======\", label_predictions.shape)\n+            # Compute accuracy\n+            correct = label_predictions.mul(labels.view(-1,1))\n+            # print(\"=======correct======\", correct.shape)\n+            accuracy = correct.add(1).div(2).mean()\n+            if crypten.is_encrypted_tensor(accuracy):\n+                accuracy = accuracy.get_plain_text()\n+\n+            # Print Accuracy once\n+            if crypten.communicator.get().get_rank() == 0:\n+                # print(\n+                #     f\"Epoch {epoch} --- Training Accuracy %.2f%%\" % (accuracy.item() * 100)\n+                # )\n+                accuracy_str = \"%.2f%%\" % (accuracy * 100)\n+                accuracy_str_without_percent = accuracy_str.replace('%', '')\n+                f.write(accuracy_str_without_percent + \",\")\n+\n+            # Backward\n+            loss_grad = -labels * (1 - correct) * 0.5  # Hinge loss\n+            # print(\"=======loss_grad======\\n\", loss_grad.get_plain_text())\n+            b_grad = loss_grad.mean()\n+            # print(\"=======b_grad ======\", b_grad.shape)\n+            w_grad = features.t().matmul(loss_grad).div(loss_grad.size(0))\n+            # print(\"=======w_grad ======\", w_grad.shape)\n+            \n+\n+            # Update\n+            w -= w_grad * lr\n+            b -= b_grad * lr\n+\n+            # if print_time:\n+            #     iter_time = time.time() - end\n+            #     pt_time.add(iter_time)\n+            #     print(\"Time %.6f (%.6f)\" % (iter_time, pt_time.value()))\n+            #     end = time.time()\n+\n+    return w, b\n+\n+\n+def evaluate_linear_svm(features, labels, w, b):\n+    \"\"\"Compute accuracy on a test set\"\"\"\n+    predictions = w.matmul(features).add(b).sign()\n+    correct = predictions.mul(labels)\n+    accuracy = correct.add(1).div(2).mean().get_plain_text()\n+    if crypten.communicator.get().get_rank() == 0:\n+        # print(\"Test accuracy %.2f%%\" % (accuracy.item() * 100))\n+        accuracy_str = \"%.2f%%\" % (accuracy * 100)\n+        filename = \"Accuracy.txt\"\n+        with open(filename, 'w') as f:\n+            f.write(accuracy_str)\n+\n+\n+def load_dataset(dataset):\n+    dataset_path = os.path.join(DATASET_DIR, dataset)\n+\n+    # 尝试打开并读取CSV文件\n+    try:\n+        with open(dataset_path, 'r', encoding='utf-8') as csvfile:\n+            spamreader = csv.reader(csvfile)\n+            data = np.array(list(spamreader))\n+    except FileNotFoundError:\n+        print(f\"Error: The file {dataset_path} was not found.\")\n+        return None, None\n+    except Exception as e:\n+        print(f\"Error: An error occurred while reading the file: {e}\")\n+        return None, None\n+\n+    # 检查数据是否为空\n+    if data.size == 0:\n+        print(\"Error: The dataset is empty.\")\n+        return None, None\n+\n+    feature = data[:, :-1].astype(np.float64)\n+    labels = data[:, -1]\n+\n+    # 创建标签映射\n+    unique_labels = np.unique(labels)\n+    label_to_int = {label: idx for idx, label in enumerate(unique_labels)}\n+    int_labels = np.array([label_to_int[label] for label in labels], dtype=np.uint8)\n+    labell = int_labels.reshape(-1,1)\n+\n+    # print(\"======feature_size=====\", feature.shape)\n+    # print(\"======label_size=====\", labell.shape)\n+    return feature, labell\n+\n+\n+\n+def run_mpc_linear_svm(\n+    epochs=100, lr=0.5\n+):\n+    crypten.init()\n+\n+    # Set random seed for reproducibility\n+    torch.manual_seed(1)\n+\n+    data_train = DataSet.leukemia_selected_half\n+    \n+    x, y = load_dataset(data_train.dataset_name)\n+\n+# NOTE：crypten.cryptensor \n+    # Encrypt features / labels\n+    x = crypten.cryptensor(x)\n+    y = crypten.cryptensor(y)\n+\n+    logging.info(\"==================\")\n+    logging.info(\"CrypTen Training\")\n+    logging.info(\"==================\")\n+# NOTE：训练无差异\n+    begin_time = time.time()\n+    w, b = train_linear_svm(x, y, epochs=epochs, lr=lr, print_time=True)\n+    end_time = time.time()\n+    \n+    time_all = end_time - begin_time\n+    print(\"time:\", time_all)\n+    # if not skip_plaintext:\n+    #     logging.info(\"PyTorch Weights  :\")\n+    #     logging.info(w_torch)\n+    # logging.info(\"CrypTen Weights:\")\n+# NOTE：get_plain_text()\n+    # logging.info(w.get_plain_text())\n+\n+    # if not skip_plaintext:\n+    #     logging.info(\"PyTorch Bias  :\")\n+    #     logging.info(b_torch)\n+    # logging.info(\"CrypTen Bias:\")\n+    # logging.info(b.get_plain_text())\n"
                },
                {
                    "date": 1719234685740,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,180 @@\n+\n+import logging\n+import time\n+import csv\n+import os\n+import crypten\n+import torch\n+import numpy as np\n+from examples.meters import AverageMeter\n+\n+\n+DATASET_DIR = os.path.join(os.path.dirname(__file__), '../dataset')\n+\n+class DataSetParam:\n+    def __init__(self, dataset_name):\n+        self.dataset_name = dataset_name\n+\n+\n+class DataSet:\n+    sonar = DataSetParam('sonar.csv')\n+    sonar_selected_55 = DataSetParam('sonar_selected_55.csv')\n+    sonar_selected_50 = DataSetParam('sonar_selected_50.csv')\n+    sonar_selected_48 = DataSetParam('sonar_selected_48.csv')\n+    sonar_selected_45 = DataSetParam('sonar_selected_45.csv')\n+    sonar_selected_40 = DataSetParam('sonar_selected_40.csv')\n+    leukemia = DataSetParam(\"leukemia.csv\")\n+    leukemia_selected_60 = DataSetParam(\"leukemia_selected_60%.csv\")\n+    leukemia_selected_half = DataSetParam(\"leukemia_selected_half.csv\")\n+    leukemia_selected_70 = DataSetParam(\"leukemia_selected_70%.csv\")\n+    leukemia_selected_80 = DataSetParam(\"leukemia_selected_half.csv\")\n+    \n+\n+\n+\n+\n+def train_linear_svm(features, labels, epochs, lr, print_time=False):\n+    # Initialize random weights\n+    w = features.new(torch.randn(features.size(1),1))\n+    b = features.new(torch.randn(1))\n+    # print(\"==========w========\", w.shape)\n+    # print(\"==========b========\", b.shape)\n+    # print(\"=======features=====\", features.shape)\n+\n+    # if print_time:\n+    #     pt_time = AverageMeter()\n+    #     end = time.time()\n+    \n+    filename = \"Accuracy.txt\"\n+    with open(filename, 'a') as f:\n+        for epoch in range(epochs):\n+            # Forward\n+            label_predictions = features.matmul(w).add(b).sign()\n+            # label_predictions = w.matmul(features.T).add(b).sign()\n+            # print(\"=======labels======\", labels.shape)\n+            # print(\"=======label_predictions======\", label_predictions.shape)\n+            # Compute accuracy\n+            correct = label_predictions.mul(labels.view(-1,1))\n+            # print(\"=======correct======\", correct.shape)\n+            accuracy = correct.add(1).div(2).mean()\n+            if crypten.is_encrypted_tensor(accuracy):\n+                accuracy = accuracy.get_plain_text()\n+\n+            # Print Accuracy once\n+            if crypten.communicator.get().get_rank() == 0:\n+                # print(\n+                #     f\"Epoch {epoch} --- Training Accuracy %.2f%%\" % (accuracy.item() * 100)\n+                # )\n+                accuracy_str = \"%.2f%%\" % (accuracy * 100)\n+                accuracy_str_without_percent = accuracy_str.replace('%', '')\n+                f.write(accuracy_str_without_percent + \",\")\n+\n+            # Backward\n+            loss_grad = -labels * (1 - correct) * 0.5  # Hinge loss\n+            # print(\"=======loss_grad======\\n\", loss_grad.get_plain_text())\n+            b_grad = loss_grad.mean()\n+            # print(\"=======b_grad ======\", b_grad.shape)\n+            w_grad = features.t().matmul(loss_grad).div(loss_grad.size(0))\n+            # print(\"=======w_grad ======\", w_grad.shape)\n+            \n+\n+            # Update\n+            w -= w_grad * lr\n+            b -= b_grad * lr\n+\n+            # if print_time:\n+            #     iter_time = time.time() - end\n+            #     pt_time.add(iter_time)\n+            #     print(\"Time %.6f (%.6f)\" % (iter_time, pt_time.value()))\n+            #     end = time.time()\n+\n+    return w, b\n+\n+\n+def evaluate_linear_svm(features, labels, w, b):\n+    \"\"\"Compute accuracy on a test set\"\"\"\n+    predictions = w.matmul(features).add(b).sign()\n+    correct = predictions.mul(labels)\n+    accuracy = correct.add(1).div(2).mean().get_plain_text()\n+    if crypten.communicator.get().get_rank() == 0:\n+        # print(\"Test accuracy %.2f%%\" % (accuracy.item() * 100))\n+        accuracy_str = \"%.2f%%\" % (accuracy * 100)\n+        filename = \"Accuracy.txt\"\n+        with open(filename, 'w') as f:\n+            f.write(accuracy_str)\n+\n+\n+def load_dataset(dataset):\n+    dataset_path = os.path.join(DATASET_DIR, dataset)\n+\n+    # 尝试打开并读取CSV文件\n+    try:\n+        with open(dataset_path, 'r', encoding='utf-8') as csvfile:\n+            spamreader = csv.reader(csvfile)\n+            data = np.array(list(spamreader))\n+    except FileNotFoundError:\n+        print(f\"Error: The file {dataset_path} was not found.\")\n+        return None, None\n+    except Exception as e:\n+        print(f\"Error: An error occurred while reading the file: {e}\")\n+        return None, None\n+\n+    # 检查数据是否为空\n+    if data.size == 0:\n+        print(\"Error: The dataset is empty.\")\n+        return None, None\n+\n+    feature = data[:, :-1].astype(np.float64)\n+    labels = data[:, -1]\n+\n+    # 创建标签映射\n+    unique_labels = np.unique(labels)\n+    label_to_int = {label: idx for idx, label in enumerate(unique_labels)}\n+    int_labels = np.array([label_to_int[label] for label in labels], dtype=np.uint8)\n+    labell = int_labels.reshape(-1,1)\n+\n+    # print(\"======feature_size=====\", feature.shape)\n+    # print(\"======label_size=====\", labell.shape)\n+    return feature, labell\n+\n+\n+\n+def run_mpc_linear_svm(\n+    epochs=100, lr=0.5\n+):\n+    crypten.init()\n+\n+    # Set random seed for reproducibility\n+    torch.manual_seed(1)\n+\n+    data_train = DataSet.leukemia_selected_half\n+    \n+    x, y = load_dataset(data_train.dataset_name)\n+\n+# NOTE：crypten.cryptensor \n+    # Encrypt features / labels\n+    x = crypten.cryptensor(x)\n+    y = crypten.cryptensor(y)\n+\n+    logging.info(\"==================\")\n+    logging.info(\"CrypTen Training\")\n+    logging.info(\"==================\")\n+# NOTE：训练无差异\n+    begin_time = time.time()\n+    w, b = train_linear_svm(x, y, epochs=epochs, lr=lr, print_time=True)\n+    end_time = time.time()\n+    \n+    time_all = end_time - begin_time\n+    print(\"time:\", time_all)\n+    # if not skip_plaintext:\n+    #     logging.info(\"PyTorch Weights  :\")\n+    #     logging.info(w_torch)\n+    # logging.info(\"CrypTen Weights:\")\n+# NOTE：get_plain_text()\n+    # logging.info(w.get_plain_text())\n+\n+    # if not skip_plaintext:\n+    #     logging.info(\"PyTorch Bias  :\")\n+    #     logging.info(b_torch)\n+    # logging.info(\"CrypTen Bias:\")\n+    # logging.info(b.get_plain_text())\n"
                },
                {
                    "date": 1719234693155,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -26,9 +26,10 @@\n     leukemia = DataSetParam(\"leukemia.csv\")\n     leukemia_selected_60 = DataSetParam(\"leukemia_selected_60%.csv\")\n     leukemia_selected_half = DataSetParam(\"leukemia_selected_half.csv\")\n     leukemia_selected_70 = DataSetParam(\"leukemia_selected_70%.csv\")\n-    leukemia_selected_80 = DataSetParam(\"leukemia_selected_half.csv\")\n+    leukemia_selected_80 = DataSetParam(\"leukemia_selected_80%.csv\")\n+        leukemia_selected_80 = DataSetParam(\"leukemia_selected_80%.csv\")\n     \n \n \n \n@@ -177,364 +178,4 @@\n     #     logging.info(\"PyTorch Bias  :\")\n     #     logging.info(b_torch)\n     # logging.info(\"CrypTen Bias:\")\n     # logging.info(b.get_plain_text())\n-\n-import logging\n-import time\n-import csv\n-import os\n-import crypten\n-import torch\n-import numpy as np\n-from examples.meters import AverageMeter\n-\n-\n-DATASET_DIR = os.path.join(os.path.dirname(__file__), '../dataset')\n-\n-class DataSetParam:\n-    def __init__(self, dataset_name):\n-        self.dataset_name = dataset_name\n-\n-\n-class DataSet:\n-    sonar = DataSetParam('sonar.csv')\n-    sonar_selected_55 = DataSetParam('sonar_selected_55.csv')\n-    sonar_selected_50 = DataSetParam('sonar_selected_50.csv')\n-    sonar_selected_48 = DataSetParam('sonar_selected_48.csv')\n-    sonar_selected_45 = DataSetParam('sonar_selected_45.csv')\n-    sonar_selected_40 = DataSetParam('sonar_selected_40.csv')\n-    leukemia = DataSetParam(\"leukemia.csv\")\n-    leukemia_selected_60 = DataSetParam(\"leukemia_selected_60%.csv\")\n-    leukemia_selected_half = DataSetParam(\"leukemia_selected_half.csv\")\n-    leukemia_selected_70 = DataSetParam(\"leukemia_selected_6k.csv\")\n-    leukemia_selected_half = DataSetParam(\"leukemia_selected_half.csv\")\n-    \n-\n-\n-\n-\n-def train_linear_svm(features, labels, epochs, lr, print_time=False):\n-    # Initialize random weights\n-    w = features.new(torch.randn(features.size(1),1))\n-    b = features.new(torch.randn(1))\n-    # print(\"==========w========\", w.shape)\n-    # print(\"==========b========\", b.shape)\n-    # print(\"=======features=====\", features.shape)\n-\n-    # if print_time:\n-    #     pt_time = AverageMeter()\n-    #     end = time.time()\n-    \n-    filename = \"Accuracy.txt\"\n-    with open(filename, 'a') as f:\n-        for epoch in range(epochs):\n-            # Forward\n-            label_predictions = features.matmul(w).add(b).sign()\n-            # label_predictions = w.matmul(features.T).add(b).sign()\n-            # print(\"=======labels======\", labels.shape)\n-            # print(\"=======label_predictions======\", label_predictions.shape)\n-            # Compute accuracy\n-            correct = label_predictions.mul(labels.view(-1,1))\n-            # print(\"=======correct======\", correct.shape)\n-            accuracy = correct.add(1).div(2).mean()\n-            if crypten.is_encrypted_tensor(accuracy):\n-                accuracy = accuracy.get_plain_text()\n-\n-            # Print Accuracy once\n-            if crypten.communicator.get().get_rank() == 0:\n-                # print(\n-                #     f\"Epoch {epoch} --- Training Accuracy %.2f%%\" % (accuracy.item() * 100)\n-                # )\n-                accuracy_str = \"%.2f%%\" % (accuracy * 100)\n-                accuracy_str_without_percent = accuracy_str.replace('%', '')\n-                f.write(accuracy_str_without_percent + \",\")\n-\n-            # Backward\n-            loss_grad = -labels * (1 - correct) * 0.5  # Hinge loss\n-            # print(\"=======loss_grad======\\n\", loss_grad.get_plain_text())\n-            b_grad = loss_grad.mean()\n-            # print(\"=======b_grad ======\", b_grad.shape)\n-            w_grad = features.t().matmul(loss_grad).div(loss_grad.size(0))\n-            # print(\"=======w_grad ======\", w_grad.shape)\n-            \n-\n-            # Update\n-            w -= w_grad * lr\n-            b -= b_grad * lr\n-\n-            # if print_time:\n-            #     iter_time = time.time() - end\n-            #     pt_time.add(iter_time)\n-            #     print(\"Time %.6f (%.6f)\" % (iter_time, pt_time.value()))\n-            #     end = time.time()\n-\n-    return w, b\n-\n-\n-def evaluate_linear_svm(features, labels, w, b):\n-    \"\"\"Compute accuracy on a test set\"\"\"\n-    predictions = w.matmul(features).add(b).sign()\n-    correct = predictions.mul(labels)\n-    accuracy = correct.add(1).div(2).mean().get_plain_text()\n-    if crypten.communicator.get().get_rank() == 0:\n-        # print(\"Test accuracy %.2f%%\" % (accuracy.item() * 100))\n-        accuracy_str = \"%.2f%%\" % (accuracy * 100)\n-        filename = \"Accuracy.txt\"\n-        with open(filename, 'w') as f:\n-            f.write(accuracy_str)\n-\n-\n-def load_dataset(dataset):\n-    dataset_path = os.path.join(DATASET_DIR, dataset)\n-\n-    # 尝试打开并读取CSV文件\n-    try:\n-        with open(dataset_path, 'r', encoding='utf-8') as csvfile:\n-            spamreader = csv.reader(csvfile)\n-            data = np.array(list(spamreader))\n-    except FileNotFoundError:\n-        print(f\"Error: The file {dataset_path} was not found.\")\n-        return None, None\n-    except Exception as e:\n-        print(f\"Error: An error occurred while reading the file: {e}\")\n-        return None, None\n-\n-    # 检查数据是否为空\n-    if data.size == 0:\n-        print(\"Error: The dataset is empty.\")\n-        return None, None\n-\n-    feature = data[:, :-1].astype(np.float64)\n-    labels = data[:, -1]\n-\n-    # 创建标签映射\n-    unique_labels = np.unique(labels)\n-    label_to_int = {label: idx for idx, label in enumerate(unique_labels)}\n-    int_labels = np.array([label_to_int[label] for label in labels], dtype=np.uint8)\n-    labell = int_labels.reshape(-1,1)\n-\n-    # print(\"======feature_size=====\", feature.shape)\n-    # print(\"======label_size=====\", labell.shape)\n-    return feature, labell\n-\n-\n-\n-def run_mpc_linear_svm(\n-    epochs=100, lr=0.5\n-):\n-    crypten.init()\n-\n-    # Set random seed for reproducibility\n-    torch.manual_seed(1)\n-\n-    data_train = DataSet.leukemia_selected_half\n-    \n-    x, y = load_dataset(data_train.dataset_name)\n-\n-# NOTE：crypten.cryptensor \n-    # Encrypt features / labels\n-    x = crypten.cryptensor(x)\n-    y = crypten.cryptensor(y)\n-\n-    logging.info(\"==================\")\n-    logging.info(\"CrypTen Training\")\n-    logging.info(\"==================\")\n-# NOTE：训练无差异\n-    begin_time = time.time()\n-    w, b = train_linear_svm(x, y, epochs=epochs, lr=lr, print_time=True)\n-    end_time = time.time()\n-    \n-    time_all = end_time - begin_time\n-    print(\"time:\", time_all)\n-    # if not skip_plaintext:\n-    #     logging.info(\"PyTorch Weights  :\")\n-    #     logging.info(w_torch)\n-    # logging.info(\"CrypTen Weights:\")\n-# NOTE：get_plain_text()\n-    # logging.info(w.get_plain_text())\n-\n-    # if not skip_plaintext:\n-    #     logging.info(\"PyTorch Bias  :\")\n-    #     logging.info(b_torch)\n-    # logging.info(\"CrypTen Bias:\")\n-    # logging.info(b.get_plain_text())\n-\n-import logging\n-import time\n-import csv\n-import os\n-import crypten\n-import torch\n-import numpy as np\n-from examples.meters import AverageMeter\n-\n-\n-DATASET_DIR = os.path.join(os.path.dirname(__file__), '../dataset')\n-\n-class DataSetParam:\n-    def __init__(self, dataset_name):\n-        self.dataset_name = dataset_name\n-\n-\n-class DataSet:\n-    sonar = DataSetParam('sonar.csv')\n-    sonar_selected_55 = DataSetParam('sonar_selected_55.csv')\n-    sonar_selected_50 = DataSetParam('sonar_selected_50.csv')\n-    sonar_selected_48 = DataSetParam('sonar_selected_48.csv')\n-    sonar_selected_45 = DataSetParam('sonar_selected_45.csv')\n-    sonar_selected_40 = DataSetParam('sonar_selected_40.csv')\n-    leukemia = DataSetParam(\"leukemia.csv\")\n-    leukemia_selected_60 = DataSetParam(\"leukemia_selected_60%.csv\")\n-    leukemia_selected_half = DataSetParam(\"leukemia_selected_half.csv\")\n-    leukemia_selected_6k = DataSetParam(\"leukemia_selected_6k.csv\")\n-    leukemia_selected_half = DataSetParam(\"leukemia_selected_half.csv\")\n-    \n-\n-\n-\n-\n-def train_linear_svm(features, labels, epochs, lr, print_time=False):\n-    # Initialize random weights\n-    w = features.new(torch.randn(features.size(1),1))\n-    b = features.new(torch.randn(1))\n-    # print(\"==========w========\", w.shape)\n-    # print(\"==========b========\", b.shape)\n-    # print(\"=======features=====\", features.shape)\n-\n-    # if print_time:\n-    #     pt_time = AverageMeter()\n-    #     end = time.time()\n-    \n-    filename = \"Accuracy.txt\"\n-    with open(filename, 'a') as f:\n-        for epoch in range(epochs):\n-            # Forward\n-            label_predictions = features.matmul(w).add(b).sign()\n-            # label_predictions = w.matmul(features.T).add(b).sign()\n-            # print(\"=======labels======\", labels.shape)\n-            # print(\"=======label_predictions======\", label_predictions.shape)\n-            # Compute accuracy\n-            correct = label_predictions.mul(labels.view(-1,1))\n-            # print(\"=======correct======\", correct.shape)\n-            accuracy = correct.add(1).div(2).mean()\n-            if crypten.is_encrypted_tensor(accuracy):\n-                accuracy = accuracy.get_plain_text()\n-\n-            # Print Accuracy once\n-            if crypten.communicator.get().get_rank() == 0:\n-                # print(\n-                #     f\"Epoch {epoch} --- Training Accuracy %.2f%%\" % (accuracy.item() * 100)\n-                # )\n-                accuracy_str = \"%.2f%%\" % (accuracy * 100)\n-                accuracy_str_without_percent = accuracy_str.replace('%', '')\n-                f.write(accuracy_str_without_percent + \",\")\n-\n-            # Backward\n-            loss_grad = -labels * (1 - correct) * 0.5  # Hinge loss\n-            # print(\"=======loss_grad======\\n\", loss_grad.get_plain_text())\n-            b_grad = loss_grad.mean()\n-            # print(\"=======b_grad ======\", b_grad.shape)\n-            w_grad = features.t().matmul(loss_grad).div(loss_grad.size(0))\n-            # print(\"=======w_grad ======\", w_grad.shape)\n-            \n-\n-            # Update\n-            w -= w_grad * lr\n-            b -= b_grad * lr\n-\n-            # if print_time:\n-            #     iter_time = time.time() - end\n-            #     pt_time.add(iter_time)\n-            #     print(\"Time %.6f (%.6f)\" % (iter_time, pt_time.value()))\n-            #     end = time.time()\n-\n-    return w, b\n-\n-\n-def evaluate_linear_svm(features, labels, w, b):\n-    \"\"\"Compute accuracy on a test set\"\"\"\n-    predictions = w.matmul(features).add(b).sign()\n-    correct = predictions.mul(labels)\n-    accuracy = correct.add(1).div(2).mean().get_plain_text()\n-    if crypten.communicator.get().get_rank() == 0:\n-        # print(\"Test accuracy %.2f%%\" % (accuracy.item() * 100))\n-        accuracy_str = \"%.2f%%\" % (accuracy * 100)\n-        filename = \"Accuracy.txt\"\n-        with open(filename, 'w') as f:\n-            f.write(accuracy_str)\n-\n-\n-def load_dataset(dataset):\n-    dataset_path = os.path.join(DATASET_DIR, dataset)\n-\n-    # 尝试打开并读取CSV文件\n-    try:\n-        with open(dataset_path, 'r', encoding='utf-8') as csvfile:\n-            spamreader = csv.reader(csvfile)\n-            data = np.array(list(spamreader))\n-    except FileNotFoundError:\n-        print(f\"Error: The file {dataset_path} was not found.\")\n-        return None, None\n-    except Exception as e:\n-        print(f\"Error: An error occurred while reading the file: {e}\")\n-        return None, None\n-\n-    # 检查数据是否为空\n-    if data.size == 0:\n-        print(\"Error: The dataset is empty.\")\n-        return None, None\n-\n-    feature = data[:, :-1].astype(np.float64)\n-    labels = data[:, -1]\n-\n-    # 创建标签映射\n-    unique_labels = np.unique(labels)\n-    label_to_int = {label: idx for idx, label in enumerate(unique_labels)}\n-    int_labels = np.array([label_to_int[label] for label in labels], dtype=np.uint8)\n-    labell = int_labels.reshape(-1,1)\n-\n-    # print(\"======feature_size=====\", feature.shape)\n-    # print(\"======label_size=====\", labell.shape)\n-    return feature, labell\n-\n-\n-\n-def run_mpc_linear_svm(\n-    epochs=100, lr=0.5\n-):\n-    crypten.init()\n-\n-    # Set random seed for reproducibility\n-    torch.manual_seed(1)\n-\n-    data_train = DataSet.leukemia_selected_half\n-    \n-    x, y = load_dataset(data_train.dataset_name)\n-\n-# NOTE：crypten.cryptensor \n-    # Encrypt features / labels\n-    x = crypten.cryptensor(x)\n-    y = crypten.cryptensor(y)\n-\n-    logging.info(\"==================\")\n-    logging.info(\"CrypTen Training\")\n-    logging.info(\"==================\")\n-# NOTE：训练无差异\n-    begin_time = time.time()\n-    w, b = train_linear_svm(x, y, epochs=epochs, lr=lr, print_time=True)\n-    end_time = time.time()\n-    \n-    time_all = end_time - begin_time\n-    print(\"time:\", time_all)\n-    # if not skip_plaintext:\n-    #     logging.info(\"PyTorch Weights  :\")\n-    #     logging.info(w_torch)\n-    # logging.info(\"CrypTen Weights:\")\n-# NOTE：get_plain_text()\n-    # logging.info(w.get_plain_text())\n-\n-    # if not skip_plaintext:\n-    #     logging.info(\"PyTorch Bias  :\")\n-    #     logging.info(b_torch)\n-    # logging.info(\"CrypTen Bias:\")\n-    # logging.info(b.get_plain_text())\n"
                },
                {
                    "date": 1719234699258,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -23,10 +23,10 @@\n     sonar_selected_48 = DataSetParam('sonar_selected_48.csv')\n     sonar_selected_45 = DataSetParam('sonar_selected_45.csv')\n     sonar_selected_40 = DataSetParam('sonar_selected_40.csv')\n     leukemia = DataSetParam(\"leukemia.csv\")\n-    leukemia_selected_60 = DataSetParam(\"leukemia_selected_60%.csv\")\n-    leukemia_selected_half = DataSetParam(\"leukemia_selected_half.csv\")\n+ leukemia_selected_half = DataSetParam(\"leukemia_selected_half.csv\")\n+     leukemia_selected_60 = DataSetParam(\"leukemia_selected_60%.csv\")   \n     leukemia_selected_70 = DataSetParam(\"leukemia_selected_70%.csv\")\n     leukemia_selected_80 = DataSetParam(\"leukemia_selected_80%.csv\")\n         leukemia_selected_80 = DataSetParam(\"leukemia_selected_80%.csv\")\n     \n"
                },
                {
                    "date": 1719234706360,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -23,13 +23,13 @@\n     sonar_selected_48 = DataSetParam('sonar_selected_48.csv')\n     sonar_selected_45 = DataSetParam('sonar_selected_45.csv')\n     sonar_selected_40 = DataSetParam('sonar_selected_40.csv')\n     leukemia = DataSetParam(\"leukemia.csv\")\n- leukemia_selected_half = DataSetParam(\"leukemia_selected_half.csv\")\n-     leukemia_selected_60 = DataSetParam(\"leukemia_selected_60%.csv\")   \n+    leukemia_selected_half = DataSetParam(\"leukemia_selected_half.csv\")\n+    leukemia_selected_60 = DataSetParam(\"leukemia_selected_60%.csv\")   \n     leukemia_selected_70 = DataSetParam(\"leukemia_selected_70%.csv\")\n     leukemia_selected_80 = DataSetParam(\"leukemia_selected_80%.csv\")\n-        leukemia_selected_80 = DataSetParam(\"leukemia_selected_80%.csv\")\n+    leukemia_selected_80 = DataSetParam(\"leukemia_selected_80%.csv\")\n     \n \n \n \n"
                },
                {
                    "date": 1719234722612,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -27,9 +27,9 @@\n     leukemia_selected_half = DataSetParam(\"leukemia_selected_half.csv\")\n     leukemia_selected_60 = DataSetParam(\"leukemia_selected_60%.csv\")   \n     leukemia_selected_70 = DataSetParam(\"leukemia_selected_70%.csv\")\n     leukemia_selected_80 = DataSetParam(\"leukemia_selected_80%.csv\")\n-    leukemia_selected_80 = DataSetParam(\"leukemia_selected_80%.csv\")\n+    leukemia_selected_90 = DataSetParam(\"leukemia_selected_90%.csv\")\n     \n \n \n \n@@ -147,9 +147,9 @@\n \n     # Set random seed for reproducibility\n     torch.manual_seed(1)\n \n-    data_train = DataSet.leukemia_selected_half\n+    data_train = DataSet.leukemia_selected_\n     \n     x, y = load_dataset(data_train.dataset_name)\n \n # NOTE：crypten.cryptensor \n"
                },
                {
                    "date": 1719234916805,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -147,9 +147,9 @@\n \n     # Set random seed for reproducibility\n     torch.manual_seed(1)\n \n-    data_train = DataSet.leukemia_selected_\n+    data_train = DataSet.leukemia_selected_80\n     \n     x, y = load_dataset(data_train.dataset_name)\n \n # NOTE：crypten.cryptensor \n"
                },
                {
                    "date": 1719235067612,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -147,9 +147,9 @@\n \n     # Set random seed for reproducibility\n     torch.manual_seed(1)\n \n-    data_train = DataSet.leukemia_selected_80\n+    data_train = DataSet.leukemia_selected_\n     \n     x, y = load_dataset(data_train.dataset_name)\n \n # NOTE：crypten.cryptensor \n"
                },
                {
                    "date": 1719235231566,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -147,9 +147,9 @@\n \n     # Set random seed for reproducibility\n     torch.manual_seed(1)\n \n-    data_train = DataSet.leukemia_selected_\n+    data_train = DataSet.leukemia_selected_60\n     \n     x, y = load_dataset(data_train.dataset_name)\n \n # NOTE：crypten.cryptensor \n"
                },
                {
                    "date": 1719236039539,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,187 @@\n+\n+import logging\n+import time\n+import csv\n+import os\n+import crypten\n+import torch\n+import numpy as np\n+from examples.meters import AverageMeter\n+\n+\n+DATASET_DIR = os.path.join(os.path.dirname(__file__), '../dataset')\n+\n+class DataSetParam:\n+    def __init__(self, dataset_name):\n+        self.dataset_name = dataset_name\n+\n+\n+class DataSet:\n+    sonar = DataSetParam('sonar.csv')\n+    sonar_selected_55 = DataSetParam('sonar_selected_55.csv')\n+    sonar_selected_50 = DataSetParam('sonar_selected_50.csv')\n+    sonar_selected_48 = DataSetParam('sonar_selected_48.csv')\n+    sonar_selected_45 = DataSetParam('sonar_selected_45.csv')\n+    sonar_selected_40 = DataSetParam('sonar_selected_40.csv')\n+    leukemia = DataSetParam(\"leukemia.csv\")\n+    leukemia_selected_half = DataSetParam(\"leukemia_selected_half.csv\")\n+    leukemia_selected_60 = DataSetParam(\"leukemia_selected_60%.csv\")   \n+    leukemia_selected_70 = DataSetParam(\"leukemia_selected_70%.csv\")\n+    leukemia_selected_80 = DataSetParam(\"leukemia_selected_80%.csv\")\n+    leukemia_selected_90 = DataSetParam(\"leukemia_selected_90%.csv\")\n+        leukemia = DataSetParam(\"leukemia.csv\")\n+    leukemia_selected_half = DataSetParam(\"leukemia_selected_half.csv\")\n+    leukemia_selected_60 = DataSetParam(\"leukemia_selected_60%.csv\")   \n+    leukemia_selected_70 = DataSetParam(\"leukemia_selected_70%.csv\")\n+    leukemia_selected_80 = DataSetParam(\"leukemia_selected_80%.csv\")\n+    leukemia_selected_90 = DataSetParam(\"leukemia_selected_90%.csv\")\n+    \n+\n+\n+\n+\n+def train_linear_svm(features, labels, epochs, lr, print_time=False):\n+    # Initialize random weights\n+    w = features.new(torch.randn(features.size(1),1))\n+    b = features.new(torch.randn(1))\n+    # print(\"==========w========\", w.shape)\n+    # print(\"==========b========\", b.shape)\n+    # print(\"=======features=====\", features.shape)\n+\n+    # if print_time:\n+    #     pt_time = AverageMeter()\n+    #     end = time.time()\n+    \n+    filename = \"Accuracy.txt\"\n+    with open(filename, 'a') as f:\n+        for epoch in range(epochs):\n+            # Forward\n+            label_predictions = features.matmul(w).add(b).sign()\n+            # label_predictions = w.matmul(features.T).add(b).sign()\n+            # print(\"=======labels======\", labels.shape)\n+            # print(\"=======label_predictions======\", label_predictions.shape)\n+            # Compute accuracy\n+            correct = label_predictions.mul(labels.view(-1,1))\n+            # print(\"=======correct======\", correct.shape)\n+            accuracy = correct.add(1).div(2).mean()\n+            if crypten.is_encrypted_tensor(accuracy):\n+                accuracy = accuracy.get_plain_text()\n+\n+            # Print Accuracy once\n+            if crypten.communicator.get().get_rank() == 0:\n+                # print(\n+                #     f\"Epoch {epoch} --- Training Accuracy %.2f%%\" % (accuracy.item() * 100)\n+                # )\n+                accuracy_str = \"%.2f%%\" % (accuracy * 100)\n+                accuracy_str_without_percent = accuracy_str.replace('%', '')\n+                f.write(accuracy_str_without_percent + \",\")\n+\n+            # Backward\n+            loss_grad = -labels * (1 - correct) * 0.5  # Hinge loss\n+            # print(\"=======loss_grad======\\n\", loss_grad.get_plain_text())\n+            b_grad = loss_grad.mean()\n+            # print(\"=======b_grad ======\", b_grad.shape)\n+            w_grad = features.t().matmul(loss_grad).div(loss_grad.size(0))\n+            # print(\"=======w_grad ======\", w_grad.shape)\n+            \n+\n+            # Update\n+            w -= w_grad * lr\n+            b -= b_grad * lr\n+\n+            # if print_time:\n+            #     iter_time = time.time() - end\n+            #     pt_time.add(iter_time)\n+            #     print(\"Time %.6f (%.6f)\" % (iter_time, pt_time.value()))\n+            #     end = time.time()\n+\n+    return w, b\n+\n+\n+def evaluate_linear_svm(features, labels, w, b):\n+    \"\"\"Compute accuracy on a test set\"\"\"\n+    predictions = w.matmul(features).add(b).sign()\n+    correct = predictions.mul(labels)\n+    accuracy = correct.add(1).div(2).mean().get_plain_text()\n+    if crypten.communicator.get().get_rank() == 0:\n+        # print(\"Test accuracy %.2f%%\" % (accuracy.item() * 100))\n+        accuracy_str = \"%.2f%%\" % (accuracy * 100)\n+        filename = \"Accuracy.txt\"\n+        with open(filename, 'w') as f:\n+            f.write(accuracy_str)\n+\n+\n+def load_dataset(dataset):\n+    dataset_path = os.path.join(DATASET_DIR, dataset)\n+\n+    # 尝试打开并读取CSV文件\n+    try:\n+        with open(dataset_path, 'r', encoding='utf-8') as csvfile:\n+            spamreader = csv.reader(csvfile)\n+            data = np.array(list(spamreader))\n+    except FileNotFoundError:\n+        print(f\"Error: The file {dataset_path} was not found.\")\n+        return None, None\n+    except Exception as e:\n+        print(f\"Error: An error occurred while reading the file: {e}\")\n+        return None, None\n+\n+    # 检查数据是否为空\n+    if data.size == 0:\n+        print(\"Error: The dataset is empty.\")\n+        return None, None\n+\n+    feature = data[:, :-1].astype(np.float64)\n+    labels = data[:, -1]\n+\n+    # 创建标签映射\n+    unique_labels = np.unique(labels)\n+    label_to_int = {label: idx for idx, label in enumerate(unique_labels)}\n+    int_labels = np.array([label_to_int[label] for label in labels], dtype=np.uint8)\n+    labell = int_labels.reshape(-1,1)\n+\n+    # print(\"======feature_size=====\", feature.shape)\n+    # print(\"======label_size=====\", labell.shape)\n+    return feature, labell\n+\n+\n+\n+def run_mpc_linear_svm(\n+    epochs=100, lr=0.5\n+):\n+    crypten.init()\n+\n+    # Set random seed for reproducibility\n+    torch.manual_seed(1)\n+\n+    data_train = DataSet.leukemia_selected_60\n+    \n+    x, y = load_dataset(data_train.dataset_name)\n+\n+# NOTE：crypten.cryptensor \n+    # Encrypt features / labels\n+    x = crypten.cryptensor(x)\n+    y = crypten.cryptensor(y)\n+\n+    logging.info(\"==================\")\n+    logging.info(\"CrypTen Training\")\n+    logging.info(\"==================\")\n+# NOTE：训练无差异\n+    begin_time = time.time()\n+    w, b = train_linear_svm(x, y, epochs=epochs, lr=lr, print_time=True)\n+    end_time = time.time()\n+    \n+    time_all = end_time - begin_time\n+    print(\"time:\", time_all)\n+    # if not skip_plaintext:\n+    #     logging.info(\"PyTorch Weights  :\")\n+    #     logging.info(w_torch)\n+    # logging.info(\"CrypTen Weights:\")\n+# NOTE：get_plain_text()\n+    # logging.info(w.get_plain_text())\n+\n+    # if not skip_plaintext:\n+    #     logging.info(\"PyTorch Bias  :\")\n+    #     logging.info(b_torch)\n+    # logging.info(\"CrypTen Bias:\")\n+    # logging.info(b.get_plain_text())\n"
                },
                {
                    "date": 1719236048076,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -22,196 +22,17 @@\n     sonar_selected_50 = DataSetParam('sonar_selected_50.csv')\n     sonar_selected_48 = DataSetParam('sonar_selected_48.csv')\n     sonar_selected_45 = DataSetParam('sonar_selected_45.csv')\n     sonar_selected_40 = DataSetParam('sonar_selected_40.csv')\n+    \n     leukemia = DataSetParam(\"leukemia.csv\")\n     leukemia_selected_half = DataSetParam(\"leukemia_selected_half.csv\")\n     leukemia_selected_60 = DataSetParam(\"leukemia_selected_60%.csv\")   \n     leukemia_selected_70 = DataSetParam(\"leukemia_selected_70%.csv\")\n     leukemia_selected_80 = DataSetParam(\"leukemia_selected_80%.csv\")\n     leukemia_selected_90 = DataSetParam(\"leukemia_selected_90%.csv\")\n-        leukemia = DataSetParam(\"leukemia.csv\")\n-    leukemia_selected_half = DataSetParam(\"leukemia_selected_half.csv\")\n-    leukemia_selected_60 = DataSetParam(\"leukemia_selected_60%.csv\")   \n-    leukemia_selected_70 = DataSetParam(\"leukemia_selected_70%.csv\")\n-    leukemia_selected_80 = DataSetParam(\"leukemia_selected_80%.csv\")\n-    leukemia_selected_90 = DataSetParam(\"leukemia_selected_90%.csv\")\n     \n-\n-\n-\n-\n-def train_linear_svm(features, labels, epochs, lr, print_time=False):\n-    # Initialize random weights\n-    w = features.new(torch.randn(features.size(1),1))\n-    b = features.new(torch.randn(1))\n-    # print(\"==========w========\", w.shape)\n-    # print(\"==========b========\", b.shape)\n-    # print(\"=======features=====\", features.shape)\n-\n-    # if print_time:\n-    #     pt_time = AverageMeter()\n-    #     end = time.time()\n-    \n-    filename = \"Accuracy.txt\"\n-    with open(filename, 'a') as f:\n-        for epoch in range(epochs):\n-            # Forward\n-            label_predictions = features.matmul(w).add(b).sign()\n-            # label_predictions = w.matmul(features.T).add(b).sign()\n-            # print(\"=======labels======\", labels.shape)\n-            # print(\"=======label_predictions======\", label_predictions.shape)\n-            # Compute accuracy\n-            correct = label_predictions.mul(labels.view(-1,1))\n-            # print(\"=======correct======\", correct.shape)\n-            accuracy = correct.add(1).div(2).mean()\n-            if crypten.is_encrypted_tensor(accuracy):\n-                accuracy = accuracy.get_plain_text()\n-\n-            # Print Accuracy once\n-            if crypten.communicator.get().get_rank() == 0:\n-                # print(\n-                #     f\"Epoch {epoch} --- Training Accuracy %.2f%%\" % (accuracy.item() * 100)\n-                # )\n-                accuracy_str = \"%.2f%%\" % (accuracy * 100)\n-                accuracy_str_without_percent = accuracy_str.replace('%', '')\n-                f.write(accuracy_str_without_percent + \",\")\n-\n-            # Backward\n-            loss_grad = -labels * (1 - correct) * 0.5  # Hinge loss\n-            # print(\"=======loss_grad======\\n\", loss_grad.get_plain_text())\n-            b_grad = loss_grad.mean()\n-            # print(\"=======b_grad ======\", b_grad.shape)\n-            w_grad = features.t().matmul(loss_grad).div(loss_grad.size(0))\n-            # print(\"=======w_grad ======\", w_grad.shape)\n-            \n-\n-            # Update\n-            w -= w_grad * lr\n-            b -= b_grad * lr\n-\n-            # if print_time:\n-            #     iter_time = time.time() - end\n-            #     pt_time.add(iter_time)\n-            #     print(\"Time %.6f (%.6f)\" % (iter_time, pt_time.value()))\n-            #     end = time.time()\n-\n-    return w, b\n-\n-\n-def evaluate_linear_svm(features, labels, w, b):\n-    \"\"\"Compute accuracy on a test set\"\"\"\n-    predictions = w.matmul(features).add(b).sign()\n-    correct = predictions.mul(labels)\n-    accuracy = correct.add(1).div(2).mean().get_plain_text()\n-    if crypten.communicator.get().get_rank() == 0:\n-        # print(\"Test accuracy %.2f%%\" % (accuracy.item() * 100))\n-        accuracy_str = \"%.2f%%\" % (accuracy * 100)\n-        filename = \"Accuracy.txt\"\n-        with open(filename, 'w') as f:\n-            f.write(accuracy_str)\n-\n-\n-def load_dataset(dataset):\n-    dataset_path = os.path.join(DATASET_DIR, dataset)\n-\n-    # 尝试打开并读取CSV文件\n-    try:\n-        with open(dataset_path, 'r', encoding='utf-8') as csvfile:\n-            spamreader = csv.reader(csvfile)\n-            data = np.array(list(spamreader))\n-    except FileNotFoundError:\n-        print(f\"Error: The file {dataset_path} was not found.\")\n-        return None, None\n-    except Exception as e:\n-        print(f\"Error: An error occurred while reading the file: {e}\")\n-        return None, None\n-\n-    # 检查数据是否为空\n-    if data.size == 0:\n-        print(\"Error: The dataset is empty.\")\n-        return None, None\n-\n-    feature = data[:, :-1].astype(np.float64)\n-    labels = data[:, -1]\n-\n-    # 创建标签映射\n-    unique_labels = np.unique(labels)\n-    label_to_int = {label: idx for idx, label in enumerate(unique_labels)}\n-    int_labels = np.array([label_to_int[label] for label in labels], dtype=np.uint8)\n-    labell = int_labels.reshape(-1,1)\n-\n-    # print(\"======feature_size=====\", feature.shape)\n-    # print(\"======label_size=====\", labell.shape)\n-    return feature, labell\n-\n-\n-\n-def run_mpc_linear_svm(\n-    epochs=100, lr=0.5\n-):\n-    crypten.init()\n-\n-    # Set random seed for reproducibility\n-    torch.manual_seed(1)\n-\n-    data_train = DataSet.leukemia_selected_60\n-    \n-    x, y = load_dataset(data_train.dataset_name)\n-\n-# NOTE：crypten.cryptensor \n-    # Encrypt features / labels\n-    x = crypten.cryptensor(x)\n-    y = crypten.cryptensor(y)\n-\n-    logging.info(\"==================\")\n-    logging.info(\"CrypTen Training\")\n-    logging.info(\"==================\")\n-# NOTE：训练无差异\n-    begin_time = time.time()\n-    w, b = train_linear_svm(x, y, epochs=epochs, lr=lr, print_time=True)\n-    end_time = time.time()\n-    \n-    time_all = end_time - begin_time\n-    print(\"time:\", time_all)\n-    # if not skip_plaintext:\n-    #     logging.info(\"PyTorch Weights  :\")\n-    #     logging.info(w_torch)\n-    # logging.info(\"CrypTen Weights:\")\n-# NOTE：get_plain_text()\n-    # logging.info(w.get_plain_text())\n-\n-    # if not skip_plaintext:\n-    #     logging.info(\"PyTorch Bias  :\")\n-    #     logging.info(b_torch)\n-    # logging.info(\"CrypTen Bias:\")\n-    # logging.info(b.get_plain_text())\n-\n-import logging\n-import time\n-import csv\n-import os\n-import crypten\n-import torch\n-import numpy as np\n-from examples.meters import AverageMeter\n-\n-\n-DATASET_DIR = os.path.join(os.path.dirname(__file__), '../dataset')\n-\n-class DataSetParam:\n-    def __init__(self, dataset_name):\n-        self.dataset_name = dataset_name\n-\n-\n-class DataSet:\n-    sonar = DataSetParam('sonar.csv')\n-    sonar_selected_55 = DataSetParam('sonar_selected_55.csv')\n-    sonar_selected_50 = DataSetParam('sonar_selected_50.csv')\n-    sonar_selected_48 = DataSetParam('sonar_selected_48.csv')\n-    sonar_selected_45 = DataSetParam('sonar_selected_45.csv')\n-    sonar_selected_40 = DataSetParam('sonar_selected_40.csv')\n-    leukemia = DataSetParam(\"leukemia.csv\")\n+    colon = DataSetParam(\"leukemia.csv\")\n     leukemia_selected_half = DataSetParam(\"leukemia_selected_half.csv\")\n     leukemia_selected_60 = DataSetParam(\"leukemia_selected_60%.csv\")   \n     leukemia_selected_70 = DataSetParam(\"leukemia_selected_70%.csv\")\n     leukemia_selected_80 = DataSetParam(\"leukemia_selected_80%.csv\")\n"
                },
                {
                    "date": 1719236056157,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -31,10 +31,10 @@\n     leukemia_selected_80 = DataSetParam(\"leukemia_selected_80%.csv\")\n     leukemia_selected_90 = DataSetParam(\"leukemia_selected_90%.csv\")\n     \n     colon = DataSetParam(\"leukemia.csv\")\n-    leukemia_selected_half = DataSetParam(\"leukemia_selected_half.csv\")\n-    leukemia_selected_60 = DataSetParam(\"leukemia_selected_60%.csv\")   \n+    colon_selected_half = DataSetParam(\"leukemia_selected_half.csv\")\n+    colon_selected_60 = DataSetParam(\"leukemia_selected_60%.csv\")   \n     leukemia_selected_70 = DataSetParam(\"leukemia_selected_70%.csv\")\n     leukemia_selected_80 = DataSetParam(\"leukemia_selected_80%.csv\")\n     leukemia_selected_90 = DataSetParam(\"leukemia_selected_90%.csv\")\n     \n"
                },
                {
                    "date": 1719236061626,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -33,11 +33,11 @@\n     \n     colon = DataSetParam(\"leukemia.csv\")\n     colon_selected_half = DataSetParam(\"leukemia_selected_half.csv\")\n     colon_selected_60 = DataSetParam(\"leukemia_selected_60%.csv\")   \n-    leukemia_selected_70 = DataSetParam(\"leukemia_selected_70%.csv\")\n-    leukemia_selected_80 = DataSetParam(\"leukemia_selected_80%.csv\")\n-    leukemia_selected_90 = DataSetParam(\"leukemia_selected_90%.csv\")\n+    colon_selected_70 = DataSetParam(\"leukemia_selected_70%.csv\")\n+    colon_selected_80 = DataSetParam(\"leukemia_selected_80%.csv\")\n+    colon_selected_90 = DataSetParam(\"leukemia_selected_90%.csv\")\n     \n \n \n \n"
                },
                {
                    "date": 1719236067484,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -30,10 +30,10 @@\n     leukemia_selected_70 = DataSetParam(\"leukemia_selected_70%.csv\")\n     leukemia_selected_80 = DataSetParam(\"leukemia_selected_80%.csv\")\n     leukemia_selected_90 = DataSetParam(\"leukemia_selected_90%.csv\")\n     \n-    colon = DataSetParam(\"leukemia.csv\")\n-    colon_selected_half = DataSetParam(\"leukemia_selected_half.csv\")\n+    colon = DataSetParam(\"colon.csv\")\n+    colon_selected_half = DataSetParam(\"colon_selected_half.csv\")\n     colon_selected_60 = DataSetParam(\"leukemia_selected_60%.csv\")   \n     colon_selected_70 = DataSetParam(\"leukemia_selected_70%.csv\")\n     colon_selected_80 = DataSetParam(\"leukemia_selected_80%.csv\")\n     colon_selected_90 = DataSetParam(\"leukemia_selected_90%.csv\")\n"
                },
                {
                    "date": 1719236072599,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -32,11 +32,11 @@\n     leukemia_selected_90 = DataSetParam(\"leukemia_selected_90%.csv\")\n     \n     colon = DataSetParam(\"colon.csv\")\n     colon_selected_half = DataSetParam(\"colon_selected_half.csv\")\n-    colon_selected_60 = DataSetParam(\"leukemia_selected_60%.csv\")   \n-    colon_selected_70 = DataSetParam(\"leukemia_selected_70%.csv\")\n-    colon_selected_80 = DataSetParam(\"leukemia_selected_80%.csv\")\n+    colon_selected_60 = DataSetParam(\"colon_selected_60%.csv\")   \n+    colon_selected_70 = DataSetParam(\"colon_selected_70%.csv\")\n+    colon_selected_80 = DataSetParam(\"colon_selected_80%.csv\")\n     colon_selected_90 = DataSetParam(\"leukemia_selected_90%.csv\")\n     \n \n \n"
                },
                {
                    "date": 1719236099780,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -35,9 +35,9 @@\n     colon_selected_half = DataSetParam(\"colon_selected_half.csv\")\n     colon_selected_60 = DataSetParam(\"colon_selected_60%.csv\")   \n     colon_selected_70 = DataSetParam(\"colon_selected_70%.csv\")\n     colon_selected_80 = DataSetParam(\"colon_selected_80%.csv\")\n-    colon_selected_90 = DataSetParam(\"leukemia_selected_90%.csv\")\n+    colon_selected_90 = DataSetParam(\"colon_selected_90%.csv\")\n     \n \n \n \n@@ -155,9 +155,9 @@\n \n     # Set random seed for reproducibility\n     torch.manual_seed(1)\n \n-    data_train = DataSet.leukemia_selected_60\n+    data_train = DataSet.colon\n     \n     x, y = load_dataset(data_train.dataset_name)\n \n # NOTE：crypten.cryptensor \n"
                },
                {
                    "date": 1719236146276,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -155,9 +155,9 @@\n \n     # Set random seed for reproducibility\n     torch.manual_seed(1)\n \n-    data_train = DataSet.colon\n+    data_train = DataSet.colon_\n     \n     x, y = load_dataset(data_train.dataset_name)\n \n # NOTE：crypten.cryptensor \n"
                }
            ],
            "date": 1719214452987,
            "name": "Commit-0",
            "content": "\nimport logging\nimport time\nimport csv\nimport os\nimport crypten\nimport torch\nimport numpy as np\nfrom examples.meters import AverageMeter\n\n\nDATASET_DIR = os.path.join(os.path.dirname(__file__), '../dataset')\n\nclass DataSetParam:\n    def __init__(self, dataset_name):\n        self.dataset_name = dataset_name\n\n\nclass DataSet:\n    sonar = DataSetParam('sonar.csv')\n    sonar_selected = DataSetParam('sonar_selected.csv')\n\n\n\n\ndef train_linear_svm(features, labels, epochs, lr, print_time=False):\n    # Initialize random weights\n    w = features.new(torch.randn(features.size(1),1))\n    b = features.new(torch.randn(1))\n    # print(\"==========w========\", w.shape)\n    # print(\"==========b========\", b.shape)\n    # print(\"=======features=====\", features.shape)\n\n    if print_time:\n        pt_time = AverageMeter()\n        end = time.time()\n    \n    filename = \"Accuracy.txt\"\n    with open(filename, 'a') as f:\n        for epoch in range(epochs):\n            # Forward\n            label_predictions = features.matmul(w).add(b).sign()\n            # label_predictions = w.matmul(features.T).add(b).sign()\n            # print(\"=======labels======\", labels.shape)\n            # print(\"=======label_predictions======\", label_predictions.shape)\n            # Compute accuracy\n            correct = label_predictions.mul(labels.view(-1,1))\n            # print(\"=======correct======\", correct.shape)\n            accuracy = correct.add(1).div(2).mean()\n            if crypten.is_encrypted_tensor(accuracy):\n                accuracy = accuracy.get_plain_text()\n\n            # Print Accuracy once\n            if crypten.communicator.get().get_rank() == 0:\n                # print(\n                #     f\"Epoch {epoch} --- Training Accuracy %.2f%%\" % (accuracy.item() * 100)\n                # )\n                accuracy_str = \"%.2f%%\" % (accuracy * 100)\n                accuracy_str_without_percent = accuracy_str.replace('%', '')\n                f.write(accuracy_str_without_percent + \",\")\n\n            # Backward\n            loss_grad = -labels * (1 - correct) * 0.5  # Hinge loss\n            # print(\"=======loss_grad======\\n\", loss_grad.get_plain_text())\n            b_grad = loss_grad.mean()\n            # print(\"=======b_grad ======\", b_grad.shape)\n            w_grad = features.t().matmul(loss_grad).div(loss_grad.size(0))\n            # print(\"=======w_grad ======\", w_grad.shape)\n            \n\n            # Update\n            w -= w_grad * lr\n            b -= b_grad * lr\n\n            if print_time:\n                iter_time = time.time() - end\n                pt_time.add(iter_time)\n                print(\"Time %.6f (%.6f)\" % (iter_time, pt_time.value()))\n                end = time.time()\n\n    return w, b\n\n\ndef evaluate_linear_svm(features, labels, w, b):\n    \"\"\"Compute accuracy on a test set\"\"\"\n    predictions = w.matmul(features).add(b).sign()\n    correct = predictions.mul(labels)\n    accuracy = correct.add(1).div(2).mean().get_plain_text()\n    if crypten.communicator.get().get_rank() == 0:\n        # print(\"Test accuracy %.2f%%\" % (accuracy.item() * 100))\n        accuracy_str = \"%.2f%%\" % (accuracy * 100)\n        filename = \"Accuracy.txt\"\n        with open(filename, 'w') as f:\n            f.write(accuracy_str)\n\n\ndef load_dataset(dataset):\n    dataset_path = os.path.join(DATASET_DIR, dataset)\n\n    # 尝试打开并读取CSV文件\n    try:\n        with open(dataset_path, 'r', encoding='utf-8') as csvfile:\n            spamreader = csv.reader(csvfile)\n            data = np.array(list(spamreader))\n    except FileNotFoundError:\n        print(f\"Error: The file {dataset_path} was not found.\")\n        return None, None\n    except Exception as e:\n        print(f\"Error: An error occurred while reading the file: {e}\")\n        return None, None\n\n    # 检查数据是否为空\n    if data.size == 0:\n        print(\"Error: The dataset is empty.\")\n        return None, None\n\n    feature = data[:, :-1].astype(np.float64)\n    labels = data[:, -1]\n\n    # 创建标签映射\n    unique_labels = np.unique(labels)\n    label_to_int = {label: idx for idx, label in enumerate(unique_labels)}\n    int_labels = np.array([label_to_int[label] for label in labels], dtype=np.uint8)\n    labell = int_labels.reshape(-1,1)\n\n    # print(\"======feature_size=====\", feature.shape)\n    # print(\"======label_size=====\", labell.shape)\n    return feature, labell\n\n\n\ndef run_mpc_linear_svm(\n    epochs=100, lr=0.5\n):\n    crypten.init()\n\n    # Set random seed for reproducibility\n    torch.manual_seed(1)\n\n    data_train = DataSet.sona\n    \n    x, y = load_dataset(data_train.dataset_name)\n\n# NOTE：crypten.cryptensor \n    # Encrypt features / labels\n    x = crypten.cryptensor(x)\n    y = crypten.cryptensor(y)\n\n    logging.info(\"==================\")\n    logging.info(\"CrypTen Training\")\n    logging.info(\"==================\")\n# NOTE：训练无差异\n    w, b = train_linear_svm(x, y, epochs=epochs, lr=lr, print_time=True)\n\n    # if not skip_plaintext:\n    #     logging.info(\"PyTorch Weights  :\")\n    #     logging.info(w_torch)\n    # logging.info(\"CrypTen Weights:\")\n# NOTE：get_plain_text()\n    # logging.info(w.get_plain_text())\n\n    # if not skip_plaintext:\n    #     logging.info(\"PyTorch Bias  :\")\n    #     logging.info(b_torch)\n    # logging.info(\"CrypTen Bias:\")\n    # logging.info(b.get_plain_text())\n"
        }
    ]
}