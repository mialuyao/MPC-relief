{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "with open(r'data/mnist_test.csv', 'r', encoding='utf-8') as csvfile:\n",
    "    spamreader = csv.reader(csvfile)\n",
    "    liver = np.array(list(spamreader))\n",
    "    \n",
    "\n",
    "data = (liver[1:, 1:]).astype(np.float64)\n",
    "labels = (liver[1:, 0]).astype(np.int8)\n",
    "\n",
    "print(data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "with open(r'data/sonar.csv', 'r', encoding='utf-8') as csvfile:\n",
    "    spamreader = csv.reader(csvfile)\n",
    "    liver = np.array(list(spamreader))\n",
    "    \n",
    "raw_data= liver[:, :-1]\n",
    "raw_labels = liver[:, -1]\n",
    "\n",
    "# 创建标签映射\n",
    "unique_labels = np.unique(raw_labels)\n",
    "label_to_int = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "int_labels = np.array([label_to_int[label] for label in raw_labels], dtype=np.uint8)\n",
    "\n",
    "print(\"raw_data:\", raw_data)\n",
    "# print(\"Raw labels:\", raw_labels)\n",
    "print(\"Integer labels:\", int_labels)\n",
    "# print(\"Label mapping:\", label_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import csv\n",
    "\n",
    "# 打开原始CSV文件，读取数据并修改\n",
    "with open('Relief_plain/data/colon.csv', 'r+', newline='', encoding='utf-8') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    writer = csv.writer(csvfile, delimiter=',')\n",
    "    \n",
    "    # 读取每一行数据，删除第一个特征，并写回文件\n",
    "    rows = [row for row in reader]\n",
    "    csvfile.seek(0)  # 移动光标到文件开头\n",
    "    \n",
    "    for row in rows:\n",
    "        if row:  # 确保行不为空\n",
    "            new_row = row[1:]  # 删除第一个特征\n",
    "            writer.writerow(new_row)\n",
    "    \n",
    "    csvfile.truncate()  # 截断文件至当前位置，确保删除可能残留的旧数据\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import crypten\n",
    "import torch\n",
    "import crypten.mpc as mpc\n",
    "import crypten.communicator as comm \n",
    "from crypten.common.functions.logic import sign\n",
    "import time\n",
    "\n",
    "crypten.init()\n",
    "\n",
    "@mpc.run_multiprocess(world_size=2)\n",
    "def examine_arithmetic_shares():\n",
    "    x_enc = crypten.cryptensor([10], ptype=crypten.mpc.arithmetic)\n",
    "    \n",
    "    rank = comm.get().get_rank()\n",
    "    crypten.print(f\"\\nRank {rank}:\\n {x_enc}\\n\", in_order=True)\n",
    "\n",
    "    x_abs = sign(x_enc)\n",
    "    print(\"x_abs\", x_abs.get_plain_text())\n",
    "        \n",
    "x = examine_arithmetic_shares()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import crypten\n",
    "import torch\n",
    "import crypten.mpc as mpc\n",
    "import crypten.mpc.primitives.beaver as beaver\n",
    "import crypten.communicator as comm \n",
    "import torch\n",
    "from crypten.mpc import MPCTensor\n",
    "from crypten.mpc.primitives import BinarySharedTensor\n",
    "import time\n",
    "\n",
    "crypten.init()\n",
    "\n",
    "def generate_boolean_tensor(N):\n",
    "    # 生成一个长度为N的随机布尔tensor\n",
    "    random_tensor = torch.randint(0, 2, (N,))\n",
    "    return random_tensor\n",
    "\n",
    "def check_data_type(tensor):\n",
    "    print(f\"Type: {type(tensor)}\")\n",
    "    if isinstance(tensor, torch.Tensor):\n",
    "        print(f\"PyTorch Tensor dtype: {tensor.dtype}\")\n",
    "    elif isinstance(tensor, crypten.mpc.MPCTensor):\n",
    "        print(\"This is a MPCTensor.\")\n",
    "    elif isinstance(tensor, crypten.mpc.primitives.binary.BinarySharedTensor):\n",
    "        print(\"This is a BinarySharedTensor.\")\n",
    "    else:\n",
    "        print(\"Unknown data type.\")\n",
    "\n",
    "N = 10\n",
    "x = generate_boolean_tensor(N)\n",
    "y = generate_boolean_tensor(N)\n",
    "x_enc = crypten.cryptensor(x, ptype=crypten.mpc.binary)\n",
    "y_enc = crypten.cryptensor(y, ptype=crypten.mpc.binary)\n",
    "x_enc_share = x_enc.share\n",
    "y_enc_share = y_enc.share\n",
    "x_enc_binary = BinarySharedTensor(x_enc_share)\n",
    "y_enc_binary = BinarySharedTensor(y_enc_share)\n",
    "check_data_type(x_enc)\n",
    "check_data_type(y_enc)\n",
    "check_data_type(x_enc_binary)\n",
    "check_data_type(y_enc_binary)\n",
    "\n",
    "begin_time = time.time()\n",
    "z_enc = x_enc_binary & y_enc_binary\n",
    "end_time = time.time()\n",
    "\n",
    "time = end_time - begin_time\n",
    "    \n",
    "# print(\"x_enc_type\")\n",
    "print(\"time:\", time)\n",
    "print(\"z_enc\", z_enc)\n",
    "print(\"z\", z_enc.get_plain_text())\n",
    "\n",
    "# examine_arithmetic_shares(x,y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rank 0:\n",
      " result_binary: tensor([0, 0, 0])\n",
      "\n",
      "\n",
      "Rank 1:\n",
      " result_binary: tensor([0, 0, 0])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import crypten\n",
    "import crypten.mpc\n",
    "import torch\n",
    "import crypten.mpc as mpc\n",
    "import crypten.communicator as comm \n",
    "import crypten.common as common\n",
    "import random\n",
    "from crypten.mpc import MPCTensor\n",
    "from crypten.mpc.primitives import BinarySharedTensor, ArithmeticSharedTensor\n",
    "import crypten.mpc.primitives.beaver as beaver\n",
    "from crypten.mpc.primitives.converters import convert\n",
    "from crypten.mpc.ptype import ptype as Ptype\n",
    "\n",
    "crypten.init()\n",
    "\n",
    "def check_data_type(tensor):\n",
    "    print(f\"Type: {type(tensor)}\")\n",
    "    if isinstance(tensor, torch.Tensor):\n",
    "        print(f\"PyTorch Tensor dtype: {tensor.dtype}\")\n",
    "    elif isinstance(tensor, crypten.mpc.MPCTensor):\n",
    "        print(\"This is a MPCTensor.\")\n",
    "    elif isinstance(tensor, crypten.mpc.primitives.binary.BinarySharedTensor):\n",
    "        print(\"This is a BinarySharedTensor.\")\n",
    "    else:\n",
    "        print(\"Unknown data type.\")\n",
    "\n",
    "def secret_sharing(x,a,b):\n",
    "    x_enc = crypten.cryptensor(x, ptype = crypten.mpc.arithmetic)\n",
    "    a_enc = crypten.cryptensor(a, ptype = crypten.mpc.arithmetic)\n",
    "    b_enc = crypten.cryptensor(b, ptype = crypten.mpc.arithmetic)\n",
    "    \n",
    "    return x_enc, a_enc, b_enc\n",
    "\n",
    "\n",
    "@mpc.run_multiprocess(world_size=2) \n",
    "def intvlTest(x, a, b):\n",
    "    x_enc, a_enc, b_enc = secret_sharing(x, a, b)\n",
    "    cmp_a_x = x_enc.ge(a_enc)\n",
    "    cmp_x_b = b_enc.ge(x_enc)\n",
    "    cmp_a_x_binary = cmp_a_x.to(crypten.mpc.binary)\n",
    "    cmp_a_x_binary_share = cmp_a_x_binary.share\n",
    "    cmp_a_x_binary_tensor = cmp_a_x_binary._tensor\n",
    "    # cmp_a_x_binarytensor = BinarySharedTensor(cmp_a_x_binary_share)\n",
    "    \n",
    "    cmp_x_b_binary = cmp_x_b.to(crypten.mpc.binary)\n",
    "    # cmp_x_b_binary_share = cmp_x_b_binary.share\n",
    "    # cmp_x_b_binarytensor = BinarySharedTensor(cmp_x_b_binary_share)\n",
    "    \n",
    "    result_binary = cmp_a_x_binary._tensor & cmp_x_b_binary._tensor\n",
    "    \n",
    "    rank = comm.get().get_rank()\n",
    "    # crypten.print(f\"\\nRank {rank}:\\n before: {type(cmp_a_x_binary)}\\n \", in_order=True)\n",
    "    # crypten.print(f\"\\nRank {rank}:\\n before: {type(cmp_a_x_binary_share)}\\n \", in_order=True)\n",
    "    # crypten.print(f\"\\nRank {rank}:\\n before: {type(cmp_a_x_binary_tensor)}\\n \", in_order=True)\n",
    "    \n",
    "    # crypten.print(f\"\\nRank {rank}:\\n before: {cmp_a_x.get_plain_text()}\\n after:  {cmp_a_x_binary.get_plain_text()}\", in_order=True)\n",
    "    # crypten.print(f\"\\nRank {rank}:\\n before: {cmp_a_x_binarytensor.get_plain_text()}\\n\", in_order=True)\n",
    "    crypten.print(f\"\\nRank {rank}:\\n result_binary: {result_binary.get_plain_text()}\\n\", in_order=True)\n",
    "\n",
    "@mpc.run_multiprocess(world_size=2) \n",
    "def test(a,b):\n",
    "    a_share = BinarySharedTensor(a)\n",
    "    b_share = BinarySharedTensor(b)\n",
    "    c_share = a_share & b_share\n",
    "    rank = comm.get().get_rank()\n",
    "    crypten.print(f\"\\nRank {rank}:\\n result: {type(b)}\\n\", in_order=True)\n",
    "    # crypten.print(f\"\\nRank {rank}:\\n result type: {type(c_share)}\\n\", in_order=True)\n",
    "    # crypten.print(f\"\\nRank {rank}:\\n result: {c_share.get_plain_text()}\\n\", in_order=True)\n",
    "\n",
    "def main():\n",
    "    # 区间范围\n",
    "    a = [0,1,0]\n",
    "    b = [1,0,1]\n",
    "    \n",
    "    #随机数范围\n",
    "    x = random.randint(-10, 10) \n",
    "    # print(\"x\", x)\n",
    "    intvlTest(x, a, b)\n",
    "    # test(a,b)\n",
    "    \n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数组 a: [-1  1 -1 -1  1  1 -1 -1  1  1]\n",
      "数组 b: [20 25  6 23 28 21 39 11  3 20]\n",
      "数组 b1 (a中对应值为1): [25 28 21  3 20] 对应索引: [1 4 5 8 9] 最小值: 3\n",
      "数组 b2 (a中对应值为-1): [20  6 23 39 11] 对应索引: [0 2 3 6 7] 最小值: 6\n",
      "数组 b': [19 14 33 16 11 18  0 28 36 19]\n",
      "数组 c: [-19  14 -33 -16  11  18   0 -28  36  19]\n",
      "c中的最大值索引(near-hit): 8\n",
      "c中的最小值索引(near-miss): 2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def generate_arrays(N, M):\n",
    "    a = np.random.choice([-1, 1], size=N)\n",
    "    b = np.random.randint(0, M+1, size=N)\n",
    "    \n",
    "    return a, b\n",
    "\n",
    "def process_arrays(a, b):\n",
    "    max_b = np.max(b)\n",
    "    b_prime = max_b - b\n",
    "    c = a * b_prime\n",
    "    max_index = np.argmax(c)\n",
    "    min_index = np.argmin(c)\n",
    "    \n",
    "    return c, max_index, min_index\n",
    "\n",
    "def split_b_based_on_a(a, b):\n",
    "    b1 = b[a == 1]\n",
    "    b1_indices = np.where(a == 1)[0]\n",
    "    b2 = b[a == -1]\n",
    "    b2_indices = np.where(a == -1)[0]\n",
    "    \n",
    "    return b1, b1_indices, b2, b2_indices\n",
    "\n",
    "\n",
    "N = 10\n",
    "M = 50\n",
    "\n",
    "a, b = generate_arrays(N, M)\n",
    "\n",
    "c, max_index, min_index = process_arrays(a, b)\n",
    "\n",
    "b1, b1_indices, b2, b2_indices = split_b_based_on_a(a, b)\n",
    "\n",
    "# 打印结果\n",
    "print(\"数组 a:\", a)\n",
    "print(\"数组 b:\", b)\n",
    "print(\"数组 b1 (a中对应值为1):\", b1, \"对应索引:\", b1_indices, \"最小值:\", min(b1))\n",
    "print(\"数组 b2 (a中对应值为-1):\", b2, \"对应索引:\", b2_indices, \"最小值:\", min(b2))\n",
    "print(\"数组 b':\", max(b) - b)\n",
    "print(\"数组 c:\", c)\n",
    "print(\"c中的最大值索引(near-hit):\", max_index)\n",
    "print(\"c中的最小值索引(near-miss):\", min_index)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def generate_binary_dataset(m, n, filename):\n",
    "    # 随机生成二元特征数据 (0 或 1)\n",
    "    data = np.random.randint(2, size=(m, n))\n",
    "    \n",
    "    # 随机生成类别标签 ('N' 或 'Y')\n",
    "    labels = np.random.choice(['N', 'Y'], size=(m,))\n",
    "    \n",
    "    # 将特征数据和标签结合起来\n",
    "    df = pd.DataFrame(data, columns=[f'Feature_{i}' for i in range(n)])\n",
    "    df['Label'] = labels\n",
    "    \n",
    "    # 将数据保存为 CSV 文件\n",
    "    df.to_csv(filename, index=False)\n",
    "\n",
    "# 示例使用\n",
    "m = 100  # 样本数量\n",
    "n = 3   # 特征数量\n",
    "filename = 'binary_dataset.csv'\n",
    "\n",
    "generate_binary_dataset(m, n, filename)\n",
    "print(f\"Dataset saved to {filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import crypten\n",
    "import torch\n",
    "import random\n",
    "\n",
    "crypten.init()\n",
    "\n",
    "feature = torch.tensor([[1, 0, 1, 0],\n",
    "                        [0, 1, 0, 1],\n",
    "                        [1, 1, 0, 0],\n",
    "                        [0, 0, 1, 1]], dtype=torch.float32)\n",
    "\n",
    "label = torch.tensor([0, 1, 1, 0], dtype=torch.float32)\n",
    "\n",
    "y_share = crypten.cryptensor(feature, ptype=crypten.mpc.binary)\n",
    "x_share = crypten.cryptensor(label, ptype=crypten.mpc.binary)\n",
    "\n",
    "random_index = random.randint(0, feature.shape[0] - 1)\n",
    "\n",
    "selected_sample_share = y_share[random_index]\n",
    "\n",
    "selected_sample_plain = selected_sample_share.get_plain_text()\n",
    "\n",
    "print(\"原始特征矩阵:\")\n",
    "print(feature)\n",
    "print(\"随机索引:\", random_index)\n",
    "print(\"原始样本:\", feature[random_index])\n",
    "print(\"解密后的样本:\", selected_sample_plain)\n",
    "\n",
    "if torch.equal(feature[random_index], selected_sample_plain):\n",
    "    print(\"解密后的样本与原始样本一致\")\n",
    "else:\n",
    "    print(\"解密后的样本与原始样本不一致\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "# 定义参数\n",
    "t_eq = 1.0\n",
    "t_diff = 2.0\n",
    "\n",
    "# 定义 sigmoid 函数\n",
    "def sigmoid(x, k, x0):\n",
    "    return 1 / (1 + np.exp(-k * (x - x0)))\n",
    "\n",
    "# 定义近似的分段函数\n",
    "def approx_function(x, k1, k2):\n",
    "    sigma1 = sigmoid(x, k1, t_eq)\n",
    "    sigma2 = sigmoid(x, k2, t_diff)\n",
    "    return sigma1 * (1 - sigma2) + sigma2\n",
    "\n",
    "# 定义原始的分段函数\n",
    "def piecewise_function(x):\n",
    "    if x < t_eq:\n",
    "        return 0\n",
    "    elif x <= t_diff:\n",
    "        return (x - t_eq) / (t_diff - t_eq)\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "# 误差函数（均方误差）\n",
    "def error_function(params, x):\n",
    "    k1, k2 = params\n",
    "    y_approx = approx_function(x, k1, k2)\n",
    "    y_piecewise = np.array([piecewise_function(xi) for xi in x])\n",
    "    return np.mean((y_approx - y_piecewise) ** 2)\n",
    "\n",
    "# 初始猜测值\n",
    "initial_guess = [10, 10]\n",
    "\n",
    "# 优化过程\n",
    "x = np.linspace(0, 3, 400)\n",
    "result = minimize(error_function, initial_guess, args=(x,))\n",
    "k1_opt, k2_opt = result.x\n",
    "\n",
    "# 绘制结果\n",
    "y_approx_opt = approx_function(x, k1_opt, k2_opt)\n",
    "y_piecewise = np.array([piecewise_function(xi) for xi in x])\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(x, y_approx_opt, label=f'Optimized Approximate Function (k1={k1_opt:.2f}, k2={k2_opt:.2f})', linestyle='--')\n",
    "plt.plot(x, y_piecewise, label='Original Piecewise Function')\n",
    "plt.title('Optimization of Sigmoid Approximation to Piecewise Function')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def L_Sigmoid(x, min_value, max_value):\n",
    "    if x < min_value:\n",
    "        return 0\n",
    "    elif x > max_value:\n",
    "        return 1\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "# 定义x的范围\n",
    "x_values = np.linspace(-10, 10, 400)\n",
    "y_values = np.array([L_Sigmoid(x, 2, 8) for x in x_values])\n",
    "\n",
    "# 创建一个掩码来去除分段中的垂直线\n",
    "mask = (x_values >= 2) & (x_values <= 8)\n",
    "x_values_segment = x_values[mask]\n",
    "y_values_segment = y_values[mask]\n",
    "\n",
    "plt.plot(x_values[x_values < 2], y_values[x_values < 2], 'b')\n",
    "plt.plot(x_values_segment, y_values_segment, 'b')\n",
    "plt.plot(x_values[x_values > 8], y_values[x_values > 8], 'b')\n",
    "\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('L_Sigmoid(x)')\n",
    "plt.title('Piecewise Linear Sigmoid Function')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/0m/0tmw2q6n0yx1kz4zh31z69gm0000gn/T/ipykernel_17499/781377217.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mDATASET_DIR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__file__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'dataset/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mDataSetParam\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import csv\n",
    " \n",
    "\n",
    "DATASET_DIR = os.path.join(os.path.dirname(__file__), 'dataset/')\n",
    "\n",
    "class DataSetParam:\n",
    "    def __init__(self, dataset_name):\n",
    "        self.dataset_name = dataset_name\n",
    "\n",
    "class DataSet:\n",
    "    sonar = DataSetParam('sonar.csv')\n",
    "    binary_dataset = DataSetParam(\"binary_dataset.csv\")\n",
    "    \n",
    "def load_dataset(dataset):\n",
    "    dataset_path = os.path.join(DATASET_DIR, dataset)\n",
    "    try:\n",
    "        with open(dataset_path, 'r', encoding='utf-8') as csvfile:\n",
    "            spamreader = csv.reader(csvfile)\n",
    "            data = np.array(list(spamreader))\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file {dataset_path} was not found.\")\n",
    "        return None, None\n",
    "    except Exception as e:\n",
    "        print(f\"Error: An error occurred while reading the file: {e}\")\n",
    "        return None, None\n",
    "\n",
    "    if data.size == 0:\n",
    "        print(\"Error: The dataset is empty.\")\n",
    "        return None, None\n",
    "\n",
    "    feature = data[:, :-1].astype(np.float64)\n",
    "    labels = data[:, -1]\n",
    "    \n",
    "    # 创建标签映射\n",
    "    unique_labels = np.unique(labels)\n",
    "    label_to_int = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "    int_labels = np.array([label_to_int[label] for label in labels], dtype=np.uint8)\n",
    "    \n",
    "    # 将标签转换为独热矩阵\n",
    "    num_classes =  len(unique_labels)\n",
    "    one_hot_labels = np.zeros((int_labels.size, num_classes), dtype=np.uint8)\n",
    "    one_hot_labels[np.arange(int_labels.size), int_labels] = 1\n",
    "\n",
    "    return feature, one_hot_labels\n",
    "\n",
    "data_train = DataSet.binary_dataset \n",
    "feature, label = load_dataset(data_train.dataset_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "relief37",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
